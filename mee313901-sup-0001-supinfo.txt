Year	Author	Title	Data Collected	Neural Network	Task	Publication Name	Volume	Issue	Pages	DOI	Url	Abstract																				
1992	"Ferrán, Edgardo A.; Ferrara, Pascual"	A neural network dynamics that resembles protein evolution	Molecular	DNN	Modeling	Physica A: Statistical Mechanics and its Applications	185	1	395-401	10.1016/0378-4371(92)90480-E	https://www.sciencedirect.com/science/article/pii/037843719290480E	"We use neutral networks to classify proteins according to their sequence similarities. A network composed by 7 _ 7 neurons, was trained with the Kohonen unsupervised learning algorithm using, as inputs, matrix patterns derived from the bipeptide composition of cytochrome c proteins belonging to 76 different species. As a result of the training, the network self-organized the activation of its neurons into topologically ordered maps, wherein phylogenetically related sequences were positioned close to each other. The evolution of the topological map during learning, in a representative computational experiment, roughly resembles the way in which one species evolves into several others. For instance, sequences corresponding to vertebrates, initially grouped together into one neuron, were placed in a contiguous zone of the final neural map, with sequences of fishes, amphibia, reptiles, birds and mammals associated to different neurons. Some apparent wrong classifications are due to the fact that some proteins have a greater degree of sequence identity than the one expected by phylogenetics. In the final neural map, each synaptic vector may be considered as the pattern corresponding to the ancestor of all the proteins that are attached to that neuron. Although it may be also tempting to link real time with learning epochs and to use this relationship to calibrate the molecular evolutionary clock, this is not correct because the evolutionary time schedule obtained with the neural network depends highly on the discrete way in which the winner neighborhood is decreased during learning."																				
1994	"Culverhouse, Pf; Ellis, Re; Simpson, Rg; Williams, R; Pierce, Rw; Turner, Jt"	"Automatic categorisation of five species of Cymatocylis (Protozoa, Tintinnida) by artificial neural network"	Images	DNN	Classification	Marine Ecology Progress Series	107		273-280	10.3354/meps107273	http://www.int-res.com/articles/meps/107/m107p273.pdf	"Photomicrographs of 5 species of Cymatocyl~s were digitised, binarised and edited by hand to remove large debris contaminating the images. An artificial neural network (back-propagation of error) was trained to categorise 201 of these specimens after pre-processing the data by Fourier transformation. Of the 299 trials which were carried out, 28% demonstrated better than 70% correct categorisation of the data used in the training sets. The best performing network learned to differentiate the training data set with an error rate of 11 U/;,. The same network gave an error rate of 18% when presented with previously unseen data. The results of training back-propagation of error networks are presented and the performance and limitations are discussed and compared with more classical morphometric and clustering techniques for the taxonomic separation of marine plankton. This automatic technique demonstrates the potential of neural network pattern classifiers for addressing the difficult taxonomic task of congeneric classification and also has wider implications for the automatic identification of field samples of marine organisms"																				
1994	"Freeman, R.; Goodacre, R.; Sisson, P. R.; Magee, J. G.; Ward, A. C.; Lightfoot, N. F.YR 1994"	Rapid identification of species within the Mycobacterium tuberculosis complex by artificial neural network analysis of pyrolysis mass spectra	Other	DNN	Classification	Journal of Medical Microbiology	40	3	170-173	10.1099/00222615-40-3-170	https://www.microbiologyresearch.org/content/journal/jmm/10.1099/00222615-40-3-170	"An artificial neural network (ANN) was trained to distinguish between Mycobacterium tuberculosis and M. bovis with averaged pyrolysis mass spectra from duplicate subcultures of four strains of each of these species, each pyrolysed in triplicate. Once trained, the ANN was interrogated with spectrum data from the original organisms (the “training set” and from 26 other mycobacterial isolates (the “ challenge set ”) of the M. tuberculosis complex (MTBC). Eight strains of M. bovis and 13 of M. tuberculosis, whether sensitive or variously resistant to antituberculosis drugs, were identified in agreement with conventional identification. Four strains of “M. africanum ” were identified as M. bovis. Of two atypical M. tuberculosis strains from South India, one was identified as M. tuberculosis and the other as M. bovis. Six strains of BCG proved heterogeneous; two gave equivocal identifications, three were identified as M. bovis and one was identified as M. tuberculosis.,"																				
1994	"Kennedy, Max J.; Thakur, M. S."	The use of neural networks to aid in microorganism identification: a case study of Haemophilus species identification	Other	DNN	Classification	Antonie van Leeuwenhoek	63	1	35-38	10.1007/BF00871729	http://link.springer.com/10.1007/BF00871729	Neural networks were evaluated as a tool for identifying microorganisms. Data from a microorganism identification table were used to train a neural network. Based on the results of identification tests the neural network could correctly identify eachHaemophilus species from a group of 13Haemophilus species.																				
1994	"Menczer, Filippo; Parisi, Domenico"	Recombination and unsupervised learning: effects of crossover in the genetic optimization of neural networks	Other	DNN	Modeling	Network: Computation in Neural Systems	3	4	423-442	10.1088/0954-898X_3_4_007	https://doi.org/10.1088/0954-898X_3_4_007	"Genetic algorithms have been successfully used for optimizing complex functions over multidimensional domains, such as the space of the connection weights in a neural network. A feed-forward layered network is used to simulate the life cycle of a synthetic animal that moves in an environment and captures food objects. The adaptation of the animal (i.e. of the network's weight matrix) to the environment can be measured by the amount of reached food objects in a given lifetime. We consider this amount as a fitness function to be optimized by a genetic algorithm over the space of the connection weights. The network can learn the weights that solve the survival task only by means of its genetic evolution. The recombination genetic operator (crossover) can be seen as a model of sexual recombination for the population, while mutation models agamic reproduction. The central problem in trying to apply crossover is the difficult mapping between the genetic code string (genotype) and the network's weight matrix (phenotype). For this reason crossover has been considered unsuitable for this kind of problem in the past. In this paper we propose a simple mapping and compare the effects of sexual versus agamic reproduction in such a problem. The results of several parametric simulations are outlined, showing that crossover actually helps to speed up the genetic learning."																				
1994	"Schneider, G; Wrede, P"	The rational design of amino acid sequences by artificial neural networks and simulated molecular evolution: de novo design of an idealized leader peptidase cleavage site.	Other	DNN	Modeling	Biophysical Journal	66	2 Pt 1	335-344	10.1016/s0006-3495(94)80782-9	https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1275700/	"A method for the rational design of locally encoded amino acid sequence features using artificial neural networks and a technique for simulating molecular evolution has been developed. De novo in machine design of Escherichia coli leader peptidase (SP1) cleavage sites serves as an example application. A modular neural network system that employs sequence descriptions in terms of physicochemical properties has been trained on the recognition of characteristic cleavage site features. It is used for sequence qualification in the design cycle, representing the sequence fitness function. Starting from a random sequence several cleavage site sequences were generated by a simulated molecular evolution technique. It is based on a simple genetic algorithm that takes the quality values calculated by the artificial neural network as a heuristic for inductive sequence optimization. Simulated in vivo mutation and selection allows the identification of predominant sequence positions in Escherichia coli signal peptide cleavage site regions (positions -2 and -6). Various amino acid distance maps are used to define metrics for the step size of mutations. Position-specific mutability values indicate sequence positions exposed to high or low selection pressure in the simulations. The use of several distance maps leads to different courses of optimization and to various idealized sequences. It is concluded that amino acid distances are context dependent. Furthermore, a method for identification of local optima during sequence optimization is presented."																				
1994	"Wu, Cathy; Shivakumar, Sailaja"	Back-propagation and counter-propagation neural networks for phylogenetic classification of ribosomal RNA sequences	Molecular	DNN	Classification	Nucleic Acids Research	22	20	4291-4299	10.1093/nar/22.20.4291	https://academic.oup.com/nar/article-abstract/22/20/4291/2400427	"A neural network system has been developed for rapid and accurate classification of ribosomal RNA sequences according to phylogenetic relationship. The molecular sequences are encoded into neural input vectors using an n-gram hashing method. A SVD (singular value decomposition) method is used to compress and reduce the size of long and sparse ngram input vectors. The neural networks used are three-layered, feed-forward networks that employ supervised learning paradigms, including the backpropagation algorithm and a modified counterpropagation algorithm. A pedagogical pattern selection strategy is used to reduce the training time. After trained with ribosomal RNA sequences of the RDP (Ribosomal Database Project) database, the system can classify query sequences into more than one hundred phylogenetic classes with a 100% accuracy at a rate of less than 0.3 CPU second per sequence on a workstation. When compared to other sequence similarity search methods, including Similarity Rank, Blast and Fasta, the neural network method has a higher classification accuracy at a speed of about an order of magnitude faster. The software tool will be made available to the biology community, and the system may be extended into a gene identification system for classifying indiscriminately sequenced DNA fragments."																				
1995	"Tolstrup, N.; Toftgård, J.; Engelbrecht, J.; Brunak, S."	Neural network model of the genetic code is strongly correlated to the GES scale of amino acid transfer free energies	Other	DNN	Modeling	Journal of Molecular Biology	243	5	816-820	10.1006/jmbi.1994.1683	https://www.sciencedirect.com/science/article/abs/pii/S0022283684716834	"A neural network trained to classify the 61 nucleotide triplets of the genetic code into 20 amino acid categories develops in its internal representation a pattern matching the relative cost of transferring amino acids with satisfied backbone hydrogen bonds from water to an environment of dielectric constant of roughly 2.0. Such environments are typically found in lipid membranes or in the interior of proteins. In learning the mapping between the codons and the categories, the network groups the amino acids according to the scale of transfer free energies developed by Engelman, Goldman and Steitz. Several other scales based on internal preference statistics also agree reasonably well with the network grouping. The network is able to relate the structure of the genetic code to quantifications of amino acid hydrophobicity-hydrophilicity more systematically than the numerous attempts made earlier. Due to its inherent non-linearity, the code is also shown to impose decisive constraints on algorithmic analysis of the protein coding potential of DNA."																				
1995	"Wu, Cathy; Shivakumar, Sailaja; Lin, Hsu-Ping; Veldurti, Srinivas; Bhatikar, Yugesh"	Neural networks for molecular sequence classification	Molecular	DNN	Classification	Mathematics and Computers in Simulation	40	1	23-33	10.1016/0378-4754(95)00016-4	https://www.sciencedirect.com/science/article/pii/0378475495000164	"A neural network classification method has been developed as an alternative approach to the search/organization problem of large molecular databases. Two artificial neural systems have been implemented on a Cray supercomputer for rapid protein/nucleic acid sequence classifications. The neural networks used are three-layered, feed-forward networks that employ back-propagation learning algorithm. The molecular sequences are encoded into neural input vectors by applying an n-gram hashing method or a SVD (singular value decomposition) method. Once trained with known sequences in the molecular databases, the neural system becomes an associative memory capable of classifying unknown sequences based on the class information embedded in its neural interconnections. The protein system, which classifies proteins into PIR (Protein Identification Resource) superfamilies, showed a 82% to a close to 100% sensitivity at a speed that is about an order of magnitude faster than other search methods. The pilot nucleic acid system, which classifies ribosomal RNA sequences according to phylogenetic groups, has achieved a 100% classification accuracy. The system could be used to reduce the database search time and help organize the molecular sequence databases. The tool is generally applicable to any databases that are organized according to family relationships."																				
1996	"Boddy, Lynne; Morris, C. W.; Wilkins, M. F.; Tarran, G. A.; Burkill, P. H."	Neural network analysis of flow cytometric data for 40 marine phytoplankton species	Other	DNN	Classification	Cytometry	15	4	283-293	10.1002/cyto.990150403	https://onlinelibrary.wiley.com/doi/abs/10.1002/cyto.990150403	"Flow cytometry data (time of flight, horizontal and, vertical forward light scatter, 90° light scatter, and “red” and “orange” integral fluorescence) were collected for laboratory cultures of 40 species of marine phytoplankton, from the following taxonomic classes, the Dinophyceae, Bacillariophyceae, Prymnesiophyceae, Cryptophyceae, and other flagellates. Single-hidden-layer “back-propagation” neural networks were trained to discriminate between species by recognising patterns in their flow cytometric signatures, and network performance Was assessed using an independent test data set. Two approaches were adopted employing: (1) a hierarchy of small networks, the first identifying to which major taxonomic group a cell belonged, and then a network for that tax-onomic group identified to species, and (2) a single large network. Discriminating some of the major taxonomic groups was successful but others less so. With networks for specific groups, cryptophyte species were all identified reliably (probability of correct classification always being ≥ 0.75); in the other groups half of the species were identified reliably. With the large network, dinoflagellates, cryptomonads, and flagellates were identified almost as well as by networks specific for these groups. The application of neural computing techniques to identification of such a large number of species represents a significant advance from earlier studies, although further development is required. © 1994 Wiley-Liss, Inc."																				
1996	"Gong, Peng; Pu, Ruiliang; Yu, Bin"	Conifer species recognition: An exploratory analysis of in situ hyperspectral data	Other	DNN	Classification	Remote Sensing of Environment	62	2	189-200	10.1016/S0034-4257(97)00094-1	https://www.sciencedirect.com/science/article/pii/S0034425797000941	In situ hyperspectral data measured above sunlit and shaded sides of canopies using a high spectral resolution radiometer were analyzed for identification of six conifer tree species. An artificial neural network algorithm was assessed for the identification purpose. Linear discrimination analysis was compared with the neural network algorithm. The hyperspectral with the neural data were further processed to smoothed reflectance and first derivative spectra and were separately used in tree species identification. Tree species recognition with data collected front six study sites was tested in seven experiments. The average accuracy of species recognition was obtained at every site. The overall performance of the neural network algorithm was better than that of linear discriminant analysis for species recognition when the same number of training samples and test samples were used. The discriminant analysis produced better accuracy than neural network at one site where many samples (10) were taken from six individual trees. Use of the average spectra of all samples for a particular tree species in training may not result in higher accuracy than use of individual spectral samples in training. Use of sunlit samples alone resulted in an overall accuracy of greater than 91%. The effects of site background including illuminating conditions on tree species specra were large. Neural networks are sensitive to subtle spectral details and can be trained to separate samples front the same species at different sites. Our experiments indicate that the discriminating power of visible bands is stronger than that of near-infrared bands. Higher recognition accuracies can be obtained in the blue to green or the red-edge spectral region as compared with four other spectral regions. A smaller set of selected bands can generate more accurate identification than all spectral bands.																				
1996	"Simmonds, John E.; Armstrong, F.; Copland, Philip J."	Species identification using wideband backscatter with neural network and discriminant analysis	Other	DNN	Classification	ICES Journal of Marine Science	53	2	189-195	10.1006/jmsc.1996.0021	https://doi.org/10.1006/jmsc.1996.0021	"The paper reports the results of species-recognition-rate measurements on caged aggregations of mackerel, horse mackerel, saithe, haddock, and two sizes of cod. Data on the acoustic backscattering coefficients were collected in eight contiguous bandwidth intervals covering the frequency band between 27 and 54 kHz. The measurements were made during two to six periods of 24 h for each aggregation of fish. Replicate experiments were carried out for mackerel, horse mackerel, and two sizes of cod. The data were processed to give average frequency spectra. The number of independent observations used to establish the mean was varied to examine the species-recognition dependence on the number of independent observations. The mean spectra were analysed using two recognition methods: neural network and discriminant analysis. A neural network was trained on subsets of the data and recognition rates established for the different numbers of samples used to calculate the mean spectra. Classical discriminant analysis was applied using the same data sets. The results of the two identification methods are presented and show that recognition rates of about 95% are possible using average spectra. The differing recognition rates by species and fish sizes are discussed and the two identification methods compared. Implications for the future development of these methods are considered."																				
1996	"Wilkins, Malcom F.; Boddy, Lynne; Morris, Colin W.; Jonker, Richard"	A comparison of some neural and non-neural methods for identification of phytoplankton from flow cytomery data	Other	"DNN, Other"	Classification	Bioinformatics	12	1	18-Sep	10.1093/bioinformatics/12.1.9	https://doi.org/10.1093/bioinformatics/12.1.9	"Four artifcial neural network paradigms (multilaver perceptron networks, learning vector quantization networks, and radial and asymmetric basis function networks) and two statistical methods (parametric statistical classification by modelling each class with Gaussian distributions, and non-parametric density estimation via the K-nearest neighbour method) were compared for their ability to identify seven freshwater and five marine phytoplankton species from flow cytometric data. Kohonen self-organizing maps were also used to examine similarities between species. Optimized networks and statistical methods performed similarly, correctly identifying between 86.8% and 90.1% of data from freshwater species, and between 81.3% and 84.1% of data from marine species. Choice of identification technique must therefore be made on the basis of other criteria. We highlight the way each method partitions the data space and thereby separates the data clusters, and discuss the relative merits of each with reference to complexity of data boundaries, training time, analysis time and behaviour when presented with ‘novel’ data."																				
1997	"Baran, Philippe; Lek, Sovan; Delacoste, Marc; Belaud, Alain"	Stochastic models that predict trout population density or biomass on a mesohabitat scale	Environmental	DNN	Regression	Hydrobiologia	337	1	9-Jan	10.1007/BF00028502	https://link.springer.com/article/10.1007/BF00028502	"Neural networks and multiple linear regression models of the abundance of brown trout (Salmo trutta L.) on the mesohabitat scale were developed from combinations of physical habitat variables in 220 channel morphodynamic units (pools, riffles, runs, etc.) of 11 different streams in the central Pyrenean mountains. For all the 220 morphodynamic units, the determination coefficients obtained between the estimated and observed values of density or biomass were significantly higher for the neural network (r2 adjusted= 0.93 and r2 adjusted=0.92 (p<0.01) for biomass and density respectively with the neural network, against r2 adjusted=0.69 (p<0.01) and r2 adjusted = 0.54 (p<0.01) with multiple linear regression). Validation of the multivariate models and learning of the neural network developed from 165 randomly chosen channel morphodynamic units, was tested on the 55 other channel morphodynamic units. This showed that the biomass and density estimated by both methods were significantly related to the observed biomass and density. Determination coefficients were significantly higher for the neural network (r2 adjusted =0.72 (p<0.01) and 0.81 (p<0.01) for biomass and density respectively) than for the multiple regression model (r2 adjusted=0.59 and r2 adjusted=0.37 for biomass and density respectively). The present study shows the advantages of the backpropagation procedure with neural networks over multiple linear regression analysis, at least in the field of stochastic salmonid ecology."																				
1997	"Dopazo, Joaquín; Wang, Huaichun; Carazo, José María"	A new type of unsupervised growing neural network for biological sequence classification that adopts the topology of a phylogenetic tree	Molecular	Other	Modeling	Biological and Artificial Computation: From Neuroscience to Technology			932-941	10.1007/BFb0032553	https://link.springer.com/chapter/10.1007/BFb0032553	"We propose a new type of unsupervised growing self-organizing neural network that expands itself following the taxonomic relationships existing among the sequences being classified. The binary tree topology of this neural network, opposite to other more classical neural network topologies, permits an efficient classification of sequences. The growing nature of this procedure allows to stop it at the desired taxonomic level without the necessity of waiting until a complete phylogenetic tree is produced. This novel approach presents a number of other interesting properties, such as a time for convergence which is, approximately, a lineal function of the number of sequences. Computer simulation and a real example shows that the algorithm accurately finds the phylogenetic tree that relates the data. All this makes of the neural network presented here an excellent tool for the phylogenetic analysis of large number of sequences."																				
1997	"Mastrorillo, Sylvain; Lek, Sovan; Dauba, Francis"	Predicting the abundance of minnow Phoxinus phoxinus (Cyprinidae) in the River Ariège (France) using artificial neural networks	Environmental	DNN	Regression	Aquatic Living Resources	10	3	169-176	10.1051/alr:1997018	https://www.alr-journal.org/articles/alr/abs/1997/03/alr97305/alr97305.html	"The study of abundance of small-bodied species of fish such as minnow is important because these species play an important role in the food-web dynamics of small streams. In this work, we propose the use of an Artificial Neural Network (ANN) to the modelling and prediction of abundance in minnow Phoxinus phoxinus using 10 environmental microhabitat variables: distance from the bank, percentage of boulders, pebbles, gravel, sand, mud, marl, cover respectively, depth and velocity. A total of 372 points were randomly chosen from a total of 465 electrofished point samples to establish a ANN model. A validation holdout of the training of the ANN was undertaken with testing on 93 other sampling points. On the test set, the prediction performance was 92%. Our study showed the advantages of the back-propagation procedure of the neural network in the field of stochastic approaches to ecology of coarse fishes. The limitations of the neural network approaches as well as statistical and ecological perspectives are discussed."																				
1997	"Wu, Cathy H."	Artificial neural networks for molecular sequence analysis	NA	NA	Review	Computers & Chemistry	21	4	237-256	10.1016/S0097-8485(96)00038-1	https://www.sciencedirect.com/science/article/pii/S0097848596000381	"Artificial neural networks provide a unique computing architecture whose potential has attracted interest from researchers across different disciplines. As a technique for computational analysis, neural network technology is very well suited for the analysis of molecular sequence data. It has been applied successfully to a variety of problems, ranging from gene identification, to protein structure prediction and sequence classification. This article provides an overview of major neural network paradigms, discusses design issues, and reviews current applications in DNA/RNA and protein sequence analysis."																				
1997	"Zakharia, Manell E.; Magand, François; Hetroit, François; Diner, Noël"	Wideband sounder for fish species identification at sea	Sound	DNN	Classification	ICES Journal of Marine Science	53	2	203-208	10.1006/jmsc.1996.0023	https://doi.org/10.1006/jmsc.1996.0023	"A brief description is given of both a wideband echo-sounder and data acquisition at sea. Experiments were conducted in the Bay of Biscay at various seasons for four years. Fish species were identified by trawling. Only echoes associated with trawl catches that were monospecific were used in the classification analyses. Species discrimination was based only on the spectral signature of the echoes and did not take into account the characteristics of the school shape. A modelling of the power spectrum of the echo was used to limit the spectral signature to a reduced set of parameters that could be used for classification using a neural network. Thirty-six different monospecific schools, including about 900 echoes, were processed. Three species were considered: sardine (Sardina pilchardus), anchovy (Engraulis encrasicolus), and horse mackerel (Trachurus trachurus). Classification performance had a success rate as high as 75%."																				
1998	"Clark, Jonathan Y.; Warwick, Kevin"	Artificial Keys for Botanical Identification using a Multilayer Perceptron Neural Network (MLP)	Other	Unknown	Classification	Artificial Intelligence for Biology and Agriculture			95-115	10.1007/978-94-011-5048-4_5	https://doi.org/10.1007/978-94-011-5048-4_5	"In this paper, practical generation of identification keys for biological taxa using a multilayer perceptron neural network is described. Unlike conventional expert systems, this method does not require an expert for key generation, but is merely based on recordings of observed character states. Like a human taxonomist, its judgement is based on experience, and it is therefore capable of generalized identification of taxa. An initial study involving identification of three species of Iris with greater than 90% confidence is presented here. In addition, the horticulturally significant genus Lithops (Aizoaceae/Mesembryanthemaceae), popular with enthusiasts of succulent plants, is used as a more practical example, because of the difficulty of generation of a conventional key to species, and the existence of a relatively recent monograph. It is demonstrated that such an Artificial Neural Network Key (ANNKEY) can identify more than half (52.9%) of the species in this genus, after training with representative data, even though data for one character is completely missing."																				
1998	"Goodacre, Royston; Timmins, Eadaoin M.; Rooney, Paul J.; Rowland, Jem J.; Kell, Douglas B."	Rapid identification of Streptococcus and Enterococcus species using diffuse reflectance-absorbance Fourier transform infrared spectroscopy and artificial neural networks	Other	DNN	Classification	FEMS Microbiology Letters	140	3-Feb	233-239	10.1111/j.1574-6968.1996.tb08342.x	https://academic.oup.com/femsle/article/140/2-3/233/566856	"Diffuse reflectance-absorbance Fourier transform infrared spectroscopy (FT-IR) was used to analyse 19 hospital isolates which had been identified by conventional means to one of Enterococcus faecalis, E. faecium, Streptococcus bovis, S. mitis, S. pneumoniae, or S. pyogenes. Principal components analysis of the FT-IR spectra showed that this ‘unsupervised’ learning method failed to form six separable clusters (one for each species) and thus could not be used to identify these bacteria based on their FT-IR spectra. By contrast, artificial neural networks (ANNs) could be trained by ‘supervised’ learning (using the back-propagation algorithm) with the principal components scores of derivatised spectra to recognise the strains from their FT-IR spectra. These results demonstrate that the combination of FT-IR and ANNs provides a rapid, novel and accurate bacterial identification technique."																				
1998	"Guégan, Jean-François; Lek, Sovan; Oberdorff, Thierry"	Energy availability and habitat heterogeneity predict global riverine fish diversity	Environmental	DNN	Regression	Nature	391	6665	382-384	10.1038/34899	https://www.nature.com/articles/34899	"Processes governing patterns of richness of riverine fish species at the global level can be modelled using artificial neural network (ANN) procedures. These ANNs are the most recent development in computer-aided identification and are very different from conventional techniques1,2. Here we use the potential of ANNs to deal with some of the persistent fuzzy and nonlinear problems that confound classical statistical methods for species diversity prediction. We show that riverine fish diversity patterns on a global scale can be successfully predicted by geographical patterns in local river conditions. Nonlinear relationships, fitted by ANN methods, adequately describe the data, with up to 93 per cent of the total variation in species richness being explained by our results. These findings highlight the dominant effect of energy availability and habitat heterogeneity on patterns of global fish diversity. Our results reinforce the species-energy theory3 and contrast with those from a recent study on North American mammal species4, but, more interestingly, they demonstrate the applicability of ANN methods in ecology."																				
1998	"Jordan, R.; Feeney, F.; Nesbitt, N.; Evertsen, J. A."	Classification of wood species by neural network analysis of ultrasonic signals	Sound	DNN	Classification	Ultrasonics	36	1	219-222	10.1016/S0041-624X(97)00148-0	https://www.sciencedirect.com/science/article/pii/S0041624X97001480	The passage of ultrasonic waves through an anisotropic inhomogeneous material such as wood involves complex interactions between the physical vibrations of the ultrasound and the elastic response of the wood. The initial ultrasound signal is modified by the transmission medium in a way characteristic of the elastic anisotropy of the medium. The many species of wood have subtly different elastic responses. In this work the characteristic signals formed by these responses is examined. A neural network system is used to classify these signals in terms of species. The neural network is shown to have a high success rate in identifying wood species from the ultrasonic trace. It is established that this identification is not possible using wave velocity or received signal amplitudes. The most appropriate propagation direction for species identification is also considered.																				
1999	"Dopazo, Joaquín; Carazo, José María"	Phylogenetic Reconstruction Using an Unsupervised Growing Neural Network That Adopts the Topology of a Phylogenetic Tree	Molecular	Other	Modeling	Journal of Molecular Evolution	44	2	226-233	10.1007/PL00006139	https://doi.org/10.1007/PL00006139	"We propose a new type of unsupervised, growing, self-organizing neural network that expands itself by following the taxonomic relationships that exist among the sequences being classified. The binary tree topology of this neutral network, contrary to other more classical neural network topologies, permits an efficient classification of sequences. The growing nature of this procedure allows to stop it at the desired taxonomic level without the necessity of waiting until a complete phylogenetic tree is produced. This novel approach presents a number of other interesting properties, such as a time for convergence which is, approximately, a lineal function of the number of sequences. Computer simulation and a real example show that the algorithm accurately finds the phylogenetic tree that relates the data. All this makes the neural network presented here an excellent tool for phylogenetic analysis of a large number of sequences."																				
1999	"Goodacre, Royston; Timmins, Éadaoin M; Burton, Rebecca; Kaderbhai, Naheed; Woodward, Andrew M.; Kell, Douglas B.; Rooney, Paul J.YR 1998"	Rapid identification of urinary tract infection bacteria using hyperspectral whole-organism fingerprinting and artificial neural networks	Other	DNN	Classification	Microbiology	144	5	1157-1170	10.1099/00221287-144-5-1157	https://www.microbiologyresearch.org/content/journal/micro/10.1099/00221287-144-5-1157	"Three rapid spectroscopic approaches for whole-organism fingerprinting-pyrolysis mass spectrometry (PyMS), Fourier transform infra-red spectroscopy (FT-IR) and dispersive Raman microscopy - were used to analyse a group of 59 clinical bacterial isolates associated with urinary tract infection. Direct visual analysis of these spectra was not possible, highlighting the need to use methods to reduce the dimensionality of these hyperspectral data. The unsupervised methods of discriminant function and hierarchical cluster analyses were employed to group these organisms based on their spectral fingerprints, but none produced wholly satisfactory groupings which were characteristic for each of the five bacterial types. In contrast, for PyMS and FT-IR, the artificial neural network (ANN) approaches exploiting multi-layer perceptrons or radial basis functions could be trained with representative spectra of the five bacterial groups so that isolates from clinical bacteriuria in an independent unseen test set could be correctly identified. Comparable ANNs trained with Raman spectra correctly identified some 80% of the same test set. PyMS and FT-IR have often been exploited within microbial systematics, but these are believed to be the first published data showing the ability of dispersive Raman microscopy to discriminate clinically significant intact bacterial species. These results demonstrate that modern analytical spectroscopies of high intrinsic dimensionality can provide rapid accurate microbial characterization techniques, but only when combined with appropriate chemometrics.,"																				
1999	"Gozlan, R. E.; Mastrorillo, S.; Copp, G. H.; Lek, S."	Predicting the structure and diversity of young-of-the-year fish assemblages in large rivers	Environmental	DNN	Regression	Freshwater Biology	41	4	809-820	10.1046/j.1365-2427.1999.00423.x	https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1365-2427.1999.00423.x	"1. Interactions between environmental variables and 0+ fish assemblages in the upper River Garonne (France) were quantified during late August 1995. 2. The abundance and diversity of the fish assemblages in floodplain channels were modelled using Artificial Neural Network (ANN) analysis and nine variables: the abundance of the six dominant species, fish specific richness, overall abundance of 0+ fish and the Shannon index of diversity. Multiple regression analysis was also used to assess ANN performance. 3. Using 596 samples, correlation coefficients (r adjusted) between observed and estimated values of the nine dependent parameters were all highly significant (P < 0.01). Expected values from the tested data were significantly related to the observed values. The correlation coefficient between observed and estimated values (r) varied from 0.70 to 0.85. 4. The ANN provided a high quality prediction, despite the complex nature of the relationship between microhabitat composition and fish abundance. 5. Garson’s algorithm was used to provide the explanatory power needed in ecology when using black-box models. Parameters contained in the models (i.e. weighting) were used to determine the relative contributions of explanatory variables and thus to ascertain the structure of fish communities."																				
1999	"Holmgren, Noél M. A.; Enquist, Magnus"	Dynamics of mimicry evolution	Other	DNN	Modeling	Biological Journal of the Linnéan Society	66		145–158	10.1111/j.1095-8312.1999.tb01880.x	https://academic.oup.com/biolinnean/article/66/2/145/2661309	"We simulated mimicry evolution by allowing three populations to coevolve: two populations of senders and one of receivers. Artificial neural networks were used to model receivers, and it was assumed that recognition was inherited. The senders ’ signals consisted of nine dimensions. Changes to receivers and senders were caused by random mutations during the course of the simulation. Whereas it paid both types of senders to elicit the same response from the receiver, it benefited the receiver to respond in this way only towards one of the sender types. The receiver was thus in conflict with one of the senders, e.g. as in Batesian mimicry. Monotonically increasing response gradients caused the appearance of the model and the mimic to move in the same direction. Mimicry evolved because the mimic approached the model faster than the model moved away. Even after mimicry was established the model and the mimic were constantly changing in appearance. Our results conform with what is known in comparative psychology and ethology about how animals respond to stimuli. Several of our results are a direct consequence of recognition and have not, to our knowledge, been reported before, showing the importance of considering the recognition mechanism in"																				
1999	"Huse, Geir; Strand, Espen; Giske, Jarl"	Implementing behaviour in individual-based models using neural networks and genetic algorithms	Other	DNN	Modeling	Evolutionary Ecology	13	5	469-483	10.1023/A:1006746727151	https://link.springer.com/article/10.1023/A:1006746727151	"Even though individual-based models (IBMs) have become very popular in ecology during the last decade, there have been few attempts to implement behavioural aspects in IBMs. This is partly due to lack of appropriate techniques. Behavioural and life history aspects can be implemented in IBMs through adaptive models based on genetic algorithms and neural networks (individual-based-neural network-genetic algorithm, ING). To investigate the precision of the adaptation process, we present three cases where solutions can be found by optimisation. These cases include a state-dependent patch selection problem, a simple game between predators and prey, and a more complex vertical migration scenario for a planktivorous fish. In all cases, the optimal solution is calculated and compared with the solution achieved using ING. The results show that the ING method finds optimal or close to optimal solutions for the problems presented. In addition it has a wider range of potential application areas than conventional techniques in behavioural modelling. Especially the method is well suited for complex problems where other methods fail to provide answers."																				
1999	"Lek, Sovan; Guégan, J. F."	"Artificial neural networks as a tool in ecological modelling, an introduction"	NA	NA	Review	Ecological Modelling	120	2	65-73	10.1016/S0304-3800(99)00092-7	https://www.sciencedirect.com/science/article/pii/S0304380099000927	"Artificial neural networks (ANNs) are non-linear mapping structures based on the function of the human brain. They have been shown to be universal and highly flexible function approximators for any data. These make powerful tools for models, especially when the underlying data relationships are unknown. In this reason, the international workshop on the applications of ANNs to ecological modelling was organized in Toulouse, France (December 1998). During this meeting, we discussed different methods, and their reliability to deal with ecological data. The special issue of this ecological modelling journal begins with the state-of-the-art with emphasis on the development of structural dynamic models presented by S.E. Jorgensen (DK). Then, to illustrate the ecological applications of ANNs, examples are drawn from several fields, e.g. terrestrial and aquatic ecosystems, remote sensing and evolutionary ecology. In this paper, we present some of the most important papers of the first workshop about ANNs in ecological modelling. We briefly introduce here two algorithms frequently used; (i) one supervised network, the backpropagation algorithm; and (ii) one unsupervised network, the Kohonen self-organizing mapping algorithm. The future development of ANNs is discussed in the present work. Several examples of modelling of ANNs in various areas of ecology are presented in this special issue."																				
1999	"Özesmi, Stacy L; Özesmi, Uygar"	An artificial neural network approach to spatial habitat modelling with interspecific interaction	Environmental	DNN	Regression	Ecological Modelling	116	1	15-31	10.1016/S0304-3800(98)00149-5	https://www.sciencedirect.com/science/article/pii/S0304380098001495	"Spatial models for habitat selection of marsh-breeding bird species were developed using artificial neural networks. The habitat models included single and multiple species artificial neural networks for red-winged blackbird (Agelaius phoeniceus) and marsh wren (Cistothorus palustris). Data for the study came from two diked wetland basins on southwestern Lake Erie, USA. The single species artificial neural network model performed better than the logistic regression model except in the presence of interspecific interaction with marsh wren. A multiple species habitat model was developed using data from one basin that included both nesting red-winged blackbirds and marsh wrens. The multiple species neural network model performed better than the logistic regression model in the presence of interspecific interaction and could simultaneously predict the nest locations of both species. Using neural interpretation diagrams, relevances, and sensitivity analyses, we determined the mechanisms of habitat selection in red-winged blackbirds and marsh wrens. Habitat selection in marsh-breeding bird species was a non-linear process that could not be sufficiently understood in terms of general linear models. The non-linear structure of the neural network model not only predicts habitat selection better, but with a critical evaluation through neural interpretation diagrams, relevances and sensitivity analyses can lead to a better understanding of the mechanisms of habitat selection. As predictive tools single species neural network models were too specific in cases where the system changed to include interacting species. In these cases linear models might be better predictors but not necessarily provide a better understanding. In the presence of two interacting species we suggest the use of a neural network model that is trained with a data set from a wetland where all the interacting species are present. In the absence of the interacting species the dynamics will change and habitat selection can be based on an entirely different set of rules and relationships. Therefore, the decision on which neural network model to use must be based on an in-depth understanding of the ecology of the system under study."																				
1999	"Spitz, François; Lek, Sovan"	Environmental impact prediction using neural network modelling. An example in wildlife damage	Environmental	DNN	Regression	Journal of Applied Ecology	36	2	317-326	10.1046/j.1365-2664.1999.00400.x	https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1365-2664.1999.00400.x	"1. Decision making in management of environmental impact confronts the problem of analysing relationships in highly complex ecological systems. These relationships are generally non-linear, and conventional techniques do not apply satisfactorily. The problem is equivalent to that of predicting the output of a black box. Artificial neural networks (ANN) have shown tremendous promise in modelling such situations. 2. The present work describes the development and validation of an ANN in modelling wildlife damage to farmland, a particular instance of ecological impact. An ANN approach was developed and tested using data from 200 damaged plots, and a control sample of 20 undamaged plots, described by 17 environmental characters. The dependent variable was the financial cost of impact per plot. 3. The predictive quality of the ANN models was evaluated through the ‘leave-one-out’ procedure. For 82% of predicted values, deviation from observed values is lower than 1780, that is 10% of the range of the observed values. The frequency of bad predictions depends on the minimum level of impact (critical effect size) considered. In France, compensation is given starting from a minimum level of 200 FF. At this level, the frequency of occurrence of Type I errors (predicted impact does not occur) is 7·11%. Different strategies of prevention of impact, using different threshold values for prevention, are analysed. Frequency of Type I errors increases, and that of Type II errors (occurrence of unpredicted impact) decreases as the threshold for prevention increases. 4. Sensitivity analysis allows the determination of the effect of seven quantitative variables on the cost of damage compensation. Proximity of a paved road, proximity and number of houses, and number of other buildings contribute negatively, and three other variables (proportion of the perimeter of the plot occupied by woody vegetation, density of the vegetation, and density of wild boar in the surrounding area) contribute positively to the predicted value. 5. Results show that the utility of impact prediction for prevention depends on the cost of errors and the absolute cost of prevention. 6. Finally, ANNs proved able to learn complex relationships between environmental variables and impact assessment, and to produce operationally relevant predictions. Good predictions can help managers to distribute efficiently their actions between prevention, protection and compensation."																				
2000	"Boddy, L; Morris, Cw; Wilkins, Mf; Al-Haddad, L; Tarran, Ga; Jonker, Rr; Burkill, Ph"	Identification of 72 phytoplankton species by radial basis function neural network analysis of flow cytometric data	Other	DNN	Classification	Marine Ecology Progress Series	195		47-59	10.3354/meps195047	http://www.int-res.com/abstracts/meps/v195/p47-59/	"Radial basis function artificial neural networks (ANNs) were trained to discriminate between phytoplankton species based on 7 flow cytometric parameters measured on axenic cultures. Comparison was made between the performance of networks restricted to using radially-symmetric basis functions and networks using more general arbitrarily oriented ellipso~dabl asis functions, with the latter proving significantly superior in performance. ANNs trained on 62, 54 and 72 taxa identified them with respectively 77, 73 and 70% overall success. As well as high success in identification, high confidence of correct identification was also achieved. Misidentifications resulted from overlap of character distributions. Improved overall identification success can be achieved by grouping together species with similar character distributions. This can be done within genera or based on groupings indicated in dendrograms constructed for the data on all species. When a n ANN trained on 1 data set was tested with data on cells grown under different light conditions, overall successful identification was low (<20%), but when a n ANN was trained on a combined data set identification success was high (>?0%). Clearly it is essential to include data on cells covering the whole spectrum of biological variatlon. Ways of obtaining data for training ANNs to identify phytoplankton from field samples are discussed."																				
2000	"Chon, Tae-Soo; Park, Young-Seuk; Kim, Ja-Myung; Lee, Buom-Young; Chung, Yeong-Jin; Kim, YooShin"	Use of an Artificial Neural Network to Predict Population Dynamics of the Forest–Pest Pine Needle Gall Midge (Diptera: Cecidomyiida)	Temporal	DNN	Regression	Environmental Entomology	29	6	1208-1215	10.1603/0046-225X-29.6.1208	https://doi.org/10.1603/0046-225X-29.6.1208	"The backpropagation algorithm in artificial neural networks was used to forecast dynamic data of a forest pest population of the pine needle gall midge, Thecodiplosis japonensis Uchida et Inouye, a serious pest in pine trees in northeast Asia. Data for changes in population density were sequentially given as input, whereas densities of subsequent samplings were provided as matching target data for training of the network. Convergence was reached, generally after 20,000 iterations with learning coefficients of 0.5–0.8. When new input data were given to the trained network, recognition was possible and population density at the subsequent sampling time could be predicted."																				
2000	"Giacomini, M; Ruggiero, C; Calegari, L; Bertone, S"	Artificial neural network based identification of environmental bacteria by gas-chromatographic and electrophoretic data	Other	DNN	Classification	Journal of Microbiological Methods	43	1	45-54	10.1016/S0167-7012(00)00203-7	https://www.sciencedirect.com/science/article/pii/S0167701200002037	"Chemotaxonomic identification techniques are powerful tools for environmental micro-organisms, for which poor diagnostic schemes are available. Whole cellular fatty acid methyl esters (FAME) content is a stable bacterial profile, the analysis method is rapid, cheap, simple to perform and highly automated. Whole-cell protein is an even more powerful tool because it yields information at or below the species level. The description of new species and genera and subsequent continuous rearrangement provide large amounts of data, resulting in large databases. In order to set up suitable software tools to work on such large databases artificial neural network (ANN) based programs have been used to classify and identify marine bacteria at genus and species levels, starting from the fatty acid profiles and protein profiles respectively. We analysed 50 certified strains belonging to Halomonas, Marinomonas, Marinospirillum, Oceanospirillum and Pseudoalteromonas genera. Both supervised and unsupervised ANNs provide a correct classification of the marine strains analyzed. Moreover, a set of 73 marine fresh isolates were used as an example of identification using ANNs. We propose supervised and unsupervised ANNs as a reliable tool for classification of bacteria by means of their FAME and of whole-protein analyses and as a sound basis for a comprehensive artificial intelligence based system for polyphasic taxonomy."																				
2000	"Haddow, K. A.; King, D. J.; Pouliot, D. A.; Pitt, D. G.; Bell, F. W."	Early regeneration conifer identification and competition cover assessment using airborne digital camera imagery	Images	DNN	Classification	The Forestry Chronicle	76	6	915-928	10.5558/tfc76915-6	https://pubs.cif-ifc.org/doi/10.5558/tfc76915-6	"The potential of low cost, high-resolution airborne digital camera imagery for use in early stage forest regeneration assessment was investigated. Airborne imagery with 2.5-cm pixel size was acquired near Sault Ste. Marie, Ontario, over a forest vegetation management research site to: i) evaluate capabilities for identification and stem counting of two-year old conifer crop species under leaf-off and leaf-on conditions using classification of spectral and textural image information, and ii) develop models relating vegetation cover parameters to image spectral and texture information. Results indicate strong potential for identification and counting of conifer trees when competing vegetation cover is low or in leaf-off condition. However, systematic decreases in class separability and conifer count accuracy were observed with increasing competition. In image modelling of competition Leaf Area Index and Cover, statistically significant relations were found using primarily spectral measures. Stratification by competition species improved model fits and included texture measures in some models. Key words: airborne remote sensing, forest vegetation management, regeneration, digital cameras, leaf area index, cover, tree classification"																				
2000	"Laë, Raymond; Lek, Sovan; Moreau, Jacques"	Predicting fish yield of African lakes using neural networks	Environmental	DNN	Regression	Ecological Modelling	120	2	325-335	10.1016/S0304-3800(99)00112-X	https://www.sciencedirect.com/science/article/pii/S030438009900112X	"Artificial neural network (ANN) approaches to modelling and prediction of fish yield as related to the environmental characteristics were developed from the combination of six variables: catchment area over maximum area, fishing effort, conductivity, depth, altitude and latitude. For a total of 59 lakes studied, the correlation coefficients obtained between the estimated and observed values of abundance were significantly high with the neural network procedure (r adjusted=0.95, P<0.01). The predictive power of the ANN models was determined by the leave one out cross-validation procedures. This is an appropriate testing method when the data set is quite small and/or when each sample is likely to have ‘unique information’ that is relevant to the model. Fish yields estimated with this method were significantly related to the observed fish yields with the correlation coefficient reaching 0.83 (P<0.01). Our study shows the advantages of the backpropagation procedure of the neural network in stochastic approaches to fisheries ecology. Using the specific algorithm, we can identify the factor influencing the fish yield and the mode of action of each factor. The limitations of the neural network approaches as well as statistical and ecological perspectives are discussed."																				
2000	M. S. El-Faki; N. Zhang; D. E. Peterson	WEED DETECTION USING COLOR MACHINE VISION	Images	DNN	Classification	Transactions of the ASAE	43	6	1969-1978	10.13031/2013.3103	http://elibrary.asabe.org/abstract.asp??JID=3&AID=3103&CID=t2000&v=43&i=6&T=1	"Many weed species have reddish stems, but stems of wheat and soybean are green. These color features were used in this study to establish a simple weed-detection method using a color machine-vision system. This method is more practical than texture- or shape-based methods because of its low sensitivity to canopy overlap, leaf orientation, camera focusing, and wind effect. Four types of relative color indices formed by RGB gray levels were designed. The most effective combinations of these color indices were selected using a statistical method. These combinations were used as the input variables for a statistical classifier based on discriminant analysis (DA) and two artificial neural-network (NN) classifiers. These classifiers were trained and tested using three weed species (Johnsongrass, redroot pigweed, and yellow foxtail) with soybean and three weed species (wild buckwheat, cheat, and field bindweed) with wheat. Preprocessing and postprocessing algorithms were developed to shorten the processing time and to reduce noise. The results showed that the statistical DA classifier was more accurate than the NN classifiers in classification accuracy. The least-square means of the classification rates using the DA classifiers for soybean and wheat were 54.9% and 62.2%, respectively. The misclassification rates for most weed species were below 3%. Because the reddish colors on the stems of some weed species vary as the plants grow, an in-field calibration procedure will be needed to make the classifiers more adaptive to different circumstances."																				
2000	"Parsons, S.; Jones, G."	Acoustic identification of twelve species of echolocating bat by discriminant function analysis and artificial neural networks	Sound	DNN	Classification	Journal of Experimental Biology	203	17	2641-2656	10.1242/jeb.203.17.2641	https://doi.org/10.1242/jeb.203.17.2641	"We recorded echolocation calls from 14 sympatric species of bat in Britain. Once digitised, one temporal and four spectral features were measured from each call. The frequency-time course of each call was approximated by fitting eight mathematical functions, and the goodness of fit, represented by the mean-squared error, was calculated. Measurements were taken using an automated process that extracted a single call from background noise and measured all variables without intervention. Two species of Rhinolophus were easily identified from call duration and spectral measurements. For the remaining 12 species, discriminant function analysis and multilayer back-propagation perceptrons were used to classify calls to species level. Analyses were carried out with and without the inclusion of curve-fitting data to evaluate its usefulness in distinguishing among species. Discriminant function analysis achieved an overall correct classification rate of 79% with curve-fitting data included, while an artificial neural network achieved 87%. The removal of curve-fitting data improved the performance of the discriminant function analysis by 2 %, while the performance of a perceptron decreased by 2 %. However, an increase in correct identification rates when curve-fitting information was included was not found for all species. The use of a hierarchical classification system, whereby calls were first classified to genus level and then to species level, had little effect on correct classification rates by discriminant function analysis but did improve rates achieved by perceptrons. This is the first published study to use artificial neural networks to classify the echolocation calls of bats to species level. Our findings are discussed in terms of recent advances in recording and analysis technologies, and are related to factors causing convergence and divergence of echolocation call design in bats."																				
2000	"Phelps, S. M.; Ryan, M. J."	History influences signal recognition: neural network models of túngara frogs	Other	DNN	Modeling	Proceedings of the Royal Society of London. Series B: Biological Sciences	267	1453	1633-1639	10.1098/rspb.2000.1189	https://royalsocietypublishing.org/doi/10.1098/rspb.2000.1189	"Animals often attend to only a few of the cues provided by the complex displays of conspecifics. We suggest that these perceptual biases are influenced by mechanisms of signal recognition inherited from antecedent species. We tested this hypothesis by manipulating the evolutionary history of artificial neural networks, observing how the resulting networks respond to many novel stimuli and comparing these responses to the behaviour of females in phonotaxis experiments. Networks with different evolutionary histories proved equally capable of evolving to recognize the call of the tungara frog, Physalaemus pustulosus, but exhibited distinct responses to novel stimuli. History influenced the ability of networks to predict known responses of tungara frogs; network accuracy was determined by how closely the network history approximated the hypothesized history of the tungara frog. Our findings emphasize the influence of past selection pressures on current perceptual mechanisms, and demonstrate how neural network models can be used to address behavioural questions that are intractable through traditional methods."																				
2000	"Shinn, A. P.; Kay, J. W.; Sommerville, C."	The use of statistical classifiers for the discrimination of species of the genus Gyrodactylus (Monogenea) parasitizing salmonids	Images	DNN	Classification	Parasitology	120	3	261-269	10.1017/S0031182099005454	https://www.cambridge.org/core/journals/parasitology/article/use-of-statistical-classifiers-for-the-discrimination-of-species-of-the-genus-gyrodactylus-monogenea-parasitizing-salmonids/8E5FF65DBF6238126DD1371ABA1850AF	"This study applies flexible statistical methods to morphometric measurements obtained via light and scanning electron microscopy (SEM) to discriminate closely related species of Gyrodactylus parasitic on salmonids. For the first analysis, morphometric measurements taken from the opisthaptoral hooks and bars of 5 species of gyrodactylid were derived from images obtained by SEM and used to assess the prediction performance of 4 statistical methods (nearest neighbours; feed-forward neural network; projection pursuit regression and linear discriminant analysis). The performance of 2 methods, nearest neighbours and a feed-forward neural network provided perfect discrimination of G. salaris from 4 other species of Gyrodactylus when using measurements taken from only a single structure, the marginal hook. Data derived from images using light microscopy taken from the full complement of opisthaptoral hooks and bars were also tested and nearest neighbours and linear discriminant analysis gave perfect discrimination of G. salaris from G. derjavini Mikailov, 1975 and G. truttae Gläser, 1974. The nearest neighbours method had the least misclassifications and was therefore assessed further for the analysis of individual hooks. Five morphometric parameters from the marginal hook subset (total length, shaft length, sickle length, sickle proximal width and sickle distal width) gave near perfect discrimination of G. salaris. For perfect discrimination therefore, larger numbers of parameters are required at the light level than at the SEM level."																				
2000	T. F. Burks; S. A. Shearer; R. S. Gates; K. D. Donohue	BACKPROPAGATION NEURAL NETWORK DESIGN AND EVALUATION FOR CLASSIFYING WEED SPECIES USING COLOR IMAGE TEXTURE	Images	DNN	Classification	Transactions of the ASAE	43	4	1029-1037	10.13031/2013.2971	http://elibrary.asabe.org/abstract.asp??JID=3&AID=2971&CID=t2000&v=43&i=4&T=1	"Color co-occurrence method (CCM) texture statistics were used as input variables for a backpropagation (BP) neural network weed classification model. Thirty-three unique CCM texture statistic inputs were generated for 40 images per class, within a six class data set. The following six classes were studied: giant foxtail, large crabgrass, common lambsquarter, velvetleaf, ivyleaf morningglory, and clear soil surface. The texture data was used to build six different input variable models for the BP network, consisting of various combinations of hue, saturation, and intensity (HSI) color texture statistics. The study evaluated classification accuracy as a function of network topology, and training parameter selection. In addition, training cycle requirements and training repeatability were studied. The BP topology evaluation consisted of a series of tests on symmetrical two hidden-layer network, a test of constant complexity topologies, and tapered topology networks. The best symmetrical BP network achieved a 94.7% classification accuracy for a model consisting of 11 inputs, five nodes at each of the two hidden layers and six output nodes (11 _ 5 _ 5 _ 6 BP network). A tapered topology ( 11 _ 12 _ 6 _ 6 BP network) out performed all other BP topologies with an overall accuracy of 96.7% and individual class accuracies of 90.0% or higher."																				
2000	"Wachtmeister, Carl-Adam; Enquist, Magnus"	The evolution of courtship rituals in monogamous species	Other	RNN	Modeling	Behavioral Ecology	11	4	405-410	10.1093/beheco/11.4.405	https://academic.oup.com/beheco/article/11/4/405/177035?login=false	"In this paper we propose an alternative explanation for the evolution of courtship rituals in monogamous species. We demonstrate, using computer simulations, how male courtship might develop as males exploit response biases in females to manipulate the female into starting reproduction before she has been able to assess the male's intentions. In our coevolutionary simulations, a recurrent, artificial neural network is used to model the female recognition mechanism, while the displaying male is represented by a sequence of signals. Our particular model situation is just one example of how a reproductive conflict could result in the evolution of ritualized displays in monogamous species. Since reproductive conflicts occur even after pair formations, the explanation we propose may also apply to rituals that occur after pair formation."																				
2000	"Wilkins, M. F.; Boddy, Lynne; Morris, C. W.; Jonker, R. R."	Identification of Phytoplankton from Flow Cytometry Data by Using Radial Basis Function Neural Networks	Other	DNN	Classification	Applied and Environmental Microbiology	65	10	4404-4410	10.1128/AEM.65.10.4404-4410.1999	https://journals.asm.org/doi/10.1128/AEM.65.10.4404-4410.1999	"We describe here the application of a type of artificial neural network, the Gaussian radial basis function (RBF) network, in the identification of a large number of phytoplankton strains from their 11-dimensional flow cytometric characteristics measured by the European Optical Plankton Analyser instrument. The effect of network parameters on optimization is examined. Optimized RBF networks recognized 34 species of marine and freshwater phytoplankton with 91.5% success overall. The relative importance of each measured parameter in discriminating these data and the behavior of RBF networks in response to data from “novel” species (species not present in the training data) were analyzed."																				
2001	"Brosse, S; Giraudel, J. L; Lek, S"	Utilisation of non-supervised neural networks and principal component analysis to study fish assemblages	Environmental	DNN	Modeling	Ecological Modelling	146	1	159-166	10.1016/S0304-3800(01)00303-9	https://www.sciencedirect.com/science/article/pii/S0304380001003039	"Kohonen self-organizing maps (SOM) belong to the non-supervised artificial neural network modelling methods. It typically displays a high dimensional data set in a lower dimensional space. In this way, that method can be considered as a non-linear surrogate to the principal component analysis (PCA). In order to test the efficiency of SOM on complex ecological data gathered in the natural environment, we made a comparison between PCA and SOM capabilities to analyse the spatial occupancy of several European freshwater fish species in the littoral zone of a large French lake. The same data matrix consisting of 710 samples and 15 species was analysed using PCA and SOM. Both methods provided insights on the major trends in fish spatial occupancy. However, a more detailed analysis showed that only SOM was able to reliably visualise the entire fish assemblage in a two dimensional space (i.e. both dominant and scarce species). On the contrary PCA provided irrelevant ecological information for some species. These drawbacks were afforded to data heterogeneity, scarce species being poorly represented on the PCA plane. These results led us to conclude that SOM constitute a more reliable data representation method than PCA when complex ecological data sets are used."																				
2001	"Céréghino, R.; Giraudel, J. L.; Compin, A."	"Spatial analysis of stream invertebrates distribution in the Adour-Garonne drainage basin (France), using Kohonen self organizing maps"	Environmental	DNN	Modeling	Ecological Modelling	146	1	167-180	10.1016/S0304-3800(01)00304-0	https://www.sciencedirect.com/science/article/pii/S0304380001003040	"We analysed the regional distribution of 283 lotic macroinvertebrate species from four insect orders (Ephemeroptera, Plecoptera, Trichoptera, Coleoptera=EPTC) in the Adour-Garonne drainage basin (South–Western France, surface=116_000 km2). The aim of this work was to provide a stream classification based on characteristic species assemblages. The faunistic data corresponded to the occurrence (presence or absence) of 283 species at 252 sampling sites. These data were computed with the Kohonen self organised map algorithm (SOM) (Kohonen, Self-Organizing Maps, volume30 of Springer Series in Information Sciences. Springer, Berlin, Heidelberg. (Second Extended Edition 1997)). This neural network algorithm has already been successfully used in ecology (Giraudel et al., Artificial neural networks, applications to ecology and evolution. Springer-Verlag, (in press); Chon et al., Ecol. Model., 90,1996,69–78) for communities patternizing. SOM enable visualisation of the complex species assemblage in a two-dimensional space, preserving the topology of the input data. Then, using the U-matrix method, it was possible to classify the data without prior knowledge. Four major EPTC regions were characterised within the drainage basin (Massif Central mountains, Pyrénées mountains, Piedmont and plains, Toulouse city agglomeration), along with their theoretical species assemblage. The number of species characterising each region ranged from 45 to 159, underlining the spatial (i.e. longitudinal and geographical) differences in EPTC assemblages. The main interest of our results is that the stability of these theoretical assemblages may be used to define representative and/or reference sites for biological surveillance, as any change in species composition within a given EPTC region can be considered as a biological indicator of environmental changes."																				
2001	"Chon, Tae-Soo; Kwak, Inn-Sil; Park, Young-Seuk; Kim, Tae-Hyung; Kim, YooShin"	Patterning and short-term predictions of benthic macroinvertebrate community dynamics by using a recurrent artificial neural network	Temporal	RNN	Regression	Ecological Modelling	146	3-Jan	181-193	10.1016/S0304-3800(01)00305-2	https://linkinghub.elsevier.com/retrieve/pii/S0304380001003052	"Dynamic features of community data were extracted by training with a recurrent artificial neural network. Field data collected monthly from an urbanized stream consisted of densities of selected taxa in benthic macroinvertebrate communities. Sets of time-sequence data for communities were provided as the input for the network. The connectivity of computation nodes was arranged in such a way that the previous community data have recurrent feedback. In concurrence with the input of biological data, corresponding sets of environmental data such as water velocity and depth, sedimented organic matter, and volume of small substrates were also provided for the network. Through the connectivity of the network, environmental data were used as input to produce continuous, independent effects on determining community abundance. A trained pattern effectively represented the effects of habitat types and environmental impact on determining community dynamics. Short-term predictions of changes in the densities of selected taxa were made possible by a trained network after new sets of data were provided to the network."																				
2001	"Giraudel, J. L.; Lek, S."	A comparison of self-organizing map algorithm and some conventional statistical methods for ecological community ordination	Environmental	DNN	Modeling	Ecological Modelling	146	1	329-339	10.1016/S0304-3800(01)00324-6	https://www.sciencedirect.com/science/article/pii/S0304380001003246	"In order to summarise the structure of ecological communities some ordination techniques are well known and widely-used, (e.g. Principal Component Analysis (PCA), Correspondence Analysis (CoA). Inspired by the structure and the mechanism of the human brain, the Artificial Neural Networks should be a convenient alternative tool to traditional statistical methods. The Kohonen Self-Organizing Map (SOM) is one of the most well-known neural network with unsupervised learning rules; it performs a topology-preserving projection of the data space onto a regular two-dimensional space. Its achievement has already been demonstrated in various areas, but this approach is not yet widely known and used by ecologists. The present work describes how SOM can be used for the study of ecological communities. After the presentation of SOM adapted to ecological data, SOM was trained on popular example data; upland forest in Wisconsin (USA). The SOM results were compared with classical statistical techniques. Similarity between the results may be observed and constitutes a validation of the SOM method. SOM algorithm seems fully usable in ecology, it can perfectly complete classical techniques for exploring data and for achieving community ordination."																				
2001	"Hilbert, David W.; Ostendorf, Bertram"	"The utility of artificial neural networks for modelling the distribution of vegetation in past, present and future climates"	Environmental	DNN	Classification	Ecological Modelling	146	1	311-327	10.1016/S0304-3800(01)00323-4	https://www.sciencedirect.com/science/article/pii/S0304380001003234	"A feedforward artificial neural network, coupled with a regional GIS (geographic information system), is described that is being used to assess the potential impacts of climate change on a complex landscape of tropical forests. The model quantifies the relative suitability of environments for 15 forests classes using the best information that is available: a structural-environmental classification of forest types, vegetation maps and spatial estimates of environmental variables. Inputs to the model include climate variables, soil parent material classes and terrain variables. The model is highly successful at distinguishing the relative suitability of environments for the forest classes with 75% of the forest mosaic accurately predicted by the model at a one hectare resolution over more than two million hectares. The model was used to estimate potential forest distributions in several climates occurring since the end of the last glacial period. These distributions shift dramatically in response to scenarios representing past climates. Certain locations are occupied by a forest class in only some climates while others are always occupied by the same class despite large changes in regional mean annual temperature and precipitation. Using the model to assess the possible impacts of future climate change and estimating the pre-settlement distribution of forest types in the region is also discussed. The coupling of neural networks with a cellular automata model is also described as a means to assess the importance of spatial constraints on the potential redistribution of forest types in the future. The usefulness of artificial neural networks when applied to vegetation change studies in our region suggests that this approach could be applied in many tropical regions, where floristic diversity is high and mechanistic understanding is comparatively low."																				
2001	"Jeong, Kwang-Seuk; Joo, Gea-Jae; Kim, Hyun-Woo; Ha, Kyong; Recknagel, Friedrich"	Prediction and elucidation of phytoplankton dynamics in the Nakdong River (Korea) by means of a recurrent artificial neural network	Temporal	RNN	Modeling	Ecological Modelling	146	3-Jan	115-129	10.1016/S0304-3800(01)00300-3	https://linkinghub.elsevier.com/retrieve/pii/S0304380001003003	"A recurrent artificial neural network was used for time series modelling of phytoplankton dynamics in the hypertrophic Nakdong River system. The model considered meteorological, hydrological and limnological parameters as input variables and chl. a concentration as output variable. It was trained and validated by means of a complex database measured from 1994 to 1998 at a study site 27 km upstream of the river mouth. The validation results for 1994 indicated that the recurrent training algorithm and a 3 days time lag of input data predict reasonably accurate the timing and magnitudes of chl. a. A comprehensive sensitivity analysis of the model revealed relationships between seasons, specific input variables and chl. a that correspond well with theoretical assumptions and literature findings."																				
2001	"Parsons, Stuart"	Identification of New Zealand bats (Chalinolobus tuberculatus and Mystacina tuberculata) in flight from analysis of echolocation calls by artificial neural networks	Sound	DNN	Classification	Journal of Zoology	253	4	447-456	10.1017/S0952836901000413	https://www.cambridge.org/core/journals/journal-of-zoology/article/identification-of-new-zealand-bats-chalinolobus-tuberculatus-and-mystacina-tuberculata-in-flight-from-analysis-of-echolocation-calls-by-artificial-neural-networks/ED2FDE1F9EC594E819A91F267BFA9B8B	"Time-expanded and heterodyned echolocation calls of the New Zealand long-tailed Chalinolobus tuberculatus and lesser short-tailed bat Mystacina tuberculata were recorded and digitally analysed. Temporal and spectral parameters were measured from time-expanded calls and power spectra generated for both time-expanded and heterodyned calls. Artificial neural networks were trained to classify the calls of both species using temporal and spectral parameters and power spectra as input data. Networks were then tested using data not previously seen. Calls could be unambiguously identified using parameters and power spectra from time-expanded calls. A neural network, trained and tested using power spectra of calls from both species recorded using a heterodyne detector set to 40 kHz (the frequency with the most energy of the fundamental of C. tuberculatus call), could identify 99% and 84% of calls of C. tuberculatus and M. tuberculata, respectively. A second network, trained and tested using power spectra of calls from both species recorded using a heterodyne detector set to 27 kHz (the frequency with the most energy of the fundamental of M. tuberculata call), could identify 34% and 100% of calls of C. tuberculatus and M. tuberculata, respectively. This study represents the first use of neural networks for the identification of bats from their echolocation calls. It is also the first study to use power spectra of time-expanded and heterodyned calls for identification of chiropteran species. The ability of neural networks to identify bats from their echolocation calls is discussed, as is the ecology of both species in relation to the design of their echolocation calls."																				
2001	"Phelps, S. M.; Ryan, M. J.; Rand, A. S."	Vestigial preference functions in neural networks and túngara frogs.	Sound	DNN	Modeling	Proceedings of the National Academy of Sciences	98	23	13161-13166	10.1073/pnas.231296998	https://www.pnas.org/doi/10.1073/pnas.231296998	"Although there is a growing interest in understanding how perceptual mechanisms influence behavioral evolution, few studies have addressed how perception itself is shaped by evolutionary forces. We used a combination of artificial neural network models and behavioral experiments to investigate how evolutionary history influenced the perceptual processes used in mate choice by female túngara frogs. We manipulated the evolutionary history of artificial neural network models and observed an emergent bias toward calls resembling known ancestral states. We then probed female túngara frogs for similar preferences, finding strong biases toward stimuli that resemble a call hypothesized for a recent ancestor. The data strongly suggest that female túngara frogs exhibit vestigial preferences for ancestral calls, and provide a general strategy for exploring the role of historical contingency in perceptual biases."																				
2001	"Reyjol, Yorick; Lim, Puy; Belaud, Alain; Lek, Sovan"	Modelling of microhabitat used by fish in natural and regulated flows in the river Garonne (France)	Environmental	DNN	Regression	Ecological Modelling	146	1	131-142	10.1016/S0304-3800(01)00301-5	https://www.sciencedirect.com/science/article/pii/S0304380001003015	"The aim of our study was to compare the microhabitat used by three fish species: brown trout (Salmo trutta L.), European minnow (Phoxinus phoxinus L.) and stone loach (Barbatula barbatula L.), in natural and regulated flows of a section of the river Garonne (France). Six Artificial Neural Network (ANN) models were set up, one for each fish species in each flow condition. Models were run and tested with 1107 observations obtained by point abundance sampling performed by electrofishing. Each model had thirteen independent environmental variables (distance from the bank, water depth, water velocity, percentage of different substratum fractions defined as large boulders, small boulders, large pebbles, small pebbles, gravels, sand, mud and bedrock, flooded vegetation cover, and presence or absence of ‘blockage’ which is one or several pieces of wood providing shelter), and one dependent variable (fish density for the considered population). A cross-validation testing procedure (leave-one-out bootstrap) was performed to validate the ANN models. Finally, we used a method based on the first partial derivatives of the network's output with respect to each input to focus on the sensitivity of some of the variables selected. During the training phase, all models were judged satisfactory with Mean Squared Errors (MSE) ranging from 0.40 to 1.93, and Performance Indexes (PI's) from 60 to 89%. After the testing procedure, MSE ranged between 1.53 and 8.23, and PI's between 51 and 80%. With the exception of brown trout in regulated flow, patterns of microhabitat use obtained revealed that fish densities were highly connected to one major influencing variable: water depth for brown trout and stone loach, and water velocity for European minnow, other variables accounting for lower individual contributions. Analysis of the partial derivatives brought into relief some differences when comparing microhabitat use in natural and regulated flows for some of the variables tested, and no differences when comparing others. The results are discussed with regard to the biology and the ecology of each fish species at microhabitat and macrohabitat scales, and according to the relationship between microhabitat utilization and microhabitat availability."																				
2001	"Walter, Mark; Recknagel, Friedrich; Carpenter, Craig; Bormans, Myriam"	Predicting eutrophication effects in the Burrinjuck Reservoir (Australia) by means of the deterministic model SALMO and the recurrent neural network model ANNA	Temporal	RNN	Regression	Ecological Modelling	146	3-Jan	97-113	10.1016/S0304-3800(01)00299-X	https://linkinghub.elsevier.com/retrieve/pii/S030438000100299X	"Two modelling paradigms were applied to the prediction of phytoplankton abundance in the Burrinjuck Reservoir: the deductive model SALMO and the inductive model ANNA. While SALMO is driven by process-based differential equations, the model ANNA is designed as recurrent feedforward neural network trained by time series data. Predictions of chlorophyll-a for the years 1979–1982 by both models were validated by means of measured data. Results showed that SALMO is able to predict annual average trends not only of chlorophyll-a but other chemical and biological state variables as well. It supports decision making by evaluating alternative scenarios for strategic eutrophication control. The model ANNA achieved reasonable accuracy in predicting timing and magnitudes of algal biomass up to 7 days ahead. The recurrent feedforward architecture of ANNA proved to be most efficient in order to model and predict seasonal dynamics of chlorophyll-a and its forecasting results can be utilized for early warning and tactical control of algal blooms in freshwater lakes. A sensitivity analysis conducted by ANNA revealed that algal abundance in Burrinjuck Reservoir is not only driven by physical and chemical characteristics of the water body but to a large extend by hydrological characteristics such as water depth as well."																				
2001	"Ward, Christopher R.; Gobet, Fernand; Kendall, Graham"	Evolving Collective Behavior in an Artificial Ecology	Other	DNN	Modeling	Artificial Life	7	2	191-209	10.1162/106454601753139005	https://doi.org/10.1162/106454601753139005	"Collective behavior refers to coordinated group motion, common to many animals. The dynamics of a group can be seen as a distributed model, each “animal” applying the same rule set. This study investigates the use of evolved sensory controllers to produce schooling behavior. A set of artificial creatures “live” in an artificial world with hazards and food. Each creature has a simple artificial neural network brain that controls movement in different situations. A chromosome encodes the network structure and weights, which may be combined using artificial evolution with another chromosome, if a creature should choose to mate. Prey and predators coevolve without an explicit fitness function for schooling to produce sophisticated, nondeterministic, behavior. The work highlights the role of species' physiology in understanding behavior and the role of the environment in encouraging the development of sensory systems."																				
2002	"Campbell, Gregory S.; Gisiner, Robert C.; Helweg, David A.; Milette, Linda L."	Acoustic identification of female Steller sea lions (Eumetopias jubatus)	Sound	DNN	Classification	The Journal of the Acoustical Society of America	111	6	2920-2928	10.1121/1.1474443	https://asa.scitation.org/doi/10.1121/1.1474443	"Steller sea lion (Eumetopias jubatus) mothers and pups establish and maintain contact with individually distinctive vocalizations. Our objective was to develop a robust neural network to classify females based on their mother-pup contact calls. We catalogued 573 contact calls from 25 females in 1998 and 1323 calls from 46 females in 1999. From this database, a subset of 26 females with sufficient samples of calls was selected for further study. Each female was identified visually by marking patterns, which provided the verification for acoustic identification. Average logarithmic spectra were extracted for each call, and standardized training and generalization datasets created for the neural network classifier. A family of backpropagation networks was generated to assess relative contribution of spectral input bandwidth, frequency resolution, and network architectural variables to classification accuracy. The network with best overall generalization accuracy (71%) used an input representation of 0–3 kHz of bandwidth at 10.77 Hz/bin frequency resolution, and a 2:1 hidden:output layer neural ratio. The network was analyzed to reveal which portions of the call spectra were most influential for identification of each female. Acoustical identification of distinctive female acoustic signatures has several potentially important conservation applications for this endangered species, such as rapid survey of females present on a rookery."																				
2002	"Culverhouse, Phil F.; Williams, Robert; Reguera, Beatriz; Herry, Vincent; González-Gil, Sonsoles"	Do experts make mistakes? A comparison of human and machine indentification of dinoflagellates	Images	DNN	Classification	Marine Ecology Progress Series	247		17-25	10.3354/meps247017	https://www.int-res.com/abstracts/meps/v247/p17-25/	"The authors present evidence of the difficulties facing human taxonomists/ecologists in identifying marine dinoflagellates. This is especially important for work on harmful algal blooms in marine aquaculture. It is shown that it is difficult for people to categorise specimens from species with significant morphological variation, perhaps with morphologies overlapping with those of other species. Trained personnel can be expected to achieve 67 to 83% self-consistency and 43% consensus between people in an expert taxonomic labelling task. Experts who are routinely engaged in particular discriminations can return accuracies in the range of 84 to 95%. In general, neither human nor machine can be expected to give highly accurate or repeatable labelling of specimens. It is also shown that automation methods can perform as well as humans on these complex categorisations."																				
2002	"EjrnÆs, Rasmus; Aude, Erik; Nygaard, Bettina; Münier, Bernd"	Prediction of Habitat Quality Using Ordination and Neural Networks	Environmental	DNN	Classification	Ecological Applications	12	4	1180-1187	10.1890/1051-0761(2002)012[1180:POHQUO]2.0.CO;2	https://onlinelibrary.wiley.com/doi/abs/10.1890/1051-0761%282002%29012%5B1180%3APOHQUO%5D2.0.CO%3B2	"The development of an automatic classification model for prediction of conservation value is described. The classifier combines ordination and neural network (NN). The classifier was trained to predict the probability of a sample being of potential conservation interest. The neural network was trained on a priori classified data and used sample scores derived from ordination for prediction. The complexity of the NN classifier and the selection of the optimal ordination method were guided by cross-validation of a series of candidate models. The conservation value of a test data set was predicted by the NN classifier, and this classification was evaluated in terms of species richness, nativeness, rarity, and _ diversity. Finally, we evaluated the capability of the approach to handle new samples not included in the ordination. These samples were derived from habitats of threatened vascular plants, and they were all successfully predicted to be valuable. It is shown that the combination of ordination and neural networks successfully reproduces the a priori classification. It is further demonstrated on a test data set which the classifier discriminates with respect to traditional measures of conservation interest such as rarity, nativeness, and diversity. The developed method may be seen as a promising approach to assessment of biological integrity at the scale of plant communities, and further opportunities for its application are suggested."																				
2002	"Hilbert, David W.; Ostendorf, Bertram; Hopkins, Mike S."	Sensitivity of tropical forests to climate change in the humid tropics of north Queensland	Environmental	DNN	Classification	Austral Ecology	26	6	590-603	10.1046/j.1442-9993.2001.01137.x	https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1442-9993.2001.01137.x	"An analysis using an artificial neural network model suggests that the tropical forests of north Queensland are highly sensitive to climate change within the range that is likely to occur in the next 50–100 years. The distribution and extent of environments suitable for 15 structural forest types were estimated, using the model, in 10 climate scenarios that include warming up to 1°C and altered precipitation from –10% to +20%. Large changes in the distribution of forest environments are predicted with even minor climate change. Increased precipitation favours some rainforest types, whereas decreased rainfall increases the area suitable for forests dominated by sclerophyllous genera such as Eucalyptus and Allocasuarina. Rainforest environments respond differentially to increased temperature. The area of lowland mesophyll vine forest environments increases with warming, whereas upland complex notophyll vine forest environments respond either positively or negatively to temperature, depending on precipitation. Highland rainforest environments (simple notophyll and simple microphyll vine fern forests and thickets), the habitat for many of the region’s endemic vertebrates, decrease by 50% with only a 1°C warming. Estimates of the stress to present forests resulting from spatial shifts of forest environments (assuming no change in the present forest distributions) indicate that several forest types would be highly stressed by a 1°C warming and most are sensitive to any change in rainfall. Most forests will experience climates in the near future that are more appropriate to some other structural forest type. Thus, the propensity for ecological change in the region is high and, in the long term, significant shifts in the extent and spatial distribution of forests are likely. A detailed spatial analysis of the sensitivity to climate change indicates that the strongest effects of climate change will be experienced at boundaries between forest classes and in ecotonal communities between rainforest and open woodland."																				
2002	"Moore, A; Miller, R H"	Automated Identification of Optically Sensed Aphid (Homoptera: Aphidae) Wingbeat Waveforms	Sound	DNN	Classification	Annals of the Entomological Society of America	95	1	8-Jan	10.1603/0013-8746(2002)095[0001:AIOOSA]2.0.CO;2	https://academic.oup.com/aesa/article/95/1/1/2759125	"An optical sensor was used to make digital recordings of wingbeat waveforms for the five most common aphids found on Guam: Aphis craccivora Koch, A. gossypii Glover, A. nerii Fonscolombe, Pentalonia nigronervosa Coquerel, and Toxoptera citricida (Kirkaldy). Wingbeat frequencies for each species overlapped all other species. However, mean wingbeat frequencies were significantly different for all species. Wingbeat frequencies and harmonic patterns were extracted from the recordings and submitted to cluster analysis, which failed to separate species completely. Several nearest neighbor and probabilistic neural network classifiers were built using time series, frequency spectra, wingbeat frequencies, and harmonic patterns as input variables. These classifiers were evaluated by having them identify wingbeat waveforms from aphids collected and recorded after their construction. The best performing classifier model was a probabilistic artificial neural network trained using 256-bin frequency spectra as input. Sixty-nine percent of the waveforms presented to this network were identified correctly. This study demonstrates the feasibility of developing an insect flight monitor that automatically counts and identifies individual flying insects. Essential components of the monitoring system are a photosensor, a multimedia personal computer, and software that identifies wingbeat frequency spectra using an artificial neural network."																				
2002	"Niv, Yael; Joel, Daphna; Meilijson, Isaac; Ruppin, Eytan"	Evolution of reinforcement learning in foraging bees: a simple explanation for risk averse behavior	Other	Other	Modeling	Neurocomputing	44-46		951-956	10.1016/S0925-2312(02)00496-4	https://www.sciencedirect.com/science/article/pii/S0925231202004964	"Reinforcement learning is a fundamental process by which organisms learn to achieve goals from their interactions with the environment. We use evolutionary computation techniques to derive (near-)optimal neuronal learning rules in a simple neural network model of decision-making in simulated bumblebees foraging for nectar. The resulting bees exhibit efficient reinforcement learning. The evolved synaptic plasticity dynamics give rise to varying exploration/exploitation levels and to the well-documented foraging strategy of risk aversion. This behavior is shown to emerge directly from optimal reinforcement learning, providing a biologically founded, parsimonious and novel explanation of risk-averse behavior."																				
2002	"Pearson, R. G; Dawson, T. P; Berry, P. M; Harrison, P. A"	SPECIES: A Spatial Evaluation of Climate Impact on the Envelope of Species	Environmental	DNN	Modeling	Ecological Modelling	154	3	289-300	10.1016/S0304-3800(02)00056-X	https://www.sciencedirect.com/science/article/pii/S030438000200056X	"A model, A Spatial Evaluation of Climate Impact on the Envelope of Species (SPECIES), is presented which has been developed to evaluate the impacts of climate change on the bioclimatic envelope of plant species in Great Britain. SPECIES couples an artificial neural network with a climate–hydrological process model. The hybrid model has been successfully trained to estimate current species distributions using climate and soils data at the European scale before application at a finer resolution national scale. Using this multi-scale approach ensures encapsulation of the full extent of future climate scenarios within Great Britain without extrapolating outside of the model's training dataset. Application of the model to 32 plant species produced a mean Pearson correlation coefficient of 0.841 and a mean Kappa statistic of 0.772 between observed and simulated distributions. Simulations of four climate change scenarios revealed that changes to suitable climate space in Great Britain is highly species dependent and that distribution changes may be multidirectional and temporally non-linear. Analysis of the SPECIES results suggests that the neural network methodology can provide a feasible alternative to more classical spatial statistical techniques."																				
2003	"Aitkenhead, M. J.; Dalgetty, I. A.; Mullins, C. E.; McDonald, A. J. S.; Strachan, N. J. C."	Weed and crop discrimination using image analysis and artificial intelligence methods	Images	DNN	Classification	Computers and Electronics in Agriculture	39	3	157-171	10.1016/S0168-1699(03)00076-0	https://www.sciencedirect.com/science/article/pii/S0168169903000760	"Development of a visual method of discriminating between crop seedlings and weeds is an important and necessary step towards the automation of non-chemical weed control systems in agriculture, and towards the reduction in chemical use through spot spraying. Two methods were applied to recognise carrot (Daucus carota L.) seedlings from those of ryegrass (Lolium perenne) and Fat Hen (Chenopodium album) using digital imaging. The first method involved the use of a simple morphological characteristic measurement of leaf shape (perimeter2/area), which had varying effectiveness (between 52 and 74%) in discriminating between the two types of plant, with the variation dependent on plant size. The second involved a self-organising neural network more biologically plausible than many commonly used NN methods. While the latter did not give results as good as those required for commercial purposes, it showed that a neural network-based methodology exists which allows the system to learn and discriminate between species to an accuracy exceeding 75% without predefined plant descriptions being necessary."																				
2003	"Clark, Jonathan Y"	Artificial neural networks for species identification by taxonomists	Other	DNN	Classification	Biosystems	72	1	131-147	10.1016/S0303-2647(03)00139-4	https://www.sciencedirect.com/science/article/pii/S0303264703001394	"This paper is a study of the value of applying artificial neural networks (ANNs), specifically a multilayer perceptron (MLP), to identification of higher plants using morphological characters collected by conventional means. A practical methodology is thus demonstrated to enable botanical or zoological taxonomists to use ANNs as advisory tools for identification purposes. A comparison is made between the ability of the neural network and that of traditional methods for plant identification by means of a case study in the flowering plant genus Lithops N.E. Brown (Aizoaceae). In particular, a comparison is made with taxonomic keys generated by means of the DELTA system. The ANN is found to perform better than the DELTA key generator, for conditions where the available data is limited, and species relatively difficult to distinguish."																				
2003	"Corne, Simon A.; Carver, Stephen J.; Kunin, William E.; Lennon, Jack J.; van Hees, Willem W. S. van"	Predicting Forest Attributes in Southeast Alaska Using Artificial Neural Networks	Environmental	DNN	Classification	Forest Science	50	2	259-276	10.1093/forestscience/50.2.259	https://academic.oup.com/forestscience/article/50/2/259/4617257	"Artificial neural network (ANN) methods are used to predict forest characteristics. The data source is the Southeast Alaska (SEAK) Grid Inventory, a ground survey compiled by the USDA Forest Service at several thousand sites. The main objective of this article is to predict characteristics at unsurveyed locations between grid sites. A secondary objective is to evaluate the relative performance of different ANNs. Data from the grid sites are used to train six ANNs: multilayer perceptron, fuzzy ARTMAP, probabilistic, generalized regression, radial basis function, and learning vector quantization. A classification and regression tree method is used for comparison. Topographic variables are used to construct models: latitude and longitude coordinates, elevation, slope, and aspect. The models classify three forest characteristics: crown closure, species land cover, and tree size/structure. Models are constructed using n-fold cross-validation. Predictive accuracy is calculated using a method that accounts for the influence of misclassification as well as measuring correct classifications. The probabilistic and generalized regression networks are found to be the most accurate. The predictions of the ANN models are compared with a classification of the Tongass national forest in southeast Alaska based on the interpretation of satellite imagery and are found to be of similar accuracy. FOR. SCI. 50(2):259–276."																				
2003	"Embleton, K. V.; Gibson, C. E.; Heaney, S. I."	Automated counting of phytoplankton by pattern recognition: a comparison with a manual counting method	Images	DNN	Regression	Journal of Plankton Research	25	6	669-681	10.1093/plankt/25.6.669	https://doi.org/10.1093/plankt/25.6.669	"Computer-based image analysis and pattern recognition methods were used to construct a system able automatically to identify, count and measure selected groups of phytoplankton. An image analysis algorithm was employed to isolate and measure objects from digitized images of a phytoplankton sample. The measurements obtained were used to identify selected groups of phytoplankton by a combination of artificial neural networks and simple rule-based procedures. The system was trained and tested using samples of lake water covering an annual growth cycle from Lough Neagh in Northern Ireland. Total volume estimates were obtained for the four major phytoplankton species, using both the automated system and a manual counting method. Estimates of total cell volume obtained from the automated system were within 10% of those derived by manual analysis of the same cells. The automated system produced total cell volume estimates close to those obtained from manual analysis of different aliquots of the same water sample. Variation between successive counts of the same water sample was higher with the automated system than with the manual counting method. Limitations and possible improvements to the technology are discussed."																				
2004	"Broders, Hugh G.; Findlay, C. Scott; Zheng, Ligang"	Effects of Clutter on Echolocation Call Structure of Myotis septentrionalisand M. lucifugus	Sound	Other	Classification	Journal of Mammalogy	85	2	273-281	10.1644/BWG-102	https://doi.org/10.1644/BWG-102	"The structure of echolocation calls, and the distance over which bats perceive their environment, varies with the amount of structural clutter through which they are flying. Clutter and species had significant effects on the frequency-time characteristics of search-phase echolocation calls of northern long-eared (Myotis septentrionalis) and little brown bats (M. lucifugus). We tested an a priori derived model that predicted the pattern of differences in echolocation call variable values among clutter categories would provide insight into the relative maximum distances that bat species could perceive using echolocation. Specifically, the model predicted that species adapted to flying and foraging in cluttered habitats would have a shorter maximum perceptual distance than species adapted to flying and foraging in uncluttered habitats. The results supported this model and suggest the clutter-adapted M. septentrionalis had a shorter maximum perceptual distance than M. lucifugus, a species known to forage in a variety of habitats but mainly in uncluttered areas (i.e., over water). Using calls as the sampling unit, a neural network correctly classified &gt;94% of the echolocation calls to species in high clutter. In medium and low clutter, &gt;82% of the calls were correctly classified to species; however &gt;90% correct classification was achieved by leaving &gt;30% of calls unclassified. Researchers should develop clutter-specific call libraries to improve species classification accuracy for echolocation calls."																				
2004	"Fuller, D. O."	Remote detection of invasive Melaleuca trees (Melaleuca quinquenervia) in South Florida with multispectral IKONOS imagery	Other	DNN	Classification	International Journal of Remote Sensing	26	5	1057-1063	10.1080/01430060512331314119	https://www.tandfonline.com/doi/abs/10.1080/01430060512331314119?journalCode=tres20	"The distribution of invasive Melaleuca (Melaleuca quinquenervia (Cav.) S.T. Blake) was mapped using 4_m spatial resolution, multispectral IKONOS imagery in an area of south Florida along the eastern edge of Everglades National Park. Detection of Melaleuca stands was achieved using a back_propagation neural network classifier, which allowed identification of dense stands, but in some instances misclassified other woody canopies as Melaleuca. The use of IKONOS multispectral imagery to detect low_density occurrences of Melaleuca appears limited relative to traditional methods of aerial photographic interpretation. However, analysis of landscape_level distribution of moderate_to_dense Melaleuca, using Fragstats, indicated a highly aggregated Melaleuca distribution relative to other woody vegetation patches. The distribution of Melaleuca stands was associated with cultural features in the suburban environment such as canals and roads, which may act as dispersal corridors for seeds. Thus, classified IKONOS imagery may be useful for inferring landscape patterns that relate to the persistence and spread of Melaleuca and other invasive species."																				
2004	"Power, A. M.; Balbuena, J. A.; Raga, J. A."	Parasite infracommunities as predictors of harvest location of bogue (Boops boops L.): a pilot study using statistical classifiers	Environmental	DNN	Classification	Fisheries Research	72	2	229-239	10.1016/j.fishres.2004.10.001	https://www.sciencedirect.com/science/article/pii/S0165783604002486	"The accuracy of classifying bogue (Boops boops) according to the fishery from which it was harvested was evaluated by applying several statistical classification techniques to fish parasite abundances. Bogue captured in 2001 in two fisheries off the Atlantic coast of Spain were compared with one off the Spanish Mediterranean coast. One hundred bogue were classified to each harvest location (fishery) using different numbers of parasite species chosen as predictors by a best subset method. Two parametric methods of classification (linear and quadratic discriminant analysis) were compared with two non-parametric approaches (k-nearest neighbour classification and feed-forward neural network) and the cross-validated correct classification rate determined in each case. The best results were achieved for k-nearest neighbour classification with 96% of fish being correctly assigned to their fishery. That result was based on five predictor parasite species, namely Aphanurus stossichii, Bacciger israelensis, Hemiurus communis, Microcotyle erythrini and Lecithocladium excisum. The optimal classification for a feed-forward neural network was very similar to that achieved with linear discriminant analysis at 94% correct classification rate for only four predictor species. Quadratic discriminant analysis performed worst of the four classification methods examined. Classification accuracies for all four statistical approaches were, however, remarkably similar and were quite accurate with only between 4 and 8% of fish incorrectly classified regardless of the method used. With greater temporal and spatial resolution of sampling effort, this technique holds promise as a cost-effective method of distinguishing harvest locations of bogue that can readily be adapted to other fish species."																				
2004	"Voisin, Sébastien; Terreux, Raphaël; Renaud, François N.R.; Freney, Jean; Domard, Monique; Deruaz, Daniel"	Pyrolysis patterns of 5 close Corynebacterium species analyzed by artificial neural networks	Other	DNN	Classification	Antonie van Leeuwenhoek	85	4	287-296	10.1023/B:ANTO.0000020165.21866.67	https://link.springer.com/article/10.1023/B:ANTO.0000020165.21866.67	"In the present study, an artificial neural network was trained with the Stuttgart Neural Networks Simulator, in order to identify Corynebacterium species by analyzing their pyrolysis patterns. An earlier study described the combination of pyrolysis, gas chromatography and atomic emission detection we used on whole cell bacteria. Carbon, sulfur and nitrogen were detected in the pyrolysis compounds. Pyrolysis patterns were obtained from 52 Corynebacterium strains belonging to 5 close species. These data were previously analyzed by Euclidean distances calculation followed by Unweighted Pair Group Method of Averages, a clustering method. With this early method, strains from 3 of the 5 species (C. xerosis, C. freneyi and C. amycolatum) were correctly characterized even if the 29 strains of C. amycolatum were grouped into 2 subgroups. Strains from the 2 remaining species (C. minutissimum and C. striatum) cannot be separated. To build an artificial neural network, able to discriminate the 5 previous species, the pyrolysis data of 42 selected strains were used as learning set and the 10 remaining strains as testing set. The chosen learning algorithm was Back-Propagation with Momentum. Parameters used to train a correct network are described here, and the results analyzed. The obtained artificial neural network has the following cone-shaped structure: 144 nodes in input, 25 and 9 nodes in 2 successive hidden layers, and then 5 outputs. It could classify all the strains in their species group. This network completes a chemotaxonomic method for Corynebacterium identification."																				
2004	"Yen, P.P.W.; Huettmann, F.; Cooke, F."	"A large-scale model for the at-sea distribution and abundance of marbled murrelets (Brachyramphus marmoratus) during the breeding season in coastal British Columbia, Canada"	Environmental	DNN	Regression	Ecological Modelling	171	4	395-413	10.1016/j.ecolmodel.2003.07.006	https://linkinghub.elsevier.com/retrieve/pii/S0304380003003570	"The role that the marine environment plays in the distribution and abundance of Marbled Murrelets (Brachyramphus marmoratus), a seabird which nests in old-growth forests, is not well understood. Therefore, we investigated how Marbled Murrelet marine distribution and abundance is related to the abiotic and biotic components of the marine environment. Data on the marine distribution of Marbled Murrelets in British Columbia (BC), densities (birds/km2; 1972–1993), counts (number of birds per survey; 1922–1989), and pertinent environmental variables as identified from the literature were compiled and then organized in a Geographic Information System (GIS). On a 10 km scale, count surveys were not correlated with density surveys (r2=0.01, P=0.46). This suggests the interpretation of count survey data (relative abundance) should be done with care; and it is not further used in this study. We built a parsimonious model to explain marine densities with marine predictors. First, significant predictors were identified with multivariate Generalized Linear Models (GLMs) by evaluating the shortest distances from survey locations to predictor variables. Murrelet density is higher close to sandy substrate, estuaries and cooler sea temperatures, and lower close to glaciers and herring spawn areas. Model predictors selected by using P-values and AIC include sea surface temperature, herring spawn index, estuary locations, distribution of sand and fine gravel substrates (as a proxy for sand lance distribution), and proximity to glaciers. Secondly, spatially explicit large-scale distribution model algorithms use this set of significant predictors to predict Marbled Murrelet abundance (density), distribution and populations in coastal BC. The modelling algorithms used include GLM, Classification and Regression Trees (CART) [Classification and Regression Trees, Wadsworth & Brooks, Pacific Grove, CA, 368 pp.; Software CART and MARS, San Diego, CA] and Tree (SPLUS) [Modern Applied Statistics with S-Plus, Statistics and Computing, 2nd ed., Springer, New York, 462 pp.], Multivariate Adaptive Regression Splines (MARS) [Software CART and MARS, San Diego, CA], and Artificial Neural Networks (ANNs) (SPLUS) [Modern Applied Statistics with S-Plus, Statistics and Computing, 2nd ed., Springer, New York 462 pp.]. Model performances were evaluated by backfitting, and by standardizing models. Tree-SPLUS was identified as the best performing model, and therefore used to predict the maximum carrying capacity of 170,500 birds for the marine habitat of coastal BC. An additional, a posteriori predictor, the shortest distance to old-growth forest, explained much of the remaining residual variance. This model result led us to a hypothesis of how Marbled Murrelet distribution and abundance relates to proximity to old-growth forests, and it makes an initial basic link between the marine and terrestrial aspects of Marbled Murrelet habitat. Our approach presents the first predictive abundance and distribution models applied to Marbled Murrelets on a large scale (British Columbia coast). Our approach is robust, and the statistical algorithms compared here are fully described and are known to perform well. Our findings are crucial for decision making and consider conservation management on a scale pertinent for the habitat protection of this species."																				
2005	"_erná, Lenka; Chytr_, Milan"	Supervised Classification of Plant Communities with Artificial Neural Networks	Environmental	DNN	Classification	Journal of Vegetation Science	16	4	407-414	NA	https://www.jstor.org/stable/4096621	"Questions: Are artificial neural networks useful for the automatic assignment of species composition records from vegetation plots to a priori established classes (vegetation units)? Is the assignment more accurate (1) if the classes are defined by numerical classification rather than by expert-based classification; (2) if the training data set is selected to include plots that are richer in diagnostic species of particular classes? Material: Species composition records (relevés) from 4186 plots of Czech grasslands. Methods: Plots were classified into 11 phytosociological alliances (expert classification) and into 11 clusters derived from numerical cluster analysis. Some plots were used for training the classifiers, which were the multi-layer perceptrons (MLP; a type of artificial neural network). Other plots were used for testing the performance of these classifiers. Plots used for training were selected (1) randomly; (2) according to higher representation of diagnostic species of particular classes. Results: Different MLP classifiers correctly classified 77-83% of plots to the classes of the expert classification and 70-78% to the classes of the numerical classification. The better result in the former case was mainly due to two classes in the expert classification, which were well recognized by the classifiers and at the same time contained a large proportion of the plots of the entire data set. Correct classification of the plots belonging to these large classes resulted in a good overall performance of the classifiers. After training with randomly chosen plots, the classifiers produced better results than after training with plots that contained more diagnostic species. This indicates that the biased selection of the training plots disables the classifiers to recognize the entire variation within the classes and results in errors when new plots are to be classified. Conclusions: MLP is suitable for assigning vegetation plots to already established classes. Unlike some other methods of supervised classification, it performs well even in communities that are poor in diagnostic species. However, the method does not provide clear assignment keys that could be used for class identification in field surveys. It is therefore more appropriate in applications that aim at a reliable class assignment rather than understanding the assignment rules."																				
2005	"Du, Jixiang; Huang, Deshuang; Wang, Xiaofeng; Gu, Xiao"	Shape Recognition Based on Radial Basis Probabilistic Neural Network and Application to Plant Species Identification	Images	Other	Classification	Advances in Neural Networks – ISNN 2005			281-285	10.1007/11427445_45	https://link.springer.com/chapter/10.1007/11427445_45	"In this paper, a novel shape recognition method based on radial basis probabilistic neural network (RBPNN) is proposed. The orthogonal least square algorithm (OLSA) is used to train the RBPNN and the recursive OLSA is adopted to optimize the structure of the RBPNN. A leaf image database is used to test the proposed method. And a modified Fourier method is applied to descript the shape of the plant leaf. The experimental result shows that the RBPNN achieves higher recognition rate and better classification efficiency with respect to radial basis function neural network (RBFNN), BP neural network (BPNN) and multi-Layer perceptron network (MLPN) for the plant species identification."																				
2005	"Granitto, Pablo M.; Verdes, Pablo F.; Ceccatto, H. Alejandro"	Large-scale investigation of weed seed identification by machine vision	Images	DNN	Classification	Computers and Electronics in Agriculture	47	1	15-24	10.1016/j.compag.2004.10.003	https://www.sciencedirect.com/science/article/pii/S016816990400122X	"We explore the feasibility of implementing fast and reliable computer-based systems for the automatic identification of weed seeds from color and black and white images. Seeds size, shape, color and texture characteristics are obtained by standard image-processing techniques, and their discriminating power as classification features is assessed. These investigations are performed on a database much larger than those used in previous studies, containing 10,310 images of 236 different weed species. We consider the implementation of a simple Bayesian approach (naïve Bayes classifier) and (single and bagged) artificial neural network systems for seed identification. Our results indicate that the naïve Bayes classifier based on an adequately selected set of classification features has an excellent performance, competitive with that of the comparatively more sophisticated neural network approach. In addition, we discuss the possibility of using only morphological and textural characteristics as classification features, which would reduce the operational complexity and hardware cost of a commercial system since they can be obtained from black and white images. We find that, under particular operational conditions, this would result in a relatively small loss in performance when compared to the implementation based on color images."																				
2005	"Hu, Qiao; Davis, Cabell"	Accurate automatic quantification of taxa-specific plankton abundance using dual classification with correction	Images	Other	Classification	Marine Ecology Progress Series	306		51-61	10.3354/meps306051	https://www.int-res.com/abstracts/meps/v306/p51-61/	"Optical imaging samplers are becoming widely used in plankton ecology, but image analysis methods have lagged behind image acquisition rates. Automated methods for analysis and recognition of plankton images have been developed, which are capable of real-time processing of incoming image data into major taxonomic groups. The limited accuracy of these methods can require significant manual post-processing to correct the automatically generated results, in order to obtain accurate estimates of plankton abundance patterns. We present here a dual-classification method in which each plankton image is first identified using a shaped-based feature set and a neural network classifier, and then a second time using a texture-based feature set and a support vector machine classifier. The plankton image is considered to belong to a given taxon only if the 2 identifications agree; otherwise it is labeled as unknown. This dual-classification method greatly reduces the false positive rate, and thus gives better abundance estimation in regions of low relative abundance. A confusion matrix is computed from a set of training images in order to determine the detection and false positives rates. These rates are used to correct abundances estimated from the automatic classification results. Aside from the manual sorting required to generate the initial training set of images, this dual-classification method is fully automatic and does not require subsequent manual correction of automatically sorted images. The resulting abundances agree closely with those obtained using manually sorted results. A set of images from a Video Plankton Recorder was used to evaluate this method and compare it with previously reported single-classifier results for major taxa."																				
2005	"Khalifa, Nour Eldeen M; Loey, Mohamed; Taha, Mohamed Hamed N"	Insect pests recognition based on deep transfer learning models	Images	CNN	Classification	Journal of Theoretical and Applied Information Technology	98	1	9	10.6084/m9.figshare.13271123	http://dx.doi.org/10.6084/m9.figshare.13271123	"Agriculture is one of the most important sources for human food throughout the history of humankind. In many countries, agriculture is the foundation of its economy, and more than 90% of its population deriving their livelihoods from it. Insect pests are one of the main factors affecting agricultural crop production. With the advances of computer algorithms and artificial intelligence, accurate and speedy recognition of insect pests in early stages may help in avoiding economic losses in short and long term. In this paper, an insect pest recognition based on deep transfer learning models will be presented. The IP102 insect pest dataset was selected in this research. The IP102 dataset consists of 27500 images and contains 102 classes of insect pests, it is considered one the biggest dataset for insect pest and was launched in 2019. Through the paper, AlexNet, GoogleNet, and SqueezNet were the selected deep transfer learning models. Those models were selected based on their small number of layers on their architectures, which will reflect in reducing the complexity of the models and the consumed memory and time. Data augmentation techniques were used to render the models more robust and to overcome the overfitting problem by increasing the dataset images up to 4 times than original images. The testing accuracy and performance metrics, such as the precision, recall, and F1 score, were calculated to prove the robustness of the selected models. The AlexNet model achieved the highest testing accuracy at 89.33%. In addition, it has a minimum number of layers, which decreases the training time and computational complexity. Moreover, the choice of data augmentation techniques played an important role in achieving better results. Finally, A comparison results were carried out at the end of the research with related work which used the same dataset IP102. The presented work achieved a superior result than the related work in terms of testing accuracy, precision, recall, and F1 score."																				
2006	"Björklund, Mats"	Mate choice for indirect benefits displayed by a large ornament: simulations using a neural network	Other	DNN	Modeling	Animal Behaviour	71	3	549-553	10.1016/j.anbehav.2005.05.018	https://www.sciencedirect.com/science/article/pii/S0003347206000091	"I analysed mate choice for indirect genetic benefits displayed by an ornament theoretically by means of a neural network model. In particular, the fitness of a choosy female was compared to that of a nonchoosy one under various ecological conditions such as variation in ornament size between males, the cost of searching, the heritability of the ornament and a correlation between ‘good genes’ and the phenotypic expression of the ornament. Females were allowed to choose between either six or 43 males with ornaments of various sizes. They were allowed to compare males until the largest of the presented males was chosen. I found that choosiness was favoured with increasing variation in ornament size between males, combined with a high heritability of the ornament, a very high correlation between the ‘good genes’ and the phenotype, and low search costs. In general, as the correlation between the ‘good genes’ and the phenotype decreased the variance in expected fitness of choosy females increased. The results suggest that the conditions favouring this type of mate choice are restrictive and apply only to a small set of species."																				
2006	"Deecke, Volker B.; Janik, Vincent M."	Automated categorization of bioacoustic signals: Avoiding perceptual pitfalls	Sound	Other	Modeling	The Journal of the Acoustical Society of America	119	1	645-653	10.1121/1.2139067	https://asa.scitation.org/doi/abs/10.1121/1.2139067	"Dividing the acoustic repertoires of animals into biologically relevant categories presents a widespread problem in the study of animal sound communication, essential to any comparison of repertoires between contexts, individuals, populations, or species. Automated procedures allow rapid, repeatable, and objective categorization, but often perform poorly at detecting biologically meaningful sound classes. Arguably this is because many automated methods fail to address the nonlinearities of animal sound perception. We present a new method of categorization that incorporates dynamic time-warping and an adaptive resonance theory (ART) neural network. This method was tested on 104 randomly chosen whistle contours from four captive bottlenose dolphins (Tursiops truncatus), as well as 50 frequency contours extracted from calls of transient killer whales (Orcinus orca). The dolphin data included known biologically meaningful categories in the form of 42 stereotyped whistles produced when each individual was isolated from its group. The automated procedure correctly grouped all but two stereotyped whistles into separate categories, thus performing as well as human observers. The categorization of killer whale calls largely corresponded to visual and aural categorizations by other researchers. These results suggest that this methodology provides a repeatable and objective means of dividing bioacoustic signals into biologically meaningful categories."																				
2006	"Francois, Patrice; Charbonnier, Yvan; Jacquet, Jean; Utinger, Dominic; Bento, Manuela; Lew, Daniel; Kresbach, Gerhard M.; Ehrat, Markus; Schlegel, Werner; Schrenzel, Jacques"	Rapid bacterial identification using evanescent-waveguide oligonucleotide microarray classification	Molecular	DNN	Classification	Journal of Microbiological Methods	65	3	390-403	10.1016/j.mimet.2005.08.012	https://www.sciencedirect.com/science/article/pii/S016770120500268X	"Bacterial identification relies primarily on culture-based methodologies and requires 48–72 h to deliver results. We developed and used i) a bioinformatics strategy to select oligonucleotide signature probes, ii) a rapid procedure for RNA labelling and hybridization, iii) an evanescent-waveguide oligoarray with exquisite signal/noise performance, and iv) informatics methods for microarray data analysis. Unique 19-mer signature oligonucleotides were selected in the 5_-end of 16s rDNA genes of human pathogenic bacteria. Oligonucleotides spotted onto a Ta2O5-coated microarray surface were incubated with chemically labelled total bacterial RNA. Rapid hybridization and stringent washings were performed before scanning and analyzing the slide. In the present paper, the eight most abundant bacterial pathogens representing >54% of positive blood cultures were selected. Hierarchical clustering analysis of hybridization data revealed characteristic patterns, even for closely related species. We then evaluated artificial intelligence-based approaches that outperformed conventional threshold-based identification schemes on cognate probes. At this stage, the complete procedure applied to spiked blood cultures was completed in less than 6 h. In conclusion, when coupled to optimal signal detection strategy, microarrays provide bacterial identification within a few hours post-sampling, allowing targeted antimicrobial prescription."																				
2006	"Özesmi, Stacy L.; Tan, Can O.; Özesmi, Uygar"	"Methodological issues in building, training, and testing artificial neural networks in ecological applications"	NA	NA	Review	Ecological Modelling	195	1	83-93	10.1016/j.ecolmodel.2005.11.012	https://www.sciencedirect.com/science/article/pii/S0304380005005806	"We evaluate the use of artificial neural networks, particularly the feedforward multilayer perceptron with back-propagation for training (MLP), in ecological modelling and make suggestions on its use. In MLP modelling, there are no assumptions about the underlying form of the data that must be met as in standard statistical techniques. Instead, researchers must clarify the process of modelling, as this is most critical to how the model performs and is interpreted. Overfitting on the data, a potential problem, can be avoided by limiting the complexity of the model and by using techniques such as weight decay, training with noise, and limiting the training of the network. Methods on when to stop training include: (1) early stopping based on cross-validation, (2) stopping after a analyst defined error is reached or after the error levels off, and (3) use of a test data set. The third method is not ideal as the test data set is then not independent of model development and the resulting model may have little generalizability. The importance of an independent data set cannot be overemphasized as we found dramatic differences in model accuracy assessed with prediction accuracy on the training data set, as estimated with bootstrapping, and from use of an independent data set. The comparison of the artificial neural network with a general linear model (GLM) as a standard procedure is recommended because a GLM may perform as well or better than the MLP. In such cases, there are no interactions or non-linear terms that need to be modelled and it will save time to use the GLM. Techniques such as sensitivity analyses, input variable relevances, neural interpretation diagrams, randomization tests, and partial derivatives should be used to make MLP models more transparent, and further our ecological understanding, an important goal of the modelling process. Based on our experience we discuss how to build an MLP model and how to optimize the parameters and architecture. The process should be explained explicitly to make the MLP models more readily accepted by the ecological research community at large, as well as to make it possible to replicate the research."																				
2006	"Peters, Richard A.; Davis, Colin J."	Discriminating signal from noise: Recognition of a movement-based animal display by artificial neural networks	Video	"DNN, RNN"	Regression	Behavioural Processes	72	1	52-64	10.1016/j.beproc.2005.12.002	https://www.sciencedirect.com/science/article/pii/S0376635705002433	"In this study, we investigated the feasibility of applying neural networks to understanding movement-based visual signals. Networks based on three different models were constructed, varying in their input format and network architecture: a Static Input model, a Dynamic Input model and a Feedback model. The task for all networks was to distinguish a lizard (Amphibolurus muricatus) tail-flick from background plant movement. Networks based on all models were able to distinguish the two types of visual motion, and generalised successfully to unseen exemplars. We used curves defined by the receiver-operating characteristic (ROC) to select a single network from each model to be used in regression analyses of network response and several motion variables. Collectively, the models predicted that tail-flick efficacy would be enhanced by faster speeds, greater acceleration and longer durations."																				
2006	"Pfennig, Karin S; Ryan, Michael J"	Reproductive character displacement generates reproductive isolation among conspecific populations: an artificial neural network study	Other	RNN	Modeling	Proceedings of the Royal Society B: Biological Sciences	273	1592	1361-1368	10.1098/rspb.2005.3446	https://royalsocietypublishing.org/doi/10.1098/rspb.2005.3446	"When interactions with heterospecifics prevent females from identifying conspecific mates, natural selection can promote the evolution of mating behaviours that minimize such interactions. Consequently, mating behaviours may diverge among conspecific populations in sympatry and in allopatry with heterospecifics. This divergence in conspecific mating behaviours—reproductive character displacement—can initiate speciation if mating behaviours become so divergent as to generate reproductive isolation between sympatric and allopatric conspecifics. We tested these ideas by using artificial neural networks to simulate the evolution of conspecific mate recognition in populations sympatric and allopatric with different heterospecifics. We found that advertisement calls diverged among the different conspecific populations. Consequently, networks strongly preferred calls from their own population to those from foreign conspecific populations. Thus, reproductive character displacement may promote reproductive isolation and, ultimately, speciation among conspecific populations."																				
2006	"Phelps, Steven M"	Sensory ecology and perceptual allocation: new prospects for neural networks	NA	NA	Review	Philosophical Transactions of the Royal Society B: Biological Sciences	362	1479	355-367	10.1098/rstb.2006.1963	https://royalsocietypublishing.org/doi/10.1098/rstb.2006.1963	"Sensory ecology provides a conceptual framework for considering how animals ought to design sensory systems to capture meaningful information from their environments. The framework has been particularly successful at describing how one should allocate sensory receptors to maximize performance on a given task. Neural networks, in contrast, have made unique contributions to understanding how ‘hidden preferences’ can emerge as a by-product of sensory design. The two frameworks comprise complementary techniques for understanding the design and the evolution of sensation. This article reviews empirical literature from multiple modalities and levels of sensory processing, considering vision, audition and touch from the viewpoints of sensory ecology and neuroethology. In the process, it presents modifications of extant neural network algorithms that would allow a more effective integration of these diverse approaches. Together, the reviewed literature suggests important advances that can be made by explicitly formulating neural network models in terms of sensory ecology, by incorporating neural costs into models of perceptual evolution and by exploring how such demands interact with historical forces."																				
2006	"Song, Mi-Young; Park, Young-Seuk; Kwak, Inn-Sil; Woo, Hyoseop; Chon, Tae-Soo"	Characterization of benthic macroinvertebrate communities in a restored stream by using self-organizing map	Environmental	DNN	Modeling	Ecological Informatics	1	3	295-305	10.1016/j.ecoinf.2005.12.001	https://www.sciencedirect.com/science/article/pii/S1574954106000574	"The Self-Organizing Map (SOM) was used for revealing the ecological states of streams in recovery through patterning of benthic macroinvertebrate communities. SOM was capable of showing different clusters of the sample sites in a small scale according to changes in environmental variables such as water velocity, depth, substrate roughness and the amount of silt. Community abundance correspondingly varied in different clusters of the sample sites. Within each cluster, data for community abundance were further grouped according to temporal changes in water quality. The patterns of benthic macroinvertebrate communities in the trained SOM were efficient in assessing recovery processes in the polluted sample sites, revealing the effects of river restoration projects in stream ecosystems. The study showed that spatial heterogeneity at the local level plays an important role in characterizing community patterns and consequently biological water quality assessment."																				
2006	"Worner, S. P.; Gevrey, Muriel"	Modelling global insect pest species assemblages to determine risk of invasion	Environmental	DNN	Modeling	Journal of Applied Ecology	43	5	858-867	10.1111/j.1365-2664.2006.01202.x	https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2664.2006.01202.x	"1 The many thousands of potential invasive species pose one of the greatest threats to global biodiversity world-wide. In this study we propose that assemblages of well-known global invasive pest species, irrespective of whether they arise by anthropogenic means, are non-random species groupings that contain hidden predictive information. Such information can assist the identification and prioritization of species that have the potential to pose an invasive threat in regions where they are not normally found. 2 Data comprising the presence and absence of 844 insect pest species recorded over 459 geographical regions world-wide were analysed using a self-organizing map (SOM), a well-known artificial neural network algorithm. The SOM analysis classified the high dimensional data into two-dimensional space such that geographical areas that had similar pest species assemblages were organized as neighbours on a map or grid. 3 The SOM analysis allowed each species to be ranked in terms of its risk of invasion in each area based on the strength of its association with the assemblage that was characteristic for each geographical region. A risk map for example species was produced to illustrate how such a map can be compared with the species’ actual distribution and used with other information, such as the species’ biotic characteristics and interactions with the abiotic environment, to improve pest risk assessments further. 4 Synthesis and applications. This study presents a new approach to the identification of potentially high-risk invasive pest species based on the hypothesis that global insect pest assemblages are non-random species groupings that can be subjected to traditional community analysis. A well-known data mining and knowledge discovery method for high dimensional data, SOM, was used to determine pest species assemblages for global regions. Species were ranked according to their potential for establishment based on their strength of association with the species assemblage that characterizes a particular region. Such an analysis can then be used to support additional risk assessment of potential invasive species, giving invasive species researchers, conservation managers, quarantine and biosecurity scientists a means for prioritizing species as candidates for further research."																				
2006	"Zhu, Bin; Zhao, Na; Shao, Zhaojun; Lek, Sovan; Chang, Jianbo"	Genetic population structure of Chinese sturgeon (Acipenser sinensis) in the Yangtze River revealed by artificial neural network	Molecular	DNN	Modeling	Journal of Applied Ichthyology	22	s1	82-88	10.1111/j.1439-0426.2007.00932.x	https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0426.2007.00932.x	"An extensive risk analysis should always precede a stocking program. In order to determine the genetic effects of the program, information on genetic composition of the population both prior and after the stocking program is required. Genetic variations within and among three annual spawning runs of Chinese sturgeon were measured by six microsatellites. We found substantial genetic variation remaining within all spawning runs, probably related to the recent nature of the population impact, the longevity of the species, and their apparent self-incompatibility. A subtle genetic structure was detected in the annual spawning runs by an unsupervised self-organizing model. Meanwhile these genetically differentiated spawning stocks may occur sympatrically on a small geographic scale. These results further suggest that the current supportive breeding of A. sinensis may require a careful identification of broodstocks in artificial propagation in order to avoid admixture and hybridization among these genetically different spawning stocks."																				
2007	"Aldrich, Benjamin T.; Maghirang, Elizabeth B.; Dowell, Floyd E.; Kambhampati, Srinivas"	Identification of termite species and subspecies of the genus Zootermopsis using near-infrared reflectance spectroscopy	Other	Unknown	Classification	Journal of Insect Science	7	1	18	10.1673/031.007.1801	https://doi.org/10.1673/031.007.1801	"Dampwood termites of the genus Zootermopsis (Isoptera: Termopsidae) are an abundant group of basal termites found in temperate forests of western North America. Three species are currently recognized in the genus and one of these species is subdivided into two subspecies. Although morphological and genetic characters are useful in differentiating among the three species and the two subspecies, respectively, only hydrocarbon analysis can enable differentiation both among the three species and the two subspecies. Due to the limitations of hydrocarbon analysis, such as the need for fresh specimens, alternative methods that could rapidly and accurately identify Zootermopsis would be useful. Using a partial least squares analysis of near-infrared spectra, each of the Zootermopsis species and subspecies were identified with greater than 95% and 80% accuracy, respectively. Neural network analysis of the near-infrared spectra successfully enabled the identification of the species and subspecies with greater than 99% accuracy. The inexpensive, reproducible, and rapid nature of near-infrared spectroscopy makes it a viable alternative to morphological, hydrocarbon, or genetic analysis for identifying Zootermopsis."																				
2007	"Bain, Roderick S; Rashed, Arash; Cowper, Verity J; Gilbert, Francis S; Sherratt, Thomas N"	The key mimetic features of hoverflies through avian eyes	Images	DNN	Modeling	Proceedings of the Royal Society B: Biological Sciences	274	1621	1949-1954	10.1098/rspb.2007.0458	https://royalsocietypublishing.org/doi/10.1098/rspb.2007.0458	"Batesian mimicry occurs when a palatable species (the mimic) gains protection from predators by resembling an unpalatable or otherwise protected species (the model). While some mimetic species resemble their models closely, other species (‘imperfect mimics’) are thought to bear only a crude likeness. In an earlier study, pigeons (Columba livia) were trained to recognize wasp images in one experiment and non-mimetic (NM) fly images in another by rewarding the pigeons for pecking on the respective image types. These pigeons were subsequently presented with different images, including seemingly wasp-like hoverfly species, and the recorded peck rates on these images were used as a measure of the pigeons' perception of the hoverflies' mimetic similarity. To identify a candidate set of morphological features that the pigeons used when assessing this mimetic similarity, we first extracted a range of biometrical measurements from images originally presented to the pigeons. We then repeatedly optimized an empirical model in an attempt to match the recorded pigeon peck rates while using as few biometrical features as input as possible. Our models were able to fit the pigeon peck rates with considerable accuracy even while excluding many input features. Antennal length, a feature commonly used to discriminate between flies and wasps, was regularly retained as an input variable, but overall a different set of biometrical features was important for predicting the peck rates of pigeons rewarded for identifying wasps compared to those rewarded for identifying NM flies. In highlighting the importance of specific biometrical features in promoting mimicry and the irrelevance of others, our optimized models provide an explanation as to why certain species that appear to be poor mimics to humans are judged to be good mimics by birds."																				
2007	"GANCHEV, TODOR; POTAMITIS, ILYAS"	Automatic Acoustic Identification of Singing Insects	Sound	Other	Classification	Bioacoustics	16	3	281-328	10.1080/09524622.2007.9753582	https://doi.org/10.1080/09524622.2007.9753582	"We report on our research efforts towards developing efficient equipment for the automatic recognition of insects using only the acoustic modality. Specifically, we deal with three groups of insects, namely the crickets, cicadas and katydids. Inspired by well-documented tactics of speech processing, the signal processing employed in the present work is elaborated further with respect to the sound production mechanisms of insects. In order to improve the practical efficacy of our equipment, we adopt a score-level fusion of classifiers with non-parametric (probabilistic neural network) and parametric (Gaussian mixture models) estimation of the probability density function. An efficient hierarchic classification scheme is introduced, where the identification of unlabelled input takes place at various levels of hierarchy, such as suborder, family, subfamily, genus and species. We evaluate the practical significance of our approach on a large and well-documented catalogue of recordings of crickets, cicadas and katydids. For the hierarchic classification scheme, we report identification accuracy that exceeds 99% at suborder and family levels. In the straight classification scheme, we report accuracy of 90% for 307 species."																				
2007	"Ginoris, Y. P.; Amaral, A. L.; Nicolau, A.; Coelho, M. A. Z.; Ferreira, E. C."	Development of an image analysis procedure for identifying protozoa and metazoa typical of activated sludge system	Images	DNN	Classification	Water Research	41	12	2581-2589	10.1016/j.watres.2007.02.006	https://www.sciencedirect.com/science/article/pii/S0043135407001042	"A procedure for the semi-automatic identification of the main protozoa and metazoa species present in the activated sludge of wastewater treatment plants was developed. This procedure was based on both image processing and multivariable statistical methodologies, leading to the use of the image analysis morphological descriptors by discriminant analysis and neural network techniques. The image analysis program written in Matlab has proved to be adequate in terms of protozoa and metazoa recognition, as well as for the operating conditions assessment."																				
2007	"Ginoris, Y. P.; Amaral, A. L.; Nicolau, A.; Coelho, M. A. Z.; Ferreira, E. C."	"Recognition of protozoa and metazoa using image analysis tools, discriminant analysis, neural networks and decision trees"	Images	DNN	Classification	Analytica Chimica Acta	595	1	160-169	10.1016/j.aca.2006.12.055	https://www.sciencedirect.com/science/article/pii/S0003267007000542	"Protozoa and metazoa are considered good indicators of the treatment quality in activated sludge systems due to the fact that these organisms are fairly sensitive to physical, chemical and operational processes. Therefore, it is possible to establish close relationships between the predominance of certain species or groups of species and several operational parameters of the plant, such as the biotic indices, namely the Sludge Biotic Index (SBI). This procedure requires the identification, classification and enumeration of the different species, which is usually achieved manually implying both time and expertise availability. Digital image analysis combined with multivariate statistical techniques has proved to be a useful tool to classify and quantify organisms in an automatic and not subjective way. This work presents a semi-automatic image analysis procedure for protozoa and metazoa recognition developed in Matlab language. The obtained morphological descriptors were analyzed using discriminant analysis, neural network and decision trees multivariable statistical techniques to identify and classify each protozoan or metazoan. The obtained procedure was quite adequate for distinguishing between the non-sessile protozoa classes and also for the metazoa classes, with high values for the overall species recognition with the exception of sessile protozoa. In terms of the wastewater conditions assessment the obtained results were found to be suitable for the prediction of these conditions. Finally, the discriminant analysis and neural networks results were found to be quite similar whereas the decision trees technique was less appropriate."																				
2007	"Goodacre, Royston; Roberts, Luned; Ellis, David I.; Thorogood, Danny; Reader, Stephen M.; Ougham, Helen; King, Ian"	From phenotype to genotype: whole tissue profiling for plant breeding	Other	DNN	Classification	Metabolomics	3	4	489-501	10.1007/s11306-007-0062-6	http://link.springer.com/10.1007/s11306-007-0062-6	"Fourier transform infrared spectroscopy (FT-IR) was used to obtain ‘holistic’ metabolic fingerprints from a wide range of plants to differentiate species, population, single plant genotype, and chromosomal constitution differences. Sample preparation simply entailed the maceration of fresh leaves with water, and these samples were then dried and analysed by reflectance FT-IR where spectral acquisition was typically 10 s. All samples gave reproducible, characteristic biological infrared absorption spectra and these were analysed by chemometric methods. FT-IR is not biased to any particular chemical species and thus the whole tissue profiles produced measure the total biochemical makeup of the test sample; that is to say it represents a plant phenotype. We show that by simple cluster analysis these phenotypic measurements can be related to the genotypes of the plants and can reliably differentiate closely related individuals. We believe that this approach provides a valuable new tool for the rapid metabolomic profiling of plants, with applications to plant breeding and the assessment of substantial equivalency for genetically-modified plants."																				
2007	"Merilaita, Sami"	Artificial neural networks and the study of evolution of prey coloration	NA	NA	Review	Philosophical Transactions of the Royal Society B: Biological Sciences	362	1479	421-430	10.1098/rstb.2006.1969	https://royalsocietypublishing.org/doi/10.1098/rstb.2006.1969	"In this paper, I investigate the use of artificial neural networks in the study of prey coloration. I briefly review the anti-predator functions of prey coloration and describe both in general terms and with help of two studies as specific examples the use of neural network models in the research on prey coloration. The first example investigates the effect of visual complexity of background on evolution of camouflage. The second example deals with the evolutionary choice of defence strategy, crypsis or aposematism. I conclude that visual information processing by predators is central in evolution of prey coloration. Therefore, the capability to process patterns as well as to imitate aspects of predator's information processing and responses to visual information makes neural networks a well-suited modelling approach for the study of prey coloration. In addition, their suitability for evolutionary simulations is an advantage when complex or dynamic interactions are modelled. Since not all behaviours of neural network models are necessarily biologically relevant, it is important to validate a neural network model with empirical data. Bringing together knowledge about neural networks with knowledge about topics of prey coloration would provide a potential way to deepen our understanding of the specific appearances of prey coloration."																				
2007	"Mouwen, D. J. M.; Capita, R.; Alonso-Calleja, C.; Prieto-Gómez, J.; Prieto, M."	Artificial neural network based identification of Campylobacter species by Fourier transform infrared spectroscopy	Other	DNN	Classification	Journal of Microbiological Methods	67	1	131-140	10.1016/j.mimet.2006.03.012	https://www.sciencedirect.com/science/article/pii/S0167701206000686	"Two prototypes of artificial neural network (ANN), multilayer perceptron (MLP), and probabilistic neural network (PNN), were used to analyze infrared (IR) spectral data obtained from intact cells belonging to the species Campylobacter coli and Campylobacter jejuni. In order to establish a consistent identification and typing procedure, mid infrared spectra of these species were obtained by means of a Fourier transform infrared (FT-IR) spectroscope. FT-IR patterns belonging to 26 isolates subclassified into 4 genotypes were pre-processed (normalized, smoothed and derivatized) and grouped into training, verification and test sets. The two architectures tested (PNN, MLP) were developed and trained to identify or leave unassigned a number of IR patterns. Two window ranges (w4, 1200 to 900 cm_1; and w5, 900 to 700 cm_1) in the mid IR spectrum were presented as input to the ANN models functioning as pattern recognition systems. No matter the ANN used all the training sets were correctly identified at subspecies level. For the test set, the four-layer MLP network was found to be specially suitable to recognize FT-IR data since it correctly identified 99.16% of unknowns using the w4 range, and was fully successful in detecting atypical patterns from closely related Campylobacter strains and other bacterial species. The PNN network obtained lower percentages in assignation and rejection. Overall, ANNs constitute an excellent mathematical tool in microbial identification, since they are able to recognize with a high degree of confidence typical as well as atypical FT-IR fingerprints from Campylobacter spp."																				
2007	"Pfennig, Karin S; Ryan, Michael J"	Character displacement and the evolution of mate choice: an artificial neural network approach	Other	DNN	Modeling	Philosophical Transactions of the Royal Society B: Biological Sciences	362	1479	411-419	10.1098/rstb.2006.1968	https://royalsocietypublishing.org/doi/10.1098/rstb.2006.1968	"Interactions with heterospecifics can promote the evolution of divergent mating behaviours between populations that do and do not occur with heterospecifics. This process—reproductive character displacement—potentially results from selection to minimize the risk of mating with heterospecifics. We sought to determine whether heterospecific interactions lead to divergence of female preferences for aspects of conspecific male signals. We used artificial neural network models to simulate a mate recognition system in which females co-occur with different heterospecifics in different populations. Populations that evolved conspecific recognition in the presence of different heterospecifics varied in their preferences for aspects of conspecific male signals. When we tested networks for their preferences of conspecific versus heterospecific signals, however, we found that networks from allopatric populations were usually able to select against heterospecifics. We suggest that female preferences for aspects of conspecific male signals can result in a concomitant reduction in the likelihood that females will mate with heterospecifics. Consequently, even females in allopatry may discriminate against heterospecific mates depending on the nature of their preferences for conspecifics. Such a pattern could potentially explain cases where reproductive character displacement is expected, but not observed."																				
2007	"Watts, Michael J.; Worner, S. P."	Comparing ensemble and cascaded neural networks that combine biotic and abiotic variables to predict insect species distribution	Environmental	DNN	Modeling	Ecological Informatics	3	6	354-366	10.1016/j.ecoinf.2008.08.003	https://www.sciencedirect.com/science/article/pii/S1574954108000472	"Predictions of the potential for an insect species to invade a new locality have previously been made using a number of different modelling approaches that include either biotic or abiotic factors as predictor variables. Few models include both variables despite that it is recognised that both factors are important predictors of species distributions. Therefore, models that use both factors as independent input variables would be expected to be more accurate than those that are based on any factor alone. This study compares the accuracy of a range of multilayer perceptron (MLP) artificial neural network (ANN) modelling approaches for modelling the global distribution of six insect species using various combinations of abiotic and biotic factors considered to influence insect species establishment. As well as individual MLP, the modelling approaches included ensemble and cascaded networks. The biotic factors were represented by regional host plant and insect species assemblages, and abiotic factors were represented by a range of climatic variables. While no single model was found to be superior for all species, in general, ensembles of models and the combination of biotic and abiotic factors, particularly in cascaded MLP, gave improved prediction accuracy. Interestingly, sensitivity and contribution analyses showed that the presence or absence of other insect species, represented by the regional insect assemblage, was the best predictor of target species distribution compared with climate and/or host plant assemblage."																				
2008	"Banerjee, Amit Kumar; Kiran, K.; Murty, U. S. N.; Venkateswarlu, Ch."	Classification and identification of mosquito species using artificial neural networks	Molecular	DNN	Classification	Computational Biology and Chemistry	32	6	442-447	10.1016/j.compbiolchem.2008.07.020	https://www.sciencedirect.com/science/article/pii/S1476927108000996	"An artificial neural network method is presented for classification and identification of Anopheles mosquito species based on the internal transcribed spacer2 (ITS2) data of ribosomal DNA string. The method is implemented in two different multi-layered feed-forward neural network model forms, namely, multi-input single-output neural network (MISONN) and multi-input multi-output neural network (MIMONN). A number of data sequences in varying sizes of different Anopheline malarial vectors and their corresponding species coding are employed to develop the neural network models. The classification efficiency of the network models for untrained data sequences is evaluated in terms of quantitative performance criteria. The results demonstrate the efficiency of the neural network models to extract the genetic information in ITS2 sequences and to adapt to new data. The method of MISONN is found to exhibit superior performance over MIMONN in distinguishing and identification of the mosquito vectors."																				
2008	"Büchl, Nicole R.; Wenning, Mareike; Seiler, Herbert; Mietke-Hofmann, Henriette; Scherer, Siegfried"	Reliable identification of closely related Issatchenkia and Pichia species using artificial neural network analysis of Fourier-transform infrared spectra	Other	DNN	Classification	Yeast	25	11	787-798	10.1002/yea.1633	https://onlinelibrary.wiley.com/doi/abs/10.1002/yea.1633	"A reliable identification system for closely related species of the genera Issatchenkia and Pichia was established, using artificial neural network-based Fourier-transform infrared (FTIR) spectroscopy; 16 common Pichia species and all five known Issatchenkia species were included. A total of 238 strains isolated from a large variety of habitats were used as reference strains to generate an artificial neural network (ANN) identification system. This system consists of 10 single subnets connected to an ANN with four consecutive levels. An internal validation of the system, using unknown spectra of each reference strain, yielded an identification rate of 99.2%. To evaluate the performance of the ANN in routine diagnostics, 1608 spectra of 179 strains unknown to the ANN were used as a test dataset in an external validation. An overall identification rate of 98.6%, including a success rate of 100% for two common species, P. anomala and P. membranifaciens, demonstrates considerable potential of this FTIR-based artificial neural network for the identification of closely related yeast species. Copyright © 2008 John Wiley & Sons, Ltd."																				
2008	"Fedor, P.; Malenovsk_, I.; Va_hara, J.; Sierka, W.; Havel, J."	Thrips (Thysanoptera) identification using artificial neural networks	Other	DNN	Classification	Bulletin of Entomological Research	98	5	437-447	10.1017/S0007485308005750	https://www.cambridge.org/core/journals/bulletin-of-entomological-research/article/thrips-thysanoptera-identification-using-artificial-neural-networks/B095DE333BD4C41FF8244928CEFB12BF	"We studied the use of a supervised artificial neural network (ANN) model for semi-automated identification of 18 common European species of Thysanoptera from four genera: Aeolothrips Haliday (Aeolothripidae), Chirothrips Haliday, Dendrothrips Uzel, and Limothrips Haliday (all Thripidae). As input data, we entered 17 continuous morphometric and two qualitative two-state characters measured or determined on different parts of the thrips body (head, pronotum, forewing and ovipositor) and the sex. Our experimental data set included 498 thrips specimens. A relatively simple ANN architecture (multilayer perceptrons with a single hidden layer) enabled a 97% correct simultaneous identification of both males and females of all the 18 species in an independent test. This high reliability of classification is promising for a wider application of ANN in the practice of Thysanoptera identification."																				
2008	"FOX, ELIZABETH J.S.; ROBERTS, J. DALE; BENNAMOUN, MOHAMMED"	Call-Independent Individual Identification in Birds	Sound	DNN	Classification	Bioacoustics	18	1	51-67	10.1080/09524622.2008.9753590	https://doi.org/10.1080/09524622.2008.9753590	"Methods normally used for acoustic individual identification can only compare a single song type, both within and between individuals, to determine identity, i.e. they are call-dependent. Call-independent identification does not involve direct comparison of a particular song type. It can therefore be carried out regardless of the amount of song sharing between individuals, or changes in an individual's repertoire over time. This wide applicability radically expands the range of situations in which acoustic individual identification can be used. Text-independent recognition is routinely conducted on human speech and in this paper the same techniques, using mel-frequency cepstral coefficients and multilayer perceptrons, were applied to bird song. Call-independent identification accuracies ranged from 54.3–75.7% in three passerine species. To suit bird song better, we modified the feature extraction methods and neural network architecture, resulting in accuracies of 69.3–97.1%. A comparison of call-dependent and call-independent identification showed little difference in accuracy for two species, while the third species had a lower accuracy for the call-independent identification. Our results demonstrate that individual identification from bird song can occur even when direct comparison of a particular song type is not possible."																				
2008	"Jannot, Jason E.; Akman, Olcay; Kerans, Billie L.; Carr, Kareem"	Using neural networks to detect patterns in inter-specific data: An example from net-spinning caddisflies (Trichoptera: Annulipalpia)	Other	DNN	Modeling	Ecological Informatics	3	6	387-396	10.1016/j.ecoinf.2008.08.001	https://www.sciencedirect.com/science/article/pii/S1574954108000484	"We introduce neural networks (NNs) as a method for detecting patterns and visually comparing multivariate inter-specific morphological data. Neural networks have relatively relaxed statistical assumptions, do not require a phylogeny, and can collapse multivariate data sets into two dimensions. The NN converts the multivariate data into vectors which are then plotted in two dimensions on a self-organizing map. Self-organizing maps visually display any hidden patterns in the data uncovered by the NN. We used a NN to study multivariate sexual dimorphism in 40 species of adult net-spinning caddisflies (Trichoptera: Annulipalpia) from North America. Utilizing eight morphological traits of adult caddisflies, the NN accurately predicted phylogenetic structure (accuracy rate: family = 92%; genus = 82%; species = 72%) and sexual dimorphism (80%) based solely on morphology. Leg traits were most important in discriminating among families and sexes whereas antennal length and eye width were most important for predicting genus and species. Overlaying the self-organizing map on the phylogenetic tree indicated that sexual dimorphism is widespread among net-spinning caddisfly taxa. Our neural network can be used to detect patterns in inter-specific biological data from any set of organisms. Future work should be aimed at developing NNs as a tool in evolutionary biology."																				
2008	"Jeong, Kwang-Seuk; Kim, Dong-Kyun; Jung, Jong-Mun; Kim, Myoung-Chul; Joo, Gea-Jae"	Non-linear autoregressive modelling by Temporal Recurrent Neural Networks for the prediction of freshwater phytoplankton dynamics	Temporal	RNN	Modeling	Ecological Modelling	211	4-Mar	292-300	10.1016/j.ecolmodel.2007.09.029	https://linkinghub.elsevier.com/retrieve/pii/S0304380007004516	"This study was aimed at developing a Temporal Autoregressive Recurrent Neural Network (TARNN) model that could predict time-series changes of phytoplankton dynamics in a regulated river ecosystem in South Korea. In recent years, a large quantity of ecological data has been globally accumulated in habitats monitored by Long-Term Ecological Research (LTER), and that data enabled ecologists to apply non-linear data-driven ecological modelling algorithms to their systems. Numerous studies have reported that empirical modelling algorithms such as Artificial Neural Networks (ANNs) were superior to conventional models in applicability, especially for systems where underlying ecological relationship was not fully understood. However, in order to process sufficient information from the target ecosystem or entity, the size of empirical models tended to become larger by applying diverse state variables or forcing functions to the models. Despite the fact that the developed models empirically had accurate performance in prediction or classification of target data, they are occasionally not free from complex structures (e.g., large number of input variables). The TARNN algorithm used in this study can be an alternative solution to overcome the increasing size and structural complexity of the models, based on model performance, which is hardly found in freshwater ecology. In this study, the performance of TARNN for freshwater ecological data was evaluated by being applied to two types of data sets of phytoplankton dynamics. The first data encompassed intensive seasonality (monthly averaged biovolume of Stephanodiscus hantzschii) which proliferated and dominated the algal assemblage (ca. 90%) annually in the lower Nakdong River during winters. The other data was daily sampled phytoplankton biomass (chlorophyll a) in which significant seasonality did not reside. The predictability of two TARNN models was compared with appropriate statistical models, i.e., data with seasonality was modelled by Seasonal Auto-Regressive Integrated Moving Average (SARIMA), and the other data with Simple Exponential Smoothing. In both cases of data sets, the TARNN models outperformed the statistical methods in accuracy of prediction (TARNN, r2 > 0.9 for both seasonal and non-seasonal testing data sets; both statistical models, r2 < 0.3 for the testing data sets). Especially, the capacity of prediction using the TARNN algorithm was not decreased by the absence of seasonality. Through the presented results, it can be assumed that TARNN can process non-linear autoregressive analysis successfully for ecological data. The development of non-linear autoregressive models for phytoplankton prediction can suggest more efficient direction for water quality management approaches of freshwater systems with long-term database. A real-time forecasting system for algal proliferation, one of the state-of-the-art predicting systems, can be identified using the linkage between the modelling technique and telemetry."																				
2008	"Kasperski, Andrzej; Kasperska, Renata"	A new approach to the automatic identification of organism evolution using neural networks	Molecular	DNN	Classification	Biosystems	142-143		32-42	10.1016/j.biosystems.2016.03.005	https://www.sciencedirect.com/science/article/pii/S0303264716300223	"Automatic identification of organism evolution still remains a challenging task, which is especially exiting, when the evolution of human is considered. The main aim of this work is to present a new idea to allow organism evolution analysis using neural networks. Here we show that it is possible to identify evolution of any organisms in a fully automatic way using the designed EvolutionXXI program, which contains implemented neural network. The neural network has been taught using cytochrome b sequences of selected organisms. Then, analyses have been carried out for the various exemplary organisms in order to demonstrate capabilities of the EvolutionXXI program. It is shown that the presented idea allows supporting existing hypotheses, concerning evolutionary relationships between selected organisms, among others, Sirenia and elephants, hippopotami and whales, scorpions and spiders, dolphins and whales. Moreover, primate (including human), tree shrew and yeast evolution has been reconstructed."																				
2008	"Lek, Sovan; Belaud, Alain; Baran, Philippe; Dimopoulos, Ioannis; Delacoste, Marc"	Role of some environmental variables in trout abundance models using neural networks	Environmental	DNN	Regression	Aquatic Living Resources	9	1	23-29	10.1051/alr:1996004	https://www.alr-journal.org/articles/alr/abs/1996/01/alr96104/alr96104.html	"Neural networks provide a ""black box"" model for explaining and predicting trout abundance with 8 environmental variables. This work investigates the specific effect of each variable, by inputting fictitious configurations of explanatory variables and by checking the responses of the model. The comparison between this response of the model to environmental variables on one hand, and results from field observations on the other hand, shows similarities and indicates neural network modelling can be trusted. The elevation appears to be the major explanatory factor. The influence of shelters, bottom velocity and Froude number also play an important role. When considered separately, depth does not have a notable influence on the density of trout. Such confirmations of field observations suggest that these models can be used to obtain a clear identification and hierarchization of the factors influencing the abundance of trout and the mode of action of the factors. This approach can be extended to other applications in quantitative ecology in which non-linear relationships are usually observed."																				
2009	"Bianconi, André; Zuben, Cláudio J. Von; Serapião, Adriane B. de S.; Govone, José S."	"Artificial neural networks: A novel approach to analysing the nutritional ecology of a blowfly species, Chrysomya megacephala"	Environmental	"DNN, Other"	Regression	Journal of Insect Science	10	1	58	10.1673/031.010.5801	https://doi.org/10.1673/031.010.5801	"Bionomic features of blowflies may be clarified and detailed by the deployment of appropriate modelling techniques such as artificial neural networks, which are mathematical tools widely applied to the resolution of complex biological problems. The principal aim of this work was to use three well-known neural networks, namely Multi-Layer Perceptron (MLP), Radial Basis Function (RBF), and Adaptive Neural Network-Based Fuzzy Inference System (ANFIS), to ascertain whether these tools would be able to outperform a classical statistical method (multiple linear regression) in the prediction of the number of resultant adults (survivors) of experimental populations of Chrysomya megacephala (F.) (Diptera: Calliphoridae), based on initial larval density (number of larvae), amount of available food, and duration of immature stages. The coefficient of determination (R2) derived from the RBF was the lowest in the testing subset in relation to the other neural networks, even though its R2 in the training subset exhibited virtually a maximum value. The ANFIS model permitted the achievement of the best testing performance. Hence this model was deemed to be more effective in relation to MLP and RBF for predicting the number of survivors. All three networks outperformed the multiple linear regression, indicating that neural models could be taken as feasible techniques for predicting bionomic variables concerning the nutritional dynamics of blowflies."																				
2009	"Cabreira, Ariel G.; Tripode, Martín; Madirolas, Adrián"	Artificial neural networks for fish-species identification	Sound	DNN	Classification	ICES Journal of Marine Science	66	6	1119-1129	10.1093/icesjms/fsp009	https://academic.oup.com/icesjms/article/66/6/1119/690251	"Acoustic ﬁsh detection is a valuable tool for the continuous monitoring of ﬁsh schools. However, changes in species composition or mixed multispecies situations still complicate the analysis of acoustic data. Validation of echo recordings is usually accomplished by trawling, but only at point locations. However, species proportions and size distributions in the catch can be biased because of gear selectivity and ﬁsh avoidance. In this paper, techniques involving training and testing of artiﬁcial neural networks (ANNs) are applied for the automatic recognition and classiﬁcation of digital echo recordings of schools in the Southwest Atlantic. Energetic, morphometric, and bathymetric school descriptors were extracted from the echo-recordings as the input for the ANNs. Several pelagic and demersal ﬁsh species known to aggregate into schools were considered, including anchovy, rough scad, longtail hoki, sprat, and blue whiting. Different types of ANNs were tested. Best performances were obtained by levelling the input data (number of schools) per species. Correct classiﬁcation rates up to 96% were obtained, depending on the species, type of network, and the number of school descriptors utilized. Some of these species inhabit areas geographically distant from each other. Hence, the contribution of the school position as a descriptor was investigated. By deleting the geographical location of the schools from the ANN input data, the average performance decreased to some extent but was still satisfactory, proving the networks were able usually to recognize ﬁsh species based only on the intrinsic characteristics of the school. The results have encouraged further testing of this method as a useful tool for scrutinizing echograms."																				
2009	"Chapman, Robert W.; Mancia, Annalaura; Beal, Marion; Veloso, Artur; Rathburn, Charles; Blair, Anne; Sanger, Denise; Holland, A. F.; Warr, Gregory W.; Didonato, Guy"	"A transcriptomic analysis of land-use impacts on the oyster, Crassostrea virginica, in the South Atlantic bight"	Molecular	DNN	Regression	Molecular Ecology	18	11	2415-2425	10.1111/j.1365-294X.2009.04194.x	https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-294X.2009.04194.x	"Increasing utilization and human population density in the coastal zone is widely believed to place increasing stresses on the resident biota, but confirmation of this belief is somewhat lacking. While we have solid evidence that highly disturbed estuarine systems have dramatic changes in the resident biota (black and white if you will), we lack tools that distinguish the shades of grey. In part, this lack of ability to distinguish shades of grey stems from the analytical tools that have been applied to studies of estuarine systems, and perhaps more important, is the insensitivity of the biological end points that we have used to assess these impacts. In this study, we will present data on the phenotypic adjustments as measured by transcriptomic signatures of a resilient organism (oysters) to land-use practices in the surrounding watershed using advanced machine-learning algorithms. We will demonstrate that such an approach can reveal subtle and meaningful shifts in oyster gene expression in response to land use. Further, the data show that gill tissues are far more responsive and provide superior discrimination of land-use classes than hepatopancreas and that transcripts encoding proteins involved in energy production, protein synthesis and basic metabolism are more robust indicators of land use than classic biomarkers such as metallothioneins, GST and cytochrome P-450."																				
2009	"Cho, Hee-Sun; Choi, Kwang-Hee; Lee, Sang-Don; Park, Young-Seuk"	Characterizing habitat preference of Eurasian river otter (Lutra lutra) in streams using a self-organizing map	Other	DNN	Modeling	Limnology	10	3	203-213	10.1007/s10201-009-0275-7	https://link.springer.com/article/10.1007/s10201-009-0275-7	"We studied the habitat preferences of Eurasian river otters (Lutra lutra) using the distribution patterns of the numbers of spraints and sprainting spots of otters, as well as related environmental variables (habitat zone, river management, bank type, vegetation coverage, width, depth, etc.) in two streams. The numbers of otter spraints and sprainting spots were sampled monthly in two streams on Geoje Island, Republic of Korea, from January to December 2004. Additional environmental variables were measured at the sampling sites. A self-organizing map (SOM), which is an unsupervised artificial neural network, was used to characterize the habitat preferences of otters. In our results, the SOM classified three different groups of study sites based on their habitat conditions, and the habitat differences were effectively visualized on the trained SOM map. Otters showed spatial and temporal dynamics in the numbers of spraints and sprainting spots, and revealed habitat preferences for shallow, narrow areas of streams and edges of water that were not far from reservoirs but covered with trees and shrubs. Additionally, otters preferred an environment in which weirs reduced the drift of water and gathered fishes and had a natural type of stream bank; these findings are relevant for river management. Otters adapted to places close to roads, residential areas, and agricultural areas with some tolerance of human interference."																				
2009	"CLARK, JONATHAN Y."	Neural networks and cluster analysis for unsupervised classification of cultivated species of Tilia (Malvaceae)	Other	DNN	Classification	Botanical Journal of the Linnean Society	159	2	300-314	10.1111/j.1095-8339.2008.00891.x	https://doi.org/10.1111/j.1095-8339.2008.00891.x	"A case study of the classification of 19 species of the genus Tilia (Malvaceae) using morphological data is presented. The value of a self-organizing map (SOM) neural network when applied to this problem is compared with that of a standard cluster analysis method. An interpretation of the results and a discussion of traditional classification systems are provided in order to evaluate the practical usefulness of the SOM methodology. The SOM technique is shown to provide an easily understandable two-dimensional topological map which enables simple linear separation of taxonomic groups. Good separation of traditional infrageneric groups in Tilia is achieved and suggestions about changes to the existing classification are provided. It is concluded that the SOM and cluster analysis methods, whilst both producing results similar to existing classifications, are most effective at different hierarchical levels."																				
2009	"Deng, Jia; Dong, Wei; Socher, Richard; Li, Li-Jia; Kai Li; Li Fei-Fei"	ImageNet: A large-scale hierarchical image database	NA	NA	Review	2009 IEEE Conference on Computer Vision and Pattern Recognition			248-255	10.1109/CVPR.2009.5206848	https://ieeexplore.ieee.org/document/5206848/	"The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."																				
2009	"Esteban, Luis García; Fernández, Francisco García; Palacios, Paloma de Palacios de; Romero, Ruth Moreno; Cano, Nieves Navarro"	Artificial Neural Networks in Wood Identification: The Case of two Juniperus Species from the Canary Islands	Other	DNN	Classification	IAWA Journal	30	1	87-94	10.1163/22941932-90000206	https://brill.com/view/journals/iawa/30/1/article-p87_9.xml	"Neural networks are complex mathematical structures inspired on biological neural networks, capable of learning from examples (training group) and extrapolating knowledge to an unknown sample (testing group). The similarity of wood structure in many species, particularly in the case of conifers, means that they cannot be differentiated using traditional methods. The use of neural networks can be an effective tool for identifying similar species with a high percentage of accuracy. This predictive method was used to differentiate Juniperus cedrus and J. phoenicea var. canariensis, both from the Canary Islands. The anatomical features of their wood are so similar that it is not possible to differentiate them using traditional methods. An artificial neural network was used to determine if this method could differentiate the two species with a high degree of probability through the biometry of their anatomy. To achieve the differentiation, a feedforward multilayer percepton network was designed, which attained 98.6% success in the training group and 92.0% success in the testing or unknown group. The proposed neural network is satisfactory for the desired purpose and enables J. cedrus and J. phoenicea var. canariensis to be differentiated with a 92% probability."																				
2009	"Fedor, Peter; Va_hara, Jaromír; Havel, Josef; Malenovsk_, Igor; Spellerberg, Ian"	Artificial intelligence in pest insect monitoring	Images	CNN	Classification	Systematic Entomology	34	2	398-400	10.1111/j.1365-3113.2008.00461.x	http://doi.wiley.com/10.1111/j.1365-3113.2008.00461.x	"Global problems of hunger and malnutrition induced us to introduce a new tool for semi-automated pest insect identification and monitoring: an artificial neural network system. Multilayer perceptrons, an artificial intelligence method, seem to be efficient for this purpose. We evaluated 101 European economically important thrips (Thysanoptera) species: extrapolation of the verification test data indicated 95% reliability at least for some taxa analysed. Mainly quantitative morphometric characters, such as head, clavus, wing, ovipositor length and width, formed the input variable computation set in a Trajan neural network simulator. The technique may be combined with digital image analysis."																				
2009	"Lu, Hongfei; Jiang, Wu; Ghiassi, M.; Lee, Sean; Nitin, Mantri"	Classification of Camellia (Theaceae) Species Using Leaf Architecture Variations and Pattern Recognition Techniques	Other	Other	Classification	PLOS ONE	7	1	e29704	10.1371/journal.pone.0029704	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029704	"Leaf characters have been successfully utilized to classify Camellia (Theaceae) species; however, leaf characters combined with supervised pattern recognition techniques have not been previously explored. We present results of using leaf morphological and venation characters of 93 species from five sections of genus Camellia to assess the effectiveness of several supervised pattern recognition techniques for classifications and compare their accuracy. Clustering approach, Learning Vector Quantization neural network (LVQ-ANN), Dynamic Architecture for Artificial Neural Networks (DAN2), and C-support vector machines (SVM) are used to discriminate 93 species from five sections of genus Camellia (11 in sect. Furfuracea, 16 in sect. Paracamellia, 12 in sect. Tuberculata, 34 in sect. Camellia, and 20 in sect. Theopsis). DAN2 and SVM show excellent classification results for genus Camellia with DAN2's accuracy of 97.92% and 91.11% for training and testing data sets respectively. The RBF-SVM results of 97.92% and 97.78% for training and testing offer the best classification accuracy. A hierarchical dendrogram based on leaf architecture data has confirmed the morphological classification of the five sections as previously proposed. The overall results suggest that leaf architecture-based data analysis using supervised pattern recognition techniques, especially DAN2 and SVM discrimination methods, is excellent for identification of Camellia species."																				
2009	"Messina, Giuseppe; Pandolfi, Camilla; Mugnai, Sergio; Azzarello, Elisa; Dixon, Kingsley; Mancuso, Stefano; Messina, Giuseppe; Pandolfi, Camilla; Mugnai, Sergio; Azzarello, Elisa; Dixon, Kingsley; Mancuso, Stefano"	Phyllometric parameters and artificial neural networks for the identification of Banksia accessions	Other	DNN	Classification	Australian Systematic Botany	22	1	31-38	10.1071/SB08003	https://www.publish.csiro.au/sb/SB08003	"Taxonomic identification is traditionally carried out with dichotomous keys, or at least computer-based identification keys, often on the basis of subjective visual assessment and frequently unable to detect small differences at subspecies and varietal ranks. The aims of the present work were to (1) clearly discriminate a wide group of accessions (species, subspecies and varieties) belonging to the genus Banksia on the basis of 14 phyllometric parameters determined by image analysis of the leaves, and (2) unequivocally identify the accessions with a relatively simple back-propagation neural-network (BPNN) architecture (single hidden layer) in order to develop a complementary method for fast botanical identification. The results indicate that this kind of network could be effectively and successfully used to discriminate among Banksia accessions, as the BPNN enabled a 93% unequivocal and correct simultaneous identification. Our BPNN had the advantage of being able to resolve subtle associations between characters, and of making incomplete data (i.e. absence of Banksia flower parameters such as the colour or size of styles) useful in species diagnostics. This method is relatively useful; it is easy to execute as no particular competences are necessary, equipment is low cost (scanner connected to a PC and software available as freeware) and data acquisition is fast and effective."																				
2009	"Palangpour, Parviz; Venayagamoorthy, Ganesh K.; Duffy, Kevin J."	Prediction of elephant movement in a game reserve using neural networks	Other	RNN	Regression	New Mathematics and Natural Computation	5	2	421-439	10.1142/S1793005709001404	https://www.worldscientific.com/doi/abs/10.1142/S1793005709001404	"A large number of South Africa's elephants can be found on small wildlife reserves. The large nutritional demands and destructive foraging behavior of elephants can threaten rare species of vegetation. If conservation management is to protect threatened species of vegetation, knowing how long elephants will stay in one area of a reserve as well as which area they will move to next could be useful. The goal of this study was to train a recurrent neural network to predict an elephant herd's next position in the Pongola Game Reserve. Accurate predictions would provide a useful tool in assessing future impact of elephant populations on different areas of the reserve. Particle swarm optimization (PSO), PSO initialized backpropagation (PSO-BP) and PSO initialized backpropagation through time (PSO-BPTT) algorithms are used to adapt the recurrent neural network's weights. The effectiveness of PSO, PSO-BP and PSO-BPTT for training a recurrent neural network for elephant migration prediction is compared and PSO-BPTT produces the most accurate predictions at the expense of more computational cost."																				
2009	"Pu, Ruiliang"	Broadleaf species recognition with in situ hyperspectral data	Other	DNN	Classification	International Journal of Remote Sensing	30	11	2759-2779	10.1080/01431160802555820	https://doi.org/10.1080/01431160802555820	"Timely and accurate identification of tree species by spectral methods is crucial for forest and urban ecological management. In this study, a total of 394 reflectance spectra (between 350 and 2500 nm) from foliage branches or canopy of 11 important urban forest broadleaf species were measured in the City of Tampa, Florida, USA with a spectrometer. The 11 species include American elm (Ulmus americana), bluejack oak (Quercus incana), crape myrtle (Lagerstroemia indica), laurel oak (Q. laurifolia), live oak (Q. virginiana), southern magnolia (Magnolia grandiflora), persimmon (Diospyros virginiana), red maple (Acer rubrum), sand live oak (Q. geminata), American sycamore (Platanus occidentalis), and turkey oak (Q. laevis). A total of 46 spectral variables, including normalized spectra, derivative spectra, spectral vegetation indices, spectral position variables, and spectral absorption features were extracted and analysed from the in situ hyperspectral measurements. Two classification algorithms were used to identify the 11 broadleaf species: a nonlinear artificial neural network (ANN) and a linear discriminant analysis (LDA). An analysis of variance (ANOVA) indicates that the 30 selected spectral variables are effective to differentiate the 11 species. The 30 selected spectral variables account for water absorption features at 970, 1200, and 1750 nm and reflect characteristics of pigments and other biochemicals in tree leaves, especially variability of chlorophyll content in leaves. The experimental results indicate that both classification algorithms (ANN and LDA) have produced acceptable accuracies (overall accuracy from 86.3% to 87.8%, kappa from 0.83 to 0.87) and have a similar performance for classifying the 11 broadleaf species with input of the 30 selected spectral variables. The preliminary results of identifying the 11 species with the in situ hyperspectral data imply that with current remote sensing techniques, including high spatial and spectral resolution data, it is still difficult but possible to identify similar species to such 11 broadleaf species with an acceptable accuracy."																				
2009	"Tirelli, Tina; Pessani, Daniela"	Use of decision tree and artificial neural network approaches to model presence/absence of Telestes muticellus in piedmont (North-Western Italy)	Environmental	DNN	Classification	River Research and Applications	25	8	1001-1012	10.1002/rra.1199	https://onlinelibrary.wiley.com/doi/abs/10.1002/rra.1199	"In Piedmont (Italy) the impact of human beings is causing some deep environmental changes in freshwaters and their inhabitants, so much so that we need to develop some practical tools for immediate use in providing accurate ecological assessments of the freshwater system and of the conditions of the species living there, one of which is Telestes muticellus, an endangered Cyprinidae found in the western Alps and the central Apennines in Italy. We aimed to help manage this species by assessing its presence using two types of data-mining approaches—decision-tree models and artificial neural networks. We built models using 10 environmental input variables to classify sites as positive or negative for the species. The unpruned decision tree models classified a high percentage of instances correctly and made accurate predictions, as did the post-pruned tree models. The post-pruned methods yielded simpler trees and therefore clearer models. Generally, the artificial neural networks (ANN) performed better than the decision tree models, except in the case of Cohen's k. We used the sensitivity analysis technique to understand which inputs are the most important ones for building the ANN model we obtained."																				
2009	"Ye, Lin; Cai, Qinghua"	Forecasting Daily Chlorophyll a Concentration during the Spring Phytoplankton Bloom Period in Xiangxi Bay of the Three-Gorges Reservoir by Means of a Recurrent Artificial Neural Network	Temporal	RNN	Regression	Journal of Freshwater Ecology	24	4	609-617	10.1080/02705060.2009.9664338	http://www.tandfonline.com/doi/abs/10.1080/02705060.2009.9664338	"A recurrent artificial neural network was used for 0-and 7-days-ahead forecasting of daily spring phytoplankton bloom dynamics in Xiangxi Bay of Three-Gorges Reservoir with meteorological, hydrological, and limnological parameters as input variables. Daily data from the depth of 0.5 m was used to train the model, and data from the depth of 2.0 m was used to validate the calibrated model. The trained model achieved reasonable accuracy in predicting the daily dynamics of chlorophyll a both in 0-and 7-days-ahead forecasting. In 0-day-ahead forecasting, the R2 values of observed and predicted data were 0.85 for training and 0.89 for validating. In 7-days-ahead forecasting, the R2 values of training and validating were 0.68 and 0.66, respectively. Sensitivity analysis indicated that most ecological relationships between chlorophyll a and input environmental variables in 0-and 7-days-ahead models were reasonable. In the 0-day model, Secchi depth, water temperature, and dissolved silicate were the most important factors influencing the daily dynamics of chlorophyll a. And in 7-days-ahead predicting model, chlorophyll a was sensitive to most environmental variables except water level, DO, and NH3N."																				
2010	"Brey, Thomas"	An empirical model for estimating aquatic invertebrate respiration	"Environmental, Other"	DNN	Modeling	Methods in Ecology and Evolution	1	1	92-101	10.1111/j.2041-210X.2009.00008.x	https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2041-210X.2009.00008.x	"1. The role of metazoan respiration in aquatic system energetics has been neglected to some extent, particularly because limited resources hamper the simultaneous determination of individual respiration rates across many taxa. As global warming will affect poikilotherm metabolism on an ecosystem scale, we need versatile models to estimate respiration from ‘easy-to-obtain’ parameters. 2. Artificial neural networks were trained to estimate mass specific respiration of aquatic metazoans from 28 parameters: temperature, water depth, 19 taxon categories, body mass and 6 lifestyle parameters. The data base includes 22 920 data sets referring to 915 taxa (836 identified to species, 67 to genus, 12 to higher taxon) from 452 different sources. 3. Overall model fit is good (R2 = 0·847), but there is considerable residual variability of up to two orders of magnitude. 4. Variability of same species measurements between sources is almost as large as same-source variability between species, i.e. a substantial part of the residual variability in the data may represent methodical bias. 5. There are no universally valid scaling factors in the relationships of respiration to body mass and temperature, but a wide range of species-specific factors. 6. The model has been implemented in a Microsoft EXCEL spreadsheet that is available at http://www.thomas-brey/science/virtualhandbook."																				
2010	"Charef, Aymen; Ohshimo, Seiji; Aoki, Ichiro; Al Absi, Natheer"	Classification of fish schools based on evaluation of acoustic descriptor characteristics	Sound	DNN	Classification	Fisheries Science	76	1	11-Jan	10.1007/s12562-009-0186-x	https://doi.org/10.1007/s12562-009-0186-x	"Acoustic surveys were conducted from 2002 to 2006 in the East China Sea off the Japanese coast in order to develop a quantitative classification typology of a pelagic fish community and other co-occurring fishes based on acoustic descriptors. Acoustic data were postprocessed to detect and extract fish aggregations from echograms. Based on the expert visual examination of the echograms, detected schools were divided into three broad fish groups according to their schooling characteristics and ethological properties. Each fish school was described by a set of associated descriptors in order to objectively allocate each echo trace to its fish group. Two methods of supervised classification were employed, the discriminant function analysis (DFA) and the artificial neural network technique (ANN). We evaluated and compared the performance of both methods, which showed encouraging and about equally highly correct classification rates (ANN 87.6%; DFA 85.1%). In both techniques, positional and then morphological parameters were most important in discriminating among fish schools. Fish catch composition from midwater trawling validated the fish group classification through one representative example of each grouping. Both methods provided the essential information required for assessing fish stocks. Similar techniques of fish classification might be applicable to marine ecosystems with high pelagic fish diversity."																				
2010	"Charrier, Isabelle; Aubin, Thierry; Mathevon, Nicolas"	Mother–Calf vocal communication in Atlantic walrus: a first field experimental study	Sound	DNN	Classification	Animal Cognition	13	3	471-482	10.1007/s10071-009-0298-9	https://doi.org/10.1007/s10071-009-0298-9	"In all colonial pinnipeds studied, mother–young vocal recognition exists and allows rapid and reliable meetings in spite of the confusing environment of the breeding colony. The efficiency of this recognition process guarantees pup survival, especially in species where females alternate foraging sea trips and lactation periods on land. The Atlantic Walrus (Odobenus rosmarus rosmarus) is a highly gregarious pinniped with females attending their calves for an extended period of time (2–3 years). Although we expect mother–calf vocal recognition to occur in this species due to the high density of individuals packed in herds, it has never been experimentally demonstrated. Here, we assessed the individual stereotypy of both mother and calf barks recorded in the wild by measuring frequency and temporal acoustic parameters. Both discriminant function and artificial neural network analyses resulted in high correct classification rates, underlying a well-defined individual stereotypy in parameters related to frequency modulation and frequency values. Playback experiments showed that mothers were more responsive to the barks of their own calf than to those of unrelated young. Finally, propagation experiments revealed that barks propagate at greater distances over water surface than over ice, acoustic features such as frequency modulation and frequency spectrum being highly resistant to degradation during propagation. Thus, acoustic analysis and propagation experiments suggest that these frequency parameters might be the key acoustic features involved in the individual identification process. This experimental study clearly demonstrates that Atlantic walrus has developed a highly reliable mother–calf vocal communication allowing such strong social bond."																				
2010	"Deecke, Volker B.; Barrett-Lennard, Lance G.; Spong, Paul; Ford, John K. B."	The structure of stereotyped calls reflects kinship and social affiliation in resident killer whales (Orcinus orca)	Sound	DNN	Regression	Naturwissenschaften	97	5	513-518	10.1007/s00114-010-0657-z	https://doi.org/10.1007/s00114-010-0657-z	"A few species of mammals produce group-specific vocalisations that are passed on by learning, but the function of learned vocal variation remains poorly understood. Resident killer whales live in stable matrilineal groups with repertoires of seven to 17 stereotyped call types. Some types are shared among matrilines, but their structure typically shows matriline-specific differences. Our objective was to analyse calls of nine killer whale matrilines in British Columbia to test whether call similarity primarily reflects social or genetic relationships. Recordings were made in 1985–1995 in the presence of focal matrilines that were either alone or with groups with non-overlapping repertoires. We used neural network discrimination performance to measure the similarity of call types produced by different matrilines and determined matriline association rates from 757 encounters with one or more focal matrilines. Relatedness was measured by comparing variation at 11 microsatellite loci for the oldest female in each group. Call similarity was positively correlated with association rates for two of the three call types analysed. Similarity of the N4 call type was also correlated with matriarch relatedness. No relationship between relatedness and association frequency was detected. These results show that call structure reflects relatedness and social affiliation, but not because related groups spend more time together. Instead, call structure appears to play a role in kin recognition and shapes the association behaviour of killer whale groups. Our results therefore support the hypothesis that increasing social complexity plays a role in the evolution of learned vocalisations in some mammalian species."																				
2010	"Gong, P.; Yu, B."	Conifer species recognition: Effects of data transformation	Other	DNN	Classification	International Journal of Remote Sensing	22	17	3471-3481	10.1080/01431160110034654	https://doi.org/10.1080/01431160110034654	"In situ hyperspectral data obtained with a high spectral resolution radiometer were analysed for identification of six conifer species. Hyperspectral data were measured in the summer and late fall seasons at 15-20 cm above portions of tree canopies from both the sunlit and shaded sides. An artificial neural network algorithm was applied for identification purposes. Six types of transformation were applied to the hyperspectral reflectance data ( R ), preprocessed with a simple smoothing, followed by band aggregation. These include log( R ), first derivative of R, first derivative of log( R ), normalized R, first derivative of normalized R, and log(normalized R ). First derivative of log( R ) and first derivative of normalized R resulted in best species recognition accuracies with greater than 90% average accuracies, more than 20% greater than the average accuracy obtained from the pre-processed hyperspectral data. The effect of hyperspectral data taken from the shade sides of tree canopies can be minimized by applying normalization or by taking the derivatives after applying a logarithm to the pre-processed data. We found that a big difference in solar angle did not cause a noticeable difference in accuracies of species recognition."																				
2010	"Liu, ZeLin; Peng, ChangHui; Xiang, WenHua; Tian, DaLun; Deng, XiangWen; Zhao, MeiFang"	Application of artificial neural networks in global climate change and ecological research: An overview	NA	NA	Review	Chinese Science Bulletin	55	34	3853-3863	10.1007/s11434-010-4183-3	https://doi.org/10.1007/s11434-010-4183-3	"Fields that employ artificial neural networks (ANNs) have developed and expanded continuously in recent years with the ongoing development of computer technology and artificial intelligence. ANN has been adopted widely and put into practice by researchers in light of increasing concerns over ecological issues such as global warming, frequent El Niño-Southern Oscillation (ENSO) events, and atmospheric circulation anomalies. Limitations exist and there is a potential risk for misuse in that ANN model parameters require typically higher overall sensitivity, and the chosen network structure is generally more dependent upon individual experience. ANNs, however, are relatively accurate when used for short-term predictions; despite global climate change research favoring the effects of interactions as the basis of study and the preference for long-term experimental research. ANNs remain a better choice than many traditional methods when dealing with nonlinear problems, and possesses great potential for the study of global climate change and ecological issues. ANNs can resolve problems that other methods cannot. This is especially true for situations in which measurements are difficult to conduct or when only incomplete data are available. It is anticipated that ANNs will be widely adopted and then further developed for global climate change and ecological research."																				
2010	"Robotham, Hugo; Bosch, Paul; Gutiérrez-Estrada, Juan Carlos; Castillo, Jorge; Pulido-Calvo, Inmaculada"	Acoustic identification of small pelagic fish species in Chile using support vector machines and neural networks	Sound	DNN	Classification	Fisheries Research	102	1	115-122	10.1016/j.fishres.2009.10.015	https://www.sciencedirect.com/science/article/pii/S0165783609002793	"Hydroacoustic techniques are a valuable tool for the stock assessments of many fish species. Nonetheless, such techniques are limited by problems of species identification. Several methods and techniques have been used in addressing the problem of acoustic identification species. In this paper, schools of anchovy, common sardine, and jack mackerel were classified using support vector machines (SVMs) and two types of supervised artificial neural networks (multilayer perceptron, MLP; and probabilistic neural networks, PNNs) during acoustic surveys in south-central Chile. Classification was done using a set of descriptors for the schools extracted from the acoustic records. The problem was approached through two multi-class SVMs classifiers: one-species-against-one (1-vs-1) and one-species-against-the-Rest (1-vs-R). Multi-class classifications showed that the MLP neural network and SVM approach performed better than the PNN. The classification rates averaged 79.4% with PNN and 89.5% with MLP and SVM."																				
2010	"Strand, Espen; Huse, Geir; Giske, Jarl"	Artificial Evolution of Life History and Behavior.	Other	DNN	Modeling	The American Naturalist	159	6	624-644	10.1086/339997	https://www.journals.uchicago.edu/doi/full/10.1086/339997	"We present an individual_based model that uses artificial evolution to predict fit behavior and life_history traits on the basis of environmental data and organism physiology. Our main purpose is to investigate whether artificial evolution is a suitable tool for studying life history and behavior of real biological organisms. The evolutionary adaptation is founded on a genetic algorithm that searches for improved solutions to the traits under scrutiny. From the genetic algorithm’s “genetic code,” behavior is determined using an artificial neural network. The marine planktivorous fish Müller’s pearlside (Maurolicus muelleri) is used as the model organism because of the broad knowledge of its behavior and life history, by which the model’s performance is evaluated. The model adapts three traits: habitat choice, energy allocation, and spawning strategy. We present one simulation with, and one without, stochastic juvenile survival. Spawning pattern, longevity, and energy allocation are the life_history traits most affected by stochastic juvenile survival. Predicted behavior is in good agreement with field observations and with previous modeling results, validating the usefulness of the presented model in particular and artificial evolution in ecological modeling in general. The advantages, possibilities, and limitations of this modeling approach are further discussed."																				
2010	"Tonnang, Henri E. Z.; Nedorezov, Lev V.; Owino, John O.; Ochanda, Horace; Löhr, Bernhard"	Host–parasitoid population density prediction using artificial neural networks: diamondback moth and its natural enemies	Environmental	DNN	Regression	Agricultural and Forest Entomology	12	3	233-242	10.1111/j.1461-9563.2009.00466.x	https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1461-9563.2009.00466.x	"1 An integrated pest management (IPM) system incorporating the introduction and field release of Diadegma semiclausum (Hellén), a parasitoid of diamondback moth (DBM) Plutella xylostella (L.), comprising the worst insect pest of the cabbage family, has been developed in Kenya to replace the pesticides-only approach. 2 Mathematical modelling using differential equations has been used in theoretical studies of host–parasitoid systems. Although, this method helps in gaining an understanding of the system's dynamics, it is generally less accurate when used for prediction. The artificial neural network (ANN) approach was therefore chosen to aid prediction. 3 The ANN methodology was applied to predict the population density of the DBM and D. semiclausum, its larval parasitoid. Two data sets, each from different release areas in the Kenya highlands, and both collected during a 3-year period after the release of the parasitoid, were used in the present study. Two ANN models were developed using these data. 4 The ANN approach gave satisfactory results for DBM and for D. semiclausum. Sensitivity analysis suggested that pest populations may be naturally controlled by rainfall. 5 The ANN provides a powerful tool for predicting host–parasitoid population densities and made few assumptions on the field data. The approach allowed the use of data collected at any appropriate scale of the system, bypassing the assumptions and uncertainties that could have occurred when parameters are imported from other systems. The methodology can be explored with respect to the development of tools for monitoring and forecasting the population densities of a pest and its natural enemies. In addition, the model can be used to evaluate the relative effectiveness of the natural enemies and to investigate augmentative biological control strategies."																				
2010	"Turner, Stephen D.; Dudek, Scott M.; Ritchie, Marylyn D."	ATHENA: A knowledge-based hybrid backpropagation-grammatical evolution neural network algorithm for discovering epistasis among quantitative trait Loci	Molecular	Other	Regression	BioData Mining	3	1	5	10.1186/1756-0381-3-5	https://doi.org/10.1186/1756-0381-3-5	"Growing interest and burgeoning technology for discovering genetic mechanisms that influence disease processes have ushered in a flood of genetic association studies over the last decade, yet little heritability in highly studied complex traits has been explained by genetic variation. Non-additive gene-gene interactions, which are not often explored, are thought to be one source of this ""missing"" heritability."																				
2010	"Tyystjärvi, Esa; Nørremark, Michael; Mattila, Heta; Keränen, Mika; Hakala-Yatkin, Marja; Ottosen, Carl-Otto; Rosenqvist, Eva"	Automatic identification of crop and weed species with chlorophyll fluorescence induction curves	Other	DNN	Classification	Precision Agriculture	12	4	546-563	10.1007/s11119-010-9201-6	https://doi.org/10.1007/s11119-010-9201-6	"Automatic identification of crop and weed species is required for many precision farming practices. The use of chlorophyll fluorescence fingerprinting for identification of maize and barley among six weed species was tested. The plants were grown in outdoor pots and the fluorescence measurements were done in variable natural conditions. The measurement protocol consisted of 1 s of shading followed by two short pulses of strong light (photosynthetic photon flux density 1700 _mol m_2 s_1) with 0.2 s of darkness in between. Both illumination pulses caused the fluorescence yield to increase by 30–60% and to display a rapid fluorescence transient resembling transients obtained after long dark incubation. A neural network classifier, working on 17 features extracted from each fluorescence induction curve, correctly classified 86.7–96.1% of the curves as crop (maize or barley) or weed. Classification of individual species yielded a 50.2–80.8% rate of correct classifications. The best results were obtained if the training and test sets were measured on the same day, but good results were also obtained when the training and test sets were measured on different dates, and even if fluorescence induction curves measured from both leaf sides were mixed. The results indicate that fluorescence fingerprinting has potential for rapid field separation of crop and weed species."																				
2010	"Yáñez, Eleuterio; Plaza, Francisco; Gutiérrez-Estrada, Juan Carlos; Rodríguez, Nibaldo; Barbieri, M. A.; Pulido-Calvo, Inmaculada; Bórquez, Cinthya"	Anchovy (Engraulis ringens) and sardine (Sardinops sagax) abundance forecast off northern Chile: A multivariate ecosystemic neural network approach	Environmental	DNN	Regression	Progress in Oceanography	87	1	242-250	10.1016/j.pocean.2010.09.015	https://www.sciencedirect.com/science/article/pii/S0079661110001278	"An evaluation of the performance of artificial neural networks (ANNs) to forecast monthly anchovy (Engraulis ringens) and sardine (Sardinops sagax) catches in northern Chile (18°21_S-24°S) is presented, using environmental variables, anchovy and sardine CPUE, fishing effort and catches between 1963 and 2007. An analysis of previous data was carried out, consisting of a non-linear cross-correlation analysis to estimate the time lags for each input variable. A multi-layer perceptron architecture model was used, calibrated with the Levenberg–Marquardt algorithm, thus obtaining anchovy landings and sardine CPUE forecast models. An ecosystemic approach was conducted for both models, considering local and global environmental variables, the anthropogenic effect, and the interaction between species as inputs. The variance explained by both models was slightly higher than 82% and the standard error of prediction was lower than 45%. The strong correlation between the estimated and observed series on the anchovy and sardine models suggests that ANN models capture the trend of the historical data. Furthermore, the generalization capacity along with the sensitivity analysis allowed the identification of high-weight variables in the model, as well as the partial interpretation of the statistical functional relationships between the input variables and the abundance."																				
2010	"Zhang, Xin; Chai, Li-He"	A New Statistical Dynamic Analysis of Ecosystem Patterns	Environmental	DNN	Modeling	Environmental Modeling & Assessment	15	6	519-529	10.1007/s10666-010-9222-6	https://link.springer.com/article/10.1007/s10666-010-9222-6	"While phenomenological investigations of ecosystem patterns often fail to reveal underlying dynamic mechanisms, we highlight a universal principle for pattern formation in ecosystems. We consider ecosystems to be typical complex adaptive systems that seek an optimal process to obtain maximized flux under given constraints. An analysis of the optimal process reveals underlying microscopic dynamic mechanisms that induce complex patterns in ecosystems. We emulate ecosystem patterns using a Self-Organization Feature Map: an artificial neural network theoretical model by which evolution processes, structural classifications, and the fractal growth of ecosystem patterns can be simulated. The results help us analyze the formation and dynamics of ecosystem patterns, with attending implications for the classification, protection, and optimization of ecosystems."																				
2011	"Chapman, Robert W.; Mancia, Annalaura; Beal, Marion; Veloso, Artur; Rathburn, Charles; Blair, Anne; Holland, A. F.; Warr, G. W.; Didinato, Guy; Sokolova, Inna M.; Wirth, Edward F.; Duffy, Edward; Sanger, Denise"	"The transcriptomic responses of the eastern oyster, Crassostrea virginica, to environmental conditions"	"Environmental, Molecular"	DNN	Regression	Molecular Ecology	20	7	1431-1449	10.1111/j.1365-294X.2011.05018.x	https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-294X.2011.05018.x	"Understanding the mechanisms by which organisms adapt to environmental conditions is a fundamental question for ecology and evolution. In this study, we evaluate changes in gene expression of a marine mollusc, the eastern oyster Crassostrea virginica, associated with the physico-chemical conditions and the levels of metals and other contaminants in their environment. The results indicate that transcript signatures can effectively disentangle the complex interactive gene expression responses to the environment and are also capable of disentangling the complex dynamic effects of environmental factors on gene expression. In this context, the mapping of environment to gene and gene to environment is reciprocal and mutually reinforcing. In general, the response of transcripts to the environment is driven by major factors known to affect oyster physiology such as temperature, pH, salinity, and dissolved oxygen, with pollutant levels playing a relatively small role, at least within the range of concentrations found in the studied oyster habitats. Further, the two environmental factors that dominate these effects (temperature and pH) interact in a dynamic and nonlinear fashion to impact gene expression. Transcriptomic data obtained in our study provide insights into the mechanisms of physiological responses to temperature and pH in oysters that are consistent with the known effects of these factors on physiological functions of ectotherms and indicate important linkages between transcriptomics and physiological outcomes. Should these linkages hold in further studies and in other organisms, they may provide a novel integrated approach for assessing the impacts of climate change, ocean acidification and anthropogenic contaminants on aquatic organisms via relatively inexpensive microarray platforms."																				
2011	"Genc, Ercument; Oral, Mustafa; Erol, Cavit"	"The evaluation of gnathiid (Crustacea: Isopoda: Gnathidae) parasitism in goldblotch grouper (Epinephelus costae Staindahner, 1878) in the northeastern Mediterranean Sea using the self-organizing map (SOM)"	Environmental	DNN	Regression	Parasitology Research	108	6	1417-1424	10.1007/s00436-010-2188-0	https://doi.org/10.1007/s00436-010-2188-0	"The self-organizing map (SOM), which is widely used in economics and engineering applications, is a type of artificial neural network trained without supervision. SOM is used to represent multidimensional data in much lower dimensional spaces—usually in two dimensions (2D)—while preserving the topological properties of the input space. In this study, 2D maps were produced by using SOM to display the relationship between seasons, length, weight, and isopod infestation of goldblotch grouper (Epinephelus costae Staindahner, 1878). This is first study of gnathiid isopod praniza larvae infesting goldblotch grouper (E. costae Staindahner, 1878) in the northeast Mediterranean Sea (36°36_ N–36°07_ E, 35°52_ N–36°25_ E) in Iskenderun Bay. Fish were sampled monthly from Iskenderun Bay for a period of 12 months from 2006 May to 2007 April (Nt_=_331, $$ {\hbox{Wt}}\pm {\hbox{SD}}\left( {\hbox{range}} \right) = {392}.{92}\pm {72}.{76}\,{\hbox{g}}\left( {{169} - {927}\,{\hbox{g}}} \right) $$,$$ {\hbox{TLt}}\pm {\hbox{SD}}\left( {\hbox{range}} \right) = {3}0.{85}\pm {3}.{88}\,{\hbox{cm}}\left( {{17} - {48}.{3}\,{\hbox{cm}}} \right) $$). Gnathia sp. was only extracted from the epithelium of the buccal cavity and internal side of the gills arch. The monthly patterns in infested fish samples (Np_=_109, $$ {\hbox{Wp}}\pm {\hbox{SD}}\left( {\hbox{range}} \right) = {349}.{25}\pm {182}.{79}\,{\hbox{g}}\left( {{169} - {853}\,{\hbox{g}}} \right) $$, $$ {\hbox{TLt}}\pm {\hbox{SD}}\left( {\hbox{range}} \right) = {26}.0{5}\pm {12}.{68}\,{\hbox{cm}}\left( {{18}.{2} - {45}.0\,{\hbox{cm}}} \right) $$) infestation rates (mean prevalence, P_=_28.12% (0–60) and mean intensity $$ \left( {{\hbox{MI}}\pm {\hbox{SD}} = {23}.{69}\pm {14}.{78}\left( {{4} - {82}} \right)} \right. $$, the relationship between length–weight and infested/non-infested fish were calculated. Although the gnathiid parasite high intensities were observed in fish, there was no significant effect on the growth and general health condition of infested fish."																				
2011	"Hlásny, Tomá_; K_ístek, _t_pán; Holu_a, Jaroslav; Trombik, Ji_í; Urba_cová, Nad__da"	Snow disturbances in secondary Norway spruce forests in Central Europe: Regression modeling and its implications for forest management	Environmental	DNN	Regression	Forest Ecology and Management	262	12	2151-2161	10.1016/j.foreco.2011.08.005	https://www.sciencedirect.com/science/article/pii/S0378112711004804	"Snow is an important ecological factor limiting vegetation distribution, growth, and regeneration, and the importance of snow in the latitudes of Central Europe is expected to increase in the future. We assessed snow damage to secondary spruce stands (not of native provenance therefore not adapted to local conditions) in a mountainous region of 14500ha in Central Europe (Moravian–Silesian Beskids, Czech Republic). We used neural networks-based regression modeling to study the relationship between stand and environmental parameters and four types of snow damage (top tree, crown, and stem breakage, and uprooting) that occurred during heavy snowfalls in winter 2005/2006 and 2009. Almost 40000 trees were sampled in 345 plots after each of these two events. The results suggest that parameters that can be controlled by forest management (mainly stand density and taper) were not closely associated with spruce forest resistance to snow damage. Investigated snow damage types were primarily related to the developmental stage of the stand, as indicated by stand volume, age, height, and diameter. Damage in 2009, which was caused by shorter-lasting and lower snow loads than the damage in 2005/2006, was also associated with elevation and snow depth. The response of snow damage to all stand development-related variables was clearly unimodal. We infer that forest management can reduce snow damage to secondary spruce forests in Central Europe only to a limited extent, especially under heavy snow loads. This conclusion is supported by the heavy snows that have frequently fallen on forests in Central Europe in the past and the projected increase in winter precipitation in mid- and northern latitudes; thereby increasing snow damage to forest in the future. Therefore, managers of such spruce forests should not specifically consider forest resistance to snow damage but should apply general practices that maintain forest health and productivity."																				
2011	"Holt, K.; Allen, G.; Hodgson, R.; Marsland, S.; Flenley, J."	Progress towards an automated trainable pollen location and classifier system for use in the palynology laboratory	Images	DNN	Classification	Review of Palaeobotany and Palynology	167	3	175-183	10.1016/j.revpalbo.2011.08.006	https://www.sciencedirect.com/science/article/pii/S0034666711001205	"Palynological analysis, as applied in vegetation reconstruction, climate change studies, allergy research, melissopalynology and forensic science, is a slow, laborious process. Here, we present an ongoing project aimed at the realisation of a low-cost, automatic, trainable system for the location, recognition and counting of pollen on standard glass microscope slides. This system is designed to dramatically reduce the time that the palynologist must spend at the microscope, thus considerably increasing productivity in the pollen lab. The system employs robotics, image processing and neural network technology to locate, photograph and classify pollen on a conventionally prepared pollen slide. After locating pollen grains on a microscope slide, it captures images of them. The individual images of the pollen are then analysed using a set of mathematically defined features. These feature sets are then classified by the system by comparison with feature sets previously obtained from the analysis of images of known pollen types. The classified images are then presented to the palynologist for checking. This ability for post-classification checking is a key part of the automated palynology process, as it is likely that under the current technology, it will be very difficult to produce an automated pollen counting and classifier system that is 100% correct 100% of the time. However, it is important to remember that pollen counts performed by human palynologists are seldom 100% correct 100% of the time as well. The system has been tested on slides containing fresh pollen of six different species. The slides were counted repeatedly by both the system and by human palynologists. The results of these tests show that the machine can produce counts with very similar proportions to human palynologists (typically within 1–4%). Although the means of the machine counts were usually slightly lower than those of the human counts, the variance was also lower, demonstrating that the machine counts pollen more consistently than human palynologists. The system described herein should be viewed as a potentially very valuable tool in the palynological laboratory. Its ability to discriminate between the bulk of pollen and debris on a slide and capture and store images of each pollen grain is in itself a very useful feature. This capability combined with the relatively positive results from this first all-of-system capture-and-classify test clearly demonstrate the potential of the system to considerably improve the efficiency of palynological analysis. However, more tests are required before the extent of the system's potential can be fully realised. The next step, testing the system on fossil pollen samples, is now underway."																				
2011	"Kiranyaz, Serkan; Ince, Turker; Pulkkinen, Jenni; Gabbouj, Moncef; Ärje, Johanna; Kärkkäinen, Salme; Tirronen, Ville; Juhola, Martti; Turpeinen, Tuomas; Meissner, Kristian"	Classification and retrieval on macroinvertebrate image databases	Images	CNN	Classification	Computers in Biology and Medicine	41	7	463-472	10.1016/j.compbiomed.2011.04.008	https://linkinghub.elsevier.com/retrieve/pii/S0010482511000795	"Aquatic ecosystems are continuously threatened by a growing number of human induced changes. Macroinvertebrate biomonitoring is particularly efficient in pinpointing the cause–effect structure between slow and subtle changes and their detrimental consequences in aquatic ecosystems. The greatest obstacle to implementing efficient biomonitoring is currently the cost-intensive human expert taxonomic identification of samples. While there is evidence that automated recognition techniques can match human taxa identification accuracy at greatly reduced costs, so far the development of automated identification techniques for aquatic organisms has been minimal. In this paper, we focus on advancing classification and data retrieval that are instrumental when processing large macroinvertebrate image datasets. To accomplish this for routine biomonitoring, in this paper we shall investigate the feasibility of automated river macroinvertebrate classification and retrieval with high precision. Besides the state-of-the-art classifiers such as Support Vector Machines (SVMs) and Bayesian Classifiers (BCs), the focus is particularly drawn on feed-forward artificial neural networks (ANNs), namely multilayer perceptrons (MLPs) and radial basis function networks (RBFNs). Since both ANN types have been proclaimed superior by different investigations even for the same benchmark problems, we shall first show that the main reason for this ambiguity lies in the static and rather poor comparison methodologies applied in most earlier works. Especially the most common drawback occurs due to the limited evaluation of the ANN performances over just one or few network architecture(s). Therefore, in this study, an extensive evaluation of each classifier performance over an ANN architecture space is performed. The best classifier among all, which is trained over a dataset of river macroinvertebrate specimens, is then used in the MUVIS framework for the efficient search and retrieval of particular macroinvertebrate peculiars. Classification and retrieval results present high accuracy and can match an experts' ability for taxonomic identification."																				
2011	"Lucrezia, Davide De; Slanzi, Debora; Poli, Irene; Polticelli, Fabio; Minervini, Giovanni"	Do Natural Proteins Differ from Random Sequences Polypeptides? Natural vs. Random Proteins Classification Using an Evolutionary Neural Network	Molecular	DNN	Classification	PLOS ONE	7	5	e36634	10.1371/journal.pone.0036634	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0036634	"Are extant proteins the exquisite result of natural selection or are they random sequences slightly edited by evolution? This question has puzzled biochemists for long time and several groups have addressed this issue comparing natural protein sequences to completely random ones coming to contradicting conclusions. Previous works in literature focused on the analysis of primary structure in an attempt to identify possible signature of evolutionary editing. Conversely, in this work we compare a set of 762 natural proteins with an average length of 70 amino acids and an equal number of completely random ones of comparable length on the basis of their structural features. We use an ad hoc Evolutionary Neural Network Algorithm (ENNA) in order to assess whether and to what extent natural proteins are edited from random polypeptides employing 11 different structure-related variables (i.e. net charge, volume, surface area, coil, alpha helix, beta sheet, percentage of coil, percentage of alpha helix, percentage of beta sheet, percentage of secondary structure and surface hydrophobicity). The ENNA algorithm is capable to correctly distinguish natural proteins from random ones with an accuracy of 94.36%. Furthermore, we study the structural features of 32 random polypeptides misclassified as natural ones to unveil any structural similarity to natural proteins. Results show that random proteins misclassified by the ENNA algorithm exhibit a significant fold similarity to portions or subdomains of extant proteins at atomic resolution. Altogether, our results suggest that natural proteins are significantly edited from random polypeptides and evolutionary editing can be readily detected analyzing structural features. Furthermore, we also show that the ENNA, employing simple structural descriptors, can predict whether a protein chain is natural or random."																				
2011	"Marcoux, Marianne; Auger-Méthé, Marie; Humphries, Murray M."	Variability and context specificity of narwhal (Monodon monoceros) whistles and pulsed calls	Sound	Unknown	Regression	Marine Mammal Science	28	4	649-665	10.1111/j.1748-7692.2011.00514.x	https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1748-7692.2011.00514.x	"The behavioral and environmental context of animal calls provides insights into their functions. Narwhals are a highly vocal species and, like other social cetaceans, rely on acoustic signals to communicate. We characterize and categorize narwhal whistles and pulsed calls, as well as investigate variation in these calls under different contexts (behavior, herd, and year) using recordings made during the month of August 2006–2008, in Koluktoo Bay (72°04_N, 80°32_W). We detected similarities among whistles but not pulsed calls that were produced under a similar behavioral context. Both whistles and pulsed calls recorded within the same herd were more similar than whistles and pulsed calls recorded within different herds. We did not find any type of whistle to be associated with a specific behavior although some acoustical features might be behavior specific. Both whistles and pulsed calls show properties that are consistent with the hypothesis that narwhals produce group- or individual-specific calls."																				
2011	"McKenna Jr., James E.; Johnson, James H."	Landscape Models of Brook Trout Abundance and Distribution in Lotic Habitat with Field Validation	Environmental	DNN	Regression	North American Journal of Fisheries Management	31	4	742-756	10.1080/02755947.2011.593940	https://onlinelibrary.wiley.com/doi/abs/10.1080/02755947.2011.593940	"Brook trout Salvelinus fontinalis are native fish in decline owing to environmental changes. Predictions of their potential distribution and a better understanding of their relationship to habitat conditions would enhance the management and conservation of this valuable species. We used over 7,800 brook trout observations throughout New York State and georeferenced, multiscale landscape condition data to develop four regionally specific artificial neural network models to predict brook trout abundance in rivers and streams. Land cover data provided a general signature of human activity, but other habitat variables were resistant to anthropogenic changes (i.e., changing on a geological time scale). The resulting models predict the potential for any stream to support brook trout. The models were validated by holding 20% of the data out as a test set and by comparison with additional field collections from a variety of habitat types. The models performed well, explaining more than 90% of data variability. Errors were often associated with small spatial displacements of predicted values. When compared with the additional field collections (39 sites), 92% of the predictions were off by only a single class from the field-observed abundances. Among “least-disturbed” field collection sites, all predictions were correct or off by a single abundance class, except for one where brown trout Salmo trutta were present. Other degrading factors were evident at most sites where brook trout were absent or less abundant than predicted. The most important habitat variables included landscape slope, stream and drainage network sizes, water temperature, and extent of forest cover. Predicted brook trout abundances were applied to all New York streams, providing a synoptic map of the distribution of brook trout habitat potential. These fish models set benchmarks of best potential for streams to support brook trout under broad-scale human influences and can assist with planning and identification of protection or rehabilitation sites. Received August 24, 2010; accepted March 1, 2011"																				
2011	"Müller, Daniel; Mburu, John"	"Forecasting hotspots of forest clearing in Kakamega Forest, Western Kenya"	Environmental	DNN	Regression	Forest Ecology and Management	257	3	968-977	10.1016/j.foreco.2008.10.032	https://www.sciencedirect.com/science/article/pii/S0378112708008177	"Kakamega Forest is the last remaining rainforest in Kenya and the easternmost remnant of the Guinean-Congolian rainforest belt. As such, it is home to a large number of endemic fauna and flora species. Yet the remaining natural forest is under imminent threat of degradation due to a rapidly growing population in its vicinity and a poverty rate far above the national average. The growing demand for forest resources and ecosystem services will continue to exert great pressure on the remaining forest fragments. In this paper, we predict future hotspots of forest clearing of the remaining natural and old-growth secondary forest in Kakamega Forest. We parameterized an artificial neural network model using resilient backpropagation to simulate the likelihood of forest clearing for each location. Input variables into the network included historic information on forest clearings together with variables capturing the status of forest protection, accessibility to roads and markets, as well as topography and forest density. Simulation results were used to predict future clearings based on observed rates of change. Hotspots of forest clearing were derived by assessing the neighborhood density of predicted clearings. Our results indicate that forest clearings occurred across all forest fragments. Hotspots of future forest clearing tended to occur near roads and market centers. Most future hotspots were found in areas with a lower protection status, where some forest use is allowed. But our model also predicted considerable pressure on remaining old-growth forest resources in the strictly protected National Reserve. Our predictions of deforestation hotspots contribute to a better geographic targeting of nature protection activities and forest management investments in Kakamega Forest. Thus, it will hopefully help policy makers and land managers to strike a balance between satisfying the needs of local livelihoods and preserving the unique ecological values of Kakamega Forest for future generations."																				
2011	"Palozzi, R; Quartararo, M; Marcelli, M; Arati, FM; Boccanera, P"	Combining underwater visual census and self-organising maps: a freshwater ecology application	Other	DNN	Modeling	Underwater Technology	29	4	173-181	10.3723/ut.29.173	https://www.ingentaconnect.com/content/sut/unwt/2011/00000029/00000004/art00003	"A very small and deep lake (a sinkhole) in Central Italy was studied during summer 2010 adopting an artificial intelligence based method, the self-organising map (SOM), for the analysis of data collected by a slightly modified underwater visual census (UVC) technique (strip-transects). The data were collected on the assemblage structure and individual age/size of the summer fish found in the sinkhole. UVC data are known to be in some cases partially unreliable for common quantitative statistical analysis (being noisy, uncertain and redundant, particularly in small systems). A specific type of artificial neural network (the SOM) was therefore put forward as a suitable solution for properly extracting information from this kind of data. In the past two decades SOMs have proved to be often more appropriate than other common multivariate techniques in assessing a range of ecological issues. Nevertheless, no study has explicitly taken advantage of the potential of using SOMs with UVC data. The paper gives a brief example of how SOMs can be used to represent and analyse multivariate patterns of a fish assemblage."																				
2011	"Pereira, G. C.; Ebecken, N. F. F."	Combining in situ flow cytometry and artificial neural networks for aquatic systems monitoring	Images	DNN	Classification	Expert Systems with Applications	38	8	9626-9632	10.1016/j.eswa.2011.01.140	https://www.sciencedirect.com/science/article/pii/S0957417411001734	"In order to produce a system to automatically identify field water samples, it is essential to cover the entire spectrum of biological variation that a species can be found in the natural environments. This information must be available for modeling within specific training data sets. Thus, the one of the objectives of this work is to build a set of flow cytometric data containing this information in order to develop artificial neural network models that learn the patterns of biological variation induced by some environmental parameters. The second goal is to test the model in near real time recognition of phytoplankton. Twelve isolated groups were assayed in order to define their optical signature boundaries. Our results show high performance of a Radial Basis Function Neural Network in the test data set and its recognition and enumeration capability when assessing field data. It also suggests that it would be better to use a more generalist model for the different phytoplankton groups and more specialized networks to deal with specific organisms within a taxon. A discussion about the use of this type of model in monitoring programs is presented."																				
2011	"Rodriguez, Álvaro; Bermúdez, María; Rabuñal, Juan R.; Puertas, Jerónimo; Dorado, Julián; Pena, Luís; Balairón, Luis"	Optical Fish Trajectory Measurement in Fishways through Computer Vision and Artificial Neural Networks	Video	DNN	Regression	Journal of Computing in Civil Engineering	25	4	291-301	10.1061/(ASCE)CP.1943-5487.0000092	https://ascelibrary.org/doi/abs/10.1061/%28ASCE%29CP.1943-5487.0000092	"Vertical slot fishways are hydraulic structures that allow the upstream migration of fish through obstructions in rivers. The appropriate design of a vertical slot fishway depends on the interplay between hydraulic and biological variables because the hydrodynamic properties of the fishway must match the requirements of the fish species for which it is intended. One of the primary difficulties associated with studies of real fish behavior in fishway models is that the existing mechanisms to measure the behavior of the fish in these assays, such as direct observation or placement of sensors on the specimens, are impractical or unduly affect the animal behavior. This paper proposes a new procedure for measuring the behavior of the fish. The proposed technique uses artificial neural networks and computer vision techniques to analyze images obtained from the assays by means of a camera system designed for fishway integration. It is expected that this technique will provide detailed information about the fish behavior, and it will help to improve fish passage devices, which is currently a subject of interest in the area of civil engineering. A series of assays has been performed to validate this new approach in a full-scale fishway model with living fish. We have obtained very promising results that allow accurate reconstruction of the movements of the fish within the fishway."																				
2011	"Young, William A.; Millie, David F.; Weckman, Gary R.; Anderson, Jerone S.; Klarer, David M.; Fahnenstiel, Gary L."	Modeling net ecosystem metabolism with an artificial neural network and Bayesian belief network	Environmental	"DNN, Other"	Regression	Environmental Modelling & Software	26	10	1199-1210	10.1016/j.envsoft.2011.04.004	https://www.sciencedirect.com/science/article/pii/S1364815211001022	"Artificial neural networks (ANNs) and Bayesian belief networks (BBNs) utilizing select environmental variables were developed and evaluated, with the intent to model net ecosystem metabolism (a proxy for system trophic state) within a freshwater wetland. Network modeling was completed independently for distinct data subsets, representing periods of ‘low’ and ‘high’ water levels throughout in the wetland. ANNs and BBNs were ‘benchmarked’ against traditional parametric analyses, with network architectures outperforming regression models. ANNs delivered the greatest predictive accuracy for NEM and did not require expert knowledge about system variables for their development. BBNs provided users with an interactive diagram depicting predictor interaction and the qualitative/quantitative effects of variable dynamics upon NEM, thereby affording better information extraction. Importantly, BBNs accommodated the imbalanced nature of the dataset and appeared less affected (than ANNs) with variable auto-correlation traits that are typically observed within large and ‘noisy’ environmental datasets."																				
2012	"Abirami, S.; Ramalingam, V.; Palanivel, S."	Species classification of aquatic plants using GRNN and BPNN	Images	"DNN, Other"	Classification	AI & SOCIETY	29	1	45-52	10.1007/s00146-012-0433-z	https://link.springer.com/article/10.1007/s00146-012-0433-z	"Computer-aided plant species identification acts significantly on plant digital museum system and systematic botany, which is the groundwork for research and development of plants. This work presents a method for plant species identification using the images of flowers. It focuses on the stable feature extraction of flowers such as color, texture and shape features. Color-based segmentation using k-means clustering is used to extract the color features. Texture segmentation using texture filter is used to segment the image and obtain texture features. Sobel, Prewitt and Robert operators are used to extract the boundary of image and to obtain the shape features. From 405 images of flowers, color, texture and shape features are extracted. Classification of the plants into dry land plants and aquatic plants, the aquatic plant species into wet and marsh aquatic plants, wet aquatic plants into Iridaceae and Epilobium family and marsh aquatic plants into Malvaceae and Onagraceae family, the Iridaceae family is again classified into Babiana and Crocus species, the family Epilobium into Canum and Hirsutum, the family Malvaceae into Mallow and Pavonia, the family Onagraceae into Fuschia and Ludwigia species are done using general regression neural network and backpropagation neural network classifiers."																				
2012	"Bálint, Zsolt; Kertész, Krisztián; Piszter, Gábor; Vértesy, Zofia; Biró, László P."	The well-tuned blues: the role of structural colours as optical signals in the species recognition of a local butterfly fauna (Lepidoptera: Lycaenidae: Polyommatinae)	Other	DNN	Classification	Journal of The Royal Society Interface	9	73	1745-1756	10.1098/rsif.2011.0854	https://royalsocietypublishing.org/doi/full/10.1098/rsif.2011.0854	"The photonic nanoarchitectures responsible for the blue colour of the males of nine polyommatine butterfly species living in the same site were investigated structurally by electron microscopy and spectrally by reflectance spectroscopy. Optical characterization was carried out on 110 exemplars. The structural data extracted by dedicated software and the spectral data extracted by standard software were inputted into an artificial neural network software to test the specificity of the structural and optical characteristics. It was found that both the structural and the spectral data allow species identification with an accuracy better than 90 per cent. The reflectance data were further analysed using a colour representation diagram built in a manner analogous to that of the human Commission Internationale de l'Eclairage diagram, but the additional blue visual pigment of lycaenid butterflies was taken into account. It was found that this butterfly-specific colour representation diagram yielded a much clearer distinction of the position of the investigated species compared with previous calculations using the human colour space. The specific colours of the investigated species were correlated with the 285 flight-period data points extracted from museum collections. The species with somewhat similar colours fly in distinct periods of the year such that the blue colours are well tuned for safe mate/competitor recognition. This allows for the creation of an effective pre-zygotic isolation mechanism for closely related synchronic and syntopic species."																				
2012	"Chahouki, Mohammad Ali Zare; Ahvazi, Lyla Khalasi"	"Predicting potential distributions of Zygophyllum eurypterum by three modeling techniques (ENFA, ANN and logistic) in North East of Semnan, Iran"	Environmental	Unknown	Modeling	Range Management and Agroforestry	33	2	123-128	NA	https://hero.epa.gov/hero/index.cfm/reference/details/reference_id/3334276	NA																				
2012	"Cruz-Ramírez, M.; Hervás-Martínez, C.; Jurado-Expósito, M.; López-Granados, F."	A multi-objective neural network based method for cover crop identification from remote sensed data	Other	DNN	Classification	Expert Systems with Applications	39	11	10038-10048	10.1016/j.eswa.2012.02.046	https://www.sciencedirect.com/science/article/pii/S0957417412002904	"One of the objectives of conservation agriculture to reduce soil erosion in olive orchards is to protect the soil with cover crops between rows. Andalusian and European administrations have developed regulations to subsidise the establishment of cover crops between rows in olive orchards. Current methods to follow-up the cover crops systems by administrations consist of sampling and on ground visits of around 1% of the total olive orchards surface at any time from March to late June. This paper outlines a multi-objective neural network based method for the classification of olive trees (OT), bare soil (BS) and different cover crops (CC), using remote sensing data taken in spring and summer. The main findings of this paper are: (1) the proposed models performed well in all seasons (particularly during the summer, where only 48 pixels of CC are confused with BS and 10 of BS with CC with the best model obtained. This model obtained a 97.80% of global classification, 95.20% in the class with the worst classification rate and 0.9710 in the KAPPA statistics), and (2) the best-performing models could potentially decrease the number of complaints made to the Andalusian and European administrations. The complaints in question concern the poor performance of current on-ground methods to address the presence or absence of cover crops in olive orchards."																				
2012	"Husin, Z.; Shakaff, A. Y. M.; Aziz, A. H. A.; Farook, R. S. M.; Jaafar, M. N.; Hashim, U.; Harun, A."	Embedded portable device for herb leaves recognition using image processing techniques and neural network algorithm	Images	DNN	Classification	Computers and Electronics in Agriculture	89		18-29	10.1016/j.compag.2012.07.009	https://www.sciencedirect.com/science/article/pii/S0168169912001949	"Herbs have been widely used in food preparation, medicine and cosmetic industry. Knowing which herbs to be used would be very critical in these applications. Nevertheless, the current way of identification and determination of the types of herbs is still being done manually and prone to human error. Designing a convenient and automatic recognition system of herbs species is essential since this will improve herb species classification efficiency. This research focus on recognition approach to the shape and texture features of the herbs leaves. It aims to realize the computerized method to classify the herbs plants in a very convenient way. Portable herb leaves recognition system through image and data processing techniques is implemented as automated herb plant classification system. It is very easy to use and inexpensive system designed especially for helping scientist in agricultural field. The proposed system employs neural networks algorithm and image processing techniques to perform recognition on twenty species of herbs. One hundred samples for each species went through the system and the recognition accuracy was at 98.9%. Most importantly the system is capable of identifying the herbs leaves species even though they are dried, wet, torn or deformed. The efficiency and effectiveness of the proposed method in recognizing and classifying the different herbs species is demonstrated by experiments."																				
2012	"Kang, Seung-Ho; Song, Su-Hee; Lee, Sang-Hee"	Identification of butterfly species with a single neural network system	Images	DNN	Classification	Journal of Asia-Pacific Entomology	15	3	431-435	10.1016/j.aspen.2012.03.006	https://www.sciencedirect.com/science/article/pii/S1226861512000374	"Growing interest in conservation and biodiversity increased the demand for accurate and consistent identification of biological objects, such as insects, at the level of individual or species. Among the identification issues, butterfly identification at the species level has been strongly addressed because it is directly connected to the crop plants for human food and animal feed products. However, so far, the widely-used reliable methods were not suggested due to the complicated butterfly shape. In the present study, we propose a novel approach based on a back-propagation neural network to identify butterfly species. The neural network system was designed as a multi-class pattern classifier to identify seven different species. We used branch length similarity (BLS) entropies calculated from the boundary pixels of a butterfly shape as the input feature to the neural network. We verified the accuracy and efficiency of our method by comparing its performance to that of another single neural network system in which the binary values (0 or 1) of all pixels on an image shape are used as a feature vector. Experimental results showed that our method outperforms the binary image network in both accuracy and efficiency."																				
2012	"Larsen, Peter E.; Field, Dawn; Gilbert, Jack A."	Predicting bacterial community assemblages using an artificial neural network approach	Environmental	Unknown	Modeling	Nature Methods	9	6	621-625	10.1038/nmeth.1975	https://www.nature.com/articles/nmeth.1975	Microbial Assemblage Prediction is a predictive model for the climate-dependent abundance of microbial taxa in space and time. It takes potential interactions between taxa into account and is used on longitudinal metagenomic and climate data from the Western English Channel.																				
2012	"Malek, Sorayya; Salleh, Aishah; Milow, Pozi; Baba, Mohd Sapiyan; Sharifah, S.A."	"Applying artificial neural network theory to exploring diatom abundance at tropical Putrajaya Lake, Malaysia"	Environmental	RNN	Regression	Journal of Freshwater Ecology	27	2	211-227	10.1080/02705060.2011.635883	https://www.tandfonline.com/doi/full/10.1080/02705060.2011.635883	"This article explores the relationship between diatom abundance and water quality variables in tropical Putrajaya Lake based on limnological data collected from 2001 to 2006, using supervised and unsupervised artificial neural networks (ANNs). Recurrent artificial neural network (RANN) was used for the supervised ANNs and Kohonen Self Organizing Feature Maps (SOMs) for the unsupervised ANNs. The RANN was developed for the prediction of diatom abundance using variables selected by sensitivity analysis (water temperature, pH, dissolved oxygen, and turbidity). The RANN model performance was measured using root mean squared error (19.0_cell/mL) and the r-value (0.7). SOM was used in this study for classification and clustering of diatom abundance in relation to selected water quality variables and was validated using a sensitivity curve of diatom abundance over the selected variable range generated from RANN. SOM has been employed in this study for pattern discovery of diatom abundance at Putrajaya Lake. The extracted patterns of diatom abundance in terms of propositional IF…else rules were tested and yielded an accuracy rate of 87%."																				
2012	"Mosleh, Mogeeb AA; Manssor, Hayat; Malek, Sorayya; Milow, Pozi; Salleh, Aishah"	A preliminary study on automated freshwater algae recognition and classification system	Images	DNN	Classification	BMC Bioinformatics	13	17	S25	10.1186/1471-2105-13-S17-S25	https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-13-S17-S25	"Freshwater algae can be used as indicators to monitor freshwater ecosystem condition. Algae react quickly and predictably to a broad range of pollutants. Thus they provide early signals of worsening environment. This study was carried out to develop a computer-based image processing technique to automatically detect, recognize, and identify algae genera from the divisions Bacillariophyta, Chlorophyta and Cyanobacteria in Putrajaya Lake. Literature shows that most automated analyses and identification of algae images were limited to only one type of algae. Automated identification system for tropical freshwater algae is even non-existent and this study is partly to fill this gap."																				
2012	"Pereira, Luís A. M.; Nakamura, Rodrigo Y. M.; de Souza, Guilherme F. S.; Martins, Dagoberto; Papa, João P."	Aquatic weed automatic classification using machine learning techniques	Images	DNN	Classification	Computers and Electronics in Agriculture	87		56-63	10.1016/j.compag.2012.05.015	https://www.sciencedirect.com/science/article/pii/S0168169912001299	"Aquatic weed control through chemical products has attracted much attention in the last years, mainly because of the ecological disorder caused by such plants, and also the consequences to the economical activities. However, this kind of control has been carried out in a non-automatic way by technicians, and may be a not healthy policy, since each species may react differently to the same herbicide. Thus, this work proposes the automatic identification of some species by means of supervised pattern recognition techniques and shape descriptors in order to compose a nearby future expert system for automatic application of the correct herbicide. Experiments using some state-of-the-art techniques have shown the robustness of the employed pattern recognition techniques."																				
2012	"Piszter, Gábor; Kertész, Krisztián; Vértesy, Zofia; Bálint, Zsolt; Biró, László Péter"	Color based discrimination of chitin–air nanocomposites in butterfly scales and their role in conspecific recognition	Other	Unknown	Classification	Analytical Methods	3	1	78-83	10.1039/C0AY00410C	https://pubs.rsc.org/en/content/articlelanding/2011/ay/c0ay00410c	"The self-assembled photonic nanoarchitectures occurring in the wing scales of the blue colored males of nine Lycaenid butterfly species, living in the same habitat, were investigated by reflectance measurements followed by automated data processing. The spectral signatures of the nine species analyzed using an artificial neural network software show that despite the fact that all possess similar “pepper pot” type structure, the spectral signatures exhibit enough characteristic differences to allow the unambiguous identification of conspecific individuals. By cross-correlating the position of the individuals of each species in the CIE chromaticity diagram with their flying period it was possible to show that relatively similarly looking, closely related species fly in distinct periods. The spectral identification method may prove useful in the investigation of museum exemplars which cannot be harmed. As the self-assembled, quasiordered, “pepper pot” type photonic nanoarchitectures of various colors seem to pose milder constraints on the production process as compared with perfect photonic crystals, such nanoarchitectures may find practical applications in a wide range from the textile industry to environmentally friendly colorants."																				
2012	"Szczepko, Katarzyna; Kruk, Andrzej; Bartos, Maciej"	The role of mosaicity of the post-agriculture area of the Kampinos National Park in determining the diversity of species of spider wasps (Hymenoptera: Pompilidae)	Environmental	DNN	Modeling	European Journal of Entomology	109	1	35-46	10.14411/eje.2012.006	http://www.eje.cz/doi/10.14411/eje.2012.006.html	"From 2000 to 2006 a total of 52 CPUE samples of spider wasps (Hymenoptera: Pompilidae) were collected in the mosaic landscape of the Kampinos National Park (Poland), which is a UNESCO Biosphere Reserve. The hypothesis tested was that both pompilid species richness and abundance is positively associated with spatial heterogeneity. The patterns in spider wasp assemblages were identified using a Kohonen artificial neural network (i.e., self-organizing map). The highest numbers and greatest species richness of pompilids were recorded at sites in open habitats, especially those located on dry soils that are the preferred nesting sites of ground nesting (endogeic) spider wasps. However, pompilid distribution depended not only on the character of a sampling site, but also its location in a mosaic of habitats. The highest values of pompilid abundance and species richness were also recorded at sites surrounded by several different habitats. Both parameters were lower at sites in more homogenous areas, where there were fewer habitats within the flight ranges of spider wasps. A group of three ""cultural species"" (Agenioideus cinctellus, A. sericeus and Auplopus carbonarius) was identified that is significantly associated with wooden buildings. The results of this study are thus consistent with the concept that habitat heterogeneity enhances faunal diversity, as each type of habitat, including anthropogenic ones, potentially contributes to a wider range of available resources."																				
2012	"Szczepko, Katarzyna; Kruk, Andrzej; Bartos, Maciej; Wi_niowski, Bogdan"	"Factors influencing the diversity of cuckoo wasps (Hymenoptera: Chrysididae) in the post-agriculture area of the Kampinos National Park, Poland"	Environmental	DNN	Modeling	Insect Conservation and Diversity	6	3	339-353	10.1111/j.1752-4598.2012.00223.x	https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1752-4598.2012.00223.x	"In the Kampinos National Park (Poland), which is a UNESCO Biosphere Reserve, 47 caught per unit effort samples of Chrysididae were collected in 2000–2006. The aim of the study was to identify the factors promoting the diversity of this rarely studied group of parasitic wasps. A total of 722 specimens belonging to 37 species were recorded, including 18 threatened species and six others recently described as new to the Polish fauna. No chrysidids were recorded in forests, instead they were most abundant on fallow land (i.e. in open habitats), of which those located on dry soils were preferred over humid ones, just as by their endogeic (nesting in the ground) hosts. Many chrysidids that are parasites of hypergeic (nesting above the ground) species were significantly associated with old abandoned wooden buildings, where their hosts use holes in wood for nesting. In addition to the characteristics of the habitat sampled, its position in the land mosaic also determined the diversity of chrysidids. Their lowest abundance and species diversity were recorded in samples from different types of habitat, all located in a uniform environment (i.e. with few other habitats nearby), which limited the diversity of resources available within the flight ranges of chrysidids and their hosts. Our study, thus consistent with the concept that habitat heterogeneity enhances faunal diversity, brings important conclusions for the management of park landscapes: afforestation of open areas (both intentional and resulting from natural succession of plant communities) and removal of old abandoned wooden buildings may limit the land mosaicity and thus faunal diversity."																				
2012	"Yaakob, Shahrul Nizam; Jain, Lakhmi"	An insect classification analysis based on shape features using quality threshold ARTMAP and moment invariant	Images	Other	Classification	Applied Intelligence	37	1	30-Dec	10.1007/s10489-011-0310-3	https://link.springer.com/article/10.1007/s10489-011-0310-3	"The main objective of this paper is to investigate the use of Quality Threshold ARTMAP (QTAM) neural network in classifying the feature vectors generated by moment invariant for the insect recognition task. In this work, six different types of moment invariant technique are adopted to extract the shape features of the insect images. These moment techniques are Geometrical Moment Invariant (GMI), United Moment Invariant (UMI), Zernike Moment Invariant (ZMI), Legendre Moment Invariant (LMI), Tchebichef Moment Invariant (TMI) and Krawtchouk Moment Invariant (KMI). All the moment techniques are analyzed using the concept of intraclass and interclass analysis. In intraclass analysis, several computation methods are introduced in order to examine the invariance properties of adopted moment techniques for the same insect object. Meanwhile, the classification accuracy of neural networks is adopted to measure the interclass characteristic and the effectiveness of moment technique in extracting the shape features of insect images. Other types of neural networks are also utilized in this research work. This includes novel enhancement technique based on the Gaussian and Mahalanobis function that design to increase its prediction accuracy. All the other networks used to classify the feature vectors are based on the Fuzzy ARTMAP (FAM) neural network. The experimental results indicated that the Krawtchouk Moment Invariant technique generated the highest classification accuracy for most of the networks used and generated the smallest error for the intraclass analysis. Using different normalization technique, the Quality Threshold ARTMAP and Mahalanobis distance function (QTAM-m) network gave the highest insect recognition results when compared to other networks."																				
2013	"Banerjee, Amit Kumar; Ravi, Vadlamani; Murty, U. S. N.; Sengupta, Neelava; Karuna, Batepatti"	Application of Intelligent Techniques for Classification of Bacteria Using Protein Sequence-Derived Features	"Molecular, Other"	DNN	Classification	Applied Biochemistry and Biotechnology	170	6	1263-1281	10.1007/s12010-013-0268-1	https://doi.org/10.1007/s12010-013-0268-1	"Standard molecular experimental methodologies and mathematical procedures often fail to answer many phylogeny and classification related issues. Modern artificial intelligent-based techniques, such as radial basis function, genetic algorithm, artificial neural network, and support vector machines are of ample potential in this regard. Reliance on a large number of essential parameters will aid in enhanced robustness, reliability, and better accuracy as opposed to single molecular parameter. This study was conducted with dataset of computed protein physicochemical properties belonging to 20 different bacterial genera. A total of 57 sequential and structural parameters derived from protein sequences were considered for the initial classification. Feature selection based techniques were employed to find out the most important features influencing the dataset. Various amino acids, hydrophobicity, relative sulfur percentage, and codon number were selected as important parameters during the study. Comparative analyses were performed applying RapidMiner data mining platform. Support vector machine proved to be the best method with maximum accuracy of more than 91 %."																				
2013	"Hahn, Allison H.; Hoang, John; McMillan, Neil; Campbell, Kimberley; Congdon, Jenna; Sturdy, Christopher B."	Biological salience influences performance and acoustic mechanisms for the discrimination of male and female songs	Sound	DNN	Modeling	Animal Behaviour	104		213-228	10.1016/j.anbehav.2015.03.023	https://www.sciencedirect.com/science/article/pii/S0003347215001232	"In temperate songbirds, song is traditionally considered a reproductive and territorial signal produced by males. Previous research has described the production of male and female songs by black-capped chickadees, Poecile atricapillus, a temperate songbird species. Statistical classification revealed that the frequency decrease in the first note of the song is a potential acoustic mechanism that would allow birds to distinguish between the sexes. Here we used an operant discrimination task to examine whether this statistical difference in song is an acoustic difference that is perceived by black-capped chickadees in a manner that would allow birds to quickly assess the sex of a singing conspecific. To better understand the underlying perceptual mechanisms for this sex-based discrimination, we also presented birds with untrained, manipulated songs. In experiments 1 and 2, we tested black-capped chickadees using a true category/pseudo category task. Birds in a true category group performed similarly to birds in a pseudo category group, suggesting that there is no advantage in discrimination abilities for birds using categorization (i.e. true category group) over rote memorization (i.e. pseudo category group), possibly because the heightened biological salience of the song influenced the performance of the chickadees. However, responses to untrained songs suggest that birds learned a sex-based category rule when discriminating among songs. In experiment 3, we trained artificial neural networks (ANNs) using an analogous task in order to examine responding in the absence of experiential or biological factors. Results from ANNs suggest that male and female songs are acoustically distinct and can be discriminated using categorization, and that acoustic features within the fee note are an important acoustic mechanism for this sex-based discrimination. Overall, the results suggest that the biological salience of the songs affected the birds' responses."																				
2013	"Hlásny, Tomá_; Tur_áni, Marek"	Persisting bark beetle outbreak indicates the unsustainability of secondary Norway spruce forests: case study from Central Europe	Other	DNN	Regression	Annals of Forest Science	70	5	481-491	10.1007/s13595-013-0279-7	https://link.springer.com/article/10.1007/s13595-013-0279-7	"Secondary Norway spruce forests in the Western Beskids are among the most damaged forests in Europe. Although spruce bark beetle (Ips typographus) has been recently causing large-scale damage to these forests, our understanding of I. typographus dynamics in this environment is inadequate for evaluating forest sustainability."																				
2013	"Kershenbaum, Arik; Sayigh, Laela S.; Janik, Vincent M."	The Encoding of Individual Identity in Dolphin Signature Whistles: How Much Information Is Needed?	Sound	RNN	Classification	PLOS ONE	8	10	e77671	10.1371/journal.pone.0077671	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0077671	"Bottlenose dolphins (Tursiops truncatus) produce many vocalisations, including whistles that are unique to the individual producing them. Such “signature whistles” play a role in individual recognition and maintaining group integrity. Previous work has shown that humans can successfully group the spectrographic representations of signature whistles according to the individual dolphins that produced them. However, attempts at using mathematical algorithms to perform a similar task have been less successful. A greater understanding of the encoding of identity information in signature whistles is important for assessing similarity of whistles and thus social influences on the development of these learned calls. We re-examined 400 signature whistles from 20 individual dolphins used in a previous study, and tested the performance of new mathematical algorithms. We compared the measure used in the original study (correlation matrix of evenly sampled frequency measurements) to one used in several previous studies (similarity matrix of time-warped whistles), and to a new algorithm based on the Parsons code, used in music retrieval databases. The Parsons code records the direction of frequency change at each time step, and is effective at capturing human perception of music. We analysed similarity matrices from each of these three techniques, as well as a random control, by unsupervised clustering using three separate techniques: k-means clustering, hierarchical clustering, and an adaptive resonance theory neural network. For each of the three clustering techniques, a seven-level Parsons algorithm provided better clustering than the correlation and dynamic time warping algorithms, and was closer to the near-perfect visual categorisations of human judges. Thus, the Parsons code captures much of the individual identity information present in signature whistles, and may prove useful in studies requiring quantification of whistle similarity."																				
2013	"Lampson, B. D.; Han, Y. J.; Khalilian, A.; Greene, J.; Mankin, R. W.; Foreman, E. G."	"Automatic detection and identification of brown stink bug, Euschistus servus, and southern green stink bug, Nezara viridula, (Heteroptera: Pentatomidae) using intraspecific substrate-borne vibrational signals"	Sound	Other	Classification	Computers and Electronics in Agriculture	91		154-159	10.1016/j.compag.2012.12.010	https://www.sciencedirect.com/science/article/pii/S0168169912002955	"Stink bugs cost the southeastern US cotton industry millions of dollars each year in crop losses and control costs. These losses are reduced by strategic pesticide applications; however, current methods of monitoring these pests for making management decisions are time-consuming and costly. Therefore, improved methods to identify and monitor these bugs must be investigated in order to optimize pesticide applications. One such method would be to exploit the substrate-borne vibrational signals (SBVSs) of these insects. Recordings of SBVS for two prevalent regional pests, the brown stink bug, Euschistus servus, and southern green stink bug, Nezara viridula, were segmented into separate pulses of variable duration based on signal energy. For each pulse, the linear frequency cepstral coefficients, dominant frequency, and duration were calculated and used as features. These features were classified using a Gaussian mixture model (GMM) and a probabilistic neural network (PNN) to discriminate these SBVS from incidental sounds and SBVS of different species from each other. Detection of SBVS generated by brown stink bugs was performed with over 92% accuracy for single male–female pairs with both PNN and GMM and with over 86% accuracy for 30 individuals with both PNN and GMM. Detection of SBVS generated by southern green stink bugs was performed with up to 82.5% accuracy with PNN and 68.0% accuracy with GMM for 30 individuals. Also, both PNN and GMM were over 90% accurate in identifying SBVS of brown and southern green stink bugs. Concurrent detection of SBVS from noise and identification of SBVS of brown and southern green stink bugs was 83.3% accurate using PNN and 71.5% accurate using GMM. These results indicated the capability of detecting and identifying stink bug species using their SBVS."																				
2013	"Larios, Diego Francisco; Rodríguez, Carlos; Barbancho, Julio; Baena, Manuel; Leal, Miguel Ángel; Marín, Jesús; León, Carlos; Bustamante, Javier"	An Automatic Weighting System for Wild Animals Based in an Artificial Neural Network: How to Weigh Wild Animals without Causing Stress	Other	DNN	Regression	Sensors	13	3	2862-2883	10.3390/s130302862	https://www.mdpi.com/1424-8220/13/3/2862	"This paper proposes a novel and autonomous weighing system for wild animals. It allows evaluating changes in the body weight of animals in their natural environment without causing stress. The proposed system comprises a smart scale designed to estimate individual body weights and their temporal evolution in a bird colony. The system is based on computational intelligence, and offers valuable large amount of data to evaluate the relationship between long-term changes in the behavior of individuals and global change. The real deployment of this system has been for monitoring a breeding colony of lesser kestrels (Falco naumanni) in southern Spain. The results show that it is possible to monitor individual weight changes during the breeding season and to compare the weight evolution in males and females."																				
2013	"Li, Xinhai; Wang, Yuan"	Applying various algorithms for species distribution modelling	NA	NA	Review	Integrative Zoology	8	2	124-135	10.1111/1749-4877.12000	https://onlinelibrary.wiley.com/doi/abs/10.1111/1749-4877.12000	"Species distribution models have been used extensively in many fields, including climate change biology, landscape ecology and conservation biology. In the past 3 decades, a number of new models have been proposed, yet researchers still find it difficult to select appropriate models for data and objectives. In this review, we aim to provide insight into the prevailing species distribution models for newcomers in the field of modelling. We compared 11 popular models, including regression models (the generalized linear model, the generalized additive model, the multivariate adaptive regression splines model and hierarchical modelling), classification models (mixture discriminant analysis, the generalized boosting model, and classification and regression tree analysis) and complex models (artificial neural network, random forest, genetic algorithm for rule set production and maximum entropy approaches). Our objectives are: (i) to compare the strengths and weaknesses of the models, their characteristics and identify suitable situations for their use (in terms of data type and species–environment relationships) and (ii) to provide guidelines for model application, including 3 steps: model selection, model formulation and parameter estimation."																				
2013	"Mielke, Alexander; Zuberbühler, Klaus"	"A method for automated individual, species and call type recognition in free-ranging animals"	Sound	DNN	Classification	Animal Behaviour	86	2	475-482	10.1016/j.anbehav.2013.04.017	https://www.sciencedirect.com/science/article/pii/S0003347213001978	"The ability to identify individuals reliably is often a key prerequisite for animal behaviour studies in the wild. In primates, recognition of other group members can be based on individual differences in the voice, but these cues are typically too subtle for human observers. We applied a combined mechanism consisting of a call feature extraction (mel frequency cepstral coefficients) and pattern recognition algorithm (artificial neural networks) to investigate whether automated caller identification is possible in free-ranging primates. The mechanism was tested for its accuracy in recognizing species, call type and caller identity in a large population of free-ranging blue monkeys, Cercopithecus mitis stuhlmanni, in Budongo Forest, Uganda. Classification was highly accurate with 96% at the species, 98% at the call type and 73% at the caller level. It also outperformed conventional discriminant function analysis in the individual recognition task. We conclude that software based on this method will make a powerful tool for future animal behaviour research, as it allows for automatic, fast and objective classifications in different animal species."																				
2013	"Redowan, Mohammad"	Tree Diversity Detection with Mid-Resolution Images and Environmental Data in a Neural Network	Environmental	DNN	Classification	Journal of the Indian Society of Remote Sensing	41	3	567-576	10.1007/s12524-012-0254-z	https://doi.org/10.1007/s12524-012-0254-z	"Biodiversity maps are crucial to conservation management. The present study assesses the accuracy of detecting tree diversity in an Italian forest site by combining mid-resolution images from Landsat-TM or Advanced Land Observation Satellite (ALOS)’s Advanced Visible and Near Infrared Radiometer type 2 (AVNIR-2) sensors with environmental data namely elevation, slope, aspect and solar radiation in an artificial Neural Network (NN) classifier. The map accuracies obtained for Landsat-TM and ALOS images are 60 % and 53 % respectively. Use of environmental data increases accuracies to 91 % and 81 % respectively. Landsat-TM detects tree diversity more accurately than ALOS. Both the coarser pixel size and finer spectral resolution of Landsat-TM contributed to its higher accuracy."																				
2014	"Awad, Mohamad"	Sea water chlorophyll-a estimation using hyperspectral images and supervised Artificial Neural Network	Other	DNN	Regression	Ecological Informatics	24		60-68	10.1016/j.ecoinf.2014.07.004	https://www.sciencedirect.com/science/article/pii/S1574954114000867	"The use of satellite hyperspectral images has improved the extraction of information compared to multispectral images. Although designed as a technical demonstration for land applications, Hyperion satellite hyperspectral images are used to estimate sea water parameters in the coastal area. A combination of turbid river inputs, as well as the open sea flushing, determines the quality of the sea water in the coastal area and the status of its environment. In addition, the existence of different source of pollution adds to the complexity of the coastal sea water analysis. The field campaigns to retrieve sea water parameters provided by the past completed projects were coincident with acquisition of the Hyperion image covering the pilot area. A robust method based on a supervised Feed-Forward Back-Propagation Artificial Neural Network (ANN-BP) algorithm is applied to retrieve the concentration of chlorophyll-a from hyperspectral image. In addition, Hyperion images are used to show the variation of chlorophyll-a during two different periods of time. The variation is due to many manmade environmental disasters such as oil spill and continuous discharge of chemical and solid wastes. The research proves that the new method based on ANN has improved the mathematical regression methods to a coefficient of determination almost equal 1 compared to about 0.4 for the methods not based on ANN-BP."																				
2014	"Coro, Gianpaolo; Pagano, Pasquale; Ellenbroek, Anton"	Combining simulated expert knowledge with Neural Networks to produce Ecological Niche Models for Latimeria chalumnae	Environmental	DNN	Modeling	Ecological Modelling	268		55-63	10.1016/j.ecolmodel.2013.08.005	https://www.sciencedirect.com/science/article/pii/S0304380013003980	"The order Coelacanthiformes, once thought extinct, is much studied mainly because it contains species that share characteristics with lungfishes and tetrapods. Only a few years ago living specimens were discovered to science, and observations are so rare that the species are considered to be critically endangered. Observations include Latimeria chalumnae in deep waters of the coast of south eastern Africa while Latimeria menadoensis is known from similar habitats in Indonesian waters. Because of the interest around these enigmatic species, Ecological Niche Modelling techniques have been applied to estimate their distribution. The underlying assumption is that the environmental characteristics of the observation points are representative for the species. In this article we evaluate the difference in the output between the niche distributions produced by two expert systems and by two models based on Artificial Neural Networks. We evaluate the predictive behaviour of such models by focusing on L. chalumnae, as more observations are available for this species with respect to L. menadoensis. Finally, we assess the reliability of the maps by numerically evaluating the representativeness of the environmental characteristics in the observation locations, with respect to an area where the models show significant differences. This approach is different from previous ones because one of the expert systems is used to infer pseudo-absence points, that are successively employed to feed a Neural Network. One of the models based on this Neural Network is used to estimate the potential distribution and to produce a more extended map. The method promises to be applicable to other species with few observations, and allows to exploit the power of presence_absence based techniques."																				
2014	"Deng, Xin; Xu, Jian-Xin"	A 3D undulatory locomotion model inspired by C. elegans through DNN approach	Other	Other	Modeling	Neurocomputing	131		248-264	10.1016/j.neucom.2013.10.019	https://www.sciencedirect.com/science/article/pii/S0925231213010783	"In this work, a 3D undulatory locomotion model inspired by Caenorhabditis elegans is constructed. Following the anatomical structure of C. elegans, the body of the model is represented as a multi-joint rigid link system with 12 links. The angle between two consecutive links is determined by the muscle lengths in four quadrants that are controlled by the nervous system. The nervous system of this locomotion model is represented by a dynamic neural network (DNN) that involves three parts: head DNN, central pattern generator (CPG), and body DNN. The head DNN decides turning or not, and CPG produces the sinusoid waves that are transmitted through the body DNN to control the lengths of muscles. The 3D locomotion behavior is achieved by using the DNN to control the muscle lengths, and then using the muscle lengths to control the angles between two consecutive links on both horizontal plane and vertical plane. In this work, the relations between the outputs of DNN and muscle lengths, as well as the muscle lengths and the angles between two consecutive links, are determined. Furthermore, due to the learning capability of DNN, a set of nonlinear functions that are designed to represent the chemotaxis behaviors of C. elegans are learned by the head DNN using Differential Evolution Algorithm. The testing results show good 3D performance of this locomotion model in both forward and backward locomotion, as well as slight turn and Ω turn. Furthermore, this locomotion model performs the chemotaxis behaviors of finding food and avoiding toxin successfully. Finally, quantitative analyses by comparing with the experiment results are provided to verify the realness and effectiveness of this locomotion model, which could serve as a prototype for the worm-like robot."																				
2014	"Favaro, Livio; Briefer, Elodie F.; McElligott, Alan G."	"Artificial Neural Network Approach for Revealing Individuality, Group Membership and Age Information in Goat Kid Contact Calls"	Sound	DNN	Classification	Acta Acustica united with Acustica	100	4	782-789	10.3813/AAA.918758	https://www.ingentaconnect.com/content/dav/aaua/2014/00000100/00000004/art00023	"Machine learning techniques are becoming an important tool for studying animal vocal communication. The goat (Capra hircus) is a very social species, in which vocal communication and recognition are important. We tested the reliability of a Multi-Layer Perceptron (feed-forward Artificial Neural Network, ANN) to automate the process of classification of calls according to individual identity, group membership and maturation in this species. Vocalisations were obtained from 10 half-sibling (same father but different mothers) goat kids, belonging to 3 distinct social groups. We recorded 157 contact calls emitted during first week, and 164 additional calls recorded from the same individuals at 5 weeks. For each call, we measured 27 spectral and temporal acoustic parameters using a custom built program in Praat software. For each classification task we built stratified 10-fold cross-validated neural networks. The input nodes corresponded to the acoustic parameters measured on each signal. ANNs were trained with the error-back-propagation algorithm. The number of hidden units was set to the number of attributes + classes. Each model was trained for 350 epochs (learning rate 0.2; momentum 0.2). To estimate a reliable error for the models, we repeated 10-fold cross-validation iterations 10 times and calculated the average predictive performance. The accuracy was 71.13±1.16% for vocal individuality, 79.59±0.75% for social group and 91.37±0.76% for age of the vocalising animal. Our results demonstrate that ANNs are a powerful tool for studying vocal cues to individuality, group membership and maturation in contact calls. The performances we achieved were higher than those obtained for the same classification tasks using classical statistical methods such as Discriminant Function Analysis. Further studies, investigating the reliability of these algorithms for the realtime classification of contact calls and comparing ANNs with other machine learning techniques are important to develop technology to remotely monitor the vocalisations of domestic livestock."																				
2014	"Fedor, Peter; Peña-Méndez, Eladia Maria; Kucharczyk, Halina; Va_hara, Jaromír; Havel, Josef; Dori_ová, Martina; Prokop, Pavol"	Artificial neural networks in online semiautomated pest discriminability: an applied case with 2 Thrips species	Other	DNN	Classification	Turk J Agric For			14	10.3906/tar-1305-8	https://www.researchgate.net/publication/259089066_Artificial_neural_networks_in_online_semiautomated_pest_discriminability_An_applied_case_with_2_Thrips_species	"Being faced with practical problems in pest identification, we present a methodical paper based on artificial neural networks to discriminate morphologically very similar species, Thrips sambuci Heeger, 1854 and Thrips fuscipennis Haliday, 1836 (Thysanoptera: Thripinae), as an applied case for more general use. The artificially intelligent system may be successfully applied as a credible, online, semiautomated identification tool that extracts hidden information from noisy data, even when the standard characters have much overlap and the common morphological keys hint at the practical problem of high morphological plasticity. Statistical analysis of 17 characters, measured or determined for each Thrips fuscipennis and T. sambuci specimen (reared from larvae in our laboratories), including 15 quantitative morphometric variables, was performed to elucidate morphological plasticity, detect eventual outliers, and visualize differences between the studied taxa. The computational strategy applied in this study includes a set of statistical tools (factor analysis, correlation analysis, principal component analysis, and linear discriminant analysis) followed by the application of a multilayer perceptron artificial neural network system, which models functions of almost arbitrary complexity. This complex approach has proven the existence of 2 separate species: T. fuscipennis and T. sambuci. All the specimens could be clearly distinguished with 2 distinct subgroups for each species, determined by sex. In conclusion, the use of an optimal 3-layer ANN architecture (17, 4, 1) enables fast and reliable 100% classification as proven during the extensive verification process."																				
2014	"Joutsijoki, Henry; Meissner, Kristian; Gabbouj, Moncef; Kiranyaz, Serkan; Raitoharju, Jenni; Ärje, Johanna; Kärkkäinen, Salme; Tirronen, Ville; Turpeinen, Tuomas; Juhola, Martti"	Evaluating the performance of artificial neural networks for the classification of freshwater benthic macroinvertebrates	Images	CNN	Classification	Ecological Informatics	20		12-Jan	10.1016/j.ecoinf.2014.01.004	https://linkinghub.elsevier.com/retrieve/pii/S1574954114000053	"Macroinvertebrates form an important functional component of aquatic ecosystems. Their ability to indicate various types of anthropogenic stressors is widely recognized which has made them an integral component of freshwater biomonitoring. The use of macroinvertebrates in biomonitoring is dependent on manual taxa identification which is currently a time-consuming and cost-intensive process conducted by highly trained taxonomical experts. Automated taxa identification of macroinvertebrates is a relatively recent research development. Previous studies have displayed great potential for solutions to this demanding data mining application. In this research we have a collection of 1350 images from eight different macroinvertebrate taxa and the aim is to examine the suitability of artificial neural networks (ANNs) for automated taxa identification of macroinvertebrates. More specifically, the focus is drawn on different training algorithms of Multi-Layer Perceptron (MLP), probabilistic neural network (PNN) and Radial Basis Function network (RBFN). We performed thorough experimental tests and we tested altogether 13 training algorithms for MLPs. The best classification accuracy of MLPs, 95.3%, was obtained by two conjugate gradient backpropagation variations and scaled conjugate gradient backpropagation. For PNN 92.8% and for RBFN 95.7% accuracies were achieved. The results show how important a proper choice of ANN is in order to obtain high accuracy in the automated taxa identification of macroinvertebrates and the obtained model can outperform the level of identification which is made by a taxonomist."																				
2014	"Juang, Chia-Feng; Chen, Tai-Mou"	Birdsong recognition using prediction-based recurrent neural fuzzy networks	Sound	RNN	Classification	Neurocomputing	71	1	121-130	10.1016/j.neucom.2007.08.011	https://www.sciencedirect.com/science/article/pii/S0925231207002238	"Automatic birdsong recognition using prediction-based singleton-type recurrent neural fuzzy networks (SRNFNs) is proposed in this paper. The recognition task consists of two stages. The first stage segments a significant portion from a birdsong sequence and the second stage performs recognition. For birdsong segmentation, an easy but effective segmentation approach based on time domain energy is proposed. For recognition, the linear predictive coding (LPC) coefficients of each frame in a segmented birdsong are extracted and used as features. These features are fed as inputs to SRNFN recognizers. The SRNFN is constructed by recurrent fuzzy if–then rules with fuzzy singletons in the consequences, and its recurrent aspect makes it suitable for processing patterns with temporal characteristics. In birdsong recognition, the sample prediction technique is used, where one SRNFN is responsible for learning the temporal birdsong relationships of only one species. The prediction error of each SRNFN is then used as a criterion for recognition. Experiments with 10 species of birds and their songs are performed, and a high recognition rate is achieved. Comparisons with a Takagi–Sugeno–Kang (TSK)-type recurrent fuzzy network (TRFN) and backpropagation neural network are also made in the experiments."																				
2014	"Kang, Seung-Ho; Cho, Jung-Hee; Lee, Sang-Hee"	Identification of butterfly based on their shapes when viewed from different angles using an artificial neural network	Images	DNN	Classification	Journal of Asia-Pacific Entomology	17	2	143-149	10.1016/j.aspen.2013.12.004	https://www.sciencedirect.com/science/article/pii/S1226861513001210	"Identification of butterfly species is essential because they are directly associated with crop plants used for human and animal consumption. However, the widely used reliable methods for butterfly identification are not efficient due to complicated butterfly shapes. We previously developed a novel shape recognition method that uses branch length similarity (BLS) entropy, which is a simple branching network consisting of a single node and branches. The method has been successfully applied to recognize battle tanks and characterize human faces with different emotions. In the present study, we used the BLS entropy profile (an assemble of BLS entropies) as an input feature in a feed-forward back-propagation artificial neural network to identify butterfly species according to their shapes when viewed from different angles (for vertically adjustable angle, _=±10°, ±20°, …, ±60° and for horizontally adjustable angle, _=±10°, ±20°, …, ±60°). In the field, butterfly images are generally captured obliquely by camera due to butterfly alignment and viewer positioning, which generates various shapes for a given specimen. To generate different shapes of a butterfly when viewed from different angles, we projected the shapes captured from top-view to a plane rotated through angles _ and _. Projected shapes with differing _ and _ values were used as training data for the neural network and other shapes were used as test data. Experimental results showed that our method successfully identified various butterfly shapes. In addition, we briefly discuss extension of the method to identify more complicated images of different butterfly species."																				
2014	"Kaya, Yılmaz; Kayci, Lokman"	Application of artificial neural network for automatic detection of butterfly species using color and texture features	Images	DNN	Classification	The Visual Computer	30	1	71-79	10.1007/s00371-013-0782-8	https://doi.org/10.1007/s00371-013-0782-8	"Butterflies can be classified by their outer morphological qualities, genital characteristics that can be obtained using various chemical substances and methods which are carried out manually by preparing genital slides through some certain processes or molecular techniques which is a very expensive method. In this study, a new method which is based on artificial neural networks (ANN) and an image processing technique was used for identification of butterfly species as an alternative to conventional diagnostic methods. Five texture and three color features obtained from 140 butterfly images were used for identification of species. Texture features were obtained by using the average of gray level co-occurrence matrix (GLCM) with different angles and distances. The accuracy of the purposed butterfly classification method has reached 92.85 %. These findings suggested that the texture and color features can be useful for identification of butterfly species."																				
2014	"Razavian, Ali Sharif; Azizpour, Hossein; Sullivan, Josephine; Carlsson, Stefan"	CNN Features off-the-shelf: an Astounding Baseline for Recognition	Images	CNN	Classification	arXiv:1403.6382 [cs]				10.48550/arXiv.1403.6382	http://arxiv.org/abs/1403.6382	"Recent results indicate that the generic descriptors extracted from the convolutional neural networks are very powerful. This paper adds to the mounting evidence that this is indeed the case. We report on a series of experiments conducted for different recognition tasks using the publicly available code and model of the \overfeat network which was trained to perform object classification on ILSVRC13. We use features extracted from the \overfeat network as a generic image representation to tackle the diverse range of recognition tasks of object image classification, scene recognition, fine grained recognition, attribute detection and image retrieval applied to a diverse set of datasets. We selected these tasks and datasets as they gradually move further away from the original task and data the \overfeat network was trained to solve. Astonishingly, we report consistent superior results compared to the highly tuned state-of-the-art systems in all the visual classification tasks on various datasets. For instance retrieval it consistently outperforms low memory footprint methods except for sculptures dataset. The results are achieved using a linear SVM classifier (or L2 distance in case of retrieval) applied to a feature representation of size 4096 extracted from a layer in the net. The representations are further modified using simple augmentation techniques e.g. jittering. The results strongly suggest that features obtained from deep learning with convolutional nets should be the primary candidate in most visual recognition tasks."																				
2014	"Santos, Eder C.; Armas, Eduardo Dutra; Crowley, David; Lambais, Marcio Rodrigues"	Artificial neural network modeling of microbial community structures in the Atlantic Forest of Brazil	Environmental	DNN	Modeling	Soil Biology and Biochemistry	69		101-109	10.1016/j.soilbio.2013.10.049	https://www.sciencedirect.com/science/article/pii/S0038071713003933	"Microbial communities vary across the landscape in forest soils, but prediction of their biomass and composition is a difficult challenge due to the large numbers of variables that influence their community structures. Here we examine the use of artificial neural network (ANN) models for extraction of patterns among soil chemical variables and microbial community structures in forest soils from three regions of the Atlantic Forest of Brazil. At each location, variations in soil chemical properties and FAME profiles of microbial community structures were mapped at 20 _ 20 m intervals within 10 ha parcels. Geostatistical analyses showed that spatial variability in soil physical and chemical variables could be mapped at scale distances of 20 m, but that FAME profiles representing the microbial communities were highly variable and had no spatial dependence at the same scale in most cases. RDA analysis showed that FAME signatures representing different microbial groups were positively associated with soil pH, OM, P and base cations concentrations, whereas microbial biomass was negatively associated with the same environmental factors. In contrast, ANN models revealed clear relationships between microbial community structures at each parcel location, and generated verifiable predictions of variations in FAME profiles in relation to soil pH, texture, and the relative abundances of base cations. The results suggest that ANN modeling provides a useful approach for describing the relationships between microbial community structures and soil properties in tropical forest soils that were not able to be captured using geostatistical and RDA analyses."																				
2015	"Beijbom, Oscar; Hoffman, Judy; Yao, Evan; Darrell, Trevor; Rodriguez-Ramirez, Alberto; Gonzalez-Rivero, Manuel; Guldberg, Ove Hoegh-"	Quantification in-the-wild: data-sets and baselines	Images	CNN	Modeling	arXiv:1510.04811 [cs]				10.48550/arXiv.1510.04811	http://arxiv.org/abs/1510.04811	"Quantification is the task of estimating the class-distribution of a data-set. While typically considered as a parameter estimation problem with strict assumptions on the data-set shift, we consider quantification in-the-wild, on two large scale data-sets from marine ecology: a survey of Caribbean coral reefs, and a plankton time series from Martha's Vineyard Coastal Observatory. We investigate several quantification methods from the literature and indicate opportunities for future work. In particular, we show that a deep neural network can be fine-tuned on a very limited amount of data (25 - 100 samples) to outperform alternative methods."																				
2015	"Cao, Yang; Zhang, Chaojie; Chen, Quansheng; Li, Yanyu; Qi, Shuai; Tian, Lin; Ren, YongLin"	Identification of species and geographical strains of Sitophilus oryzae and Sitophilus zeamais using the visible/near-infrared hyperspectral imaging technique	Other	DNN	Classification	Pest Management Science	71	8	1113-1121	10.1002/ps.3893	https://onlinelibrary.wiley.com/doi/abs/10.1002/ps.3893	"BACKGROUND Identifying stored-product insects is essential for granary management. Automated, computer-based classification methods are rapidly developing in many areas. A hyperspectral imaging technique could potentially be developed to identify stored-product insect species and geographical strains. This study tested and adapted the technique using four geographical strains of each of two insect species, the rice weevil and maize weevil, to collect and analyse the resultant hyperspectral data. RESULTS Three characteristic images that corresponded to the dominant wavelengths, 505, 659 and 955 nm, were selected by multivariate image analysis. Each image was processed, and 22 morphological and textural features from regions of interest were extracted as the inputs for an identification model. We found the backpropagation neural network model to be the superior method for distinguishing between the insect species and geographical strains. The overall recognition rates of the classification model for insect species were 100 and 98.13% for the calibration and prediction sets respectively, while the rates of the model for geographical strains were 94.17 and 86.88% respectively. CONCLUSION This study has demonstrated that hyperspectral imaging, together with the appropriate recognition method, could provide a potential instrument for identifying insects and could become a useful tool for identification of Sitophilus oryzae and Sitophilus zeamais to aid in the management of stored-product insects. © 2014 Society of Chemical Industry"																				
2015	"Charantonis, A. A.; Badran, F.; Thiria, S."	Retrieving the evolution of vertical profiles of Chlorophyll-a from satellite observations using Hidden Markov Models and Self-Organizing Topological Maps	Other	DNN	Modeling	Remote Sensing of Environment	163		229-239	10.1016/j.rse.2015.03.019	https://www.sciencedirect.com/science/article/pii/S0034425715001157	"We present a statistical method, denoted PROFHMM, to infer the evolution of the vertical profiles of oceanic biogeophysical variables from sea-surface data. This method makes use of discrete Hidden Markov Models whose states are defined through Self-Organizing Topological Maps. The Self-Organizing Topological Maps are used to provide the states of the Hidden Markov Model, as well as improve its parameters. After introducing the general principles of PROFHMM, we present the results obtained in a case study in which the evolution of the vertical profiles of Chlorophyll-a was inverted from sea-surface data. We applied PROFHMM for the reconstruction of the evolution of the vertical distribution of Chlorophyll-a at BATS, by training it on the numerical outputs of the NEMO-PISCES model, and reproducing the evolution of this model by using a sequence satellite observations. We obtained a root mean square error of 0.0399ng/l for the validation year 2008."																				
2015	"Cianfrani, C.; Satizábal, Héctor F.; Randin, C."	A spatial modelling framework for assessing climate change impacts on freshwater ecosystems: Response of brown trout (Salmo trutta L.) biomass to warming water temperature	Environmental	DNN	Regression	Ecological Modelling	313		12-Jan	10.1016/j.ecolmodel.2015.06.023	https://www.sciencedirect.com/science/article/pii/S0304380015002720	"Mountain regions worldwide are particularly sensitive to on-going climate change. Specifically in the Alps in Switzerland, the temperature has increased twice as fast than in the rest of the Northern hemisphere. Water temperature closely follows the annual air temperature cycle, severely impacting streams and freshwater ecosystems. In the last 20 years, brown trout (Salmo trutta L.) catch has declined by approximately 40–50% in many rivers in Switzerland. Increasing water temperature has been suggested as one of the most likely cause of this decline. Temperature has a direct effect on trout population dynamics through developmental and disease control but can also indirectly impact dynamics via food-web interactions such as resource availability. We developed a spatially explicit modelling framework that allows spatial and temporal projections of trout biomass using the Aare river catchment as a model system, in order to assess the spatial and seasonal patterns of trout biomass variation. Given that biomass has a seasonal variation depending on trout life history stage, we developed seasonal biomass variation models for three periods of the year (Autumn–Winter, Spring and Summer). Because stream water temperature is a critical parameter for brown trout development, we first calibrated a model to predict water temperature as a function of air temperature to be able to further apply climate change scenarios. We then built a model of trout biomass variation by linking water temperature to trout biomass measurements collected by electro-fishing in 21 stations from 2009 to 2011. The different modelling components of our framework had overall a good predictive ability and we could show a seasonal effect of water temperature affecting trout biomass variation. Our statistical framework uses a minimum set of input variables that make it easily transferable to other study areas or fish species but could be improved by including effects of the biotic environment and the evolution of demographical parameters over time. However, our framework still remains informative to spatially highlight where potential changes of water temperature could affect trout biomass."																				
2015	"Guan, Haiyan; Yu, Yongtao; Ji, Zheng; Li, Jonathan; Zhang, Qi"	Deep learning-based tree classification using mobile LiDAR data	Other	DNN	Classification	Remote Sensing Letters	6	11	864-873	10.1080/2150704X.2015.1088668	https://doi.org/10.1080/2150704X.2015.1088668	"Our work addresses the problem of extracting and classifying tree species from mobile LiDAR data. The work includes tree preprocessing and tree classification. In tree preprocessing, voxel-based upward-growing filtering is proposed to remove ground points from the mobile LiDAR data, followed by a tree segmentation that extracts individual trees via Euclidean distance clustering and voxel-based normalized cut segmentation. In tree classification, first, a waveform representation is developed to model geometric structures of trees. Then, deep learning techniques are used to generate high-level feature abstractions of the trees’ waveform representations. Quantitative analysis shows that our algorithm achieves an overall accuracy of 86.1% and a kappa coefficient of 0.8 in classifying urban tree species using mobile LiDAR data. Comparative experiments demonstrate that the uses of waveform representation and deep Boltzmann machines contribute to the improvement of classification accuracies of tree species."																				
2015	"Harris, David J."	Generating realistic assemblages with a joint species distribution model	Environmental	DNN	Modeling	Methods in Ecology and Evolution	6	4	465-473	10.1111/2041-210X.12332	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12332	"Species distribution models (SDMs) represent important analytical and predictive tools for ecologists. Until now, these models have either assumed (i) that species' occurrence probabilities are uncorrelated or (ii) that species respond linearly to preselected environmental variables. These two assumptions currently prevent ecologists from modelling assemblages with realistic co-occurrence and species richness properties. This paper introduces a stochastic feedforward neural network, called ‘mistnet’, which makes neither assumption. Thus, unlike most SDMs, mistnet can account for non-independent co-occurrence patterns driven by unobserved environmental heterogeneity. And unlike several recently proposed joint SDMs, the model can also learn nonlinear functions relating species' occurrence probabilities to environmental predictors. Mistnet makes more accurate predictions about the North American bird communities found along Breeding Bird Survey transects than several alternative methods tested. In particular, typical assemblages held out of sample for validation were each tens of thousands of times more likely under the mistnet model than under independent combinations of single-species predictions. Apart from improved accuracy, mistnet shows two other important benefits for ecological research and management. First: by analysing co-occurrence data, mistnet can identify unmeasured – and perhaps unanticipated – environmental variables that drive species turnover. For example, the model identified a strong grassland/forest gradient, even though only temperature and precipitation were given as model inputs. Second: mistnet is able to take advantage of outside information to guide its predictions towards more realistic assemblages. For example, mistnet automatically adjusts its expectations to include more forest-associated species in response to a stray observation of a forest-dwelling warbler."																				
2015	"Kaya, Yılmaz; Kayci, Lokman; Uyar, Murat"	Automatic identification of butterfly species based on local binary patterns and artificial neural network	Images	DNN	Classification	Applied Soft Computing	28		132-137	10.1016/j.asoc.2014.11.046	https://www.sciencedirect.com/science/article/pii/S1568494614006103	"Butterflies are classified firstly according to their outer morphological qualities. It is required to analyze genital characters of them when classification according to outer morphological qualities is not possible. Genital characteristics of a butterfly can be determined by using various chemical substances and methods. Currently, these processes are carried out manually by preparing genital slides of the collected butterfly through some certain processes. For some groups of butterflies molecular techniques should be applied for identification which is expensive to use. In this study, a computer vision method is proposed for automatically identifying butterfly species as an alternative to conventional identification methods. The method is based on local binary pattern (LBP) and artificial neural network (ANN). A total of 50 butterfly images of five species were used for evaluating the effectiveness of the proposed method. Experimental results demonstrated that the proposed method has achieved well recognition in terms of accuracy rates for butterfly species identification."																				
2015	"Lagerstrom, Ryan; Holt, Katherine; Arzhaeva, Yulia; Bischof, Leanne; Haberle, Simon; Hopf, Felicitas; Lovell, David"	Pollen Image Classification Using the Classifynder System: Algorithm Comparison and a Case Study on New Zealand Honey	Images	DNN	Classification	Signal and Image Analysis for Biomedical and Life Sciences			207-226	10.1007/978-3-319-10984-8_12	https://link.springer.com/chapter/10.1007/978-3-319-10984-8_12	"We describe an investigation into how Massey University’s Pollen Classifynder can accelerate the understanding of pollen and its role in nature. The Classifynder is an imaging microscopy system that can locate, image and classify slide based pollen samples. Given the laboriousness of purely manual image acquisition and identification it is vital to exploit assistive technologies like the Classifynder to enable acquisition and analysis of pollen samples. It is also vital that we understand the strengths and limitations of automated systems so that they can be used (and improved) to compliment the strengths and weaknesses of human analysts to the greatest extent possible. This article reviews some of our experiences with the Classifynder system and our exploration of alternative classifier models to enhance both accuracy and interpretability. Our experiments in the pollen analysis problem domain have been based on samples from the Australian National University’s pollen reference collection (2,890 grains, 15 species) and images bundled with the Classifynder system (400 grains, 4 species). These samples have been represented using the Classifynder image feature set. We additionally work through a real world case study where we assess the ability of the system to determine the pollen make-up of samples of New Zealand honey. In addition to the Classifynder’s native neural network classifier, we have evaluated linear discriminant, support vector machine, decision tree and random forest classifiers on these data with encouraging results. Our hope is that our findings will help enhance the performance of future releases of the Classifynder and other systems for accelerating the acquisition and analysis of pollen samples."																				
2015	"LeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey"	Deep learning	NA	NA	Review	Nature	521	7553	436-444	10.1038/nature14539	http://www.nature.com/articles/nature14539	"Temporal data is ubiquitous in ecology and ecologists often face the challenge of accurately differentiating these data into predefined classes, such as biological entities or ecological states. The usual approach consists of transforming the time series into user-defined features and then using these features as predictors in conventional statistical or machine learning models. Here we suggest the use of deep learning models as an alternative to this approach. Recent deep learning techniques can perform the classification directly from the time series, elimi_ nating subjective and resource-consuming data transformation steps, and potentially improving classification results. We describe some of the deep learning architectures relevant for time series classification and show how these architectures and their hyper-parameters can be tested and used for the classification problems at hand. We illustrate the approach using three case studies from distinct ecological subdisciplines: i) insect species identi_ fication from wingbeat spectrograms; ii) species distribution modelling from climate time series and iii) the classification of phenological phases from continuous meteorological data. The deep learning approach delivered ecologically sensible and accurate classifications demonstrating its potential for wide applicability across sub_ fields of ecology."																				
2015	"Leow, Lee Kien; Chew, Li-Lee; Chong, Ving Ching; Dhillon, Sarinder Kaur"	Automated identification of copepods using digital image processing and artificial neural network	Images	DNN	Classification	BMC Bioinformatics	16	18	S4	10.1186/1471-2105-16-S18-S4	https://doi.org/10.1186/1471-2105-16-S18-S4	"Copepods are planktonic organisms that play a major role in the marine food chain. Studying the community structure and abundance of copepods in relation to the environment is essential to evaluate their contribution to mangrove trophodynamics and coastal fisheries. The routine identification of copepods can be very technical, requiring taxonomic expertise, experience and much effort which can be very time-consuming. Hence, there is an urgent need to introduce novel methods and approaches to automate identification and classification of copepod specimens. This study aims to apply digital image processing and machine learning methods to build an automated identification and classification technique."																				
2015	"Leprevost, Felipe V.; Valente, Richard H.; Lima, Diogo B.; Perales, Jonas; Melani, Rafael; Yates, John R.; Barbosa, Valmir C.; Junqueira, Magno; Carvalho, Paulo C."	PepExplorer: A Similarity-driven Tool for Analyzing de Novo Sequencing Results *	Molecular	Other	Classification	Molecular & Cellular Proteomics	13	9	2480-2489	10.1074/mcp.M113.037002	https://www.mcponline.org/article/S1535-9476(20)33307-7/abstract	"Peptide spectrum matching is the current gold standard for protein identification via mass-spectrometry-based proteomics. Peptide spectrum matching compares experimental mass spectra against theoretical spectra generated from a protein sequence database to perform identification, but protein sequences not present in a database cannot be identified unless their sequences are in part conserved. The alternative approach, de novo sequencing, can make it possible to infer a peptide sequence directly from a mass spectrum, but interpreting long lists of peptide sequences resulting from large-scale experiments is not trivial. With this as motivation, PepExplorer was developed to use rigorous pattern recognition to assemble a list of homologue proteins using de novo sequencing data coupled to sequence alignment to allow biological interpretation of the data. PepExplorer can read the output of various widely adopted de novo sequencing tools and converge to a list of proteins with a global false-discovery rate. To this end, it employs a radial basis function neural network that considers precursor charge states, de novo sequencing scores, peptide lengths, and alignment scores to select similar protein candidates, from a target-decoy database, usually obtained from phylogenetically related species. Alignments are performed using a modified Smith–Waterman algorithm tailored for the task at hand. We verified the effectiveness of our approach using a reference set of identifications generated by ProLuCID when searching for Pyrococcus furiosus mass spectra on the corresponding NCBI RefSeq database. We then modified the sequence database by swapping amino acids until ProLuCID was no longer capable of identifying any proteins. By searching the mass spectra using PepExplorer on the modified database, we were able to recover most of the identifications at a 1% false-discovery rate. Finally, we employed PepExplorer to disclose a comprehensive proteomic assessment of the Bothrops jararaca plasma, a known biological source of natural inhibitors of snake toxins. PepExplorer is integrated into the PatternLab for Proteomics environment, which makes available various tools for downstream data analysis, including resources for quantitative and differential proteomics."																				
2015	"Lorenz, Camila; Ferraudo, Antonio Sergio; Suesdek, Lincoln"	Artificial Neural Network applied as a methodology of mosquito species identification	Other	DNN	Classification	Acta Tropica	152		165-169	10.1016/j.actatropica.2015.09.011	https://www.sciencedirect.com/science/article/pii/S0001706X1530108X	There are about 200 species of mosquitoes (Culicidae) known to be vectors of pathogens that cause diseases in humans. Correct identification of mosqui…																				
2015	"Park, Yongjin; Kellis, Manolis"	Deep learning for regulatory genomics	NA	NA	Review	Nature Biotechnology	33	8	825-826	10.1038/nbt.3313	http://www.nature.com/articles/nbt.3313	NA																				
2015	"Potamitis, Ilyas"	Unsupervised dictionary extraction of bird vocalisations and new tools on assessing and visualising bird activity	Sound	CNN	Classification	Ecological Informatics	26		17-Jun	10.1016/j.ecoinf.2015.01.002	https://linkinghub.elsevier.com/retrieve/pii/S1574954115000102	"A broad range of organisations and individuals are collecting wildlife audio recordings. Huge amounts of audio data have been gathered in the past and since the popularisation of automatic recording units the data are piling up exponentially. The point in gathering them is to analyse them, evaluate insights and hypotheses, identify patterns of activity that are otherwise not apparent and finally design policies on biodiversity issues. For massive volumes of data even visual inspection of spectrograms is unfeasible and interesting cases that could provide valuable insight for concrete hypotheses on the biodiversity status can slip into bliss. In this paper we research a range of techniques that work with minor human supervision. These techniques will construct a dictionary of templates extracted in an unsupervised way from reference recordings and then crawl over a large number of recordings to examine the underlying bioacoustic activity. This work is general and we have applied it to many datasets of animal's vocalisations (e.g. cetaceans, mice, birds). To test our tools objectively and for the sake of reproducibility in this work we report on the MLSP 2013 bird dataset that recently has been publicly released along with all its annotations. We are not interested as to which is the best scoring approach for this dataset. Our aim is to describe novel machine learning tools that try to refine our understanding of biodiversity by answering questions such as: Is the recording under examination void of bird vocalisations or not? If there is bird activity, how many different species are in the recording? What are the most important characteristic spectral segments for recognizing a specific species? The database however is valuable to us to quantify our findings."																				
2015	"Romanolo, K. F.; Gorski, L.; Wang, S.; Lauzon, C. R."	Rapid Identification and Classification of Listeria spp. and Serotype Assignment of Listeria monocytogenes Using Fourier Transform-Infrared Spectroscopy and Artificial Neural Network Analysis	Other	DNN	Classification	PLOS ONE	10	11	e0143425	10.1371/journal.pone.0143425	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0143425	"The use of Fourier Transform-Infrared Spectroscopy (FT-IR) in conjunction with Artificial Neural Network software NeuroDeveloper™ was examined for the rapid identification and classification of Listeria species and serotyping of Listeria monocytogenes. A spectral library was created for 245 strains of Listeria spp. to give a biochemical fingerprint from which identification of unknown samples were made. This technology was able to accurately distinguish the Listeria species with 99.03% accuracy. Eleven serotypes of Listeria monocytogenes including 1/2a, 1/2b, and 4b were identified with 96.58% accuracy. In addition, motile and non-motile forms of Listeria were used to create a more robust model for identification. FT-IR coupled with NeuroDeveloper™ appear to be a more accurate and economic choice for rapid identification of pathogenic Listeria spp. than current methods."																				
2015	"Yang, Hua; Gao, Wen; Liu, Lei; Liu, Ke; Liu, E-Hu; Qi, Lian-Wen; Li, Ping"	Discovery of characteristic chemical markers for classification of aconite herbs by chromatographic profile and probabilistic neural network	Other	Other	Classification	Journal of Pharmaceutical and Biomedical Analysis	115		19-Oct	10.1016/j.jpba.2015.06.021	https://www.sciencedirect.com/science/article/pii/S0731708515300406	"Most Aconitum species, also known as aconite, are extremely poisonous, so it must be identified carefully. Differentiation of Aconitum species is challenging because of their similar appearance and chemical components. In this study, a universal strategy to discover chemical markers was developed for effective authentication of three commonly used aconite roots. The major procedures include: (1) chemical profiling and structural assignment of herbs by liquid chromatography with mass spectrometry (LC-MS), (2) quantification of major components by LC-MS, (3) probabilistic neural network (PNN) model to calculate contributions of components toward species classification, (4) discovery of minimized number of chemical markers for quality control. The MS fragmentation pathways of diester-, monoester-, and alkyloyamine-diterpenoid alkaloids were compared. Using these rules, 42 aconite alkaloids were identified in aconite roots. Subsequently, 11 characteristic compounds were quantified. A component–species modeling by PNN was then established combining the 11 analytes and 26-batch samples from three aconite species. The contribution of each analyte to species classification was calculated. Selection of fuziline, benzoylhypaconine, and talatizamine, or a combination of more compounds based on a contribution order, can be used for successful categorization of the three aconite species. Collectively, the proposed strategy is beneficial to selection of rational chemical markers for the species classification and quality control of herbal medicines."																				
2016	"Akbarimajd, A.; Jonban, Mansour Selseleh; Nooshyar, M.; Davari, M."	Neural Network based identification of Trichoderma species	Other	DNN	Classification	Neural Network World	2016	2	155-173	10.14311/NNW.2016.26.009	http://nnw.cz/doi/2016/NNW.2016.26.009.pdf	"A software-based identification tool for recognition of different species of Trichoderma using the morphological features for identification by means of neural network is proposed. The genus Trichoderma acts as an important antagonist against phytopathogenic fungi. This paper proposes a software-based identification tool for recognition of different species of Trichoderma. The method uses the morphological features for identification. Morphological-based species recognition is common method for identifying fungi, but regarding the similarity of morphological features among different species, their manual identification is difficult, time-consuming and may bring about faulty results. In this paper it is intended to identify different species of Trichoderma by means of neural network. For this purpose, 14 characteristics are used including 5 macroscopic and 9 microscopic characteristics. After quantifying qualitative features and training a multilayer perceptron neural network with quantified data, 25 species of Trichoderma are recognized by using the network. Totally, identification of Trichoderma species as one useful fungus is achieved by using the trained network."																				
2016	"Angermueller, Christof; Pärnamaa, Tanel; Parts, Leopold; Stegle, Oliver"	Deep learning for computational biology	NA	NA	Review	Molecular Systems Biology	12	7	878	10.15252/msb.20156651	https://onlinelibrary.wiley.com/doi/10.15252/msb.20156651	"Technological advances in genomics and imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples. This rapid increase in biological data dimension and acquisition rate is challenging conventional analysis strategies. Modern machine learning methods, such as deep learning, promise to leverage very large data sets for finding hidden structure within them, and for making accurate predictions. In this review, we discuss applications of this new breed of analysis approaches in regulatory genomics and cellular imaging. We provide background of what deep learning is, and the settings in which it can be successfully applied to derive biological insights. In addition to presenting specific applications and providing tips for practical use, we also highlight possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new technology."																				
2016	"Boulmaiz, Amira; Messadeg, Djemil; Doghmane, Noureddine; Taleb-Ahmed, Abdelmalik"	Robust acoustic bird recognition for habitat monitoring with wireless sensor networks	Sound	Unknown	Classification	International Journal of Speech Technology	19	3	631-645	10.1007/s10772-016-9354-4	https://link.springer.com/article/10.1007/s10772-016-9354-4	"The key solution to study birds in their natural habitat is the continuous survey using wireless sensors networks (WSN). The final objective of this study is to conceive a system for monitoring threatened bird species using audio sensor nodes. The principal feature for their recognition is their sound. The main limitations encountered with this process are environmental noise and energy consumption in sensor nodes. Over the years, a variety of birdsong classification methods has been introduced, but very few have focused to find an adequate one for WSN. In this paper, a tonal region detector (TRD) using sigmoid function is proposed. This approach for noise power estimation offers flexibility, since the slope and the mean of the sigmoid function can be adapted autonomously for a better trade-off between noise overvaluation and undervaluation. Once the tonal regions in the noisy bird sound are detected, the features gammatone teager energy cepstral coefficients (GTECC) post-processed by quantile-based cepstral normalization were extracted from the above signals for classification using deep neural network classifier. Experimental results for the identification of 36 bird species from Tonga lake (northeast of Algeria) demonstrate that the proposed TRD–GTECC feature is highly effective and performs satisfactorily compared to popular front-ends considered in this study. Moreover, recognition performance, noise immunity and energy consumption are considerably improved after tonal region detection, indicating that it is a very suitable approach for the acoustic bird recognition in complex environments with wireless sensor nodes."																				
2016	"Chuang, Tsai-Fu; Chang, Yuan-Hsiou"	Comparison of physical characteristics between Rana latouchtii and Rana adenopleura using grey system theory and Artificial Neural Network	Other	DNN	Modeling	Ecological Engineering	68		223-232	10.1016/j.ecoleng.2014.03.038	https://www.sciencedirect.com/science/article/pii/S0925857414000986	"In recent years, the threat to amphibians is becoming more and more serious. It is generally known that the loss of habitats caused by changes to the way land is used by human beings has hit amphibians particularly hard. The construction of concrete banks along rivers associated with human development has become a serious problem in Taiwan. Most ecosystems used by amphibians are lakes and stream banks, yet no related design solutions to accommodate the needs of amphibians. The need to develop the relevant design specification considering protecting the amphibians is imperative. However, before we can establish a new design specification, some preparation is needed. It is necessary to improve the understanding of the physical characteristics of the species before we know how to build a diversified and happy habitat for amphibians. In this study, two Ranidae Species, Rana latouchtii and Rana adenopleura were chosen for investigation. The above two species are generally regarded to be “close species” due to the similarities in their physical appearance and body sizes (Yang, 1998). However, there is no further material to understand how close they are. Therefore, it is interesting and important to further compare their physical characteristics of these two species. The goal of this study was to determine (1) the comparison of physical characteristics between Rana latouchtii and Rana adenopleura, (2) whether grey system theory can be used to improve the understandings of the relation between Rana latouchtii and Rana adenopleura, (3) whether Artificial Neural Network can be used to simulate the climbing behavior of frogs. The experimental results of the physical characteristics showed that the two species are really very close. Moreover, the numerical results of Artificial Neural Network do agree with this. Finally, it is known that the climbing ability and physical characteristics are necessary data to design a diversified biological environment for various species of frogs. The results of this study can serve as a reference for technicians involved in future ecological engineering designs of banks throughout the world."																				
2016	"Ding, Weiguang; Taylor, Graham"	Automatic Moth Detection from Trap Images for Pest Management	Images	CNN	Classification	arXiv:1602.07383 [cs]				10.48550/arXiv.1602.07383	http://arxiv.org/abs/1602.07383	"Monitoring the number of insect pests is a crucial component in pheromone-based pest management systems. In this paper, we propose an automatic detection pipeline based on deep learning for identifying and counting pests in images taken inside field traps. Applied to a commercial codling moth dataset, our method shows promising performance both qualitatively and quantitatively. Compared to previous attempts at pest detection, our approach uses no pest-specific engineering which enables it to adapt to other species and environments with minimal human effort. It is amenable to implementation on parallel hardware and therefore capable of deployment in settings where real-time performance is required."																				
2016	"Dominguez-Morales, J. P.; Rios-Navarro, A.; Dominguez-Morales, M.; Tapiador-Morales, R.; Gutierrez-Galan, D.; Cascado-Caballero, D.; Jimenez-Fernandez, A.; Linares-Barranco, A."	Wireless Sensor Network for Wildlife Tracking and Behavior Classification of Animals in Doñana	Other	DNN	Classification	IEEE Communications Letters	20	12	2534-2537	10.1109/LCOMM.2016.2612652	https://ieeexplore.ieee.org/document/7574341	"The study and monitoring of wildlife has always been a subject of great interest. Studying the behavior of wild animals is a difficult task due to the difficulties of tracking and classifying their actions. Nowadays, technology allows designing low-cost systems that make these tasks easier to carry out, and some of these systems produce good results; however, none of them obtains a high-accuracy classification because of the lack of information. Doñana National Park is a very rich environment with various endangered animal species. Thereby, this park requires a more accurate and efficient system of monitoring to act quickly against animal behaviors that may endanger certain species. In this letter, we propose a hierarchical, wireless sensor network installed in this park, to collect information about animals' behaviors using intelligent devices placed on them which contain a neural network implementation to classify their behavior based on sensory information. Once a behavior is detected, the network redirects this information to an external database for further treatment. This solution reduces power consumption and facilitates animals' behavior monitoring for biologists."																				
2016	"Dyrmann, Mads; Karstoft, Henrik; Midtiby, Henrik Skov"	Plant species classification using deep convolutional neural network	Images	CNN	Classification	Biosystems Engineering	151		72-80	10.1016/j.biosystemseng.2016.08.024	https://www.sciencedirect.com/science/article/pii/S1537511016301465	"Information on which weed species are present within agricultural fields is important for site specific weed management. This paper presents a method that is capable of recognising plant species in colour images by using a convolutional neural network. The network is built from scratch trained and tested on a total of 10,413 images containing 22 weed and crop species at early growth stages. These images originate from six different data sets, which have variations with respect to lighting, resolution, and soil type. This includes images taken under controlled conditions with regard to camera stabilisation and illumination, and images shot with hand-held mobile phones in fields with changing lighting conditions and different soil types. For these 22 species, the network is able to achieve a classification accuracy of 86.2%."																				
2016	"Fu, Min; Tian, Lixin; Dong, Gaogao; Du, Ruijin; Zhou, Peipei; Wang, Minggang"	Modeling on Regional Atmosphere-Soil-Land Plant Carbon Cycle Dynamic System	Environmental	DNN	Modeling	Sustainability	8	4	303	10.3390/su8040303	https://www.mdpi.com/2071-1050/8/4/303	"This paper establishes a nonlinear carbon cycle model based on the analysis of the carbon flux relationship among the atmosphere cycle, soil cycle and land cycle. By using nonlinear dynamics method, we examine the regional carbon cycle evolution along with the temporal evolution of the regional carbon flux. A neural network has been employed to identify the parameters of the proposed model, accordingly. In the numerical study, we propose the atmosphere-soil-land cycle model for Nanjing city of China. Then, the carbon cycle evolution of Nanjing has been simulated with the given model and actual data."																				
2016	"Goëau, Hervé; Glotin, Hervé; Vellinga, Willem-Pier; Planqué, Robert; Joly, Alexis"	LifeCLEF Bird Identification Task 2016: The arrival of Deep learning	Sound	CNN	Classification	CLEF: Conference and Labs of the Evaluation Forum			440-449	NA	https://hal.archives-ouvertes.fr/hal-01373779/document	"The LifeCLEF bird identification challenge provides a largescale testbed for the system-oriented evaluation of bird species identification based on audio recordings. One of its main strength is that the data used for the evaluation is collected through Xeno-Canto, the largest network of bird sound recordists in the world. This makes the task closer to the conditions of a real-world application than previous, similar initiatives. The main novelty of the 2016-th edition of the challenge was the inclusion of soundscape recordings in addition to the usual xeno-canto recordings that focus on a single foreground species. This paper reports the methodology of the conducted evaluation, the overview of the systems experimented by the 6 participating research groups and a synthetic analysis of the obtained results."																				
2016	"Grinblat, Guillermo L.; Uzal, Lucas C.; Larese, Mónica G.; Granitto, Pablo M."	Deep learning for plant identification using vein morphological patterns	Images	CNN	Classification	Computers and Electronics in Agriculture	127		418-424	10.1016/j.compag.2016.07.003	https://www.sciencedirect.com/science/article/pii/S0168169916304665	"We propose using a deep convolutional neural network (CNN) for the problem of plant identification from leaf vein patterns. In particular, we consider classifying three different legume species: white bean, red bean and soybean. The introduction of a CNN avoids the use of handcrafted feature extractors as it is standard in state of the art pipeline. Furthermore, this deep learning approach significantly improves the accuracy of the referred pipeline. We also show that the reported accuracy is reached by increasing the model depth. Finally, by analyzing the resulting models with a simple visualization technique, we are able to unveil relevant vein patterns."																				
2016	"Korin_ek, G.; Derlink, M.; Virant-Doberlet, M.; Tuma, T."	An autonomous system of detecting and attracting leafhopper males using species- and sex-specific substrate borne vibrational signals	Sound	DNN	Classification	Computers and Electronics in Agriculture	123	C	29–39	10.1016/j.compag.2016.02.006	https://linkinghub.elsevier.com/retrieve/pii/S0168169916300291	"Models to automatically detect and indentify leafhopper vibrational male calls were developed.Call features included linear prediction cepstral coefficients.Features were classified by a multilayer perceptron and Gaussian Mixture Model.Autonomous system (AS) also played back female reply and established a duet with the live male.Results showed that AS mimicking a duetting female attracted males to the source. In leafhoppers that are among the most important vectors of plant diseases, mate recognition and location are mediated exclusively by species- and sex-specific vibrational signals exchanged in precisely coordinated duets. These pests are currently managed primarily by insecticide treatments, however, current legislation and consumers' concerns and demands require that the risks and impacts of pesticides be reduced. We present a proof-of-concept low-cost autonomous digital processing system (AS), capable of recognizing the male calls of the leafhopper Aphrodes bicincta ""Dragonja"" and generating female replies. Such a device could be used as a vibrational trap. We chose this species since its duet structure is complex, with the female replies having to appear in short (47-175ms) intervals between continuously repeated elements in the male call in order to trigger male searching behaviour. The AS male call recognition algorithm is based on linear prediction cepstral coefficient (LPCC) feature vectors and a multilayer perceptron classifier (MLP). To prevent the noise-based feature vectors from feeding into the classifier, a bandwidth-limited linear prediction call activity detector based on spectrum peak tracking was designed. We tested the efficiency of the AS in behavioural experiments with live males. The MLP classification method successfully classified vibrational calls of male A. bicincta ""Dragonja"" from background noise. The fast real time identification enabled a synchronized playback of female vibrational reply with latencies as short as 130ms. This mimicking of a duetting female by autonomous system also attracted the males to the source of the female reply. The AS is also a useful tool to enable further studies of vibrational duets that are needed to develop effective alternative control strategies."																				
2016	"Kruk, Andrzej; Ciep_ucha, Micha_; Zi_ba, Grzegorz; Tybulczuk, Szymon; Tszydel, Mariusz; Marsza_, Lidia; B_o_ska, Dagmara; Galicka, Wanda; Przybylski, Miros_aw"	"Recovery of fish fauna in the upper Warta River, Poland: Long-term (1963–2012) monitoring study"	Environmental	DNN	Modeling	Ecological Informatics	33		109-118	10.1016/j.ecoinf.2016.04.006	https://www.sciencedirect.com/science/article/pii/S1574954116300334	"The Warta River (795km long) is the largest, right side tributary of the Odra (Oder) River. The study presents results from one of the best-documented long-term monitoring projects in Poland based on four terms of electrofishing: 1963–66, 1986–88, 1996–98 and 2011–12, conducted in the upper Warta. The Warta River underwent human-induced modifications typical for most European lowland rivers (damming, regulation, water pollution), of which the most destructive for fish was point-source water pollution. In the late 1980s, pollution reached its highest level and stopped increasing as the former political system collapsed and many industrial plants went bankrupt. Surprisingly, recovered fish assemblages were not recorded during the sampling in 1996–98, but in 2011–12. This is why we believe that in large degraded rivers, it takes about 10–20years before a considerable improvement in fish fauna can be observed. Ichthyofauna recovered to a good status, but was qualitatively different compared to the good status observed in the 1960s. On the one hand, in 2011–12, high species richness and high assemblage diversity were observed, and many species, including seven rheophils, were more common than earlier. On the other hand, the populations of catadromous eel and anadromous vimba have not recovered, and these species were absent in the 2011–12 samples. Because water quality has improved, the most important factor seems to be the impact of the Jeziorsko dam reservoir which is located downstream of the study area and has no fish pass. The above patterns were recognised in this paper with a Kohonen artificial neural network, which is a tool methodically correct for analysing complex non-linear relations. Additionally, indicator species analysis allowed for the identification of significant associations of taxa with specific environmental states and was helpful in determination of ecological statuses of the river stretches. We therefore recommend the combined use of Kohonen artificial neural networks and indicator species analysis in long-term monitoring analyses."																				
2016	"Liu, Ziyi; Gao, Junfeng; Yang, Guoguo; Zhang, Huan; He, Yong"	Localization and Classification of Paddy Field Pests using a Saliency Map and Deep Convolutional Neural Network	Images	CNN	Classification	Scientific Reports	6	1	20410	10.1038/srep20410	http://www.nature.com/articles/srep20410	"We present a pipeline for the visual localization and classification of agricultural pest insects by computing a saliency map and applying deep convolutional neural network (DCNN) learning. First, we used a global contrast region-based approach to compute a saliency map for localizing pest insect objects. Bounding squares containing targets were then extracted, resized to a fixed size and used to construct a large standard database called Pest ID. This database was then utilized for self-learning of local image features which were, in turn, used for classification by DCNN. DCNN learning optimized the critical parameters, including size, number and convolutional stride of local receptive fields, dropout ratio and the final loss function. To demonstrate the practical utility of using DCNN, we explored different architectures by shrinking depth and width and found effective sizes that can act as alternatives for practical applications. On the test set of paddy field images, our architectures achieved a mean Accuracy Precision (mAP) of 0.951, a significant improvement over previous methods."																				
2016	"Ma, Jincai; Ibekwe, A. Mark; Yang, Ching-Hong; Crowley, David E."	Bacterial diversity and composition in major fresh produce growing soils affected by physiochemical properties and geographic locations	Environmental	Unknown	Regression	Science of The Total Environment	563-564		199-209	10.1016/j.scitotenv.2016.04.122	https://www.sciencedirect.com/science/article/pii/S0048969716307859	"Microbial diversity of agricultural soils has been well documented, but information on leafy green producing soils is limited. In this study, we investigated microbial diversity and community structures in 32 (16 organic, 16 conventionally managed soils) from California (CA) and Arizona (AZ) using pyrosequencing, and identified factors affecting bacterial composition. Results of detrended correspondence analysis (DCA) and dissimilarity analysis showed that bacterial community structures of conventionally managed soils were similar to that of organically managed soils; while the bacterial community structures in soils from Salinas, California were different (P<0.05) from those in soils from Yuma, Arizona and Imperial Valley, California. Canonical correspondence analysis (CCA) and artificial neural network (ANN) analysis of bacterial community structures and soil variables showed that electrical conductivity (EC), clay content, water-holding capacity (WHC), pH, total nitrogen (TN), and organic carbon (OC) significantly (P<0.05) correlated with microbial communities. CCA based variation partitioning analysis (VPA) showed that soil physical properties (clay, EC, and WHC), soil chemical variables (pH, TN, and OC) and sampling location explained 16.3%, 12.5%, and 50.9%, respectively, of total variations in bacterial community structure, leaving 13% of the total variation unexplained. Our current study showed that bacterial community composition and diversity in major fresh produce growing soils from California and Arizona is a function of soil physiochemical characteristics and geographic distances of sampling sites."																				
2016	"Mohanty, Sharada P.; Hughes, David P.; Salathé, Marcel"	Using Deep Learning for Image-Based Plant Disease Detection	Images	CNN	Classification	Frontiers in Plant Science	7		1419	10.3389/fpls.2016.01419	http://journal.frontiersin.org/article/10.3389/fpls.2016.01419/full	"Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale."																				
2016	"Sheehan, Sara; Song, Yun S."	Deep Learning for Population Genetic Inference	Molecular	CNN	Classification	PLOS Computational Biology	12	3	e1004845	10.1371/journal.pcbi.1004845	https://dx.plos.org/10.1371/journal.pcbi.1004845	"Given genomic variation data from multiple individuals, computing the likelihood of complex population genetic models is often infeasible. To circumvent this problem, we introduce a novel likelihood-free inference framework by applying deep learning, a powerful modern technique in machine learning. Deep learning makes use of multilayer neural networks to learn a feature-based function from the input (e.g., hundreds of correlated summary statistics of data) to the output (e.g., population genetic parameters of interest). We demonstrate that deep learning can be effectively employed for population genetic inference and learning informative features of data. As a concrete application, we focus on the challenging problem of jointly inferring natural selection and demography (in the form of a population size change history). Our method is able to separate the global nature of demography from the local nature of selection, without sequential steps for these two factors. Studying demography and selection jointly is motivated by Drosophila, where pervasive selection confounds demographic analysis. We apply our method to 197 African Drosophila melanogaster genomes from Zambia to infer both their overall demography, and regions of their genome under selection. We find many regions of the genome that have experienced hard sweeps, and fewer under selection on standing variation (soft sweep) or balancing selection. Interestingly, we find that soft sweeps and balancing selection occur more frequently closer to the centromere of each chromosome. In addition, our demographic inference suggests that previously estimated bottlenecks for African Drosophila melanogaster are too extreme."																				
2016	"Sprengel, Elias; Jaggi, Martin; Kilcher, Yannic; Hofmann, Thomas"	Audio Based Bird Species Identiﬁcation using Deep Learning Techniques	Sound	CNN	Classification	CLEF (Working Notes)				NA	http://ceur-ws.org/Vol-1609/16090547.pdf	"In this paper we present a new audio classification method for bird species identification. Whereas most approaches apply nearest neighbour matching [6] or decision trees [8] using extracted templates for each bird species, ours draws upon techniques from speech recognition and recent advances in the domain of deep learning. With novel preprocessing and data augmentation methods, we train a convolutional neural network on the biggest publicly available dataset [5]. Our network architecture achieves a mean average precision score of 0.686 when predicting the main species of each sound file and scores 0.555 when background species are used as additional prediction targets. As this performance surpasses current state of the art results, our approach won this years international BirdCLEF 2016 Recognition Challenge [3,4,1]."																				
2016	"Turesson, Hjalmar K.; Conceição, Thamiris Botelho Ribeiro; Ribeiro, Sidarta"	Head and gaze tracking of unrestrained marmosets	Video	CNN	Classification	bioRxiv				10.1101/079566	http://biorxiv.org/lookup/doi/10.1101/079566	"New technologies for manipulating and recording the nervous system allow us to perform unprecedented experiments. However, the influence of our experimental manipulations on psychological processes must be inferred from their effects on behavior. Today, quantifying behavior has become the bottleneck for large-scale, high-throughput, experiments. The method presented here addresses this issue by using deep learning algorithms for video-based animal tracking. Here we describe a reliable automatic method for tracking head position and orientation from simple video recordings of the common marmoset ( Callithrix jacchus ). This method for measuring marmoset behavior allows for the estimation of gaze within foveal error, and can easily be adapted to a wide variety of similar tasks in biomedical research. In particular, the method has great potential for the simultaneous tracking of multiple marmosets to quantify social behaviors."																				
2017	"Ali, Shahin S.; Shao, Jonathan; Lary, David J.; Kronmiller, Brent A.; Shen, Danyu; Strem, Mary D.; Amoako-Attah, Ishmael; Akrofi, Andrew Yaw; Begoude, B.A. Didier; ten Hoopen, G. Martijn; Coulibaly, Klotioloma; Kebe, Boubacar Ismaël; Melnick, Rachel L.; Guiltinan, Mark J.; Tyler, Brett M.; Meinhardt, Lyndel W.; Bailey, Bryan A."	"Phytophthora megakarya and Phytophthora palmivora, Closely Related Causal Agents of Cacao Black Pod Rot, Underwent Increases in Genome Sizes and Gene Numbers by Different Mechanisms"	Molecular	DNN	Modeling	Genome Biology and Evolution	9	3	536-557	10.1093/gbe/evx021	https://academic.oup.com/gbe/article/9/3/536/2982378	"Phytophthora megakarya (Pmeg) and Phytophthora palmivora (Ppal) are closely related species causing cacao black pod rot. Although Ppal is a cosmopolitan pathogen, cacao is the only known host of economic importance for Pmeg. Pmeg is more virulent on cacao than Ppal. We sequenced and compared the Pmeg and Ppal genomes and identified virulence-related putative gene models (PGeneM) that may be responsible for their differences in host specificities and virulence. Pmeg and Ppal have estimated genome sizes of 126.88 and 151.23_Mb and PGeneM numbers of 42,036 and 44,327, respectively. The evolutionary histories of Pmeg and Ppal appear quite different. Postspeciation, Ppal underwent whole-genome duplication whereas Pmeg has undergone selective increases in PGeneM numbers, likely through accelerated transposable element-driven duplications. Many PGeneMs in both species failed to match transcripts and may represent pseudogenes or cryptic genetic reservoirs. Pmeg appears to have amplified specific gene families, some of which are virulence-related. Analysis of mycelium, zoospore, and in planta transcriptome expression profiles using neural network self-organizing map analysis generated 24 multivariate and nonlinear self-organizing map classes. Many members of the RxLR, necrosis-inducing phytophthora protein, and pectinase genes families were specifically induced in planta. Pmeg displays a diverse virulence-related gene complement similar in size to and potentially of greater diversity than Ppal but it remains likely that the specific functions of the genes determine each species’ unique characteristics as pathogens."																				
2017	"Baldi, Ada; Pandolfi, Camilla; Mancuso, Stefano; Lenzi, Anna"	A leaf-based back propagation neural network for oleander (Nerium oleander L.) cultivar identification	Images	DNN	Classification	Computers and Electronics in Agriculture	142		515-520	10.1016/j.compag.2017.11.021	https://www.sciencedirect.com/science/article/pii/S0168169917310906	"Oleander (Nerium oleander L.) includes many cultivars differing for the combination of a high number of characters, therefore their identification is difficult and time consuming. Nomenclature is often inaccurate and not uniform and the commercialization of material under unreliable names or even without name but stating only flower colour and type is frequent. In this paper, a Backpropagation Neural Network (BPNN) based on the image analysis of oleander leaves was developed as support tool for cultivar identification. It was built using 18 morphometric and colorimetric leaf parameters of 880 leaves collected from 22 cultivars (40 leaves per cultivar). The model resulted to be an efficient, reliable, and rapid method for distinguishing genotypes. The percentage of leaves attributed to the correct class reached 97.50% considering the single cultivars, and 54.55% on the total of the analysed leaves. Twenty-one cultivars were identified with certainty, and similarities in leaf morphology between some genotypes were highlighted, too. The method requires care in the choice of the leaves, which must be healthy and well-developed, but it is objective and, being oleander an evergreen species, not season-dependent. The model could be implemented in efficiency by introducing more leaf parameters, or in speed and computer performance by selecting the most representative. In fact, a smaller BPNN based on eight selected leaf parameters resulted slightly less sensitive (45.45% of the leaves attributed to the correct cultivar) but faster (4.4_s vs 7.7_s using a standard computer), and it could be used for very numerous collections."																				
2017	"Barré, Pierre; Stöver, Ben C.; Müller, Kai F.; Steinhage, Volker"	LeafNet: A computer vision system for automatic plant species identification	Images	CNN	Classification	Ecological Informatics	40		50-56	10.1016/j.ecoinf.2017.05.005	https://linkinghub.elsevier.com/retrieve/pii/S1574954116302515	"Aims: Taxon identification is an important step in many plant ecological studies. Its efficiency and reproducibility might greatly benefit from partly automating this task. Image-based identification systems exist, but mostly rely on hand-crafted algorithms to extract sets of features chosen a priori to identify species of selected taxa. In consequence, such systems are restricted to these taxa and additionally require involving experts that provide taxonomical knowledge for developing such customized systems. The aim of this study was to develop a deep learning system to learn discriminative features from leaf images along with a classifier for species identification of plants. By comparing our results with customized systems like LeafSnap we can show that learning the features by a convolutional neural network (CNN) can provide better feature representation for leaf images compared to hand-crafted features. Methods: We developed LeafNet, a CNN-based plant identification system. For evaluation, we utilized the publicly available LeafSnap, Flavia and Foliage datasets. Results: Evaluating the recognition accuracies of LeafNet on the LeafSnap, Flavia and Foliage datasets reveals a better performance of LeafNet compared to hand-crafted customized systems. Conclusions: Given the overall species diversity of plants, the goal of a complete automatisation of visual plant species identification is unlikely to be met solely by continually gathering assemblies of customized, specialized and hand-crafted (and therefore expensive) identification systems. Deep Learning CNN approaches offer a self-learning state-of-the-art alternative that allows adaption to different taxa just by presenting new training data instead of developing new software systems."																				
2017	"Bo_a, Vladimír; Brejová, Bro_a; Vina_, Tomá_"	DeepNano: Deep recurrent neural networks for base calling in MinION nanopore reads	Molecular	RNN	Classification	PLOS ONE	12	6	e0178751	10.1371/journal.pone.0178751	https://dx.plos.org/10.1371/journal.pone.0178751	"The MinION device by Oxford Nanopore produces very long reads (reads over 100 kBp were reported); however it suffers from high sequencing error rate. We present an open-source DNA base caller based on deep recurrent neural networks and show that the accuracy of base calling is much dependent on the underlying software and can be improved by considering modern machine learning methods. By employing carefully crafted recurrent neural networks, our tool significantly improves base calling accuracy on data from R7.3 version of the platform compared to the default base caller supplied by the manufacturer. On R9 version, we achieve results comparable to Nanonet base caller provided by Oxford Nanopore. Availability of an open source tool with high base calling accuracy will be useful for development of new applications of the MinION device, including infectious disease detection and custom target enrichment during sequencing."																				
2017	"Cantrell, Bradley; Martin, Laura J.; Ellis, Erle C."	Designing Autonomy: Opportunities for New Wildness in the Anthropocene	NA	NA	Review	Trends in Ecology & Evolution	32	3	156-166	10.1016/j.tree.2016.12.004	https://linkinghub.elsevier.com/retrieve/pii/S0169534716302373	"Maintaining wild places increasingly involves intensive human interventions. Several recent projects use semi-automated mediating technologies to enact conservation and restoration actions, including re-seeding and invasive species eradication. Could a deep-learning system sustain the autonomy of nonhuman ecological processes at designated sites without direct human interventions? We explore here the prospects for automated curation of wild places, as well as the technical and ethical questions that such co-creation poses for ecologists, conservationists, and designers. Our goal is to foster innovative approaches to creating and maintaining the autonomy of evolving ecological systems."																				
2017	"Carranza-Rojas, Jose; Goeau, Herve; Bonnet, Pierre; Mata-Montero, Erick; Joly, Alexis"	Going deeper in the automated identification of Herbarium specimens	Images	CNN	Classification	BMC Evolutionary Biology	17	1	181	10.1186/s12862-017-1014-z	http://bmcevolbiol.biomedcentral.com/articles/10.1186/s12862-017-1014-z	"Background: Hundreds of herbarium collections have accumulated a valuable heritage and knowledge of plants over several centuries. Recent initiatives started ambitious preservation plans to digitize this information and make it available to botanists and the general public through web portals. However, thousands of sheets are still unidentified at the species level while numerous sheets should be reviewed and updated following more recent taxonomic knowledge. These annotations and revisions require an unrealistic amount of work for botanists to carry out in a reasonable time. Computer vision and machine learning approaches applied to herbarium sheets are promising but are still not well studied compared to automated species identification from leaf scans or pictures of plants in the field. Results: In this work, we propose to study and evaluate the accuracy with which herbarium images can be potentially exploited for species identification with deep learning technology. In addition, we propose to study if the combination of herbarium sheets with photos of plants in the field is relevant in terms of accuracy, and finally, we explore if herbarium images from one region that has one specific flora can be used to do transfer learning to another region with other species; for example, on a region under-represented in terms of collected data. Conclusions: This is, to our knowledge, the first study that uses deep learning to analyze a big dataset with thousands of species from herbaria. Results show the potential of Deep Learning on herbarium species identification, particularly by training and testing across different datasets from different herbaria. This could potentially lead to the creation of a semi, or even fully automated system to help taxonomists and experts with their annotation, classification, and revision works."																				
2017	"Cheng, Xi; Zhang, You-Hua; Wu, Yun-Zhi; Yue, Yi"	Agricultural Pests Tracking and Identification in Video Surveillance Based on Deep Learning	Images	CNN	Classification	Intelligent Computing Methodologies	10363		58-70	10.1007/978-3-319-63315-2_6	http://link.springer.com/10.1007/978-3-319-63315-2_6	"Agricultural pests can cause serious damage to crops and need to be identified during the agricultural pest prevention and control process. In comparison with the low-speed and inefficient artificial identification method, it is important to develop a fast and reliable method for identifying agricultural pests based on computer vision. Aiming at the problem of agricultural pest identification in complex farmland environment, a recognition method through deep learning is proposed. The method could recognize and track the agricultural pests in surveillance videos of farmlands by using deep convolutional neural network and Faster R-CNN models. Compared with the traditional machine learning methods, this method has higher recognition accuracy in high background noise, and it can still effectively recognize agricultural pests with protective colorations. Therefore, compared with the current agricultural pest static-image recognition method, this method has a higher practical value and can be put into the actual agricultural production environment with the agricultural networking technology."																				
2017	"Cheng, Xi; Zhang, Youhua; Chen, Yiqiong; Wu, Yunzhi; Yue, Yi"	Pest identification via deep residual learning in complex background	Images	CNN	Classification	Computers and Electronics in Agriculture	141		351-356	10.1016/j.compag.2017.08.005	https://linkinghub.elsevier.com/retrieve/pii/S0168169917304854	"Agricultural pests severely affect both agricultural production and the storage of crops. To prevent damage caused by agricultural pests, the pest category needs to be correctly identified and targeted control measures need to be taken; therefore, it is important to develop an agricultural pest identification system based on computer vision technology. To achieve pest identification with the complex farmland background, a pest identification method is proposed that uses deep residual learning. Compared to support vector machine and traditional BP neural networks, the pest image recognition accuracy of this method is noticeably improved in the complex farmland background. Furthermore, in comparison to plain deep convolutional neural networks such as Alexnet, the recognition performance in this method was further improved after optimized by deep residual learning. A classification accuracy of 98.67% for 10 classes of crop pest images with complex farmland background was achieved. Accordingly, the method has a high value of practical application, and can be integrated with currently used agricultural networking systems into actual agricultural pest control tasks."																				
2017	"Chessa, Stefano; Micheli, Alessio; Pucci, Rita; Hunter, Jane; Carroll, Gemma; Harcourt, Rob"	A Comparative Analysis of SVM and IDNN for Identifying Penguin Activities	Other	Other	Classification	Applied Artificial Intelligence	31	6-May	453-471	10.1080/08839514.2017.1378162	https://doi.org/10.1080/08839514.2017.1378162	"Where, when and how much animals eat provide valuable insights into their ecology. In this paper, we present a comparative analysis between Support Vector Machine (SVM) and Input Delay Neural Network (IDNN) models to identify prey capture events from penguin accelerometry data. A pre-classified dataset of 3D time-series data from back-mounted accelerometers was used. We trained both the models to classify the penguins’ behavior at intervals as either ‘prey handling’ or ‘swimming’. The aim was to determine whether IDNN could achieve the same level of classification accuracy as SVM, but with reduced memory demands. This would enable the IDNN model to be embedded on the accelerometer micro-system itself, and hence reduce the magnitude of the output data to be uploaded. Based on the classification results, this paper provides an analysis of the two models from both an accuracy and applicability point of view. The experimental results show that both models achieve an equivalent accuracy of approx. 85% using the featured data, with a memory demand of 0.5 kB for IDNN and 0.7 Mb for SVM. The raw accelerometer data let us improve the generalizability of the models with a slightly lower accuracy to around 80%. This indicates that the IDNN model can embed on the accelerometer itself, reducing problems associated with raw time-series data retrieval and loss."																				
2017	"Chicco, Davide"	Ten quick tips for machine learning in computational biology	NA	NA	Review	BioData Mining	10	1	35	10.1186/s13040-017-0155-3	https://doi.org/10.1186/s13040-017-0155-3	"Machine learning has become a pivotal tool for many projects in computational biology, bioinformatics, and health informatics. Nevertheless, beginners and biomedical researchers often do not have enough experience to run a data mining project effectively, and therefore can follow incorrect practices, that may lead to common mistakes or over-optimistic results. With this review, we present ten quick tips to take advantage of machine learning in any computational biology context, by avoiding some common errors that we observed hundreds of times in multiple bioinformatics projects. We believe our ten suggestions can strongly help any machine learning practitioner to carry on a successful project in computational biology and related sciences."																				
2017	"Dobrescu, Andrei; Giuffrida, Mario Valerio; Tsaftaris, Sotirios A."	Leveraging multiple datasets for deep leaf counting	Images	CNN	Classification	arXiv:1709.01472 [cs]				10.48550/arXiv.1709.01472	http://arxiv.org/abs/1709.01472	"The number of leaves a plant has is one of the key traits (phenotypes) describing its development and growth. Here, we propose an automated, deep learning based approach for counting leaves in model rosette plants. While state-of-the-art results on leaf counting with deep learning methods have recently been reported, they obtain the count as a result of leaf segmentation and thus require per-leaf (instance) segmentation to train the models (a rather strong annotation). Instead, our method treats leaf counting as a direct regression problem and thus only requires as annotation the total leaf count per plant. We argue that combining different datasets when training a deep neural network is beneficial and improves the results of the proposed approach. We evaluate our method on the CVPPP 2017 Leaf Counting Challenge dataset, which contains images of Arabidopsis and tobacco plants. Experimental results show that the proposed method significantly outperforms the winner of the previous CVPPP challenge, improving the results by a minimum of ~50% on each of the test datasets, and can achieve this performance without knowing the experimental origin of the data (i.e. in the wild setting of the challenge). We also compare the counting accuracy of our model with that of per leaf segmentation algorithms, achieving a 20% decrease in mean absolute difference in count (|DiC|)."																				
2017	"Esteban, Luis G.; de Palacios, Paloma; Conde, María; Fernández, Francisco G.; García-Iruela, Alberto; González-Alonso, Marta"	Application of artificial neural networks as a predictive method to differentiate the wood of Pinus sylvestris L. and Pinus nigra Arn subsp. salzmannii (Dunal) Franco	Other	DNN	Classification	Wood Science and Technology	51	5	1249-1258	10.1007/s00226-017-0932-7	https://doi.org/10.1007/s00226-017-0932-7	"The wood structure of conifers in general and the Pinus genus in particular makes species differentiation by traditional qualitative or quantitative methods complicated or even impossible at times. Pinus sylvestris L. and Pinus nigra Arn subsp. salzmannii (Dunal) Franco are a clear example of this because they cannot be differentiated by traditional methods. However, correctly identifying these species is very important in some cases as they are extensively used in a large variety of fields because of their wide distribution range in the forests of Europe and Asia. Using trees selected from the same forest to minimise the influence of site and performing a biometric study of 10 growth rings from the same climate period, a feedforward multilayer perceptron network trained by the resilient backpropagation algorithm was designed to determine whether the network could be used to differentiate these species with a high degree of probability. The artificial neural network achieved 90.4% accuracy in the training set, 81.6% in the validation set and 81.2% in the testing set. This result justifies the use of this tool for wood identification at anatomical level."																				
2017	"Fuentes, Alvaro; Yoon, Sook; Kim, Sang; Park, Dong"	A Robust Deep-Learning-Based Detector for Real-Time Tomato Plant Diseases and Pests Recognition	Images	CNN	Classification	Sensors	17	9	2022	10.3390/s17092022	http://www.mdpi.com/1424-8220/17/9/2022	"Plant Diseases and Pests are a major challenge in the agriculture sector. An accurate and a faster detection of diseases and pests in plants could help to develop an early treatment technique while substantially reducing economic losses. Recent developments in Deep Neural Networks have allowed researchers to drastically improve the accuracy of object detection and recognition systems. In this paper, we present a deep-learning-based approach to detect diseases and pests in tomato plants using images captured in-place by camera devices with various resolutions. Our goal is to find the more suitable deep-learning architecture for our task. Therefore, we consider three main families of detectors: Faster Region-based Convolutional Neural Network (Faster R-CNN), Region-based Fully Convolutional Network (R-FCN), and Single Shot Multibox Detector (SSD), which for the purpose of this work are called “deep learning meta-architectures”. We combine each of these meta-architectures with “deep feature extractors” such as VGG net and Residual Network (ResNet). We demonstrate the performance of deep meta-architectures and feature extractors, and additionally propose a method for local and global class annotation and data augmentation to increase the accuracy and reduce the number of false positives during training. We train and test our systems end-to-end on our large Tomato Diseases and Pests Dataset, which contains challenging images with diseases and pests, including several inter- and extra-class variations, such as infection status and location in the plant. Experimental results show that our proposed system can effectively recognize nine different types of diseases and pests, with the ability to deal with complex scenarios from a plant’s surrounding area."																				
2017	"Gomez Villa, Alexander; Salazar, Augusto; Vargas, Francisco"	Towards automatic wild animal monitoring: Identification of animal species in camera-trap images using very deep convolutional neural networks	Images	CNN	Classification	Ecological Informatics	41		24-32	10.1016/j.ecoinf.2017.07.004	https://linkinghub.elsevier.com/retrieve/pii/S1574954116302047	"Non-intrusive monitoring of animals in the wild is possible using camera trapping networks. The cameras are triggered by sensors in order to disturb the animals as little as possible. This approach produces a high volume of data (in the order of thousands or millions of images) that demands laborious work to analyze both useless (incorrect detections, which are the most) and useful (images with presence of animals). In this work, we show that as soon as some obstacles are overcome, deep neural networks can cope with the problem of the automated species classification appropriately. As case of study, the most common 26 of 48 species from the Snapshot Serengeti (SSe) dataset were selected and the potential of the Very Deep Convolutional neural networks framework for the species identification task was analyzed. In the worst-case scenario (unbalanced training dataset containing empty images) the method reached 35.4% Top-1 and 60.4% Top-5 accuracy. For the best scenario (balanced dataset, images containing foreground animals only, and manually segmented) the accuracy reached a 88.9% Top-1 and 98.1% Top-5, respectively. To the best of our knowledge, this is the first published attempt on solving the automatic species recognition on the SSe dataset. In addition, a comparison with other approaches on a different dataset was carried out, showing that the architectures used in this work outperformed previous approaches. The limitations of the method, drawbacks, as well as new challenges in automatic camera-trap species classification are widely discussed."																				
2017	"Jones, William; Alasoo, Kaur; Fishman, Dmytro; Parts, Leopold"	Computational biology: deep learning	NA	NA	Review	Emerging Topics in Life Sciences	1	3	257-274	10.1042/ETLS20160025	https://portlandpress.com/emergtoplifesci/article/1/3/257/76782/Computational-biology-deep-learning	"Deep learning is the trendiest tool in a computational biologist's toolbox. This exciting class of methods, based on artificial neural networks, quickly became popular due to its competitive performance in prediction problems. In pioneering early work, applying simple network architectures to abundant data already provided gains over traditional counterparts in functional genomics, image analysis, and medical diagnostics. Now, ideas for constructing and training networks and even off-the-shelf models have been adapted from the rapidly developing machine learning subfield to improve performance in a range of computational biology tasks. Here, we review some of these advances in the last 2 years."																				
2017	"Kahl, Stefan; Wilhelm-Stein, Thomas; Hussein, Hussein; Klinck, Holger; Ritter, Marc; Eibl, Maximilian"	Large-Scale Bird Sound Classification using Convolutional Neural Networks	Sound	CNN	Classification	CLEF (Working Notes)				NA	https://www.researchgate.net/profile/Danny-Kowerko/publication/322144806_Large-Scale_Bird_Sound_Classification_using_Convolutional_Neural_Networks/links/5ad4bfe2a6fdcc2935808d8e/Large-Scale-Bird-Sound-Classification-using-Convolutional-Neural-Networks.pdf	"Identifying bird species in audio recordings is a challenging field of research. In this paper, we summarize a method for large-scale bird sound classification in the context of the LifeCLEF 2017 bird identification task. We used a variety of convolutional neural networks to generate features extracted from visual representations of field recordings. The BirdCLEF 2017 training dataset consist of 36.496 audio recordings containing 1500 different bird species. Our approach achieved a mean average precision of 0,605 (official score) and 0,687 considering only foreground species."																				
2017	"Kho, Soon Jye; Manickam, Sugumaran; Malek, Sorayya; Mosleh, Mogeeb; Dhillon, Sarinder Kaur"	Automated plant identification using artificial neural network and support vector machine	Images	DNN	Classification	Frontiers in Life Science	10	1	98-107	10.1080/21553769.2017.1412361	https://doi.org/10.1080/21553769.2017.1412361	"Ficus is one of the largest genera in plant kingdom reaching to about 1000 species worldwide. While taxonomic keys are available for identifying most species of Ficus, it is very difficult and time consuming for interpretation by a nonprofessional thus requires highly trained taxonomists. The purpose of the current study is to develop an efficient baseline automated system, using image processing with pattern recognition approach, to identify three species of Ficus, which have similar leaf morphology. Leaf images from three different Ficus species namely F. benjamina, F. pellucidopunctata and F. sumatrana were selected. A total of 54 leaf image samples were used in this study. Three main steps that are image pre-processing, feature extraction and recognition were carried out to develop the proposed system. Artificial neural network (ANN) and support vector machine (SVM) were the implemented recognition models. Evaluation results showed the ability of the proposed system to recognize leaf images with an accuracy of 83.3%. However, the ANN model performed slightly better using the AUC evaluation criteria. The system developed in the current study is able to classify the selected Ficus species with acceptable accuracy."																				
2017	"Lee, Sue Han; Chan, Chee Seng; Mayo, Simon Joseph; Remagnino, Paolo"	How deep learning extracts and learns leaf features for plant classification	Images	CNN	Classification	Pattern Recognition	71		13-Jan	10.1016/j.patcog.2017.05.015	https://www.sciencedirect.com/science/article/pii/S003132031730198X	"Plant identification systems developed by computer vision researchers have helped botanists to recognize and identify unknown plant species more rapidly. Hitherto, numerous studies have focused on procedures or algorithms that maximize the use of leaf databases for plant predictive modeling, but this results in leaf features which are liable to change with different leaf data and feature extraction techniques. In this paper, we learn useful leaf features directly from the raw representations of input data using Convolutional Neural Networks (CNN), and gain intuition of the chosen features based on a Deconvolutional Network (DN) approach. We report somewhat unexpected results: (1) different orders of venation are the best representative features compared to those of outline shape, and (2) we observe multi-level representation in leaf data, demonstrating the hierarchical transformation of features from lower-level to higher-level abstraction, corresponding to species classes. We show that these findings fit with the hierarchical botanical definitions of leaf characters. Through these findings, we gained insights into the design of new hybrid feature extraction models which are able to further improve the discriminative power of plant classification systems. The source code and models are available at: https://github.com/cs-chan/Deep-Plant."																				
2017	"Li, Kezhi; Javer, Avelino; Keaveny, Eric E.; Brown, Andre E.X."	Recurrent Neural Networks with Interpretable Cells Predict and Classify Worm Behaviour	Video	RNN	"Classification, Regression"	bioRxiv				10.1101/222208	http://biorxiv.org/lookup/doi/10.1101/222208	"An important goal in behaviour analytics is to connect disease state or genome variation with observable differences in behaviour. Despite advances in sensor technology and imaging, informative behaviour quantification remains challenging. The nematode worm C. elegans provides a unique opportunity to test analysis approaches because of its small size, compact nervous system, and the availability of large databases of videos of freely behaving animals with known genetic differences. Despite its relative simplicity, there are still no reports of generative models that can capture essential differences between even well-described mutant strains. Here we show that a multilayer recurrent neural network (RNN) can produce diverse behaviours that are difficult to distinguish from real worms’ behaviour and that some of the artificial neurons in the RNN are interpretable and correlate with observable features such as body curvature, speed, and reversals. Although the RNN is not trained to perform classification, we find that artificial neuron responses provide features that perform well in worm strain classification."																				
2017	"Lim, Suchang; Kim, Seunghyun; Kim, Doyeon"	Performance effect analysis for insect classification using convolutional neural network	Images	CNN	Classification	"2017 7th IEEE International Conference on Control System, Computing and Engineering (ICCSCE)"			210-215	10.1109/ICCSCE.2017.8284406	http://ieeexplore.ieee.org/document/8284406/	"It is necessary to develop an automated insect classification method in order to create high added value of insects. Recently, image classification work applying deep learning shows the best result of classification performance. In this paper, we use convolutional neural network to classify insects and examine the effect of the classification performance with the varying number of kernels in the convolution layer and with the different image datasets. Experiments were conducted on 27 insect classes of ImageNet dataset with AlexNet. We confirmed that the classification performance of neural network improves where insects are well represented at the center of the image, and when the number of convolution kernels increases."																				
2017	"Liu, Shiliang; Yang, Rongjie; Yang, Jun; Yi, Tongpei; Song, Huixing; Jiang, Mingyan; Tripathi, Durgesh K.; Ma, Mingdong; Chen, Qibing"	"Differentiating Thamnocalamus Munro from Fargesia Franchet emend. Yi (Bambusoideae, Poaceae): novel evidence from morphological and neural-network analyses"	Other	DNN	Classification	Scientific Reports	7	1	4192	10.1038/s41598-017-04613-9	https://www.nature.com/articles/s41598-017-04613-9	"Fargesia Franchet emend. Yi is closely allied with Thamnocalamus Munro but differs in many major morphological characteristics. Based on traditional morphological characters, it is difficult to differentiate these two genera. The current study measured 19 species in these two genera to determine whether variations in 12 categories of major characters are continuous. In addition, a self-organizing map (SOM) and cluster analysis were used together to reveal whether the known species of Fargesia represent discontinuous sampling of Thamnocalamus. The results show that 46 morphological characteristics exhibited high variation at the generic and species levels. In addition, the cluster analysis showed that 32 morphological characteristics of Thamnocalamus and Fargesia were divided between two species and well separated from the outgroup. Additionally, significant differences (P_<_0.01) were observed in the reproductive structures between these two genera. The unrooted dendrogram, which was based on the SOM neural network, shows the same results as the cluster analysis of morphological characteristics. These data indicate that Fargesia is not a result of discontinuous sampling of Thamnocalamus; thus, Fargesia should not be treated as a synonym for Thamnocalamus."																				
2017	"Mehdipour Ghazi, Mostafa; Yanikoglu, Berrin; Aptoula, Erchan"	Plant identification using deep neural networks via optimization of transfer learning parameters	Images	CNN	Classification	Neurocomputing	235		228-235	10.1016/j.neucom.2017.01.018	https://www.sciencedirect.com/science/article/pii/S0925231217300498	"We use deep convolutional neural networks to identify the plant species captured in a photograph and evaluate different factors affecting the performance of these networks. Three powerful and popular deep learning architectures, namely GoogLeNet, AlexNet, and VGGNet, are used for this purpose. Transfer learning is used to fine-tune the pre-trained models, using the plant task datasets of LifeCLEF 2015. To decrease the chance of overfitting, data augmentation techniques are applied based on image transforms such as rotation, translation, reflection, and scaling. Furthermore, the networks' parameters are adjusted and different classifiers are fused to improve overall performance. Our best combined system has achieved an overall accuracy of 80% on the validation set and an overall inverse rank score of 0.752 on the official test set. A comparison of our results against the results of the LifeCLEF 2015 plant identification campaign shows that we have improved the overall validation accuracy of the top system by 15% points and its overall inverse rank score on the test set by 0.1 while outperforming the top three competition participants in all categories. The system recently obtained a very close second place in the PlantCLEF 2016."																				
2017	"Murat, Miraemiliana; Chang, Siow-Wee; Abu, Arpah; Yap, Hwa Jen; Yong, Kien-Thai"	Automated classification of tropical shrub species: a hybrid of leaf shape and machine learning approach	Images	DNN	Classification	PeerJ	5		e3792	10.7717/peerj.3792	https://peerj.com/articles/3792	"Plants play a crucial role in foodstuff, medicine, industry, and environmental protection. The skill of recognising plants is very important in some applications, including conservation of endangered species and rehabilitation of lands after mining activities. However, it is a difficult task to identify plant species because it requires specialized knowledge. Developing an automated classification system for plant species is necessary and valuable since it can help specialists as well as the public in identifying plant species easily. Shape descriptors were applied on the myDAUN dataset that contains 45 tropical shrub species collected from the University of Malaya (UM), Malaysia. Based on literature review, this is the first study in the development of tropical shrub species image dataset and classification using a hybrid of leaf shape and machine learning approach. Four types of shape descriptors were used in this study namely morphological shape descriptors (MSD), Histogram of Oriented Gradients (HOG), Hu invariant moments (Hu) and Zernike moments (ZM). Single descriptor, as well as the combination of hybrid descriptors were tested and compared. The tropical shrub species are classified using six different classifiers, which are artificial neural network (ANN), random forest (RF), support vector machine (SVM), k-nearest neighbour (k-NN), linear discriminant analysis (LDA) and directed acyclic graph multiclass least squares twin support vector machine (DAG MLSTSVM). In addition, three types of feature selection methods were tested in the myDAUN dataset, Relief, Correlation-based feature selection (CFS) and Pearson’s coefficient correlation (PCC). The well-known Flavia dataset and Swedish Leaf dataset were used as the validation dataset on the proposed methods. The results showed that the hybrid of all descriptors of ANN outperformed the other classifiers with an average classification accuracy of 98.23% for the myDAUN dataset, 95.25% for the Flavia dataset and 99.89% for the Swedish Leaf dataset. In addition, the Relief feature selection method achieved the highest classification accuracy of 98.13% after 80 (or 60%) of the original features were reduced, from 133 to 53 descriptors in the myDAUN dataset with the reduction in computational time. Subsequently, the hybridisation of four descriptors gave the best results compared to others. It is proven that the combination MSD and HOG were good enough for tropical shrubs species classification. Hu and ZM descriptors also improved the accuracy in tropical shrubs species classification in terms of invariant to translation, rotation and scale. ANN outperformed the others for tropical shrub species classification in this study. Feature selection methods can be used in the classification of tropical shrub species, as the comparable results could be obtained with the reduced descriptors and reduced in computational time and cost."																				
2017	"Pantazi, X.E.; Tamouridou, A.A.; Alexandridis, T.K.; Lagopodi, A.L.; Kashefi, J.; Moshou, D."	Evaluation of hierarchical self-organising maps for weed mapping using UAS multispectral imagery	Other	DNN	Modeling	Computers and Electronics in Agriculture	139		224-230	10.1016/j.compag.2017.05.026	https://linkinghub.elsevier.com/retrieve/pii/S0168169916308973	"Remote sensing has been used for species discrimination and for operational weed mapping. In the study presented here, the detection and mapping of Silybum marianum using a hierarchical self-organising map is reported. A multispectral camera (green-red-NIR) mounted on a ﬁxed wing Unmanned Aircraft System (UAS) was used for the acquisition of high-resolution images of a pixel size of 0.1 m, resampled to 0.5 m. The Supervised Kohonen Network (SKN), Counter-propagation Artiﬁcial Neural Network (CP-ANN) and XY-Fusion network (XY-F) were used to identify the S. marianum among other vegetation in a ﬁeld, with Avena sterilis L. being predominant. As input features to the classiﬁers, the three spectral bands of Red, Green, Near Infrared (NIR) and the texture layer were used. The S. marianum identiﬁcation rates using SKN achieved an accuracy level of 98.64%, the CP-ANN achieved 98.87%, while XY-F was 98.64%. The results prove the feasibility of operational S. marianum mapping using hierarchical self-organising maps on multispectral UAS imagery."																				
2017	"Park, Young-Seuk; Céréghino, Régis; Compin, Arthur; Lek, Sovan"	Applications of artificial neural networks for patterning and predicting aquatic insect species richness in running waters	Environmental	DNN	Modeling	Ecological Modelling	160	3	265-280	10.1016/S0304-3800(02)00258-2	https://www.sciencedirect.com/science/article/pii/S0304380002002582	"Two artificial neural networks (ANNs), unsupervised and supervised learning algorithms, were applied to suggest practical approaches for the analysis of ecological data. Four major aquatic insect orders (Ephemeroptera, Plecoptera, Trichoptera, and Coleoptera, i.e. EPTC), and four environmental variables (elevation, stream order, distance from the source, and water temperature) were used to implement the models. The data were collected and measured at 155 sampling sites on streams of the Adour–Garonne drainage basin (South-western France). The modelling procedure was carried out following two steps. First, a self-organizing map (SOM), an unsupervised ANN, was applied to classify sampling sites using EPTC richness. Second, a backpropagation algorithm (BP), a supervised ANN, was applied to predict EPTC richness using a set of four environmental variables. The trained SOM classified sampling sites according to a gradient of EPTC richness, and the groups obtained corresponded to geographic regions of the drainage basin and characteristics of their environmental variables. The SOM showed its convenience to analyze relationships among sampling sites, biological attributes, and environmental variables. After accounting for the relationships in data sets, the BP used to predict the EPTC richness with a set of four environmental variables showed a high accuracy (r=0.91 and r=0.61 for training and test data sets respectively). The prediction of EPTC richness is thus a valuable tool to assess disturbances in given areas: by knowing what the EPTC richness should be, we can determine the degree to which disturbances have altered it. The results suggested that methodologies successively using two different neural networks are helpful to understand ecological data through ordination first, and then to predict target variables."																				
2017	"Pound, Michael P; Atkinson, Jonathan A; Wells, Darren M"	Deep Learning for Multi-task Plant Phenotyping	Images	CNN	Classification	2017 IEEE International Conference on Computer Vision Workshops (ICCVW)				10.1109/ICCVW.2017.241	https://ieeexplore.ieee.org/document/8265451	"Plant phenotyping has continued to pose a challenge to computer vision for many years. There is a particular demand to accurately quantify images of crops, and the natural variability and structure of these plants presents unique difficulties. Recently, machine learning approaches have shown impressive results in many areas of computer vision, but these rely on large datasets that are at present not available for crops. We present a new dataset, called ACID, that provides hundreds of accurately annotated images of wheat spikes and spikelets, along with image level class annotation. We then present a deep learning approach capable of accurately localising wheat spikes and spikelets, despite the varied nature of this dataset. As well as locating features, our network offers near perfect counting accuracy for spikes (95.91%) and spikelets (99.66%). We also extend the network to perform simultaneous classification of images, demonstrating the power of multi-task deep architectures for plant phenotyping. We hope that our dataset will be useful to researchers in continued improvement of plant and crop phenotyping. With this in mind, alongside the dataset we will make all code and trained models available online."																				
2017	"Ramcharan, Amanda; Baranowski, Kelsee; McCloskey, Peter; Ahmed, Babuali; Legg, James; Hughes, David P."	Deep Learning for Image-Based Cassava Disease Detection	Images	CNN	Classification	Frontiers in Plant Science	8		1852	10.3389/fpls.2017.01852	http://journal.frontiersin.org/article/10.3389/fpls.2017.01852/full	"Cassava is the third largest source of carbohydrates for human food in the world but is vulnerable to virus diseases, which threaten to destabilize food security in sub-Saharan Africa. Novel methods of cassava disease detection are needed to support improved control which will prevent this crisis. Image recognition offers both a cost effective and scalable technology for disease detection. New deep learning models offer an avenue for this technology to be easily deployed on mobile devices. Using a dataset of cassava disease images taken in the field in Tanzania, we applied transfer learning to train a deep convolutional neural network to identify three diseases and two types of pest damage (or lack thereof). The best trained model accuracies were 98% for brown leaf spot (BLS), 96% for red mite damage (RMD), 95% for green mite damage (GMD), 98% for cassava brown streak disease (CBSD), and 96% for cassava mosaic disease (CMD). The best model achieved an overall accuracy of 93% for data not used in the training process. Our results show that the transfer learning approach for image recognition of field images offers a fast, affordable, and easily deployable strategy for digital plant disease detection."																				
2017	"Rawat, Waseem; Wang, Zenghui"	Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review	NA	CNN	Review	Neural Computation	29	9	2352-2449	10.1162/neco_a_00990	https://www.mitpressjournals.org/doi/abs/10.1162/neco_a_00990	"Convolutional neural networks (CNNs) have been applied to visual tasks since the late 1980s. However, despite a few scattered applications, they were dormant until the mid-2000s when developments in computing power and the advent of large amounts of labeled data, supplemented by improved algorithms, contributed to their advancement and brought them to the forefront of a neural network renaissance that has seen rapid progression since 2012. In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art deep learning systems. Along the way, we analyze (1) their early successes, (2) their role in the deep learning renaissance, (3) selected symbolic works that have contributed to their recent popularity, and (4) several improvement attempts by reviewing contributions and challenges of over 300 publications. We also introduce some of their current trends and remaining challenges."																				
2017	"Richit, L. A.; Bonatto, C.; Carlotto, T.; da Silva, R. V.; Grzybowski, J. M. V."	Modelling forest regeneration for performance-oriented riparian buffer strips	Environmental	DNN	Regression	Ecological Engineering	106		308-322	10.1016/j.ecoleng.2017.05.044	https://www.sciencedirect.com/science/article/pii/S0925857417303178	"Riparian buffer strips (RBS) play an important role in the conservation of water bodies. Yet to date the increasing degradation of riparian vegetation is a major concern due to the inherent risk it poses to quality and quantity of drinkable water. In turn, forest regeneration is known to be a process that evolves in a time-scale of years, such that the regeneration of a forested area after a perturbation can take several decades. In this context, the exploration of models of vegetation growth can contribute to the understanding and acknowledgement of diverse aspects of such phenoma. Further, from the standpoint of conservation projects, the application of models allows the assessment of different future scenarios resulting from the application of different management practices, thus allowing anticipating the likely outcomes of the management process. In this paper, we study the application of the diffusive-logistic model (DLG model) to the problem of forest regeneration. We concentrate in vegetation belonging to permanent preservation areas, such as RBS. The main contribution of this study is to propose and illustrate a thorough methodology applicable as auxiliary assessment and design tool for conservation projects. The study is developed in two steps. We build upon recent results that study on the performance of riparian buffer strips in the removal of nitrogen in agricultural catchments in which an Artificial Neural Network Ensemble (ANNE) was applied to evaluate the riparian buffer strip width needed to accomplish filtering of 90% of the residual nitrogen. On this basis, we calibrate and validate the parameters of the diffusive-logistic model of forest growth to estimate the evolution of regeneration in riparian buffer strips, considering the buffer widths obtained by the ANNE. We implement the solution in GPGPU (General Purpose Graphics Processing Unit) and then simulate for forty years ahead to verify the likely effect of conservation upon the riparian buffer strips in the watershed. The results of calibration and validation show that the diffusive-logistic model provides a rather accurate temporal and spatial account of forest regeneration. The application of the model to a case study of the Ligeiro River watershed, Brazil, shows that the model can provide valuable insights for decision-making in the context of environmental conservation and management."																				
2017	"Rzanny, Michael; Seeland, Marco; Wäldchen, Jana; Mäder, Patrick"	Acquiring and preprocessing leaf images for automated plant identification: understanding the tradeoff between effort and information gain	Images	CNN	Classification	Plant Methods	13	1	97	10.1186/s13007-017-0245-8	http://plantmethods.biomedcentral.com/articles/10.1186/s13007-017-0245-8	"Automated species identification is a long term research subject. Contrary to flowers and fruits, leaves are available throughout most of the year. Offering margin and texture to characterize a species, they are the most studied organ for automated identification. Substantially matured machine learning techniques generate the need for more training data (aka leaf images). Researchers as well as enthusiasts miss guidance on how to acquire suitable training images in an efficient way."																				
2017	"Salamon, Justin; Bello, Juan Pablo; Farnsworth, Andrew; Kelling, Steve"	Fusing shallow and deep learning for bioacoustic bird species classification	Sound	CNN	Classification	"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"			141-145	10.1109/ICASSP.2017.7952134	http://ieeexplore.ieee.org/document/7952134/	"Automated classification of organisms to species based on their vocalizations would contribute tremendously to abilities to monitor biodiversity, with a wide range of applications in the field of ecology. In particular, automated classification of migrating birds' flight calls could yield new biological insights and conservation applications for birds that vocalize during migration. In this paper we explore state-of-the-art classification techniques for large-vocabulary bird species classification from flight calls. In particular, we contrast a “shallow learning” approach based on unsupervised dictionary learning with a deep convolutional neural network combined with data augmentation. We show that the two models perform comparably on a dataset of 5428 flight calls spanning 43 different species, with both significantly outperforming an MFCC baseline. Finally, we show that by combining the models using a simple late-fusion approach we can further improve the results, obtaining a state-of-the-art classification accuracy of 0.96."																				
2017	"Schuettpelz, Eric; Frandsen, Paul; Dikow, Rebecca; Brown, Abel; Orli, Sylvia; Peters, Melinda; Metallo, Adam; Funk, Vicki; Dorr, Laurence"	Applications of deep convolutional neural networks to digitized natural history collections	Images	CNN	Classification	Biodiversity Data Journal	5		e21139	10.3897/BDJ.5.e21139	https://bdj.pensoft.net/articles.php?id=21139	"Natural history collections contain data that are critical for many scientific endeavors. Recent efforts in mass digitization are generating large datasets from these collections that can provide unprecedented insight. Here, we present examples of how deep convolutional neural networks can be applied in analyses of imaged herbarium specimens. We first demonstrate that a convolutional neural network can detect mercury-stained specimens across a collection with 90% accuracy. We then show that such a network can correctly distinguish two morphologically similar plant families 96% of the time. Discarding the most challenging specimen images increases accuracy to 94% and 99%, respectively. These results highlight the importance of mass digitization and deep learning approaches and reveal how they can together deliver powerful new investigative tools."																				
2017	"Soda, K.j.; Slice, D.e.; Naylor, G.j.p."	Artificial neural networks and geometric morphometric methods as a means for classification: A case-study using teeth from Carcharhinus sp. (Carcharhinidae)	Other	DNN	Classification	Journal of Morphology	278	1	131-141	10.1002/jmor.20626	https://onlinelibrary.wiley.com/doi/abs/10.1002/jmor.20626	"Over the past few decades, geometric morphometric methods have become increasingly popular and powerful tools to describe morphological data while over the same period artificial neural networks have had a similar rise in the classification of specimens to preconceived groups. However, there has been little research into how well these two systems operate together, particularly in comparison to preexisting techniques. In this study, geometric morphometric data and multilayer perceptrons, a style of artificial neural network, were used to classify shark teeth from the genus Carcharhinus to species. Three datasets of varying size and species differences were used. We compared the performance of this combination with geometric morphometric data in a linear discriminate function analysis, linear measurements in a linear discriminate function analysis, and a preexisting methodology from the literature that incorporates linear measurements and a two-layered discriminate function analysis. Across datasets, geometric morphometric data in a multilayer perceptron tended to yield modest accuracies but accuracies that varied less across species whereas other methods were able to achieve higher accuracies in some species at the expense of lower accuracies in others. Further, the performance of the two-layered discriminate function analysis illustrates that constraining what material is classified can increase the accuracy of a method. Based on this tradeoff, the best methodology will then depend on the scope of the study and the amount of material available. J. Morphol. 278:131–141, 2017. ©© 2016 Wiley Periodicals,Inc."																				
2017	"Song, Hong; Mehdi, Syed; __, Hui; Shahani, Kamran; Zhang, Yangfan; Ullah, Junaid; Raza, Kazim; Khan, Mushtaq"	Classification of Freshwater Zooplankton by Pre-trained Convolutional Neural Network in Underwater Microscopy	Images	DNN	Classification	International Journal of Advanced Computer Science and Applications	11	7	252-258	10.14569/IJACSA.2020.0110733	https://thesai.org/Publications/ViewPaper?Volume=11&Issue=7&Code=IJACSA&SerialNo=33	"Zooplankton is enormously diverse and fundamental group of microorganisms that exists in almost every freshwater body, determining its ecology and play a vital role in food chain. Considering the significance of zooplankton, the study of freshwater zooplankton is very essential which intensely relies on the classification of images. However, the routine manual analysis and classification is laborious, time consuming and expensive, and poses a significant challenge to experts. Thus, for recent decade much research is focused on the development of underwater imaging technologies and intelligent classification system of zooplankton. This work presents devotion to observation of freshwater zooplankton by designed underwater microscope and modeling the system for automatic classification among four different taxa. Unlike most of the existing zooplankton image classification systems, this model is trained on a comparatively small dataset collected from freshwater by designed underwater microscope. Transfer learning of pre-trained AlexNet Convolutional Neural Network (CNN) model proved to be a potential approach in the system design. Among four networks trained over two datasets, the best overall classification accuracy of up to 93.1%, comparable to other existing systems was achieved on test dataset (92.5% for Calanoid and Cyclopoid (Female), 90% for Cyclopoid (Male) and 97.5% for Daphnia). Graphical User Interface (GUI) of the model constructed on MATLAB, makes it easy for the users to collect images for building database, train network and to classify images of different taxa. Moreover, the designed system is adaptable to the addition of more classes in the future."																				
2017	"Sor, Ratha; Park, Young-Seuk; Boets, Pieter; Goethals, Peter L. M.; Lek, Sovan"	Effects of species prevalence on the performance of predictive models	Environmental	DNN	Modeling	Ecological Modelling	354		19-Nov	10.1016/j.ecolmodel.2017.03.006	https://www.sciencedirect.com/science/article/pii/S0304380016304367	"Predictive models are useful to support decision making, management and conservation planning. However, the performance of models varies across techniques and is affected by several factors including species prevalence (i.e. the occurrence rate of each species in the total samples). Here, we analysed and compared the performance of four common modelling techniques based on the species prevalence. The occurrence of macroinvertebrates collected at 63 sites along the Lower Mekong Basin was predicted using Logistic Regression, Random Forest, Support Vector Machine and Artificial Neural Network (ANN). Model performance was evaluated using Cohen’s Kappa Statistic (Kappa), area under receiver operating characteristic curve (AUC) and error rate. We found a highly significant quadratic effect of species prevalence on the four modelling techniques’ performance. Kappa and AUC were less depended on the species prevalence, making them a better measure. The best performance (Kappa and AUC) was reached when predicting species with an intermediate prevalence (e.g. 0.4–0.6). The four modelling techniques significantly yielded different performances (p<0.01), of which ANN performed generally better when using the complete prevalence range (i.e. 0.0–1.0) and the lower prevalence range (i.e. <0.1). However, the four techniques similarly performed when predicting species with a higher prevalence range (i.e. ≥0.3). Our results provide useful insights into the application of modelling techniques in predicting species occurrence and how their performance varies for species with different prevalence ranges. We suggest that the selection of appropriate modelling techniques should carefully take into account the species prevalence, particularly in the case of rare and generalist species."																				
2017	"Sun, Yu; Liu, Yuan; Wang, Guan; Zhang, Haiyan"	Deep Learning for Plant Identification in Natural Environment	Images	CNN	Classification	Computational Intelligence and Neuroscience	2017		e7361042	10.1155/2017/7361042	https://www.hindawi.com/journals/cin/2017/7361042/	"Plant image identification has become an interdisciplinary focus in both botanical taxonomy and computer vision. The first plant image dataset collected by mobile phone in natural scene is presented, which contains 10,000 images of 100 ornamental plant species in Beijing Forestry University campus. A 26-layer deep learning model consisting of 8 residual building blocks is designed for large-scale plant classification in natural environment. The proposed model achieves a recognition rate of 91.78% on the BJFU100 dataset, demonstrating that deep learning is a promising technology for smart forestry."																				
2017	"Tran, Ngoc Hieu; Zhang, Xianglilan; Xin, Lei; Shan, Baozhen; Li, Ming"	De novo peptide sequencing by deep learning	Molecular	"CNN, RNN"	Classification	Proceedings of the National Academy of Sciences	114	31	8247-8252	10.1073/pnas.1705691114	https://www.pnas.org/doi/10.1073/pnas.1705691114	"Significance  Our method, DeepNovo, introduces deep learning to de novo peptide sequencing from tandem MS data, the key technology for protein characterization in proteomics research. DeepNovo achieves major improvement of sequencing accuracy over state of the art methods and subsequently enables complete assembly of protein sequences without assisting databases. Our model is retrainable to adapt to any sources of data and provides a complete end-to-end training and prediction solution, an important feature given the growing massive amount of data. Our study also presents an innovative approach to combine deep learning and dynamic programming to solve optimization problems."																				
2017	"Valletta, John Joseph; Torney, Colin; Kings, Michael; Thornton, Alex; Madden, Joah"	Applications of machine learning in animal behaviour studies	NA	NA	Review	Animal Behaviour	124		203-220	10.1016/j.anbehav.2016.12.005	https://linkinghub.elsevier.com/retrieve/pii/S0003347216303360	"In many areas of animal behaviour research, improvements in our ability to collect large and detailed data sets are outstripping our ability to analyse them. These diverse, complex and often high-dimensional data sets exhibit nonlinear dependencies and unknown interactions across multiple variables, and may fail to conform to the assumptions of many classical statistical methods. The field of machine learning provides methodologies that are ideally suited to the task of extracting knowledge from these data. In this review, we aim to introduce animal behaviourists unfamiliar with machine learning (ML) to the promise of these techniques for the analysis of complex behavioural data. We start by describing the rationale behind ML and review a number of animal behaviour studies where ML has been successfully deployed. The ML framework is then introduced by presenting several unsupervised and supervised learning methods. Following this overview, we illustrate key ML approaches by developing data analytical pipelines for three different case studies that exemplify the types of behavioural and ecological questions ML can address. The first uses a large number of spectral and morphological characteristics that describe the appearance of pheasant, Phasianus colchicus, eggs to assign them to putative clutches. The second takes a continuous data stream of feeder visits from PIT (passive integrated transponder)-tagged jackdaws, Corvus monedula, and extracts foraging events from it, which permits the construction of social networks. Our final example uses aerial images to train a classifier that detects the presence of wildebeest, Connochaetes taurinus, to count individuals in a population. With the advent of cheaper sensing and tracking technologies an unprecedented amount of data on animal behaviour is becoming available. We believe that ML will play a central role in translating these data into scientific knowledge and become a useful addition to the animal behaviourist's analytical toolkit."																				
2017	"Xie, Jie; Towsey, Michael; Zhang, Jinglan; Roe, Paul"	Acoustic classification of Australian frogs based on enhanced features and machine learning algorithms	Sound	DNN	Classification	Applied Acoustics	113		193-201	10.1016/j.apacoust.2016.06.029	https://www.sciencedirect.com/science/article/pii/S0003682X16301864	"Frogs are often considered as excellent indicators of the overall state of the natural environment, but a steady decrease in the frog population has been noticed worldwide. To monitor this change of frog population and optimise the protection policy, frog call classification has become an important bioacoustic research topic. However, automatic acoustic classification of frog calls has not been adequately addressed in the literature. In this paper, an enhanced feature representation for frog call classification using the temporal, perceptual and cepstral features is presented. With the enhanced feature representation, the time-frequency information of frog calls can be effectively represented, which gives a good classification performance. To be specific, each continuous frog recording is first segmented into individual syllables using the Ha¨rma¨’s method. Then, temporal, perceptual, and cepstral features are calculated from each syllable: syllable duration, Shannon entropy, Rényi entropy, zero-crossing rate, averaged energy, oscillation rate, spectral centroid, spectral flatness, spectral roll-off, signal bandwidth, spectral flux, fundamental frequency, linear predictive coding, and Mel-frequency cepstral coefficients. Next, different feature vectors are fused to obtain different enhanced feature representations. Finally, different enhanced feature representations are compared using five machine learning algorithms: linear discriminant analysis, K-nearest neighbour, support vector machines, random forest, and artificial neural network. Experiment results show that our proposed feature representation could achieve better classification performance comparing to other methods with twenty-four frog species, which are geographically well distributed throughout Queensland, Australia."																				
2017	"Zeng, Qingmao; Zhu, Tonglin; Zhuang, Xueying; Zheng, Mingxuan; Guo, Yubin"	Using the periodic wavelet descriptor of plant leaf to identify plant species	Other	DNN	Classification	Multimedia Tools and Applications	76	17	17873-17890	10.1007/s11042-015-3178-0	https://doi.org/10.1007/s11042-015-3178-0	"Plant species identification is one of the most important research branches of botanical science. In this paper, a novel shape descriptor, namely Periodic Wavelet Descriptor (PWD) of plant leaf, is firstly presented. Then based on the PWDs of the leaves of different plant species, we constructed a database of PWDs. At last, a Back Propagation Neural Network (BPNN) is trained to fulfill the experiment of plant species identification. The experimental results show that the proposed algorithm combined the PWD of plant leaf with BPNN is effective with a correct identification rate about 90 %."																				
2017	"Zhu, Le-Qing; Ma, Meng-Yuan; Zhang, Zhen; Zhang, Pei-Yi; Wu, Wei; Wang, Da-Dong; Zhang, Da-Xing; Wang, Xun; Wang, Hui-Yan"	Hybrid deep learning for automated lepidopteran insect image classification	Images	CNN	Classification	Oriental Insects	51	2	79-91	10.1080/00305316.2016.1252805	https://www.tandfonline.com/doi/full/10.1080/00305316.2016.1252805	"Lepidopterans play an important role in human economy, since some of them are harmful to vegetation in agriculture and some others produce useful materials such as silks, etc. To recognize lepidopteran species correctly is very meaningful to farmers, forest workers, or even insect researchers. This study proposed a cascade architecture which combines the methods of deep convolutional neural network (DCNNs) and Supported Vector Machines (SVMs) to identify Lepidoptera species from their images. The data-set used in this study consists of 1301 Lepidoptera images from 22 species. Since the data-set is not large enough to fine-tune an end-to-end DCNN, we propose a customized solution using part of the DCNN as feature extractor, followed by SVMs as the insect classifiers. The proposed cascade architecture can achieve an accuracy of 100% with our testing data-set and it takes only about 200 ms to recognize insect species from an image, which suggests that the proposed method can be potentially used as a real time classifier for the identification of the Lepidopterans."																				
2017	"Zieli_ski, Bartosz; Plichta, Anna; Misztal, Krzysztof; Spurek, Przemys_aw; Brzychczy-W_och, Monika; Ocho_ska, Dorota"	Deep learning approach to bacterial colony classification	Images	CNN	Classification	PLOS ONE	12	9	e0184554	10.1371/journal.pone.0184554	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184554	"In microbiology it is diagnostically useful to recognize various genera and species of bacteria. It can be achieved using computer-aided methods, which make the recognition processes more automatic and thus significantly reduce the time necessary for the classification. Moreover, in case of diagnostic uncertainty (the misleading similarity in shape or structure of bacterial cells), such methods can minimize the risk of incorrect recognition. In this article, we apply the state of the art method for texture analysis to classify genera and species of bacteria. This method uses deep Convolutional Neural Networks to obtain image descriptors, which are then encoded and classified with Support Vector Machine or Random Forest. To evaluate this approach and to make it comparable with other approaches, we provide a new dataset of images. DIBaS dataset (Digital Image of Bacterial Species) contains 660 images with 33 different genera and species of bacteria."																				
2017	"_iki_, Vladimir; Lazarevi_, Maja; Milo_evi_, Djuradj"	Host range patterning of parasitoid wasps Aphidiinae (Hymenoptera: Braconidae)	Environmental	DNN	Modeling	Zoologischer Anzeiger	268		75-83	10.1016/j.jcz.2016.10.001	https://www.sciencedirect.com/science/article/pii/S0044523116301024	"Aphidiinae are exclusive endoparasitoids of aphids and together with particular plant species form tritrophic complexes. Parasitoid wasps show different levels of host specificity, which is a very important fact since they have been used in biological control programs. We present a new approach to aphid parasitoid host specificity applied on 505 species from 38 genera, covering all valid species in the world fauna excluding synonyms. For this purpose, the artificial neural network visualization was performed to show the distribution and interconnections between and among members of five a posteriory selected groups of parasitoids. The results showed that about half of the analysed species (225) belong to the group of strict specialists, consisting of monophagous parasitoids that attack only one aphid species. The group of generalists assembled 58 species with mainly Palaearctic distribution. Between specialists and generalists are the oligophagous species which are clustered in three categories: narrow, moderate and broad oligophagous. Generally, host specificity in Aphidiinae is weakly connected with their phylogeny, suggesting that the parallel evolution of aphidiines must have occurred. Host specificity mainly depends on aphid hosts which follow host plant distribution."																				
2018	"Adinugroho, Sigit; Sari, Yuita Arum"	Leaves classification using neural network based on ensemble features	Images	DNN	Classification	2018 5th International Conference on Electrical and Electronic Engineering (ICEEE)			350-354	10.1109/ICEEE2.2018.8391360	https://ieeexplore.ieee.org/document/8391360/	"An automated plant identification is necessary to identify plants, especially rarely seen ones. In this paper a framework to identify plant species based on leaf's characteristics is introduced. First, 31 features of leaves from 13 species are extracted that represents color, shape and texture of the leaves. Then, the features are selected according to their correlation to the class label. The data with 25.8% pruned features are then used to train a feedforward neural network. The network is trained and tested using 975 images by implementing 10-fold mechanism yields 95.54% accuracy."																				
2018	"Al-Jubouri, Qussay; Al-Azawi, R. J.; Al-Taee, Majid; Young, Iain"	Efficient individual identification of zebrafish using Hue/Saturation/Value color model	Images	DNN	Classification	The Egyptian Journal of Aquatic Research	44	4	271-277	10.1016/j.ejar.2018.11.006	https://www.sciencedirect.com/science/article/pii/S1687428518300748	"Automated fish species recognition is widely investigated in research but it is not explored for the individuals with the same fish species. A new classifying method for zebrafish individuals that is based on statistical texture and Hue/Saturation/Value (HSV) color features are presented in this paper. Post image acquisition, pre-processing stages and features of sub-images are extracted, using statistical texture and HSV color space domain, and grouped into HSV and statistical sets of features. An artificial neural network (ANN) and K-Nearest Neighbors (KNN) are then used to identify the subjects under test. The impact of using statistical and HSV features on the prediction accuracy and average processing time is then assessed experimentally. An improved performance for the HSV over the statistical model is clearly demonstrated. The combination of HSV model and KNN classifier has also demonstrated a superior performance over the combination of HSV and ANN classifier in terms of the accuracy (KNN_=_99.0%; ANN_=_97.8%) and average processing time (KNN_=_4.1_ms; ANN_=_24.2_ms). Such promising findings encourage further testing of the HSV model towards developing a highly-efficient and fully-automated identification system for small species individual like zebrafish."																				
2018	"Alom, Md Zahangir; Taha, Tarek M.; Yakopcic, Christopher; Westberg, Stefan; Sidike, Paheding; Nasrin, Mst Shamima; Van Esesn, Brian C.; Awwal, Abdul A. S.; Asari, Vijayan K."	The history began from AlexNet: a comprehensive survey on deep learning approaches	NA	NA	Review	arXiv				10.48550/arXiv.1803.01164	http://arxiv.org/abs/1803.01164	"Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1]."																				
2018	"Asner, Gregory P.; Brodrick, Philip G.; Philipson, Christopher; Vaughn, Nicolas R.; Martin, Roberta E.; Knapp, David E.; Heckler, Joseph; Evans, Luke J.; Jucker, Tommaso; Goossens, Benoit; Stark, Danica J.; Reynolds, Glen; Ong, Robert; Renneboog, Nathan; Kugan, Fred; Coomes, David A."	Mapped aboveground carbon stocks to advance forest conservation and recovery in Malaysian Borneo	Other	DNN	Regression	Biological Conservation	217		289-310	10.1016/j.biocon.2017.10.020	https://linkinghub.elsevier.com/retrieve/pii/S0006320717310790	"Forest carbon stocks in rapidly developing tropical regions are highly heterogeneous, which challenges efforts to develop spatially-explicit conservation actions. In addition to field-based biodiversity information, mapping of carbon stocks can greatly accelerate the identification, protection and recovery of forests deemed to be of high conservation value (HCV). We combined airborne Light Detection and Ranging (LiDAR) with satellite imaging and other geospatial data to map forest aboveground carbon density at 30 m (0.09 ha) resolution throughout the Malaysian state of Sabah on the island of Borneo. We used the mapping results to assess how carbon stocks vary spatially based on forest use, deforestation, regrowth, and current forest protections. We found that unlogged, intact forests contain aboveground carbon densities averaging over 200 Mg C ha_1, with peaks of 500 Mg C ha_1. Critically, more than 40% of the highest carbon stock forests were discovered outside of areas designated for maximum protection. Previously logged forests have suppressed, but still high, carbon densities of 60–140 Mg C ha_1. Our mapped distributions of forest carbon stock suggest that the state of Sabah could double its total aboveground carbon storage if previously logged forests are allowed to recover in the future. Our results guide ongoing efforts to identify HCV forests and to determine new areas for forest protection in Borneo."																				
2018	"Baker, Ruth E.; Peña, Jose-Maria; Jayamohan, Jayaratnam; Jérusalem, Antoine"	"Mechanistic models versus machine learning, a fight worth fighting for the biological community?"	NA	NA	Review	Biology Letters	14	5	20170660	10.1098/rsbl.2017.0660	https://royalsocietypublishing.org/doi/10.1098/rsbl.2017.0660	"Ninety per cent of the world's data have been generated in the last 5 years ( Machine learning: the power and promise of computers that learn by example  . Report no. DES4702. Issued April 2017. Royal Society). A small fraction of these data is collected with the aim of validating specific hypotheses. These studies are led by the development of mechanistic models focused on the causality of input–output relationships. However, the vast majority is aimed at supporting statistical or correlation studies that bypass the need for causality and focus exclusively on prediction. Along these lines, there has been a vast increase in the use of machine learning models, in particular in the biomedical and clinical sciences, to try and keep pace with the rate of data generation. Recent successes now beg the question of whether mechanistic models are still relevant in this area. Said otherwise, why should we try to understand the mechanisms of disease progression when we can use machine learning tools to directly predict disease outcome?"																				
2018	"Barbedo, Jayme Garcia Arnal"	Impact of dataset size and variety on the effectiveness of deep learning and transfer learning for plant disease classification	Images	CNN	Classification	Computers and Electronics in Agriculture	153		46-53	10.1016/j.compag.2018.08.013	https://www.sciencedirect.com/science/article/pii/S0168169918304617	"The problem of automatic recognition of plant diseases has been historically based on conventional machine learning techniques such as Support Vector Machines, Multilayer Perceptron Neural Networks and Decision Trees. However, the prevailing approach has shifted to the application of deep learning concepts, with focus on Convolutional Neural Networks (CNNs). In general, this kind of technique requires large datasets containing a wide variety of conditions to work properly. This is an important limitation, given the many challenges involved in the construction of a suitable image database. In this context, this study investigates how the size and variety of the datasets impact the effectiveness of deep learning techniques applied to plant pathology. This investigation was based on an image database containing 12 plant species, each presenting very different characteristics in terms of number of samples, number of diseases and variety of conditions. Experimental results indicate that while the technical constraints linked to automatic plant disease classification have been largely overcome, the use of limited image datasets for training brings many undesirable consequences that still prevent the effective dissemination of this type of technology."																				
2018	"Boer, Marijn J. A.; Vos, Rutger A."	Taxonomic Classification of Ants (Formicidae) from Images using Deep Learning	Images	CNN	Classification	bioRxiv				10.1101/407452	http://biorxiv.org/lookup/doi/10.1101/407452	"The well-documented, species-rich, and diverse group of ants (Formicidae) are important ecological bioindicators for species richness, ecosystem health, and biodiversity, but ant species identification is complex and requires specific knowledge. In the past few years, insect identification from images has seen increasing interest and success, with processing speed improving and costs lowering. Here we propose deep learning (in the form of a convolutional neural network (CNN)) to classify ants at species level using AntWeb images. We used an Inception-ResNet-V2-based CNN to classify ant images, and three shot types with 10,204 images for 97 species, in addition to a multi-view approach, for training and testing the CNN while also testing a worker-only set and an AntWeb protocol-deviant test set. Top 1 accuracy reached 62% - 81%, top 3 accuracy 80% - 92%, and genus accuracy 79% - 95% on species classification for different shot type approaches. The head shot type outperformed other shot type approaches. Genus accuracy was broadly similar to top 3 accuracy. Removing reproductives from the test data improved accuracy only slightly. Accuracy on AntWeb protocol-deviant data was very low. In addition, we make recommendations for future work concerning image threshold, distribution, and quality, multi-view approaches, metadata, and on protocols; potentially leading to higher accuracy with less computational effort."																				
2018	"Botella, Christophe; Joly, Alexis; Bonnet, Pierre; Monestiez, Pascal; Munoz, François"	Species distribution modeling based on the automated identification of citizen observations	Images	CNN	Modeling	Applications in Plant Sciences	6	2	e1029	10.1002/aps3.1029	http://doi.wiley.com/10.1002/aps3.1029	"Premise of the Study: A species distribution model computed with automatically identified plant observations was developed and evaluated to contribute to future ecological studies. Methods: We used deep learning techniques to automatically identify opportunistic plant observations made by citizens through a popular mobile application. We compared species distribution modeling of invasive alien plants based on these data to inventories made by experts. Results: The trained models have a reasonable predictive effectiveness for some species, but they are biased by the massive presence of cultivated specimens. Discussion: The method proposed here allows for fine-grained and regular monitoring of some species of interest based on opportunistic observations. More in-depth investigation of the typology of the observations and the sampling bias should help improve the approach in the future.  "																				
2018	"Browning, Ella; Bolton, Mark; Owen, Ellie; Shoji, Akiko; Guilford, Tim; Freeman, Robin"	Predicting animal behaviour using deep learning: GPS data alone accurately predict diving in seabirds	Other	DNN	Classification	Methods in Ecology and Evolution	9	3	681-692	10.1111/2041-210X.12926	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12926	"To prevent further global declines in biodiversity, identifying and understanding key habitats is crucial for successful conservation strategies. For example, globally, seabird populations are under threat and animal movement data can identify key at-sea areas and provide valuable information on the state of marine ecosystems. To date, in order to locate these areas, studies have used global positioning system (GPS) to record position and are sometimes combined with time–depth recorder (TDR) devices to identify diving activity associated with foraging, a crucial aspect of at-sea behaviour. However, the use of additional devices such as TDRs can be expensive, logistically difficult and may adversely affect the animal. Alternatively, behaviours may be resolved from measurements derived from the movement data alone. However, this behavioural analysis frequently lacks validation data for locations predicted as foraging (or other behaviours). Here, we address these issues using a combined GPS and TDR dataset from 108 individuals by training deep learning models to predict diving in European shags, common guillemots and razorbills. We validate our predictions using withheld data, producing quantitative assessment of predictive accuracy. The variables used to train these models are those recorded solely by the GPS device: variation in longitude and latitude, altitude and coverage ratio (proportion of possible fixes acquired within a set window of time). Different combinations of these variables were used to explore the qualities of different models, with the optimum models for all species predicting non-diving and diving behaviour correctly over 94% and 80% of the time, respectively. We also demonstrate the superior predictive ability of these supervised deep learning models over other commonly used behavioural prediction methods such as hidden Markov models. Mapping these predictions provides useful insights into the foraging activity of a range of seabird species, highlighting important at sea locations. These models have the potential to be used to analyse historic GPS datasets and further our understanding of how environmental changes have affected these seabirds over time. "																				
2018	"Buda, Mateusz; Maki, Atsuto; Mazurowski, Maciej A."	A systematic study of the class imbalance problem in convolutional neural networks	NA	NA	Review	Neural Networks	106		249-259	10.1016/j.neunet.2018.07.011	https://www.sciencedirect.com/science/article/pii/S0893608018302107	"In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest."																				
2018	"Burbrink, Frank T; Gehara, Marcelo"	The Biogeography of Deep Time Phylogenetic Reticulation	Molecular	CNN	Classification	Systematic Biology	67	5	743-755	10.1093/sysbio/syy019	https://academic.oup.com/sysbio/article/67/5/743/4925328	"Most phylogenies are typically represented as purely bifurcating. However, as genomic data have become more common in phylogenetic studies, it is not unusual to find reticulation among terminal lineages or among internal nodes (deep time reticulation; DTR). In these situations, gene flow must have happened in the same or adjacent geographic areas for these DTRs to have occurred and therefore biogeographic reconstruction should provide similar area estimates for parental nodes, provided extinction or dispersal has not eroded these patterns. We examine the phylogeny of the widely distributed New World kingsnakes (Lampropeltis), determine if DTR is present in this group, and estimate the ancestral area for reticulation. Importantly, we develop a new method that uses coalescent simulations in a machine learning framework to show conclusively that this phylogeny is best represented as reticulating at deeper time. Using joint probabilities of ancestral area reconstructions on the bifurcating parental lineages from the reticulating node, we show that this reticulation likely occurred in northwestern Mexico/southwestern US, and subsequently, led to the diversification of the Mexican kingsnakes. This region has been previously identified as an area important for understanding speciation and secondary contact with gene flow in snakes and other squamates. This research shows that phylogenetic reticulation is common, even in well-studied groups, and that the geographic scope of ancient hybridization is recoverable."																				
2018	"Carpentier, Mathieu; Giguère, Philippe; Gaudreault, Jonathan"	Tree Species Identification from Bark Images Using Convolutional Neural Networks	Images	CNN	Classification	arXiv:1803.00949 [cs]				10.48550/arXiv.1803.00949	http://arxiv.org/abs/1803.00949	"Tree species identification using bark images is a challenging problem that could prove useful for many forestry related tasks. However, while the recent progress in deep learning showed impressive results on standard vision problems, a lack of datasets prevented its use on tree bark species classification. In this work, we present, and make publicly available, a novel dataset called BarkNet 1.0 containing more than 23,000 high-resolution bark images from 23 different tree species over a wide range of tree diameters. With it, we demonstrate the feasibility of species recognition through bark images, using deep learning. More specifically, we obtain an accuracy of 93.88% on single crop, and an accuracy of 97.81% using a majority voting approach on all of the images of a tree. We also empirically demonstrate that, for a fixed number of images, it is better to maximize the number of tree individuals in the training database, thus directing future data collection efforts."																				
2018	"Chan, Jeffrey; Perrone, Valerio; Spence, Jeffrey P.; Jenkins, Paul A.; Mathieson, Sara; Song, Yun S."	A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks	Molecular	CNN	Regression	"arXiv:1802.06153 [cs, q-bio, stat]"				10.48550/arXiv.1802.06153	http://arxiv.org/abs/1802.06153	"An explosion of high-throughput DNA sequencing in the past decade has led to a surge of interest in population-scale inference with whole-genome data. Recent work in population genetics has centered on designing inference methods for relatively simple model classes, and few scalable general-purpose inference techniques exist for more realistic, complex models. To achieve this, two inferential challenges need to be addressed: (1) population data are exchangeable, calling for methods that efficiently exploit the symmetries of the data, and (2) computing likelihoods is intractable as it requires integrating over a set of correlated, extremely high-dimensional latent variables. These challenges are traditionally tackled by likelihood-free methods that use scientific simulators to generate datasets and reduce them to hand-designed, permutation-invariant summary statistics, often leading to inaccurate inference. In this work, we develop an exchangeable neural network that performs summary statistic-free, likelihood-free inference. Our framework can be applied in a black-box fashion across a variety of simulation-based tasks, both within and outside biology. We demonstrate the power of our approach on the recombination hotspot testing problem, outperforming the state-of-the-art."																				
2018	"Chen, Jian; Fan, Yangyang; Wang, Tao; Zhang, Chu; Qiu, Zhengjun; He, Yong"	Automatic Segmentation and Counting of Aphid Nymphs on Leaves Using Convolutional Neural Networks	Images	CNN	Classification	Agronomy	8	8	129	10.3390/agronomy8080129	https://www.mdpi.com/2073-4395/8/8/129	"The presence of pests is one of the main problems in crop production, and obtaining reliable statistics of pest infestation is essential for pest management. Detection of pests should be automated because human monitoring of pests is time-consuming and error-prone. Aphids are among the most destructive pests in greenhouses and they reproduce quickly. Automatic detection of aphid nymphs on leaves (especially on the lower surface) using image analysis is a challenging problem due to color similarity and complicated background. In this study, we propose a method for segmentation and counting of aphid nymphs on leaves using convolutional neural networks. Digital images of pakchoi leaves at different aphid infestation stages were obtained, and corresponding pixel-level binary mask annotated. In the test, segmentation results by the proposed method achieved high overlap with annotation by human experts (Dice coefficient of 0.8207). Automatic counting based on segmentation showed high precision (0.9563) and recall (0.9650). The correlation between aphid nymph count by the proposed method and manual counting was high (R2 = 0.99). The proposed method is generic and can be applied for other species of pests."																				
2018	"Collin, Antoine; Ramambason, Camille; Pastol, Yves; Casella, Elisa; Rovere, Alessio; Thiault, Lauric; Espiau, Benoît; Siu, Gilles; Lerouvreur, Franck; Nakamura, Nao; Hench, James L.; Schmitt, Russell J.; Holbrook, Sally J.; Troyer, Matthias; Davies, Neil"	Very high resolution mapping of coral reef state using airborne bathymetric LiDAR surface-intensity and drone imagery	Other	DNN	Classification	International Journal of Remote Sensing	39	17	5676-5688	10.1080/01431161.2018.1500072	https://doi.org/10.1080/01431161.2018.1500072	"Very high resolution (VHR) airborne data enable detection and physical measurements of individual coral reef colonies. The bathymetric LiDAR system, as an active remote sensing technique, accurately computes the coral reef ecosystem’s surface and reflectance using a single green wavelength at the decimetre scale over 1-to-100 km2 areas. A passive multispectral camera mounted on an airborne drone can build a blue-green-red (BGR) orthorectified mosaic at the centimetre scale over 0.01-to-0.1 km2 areas. A combination of these technologies is used for the first time here to map coral reef ecological state at the submeter scale. Airborne drone BGR values (0.03 m pixel size) serve to calibrate airborne bathymetric LiDAR surface and intensity data (0.5 m pixel size). A classification of five ecological states is then mapped through an artificial neural network (ANN). The classification was developed over a small area (0.01 km2) in the lagoon of Moorea Island (French Polynesia) at VHR (0.5 m pixel size) and then extended to the whole lagoon (46.83 km2). The ANN was first calibrated with 275 samples to determine the class of coral state through LiDAR-based predictors; then, the classification was validated through 135 samples, reaching a satisfactory performance (overall accuracy = 0.75)."																				
2018	"Di Minin, Enrico; Fink, Christoph; Tenkanen, Henrikki; Hiippala, Tuomo"	Machine learning for tracking illegal wildlife trade on social media	Images	CNN	Classification	Nature Ecology & Evolution	2	3	406-407	10.1038/s41559-018-0466-x	http://www.nature.com/articles/s41559-018-0466-x	NA																				
2018	"Dwivedi, Ashok Kumar; Chouhan, Usha"	Comparative study of artificial neural network for classification of hot and cold recombination regions in Saccharomyces cerevisiae	Molecular	Unknown	Classification	Neural Computing and Applications	29	2	529-535	10.1007/s00521-016-2466-6	https://link.springer.com/article/10.1007/s00521-016-2466-6	"At the chromosomal level of evolution, recombination is a major factor for genetic variations. However, recombination does not occur with equal frequency at various regions of genome. The recombination has the tendency to occur at specific region with higher frequency and with low frequency at other regions, and former regions are named as hot recombination regions whereas later are called cold regions for recombination. In this paper, we have developed supervised machine learning-based models using artificial neural network, support vector machine and Naïve Bayes for efficient and effective classification of such hot and cold recombination regions based on the nucleotide composition of sequences. All models were validated and tested using tenfold cross-validation. Furthermore, neural network model was validated using leave one out and random sampling techniques in addition to tenfold cross-validation. Moreover, models were evaluated using receiver-operating curve. Our results indicate that artificial neural network achieves the best result."																				
2018	"Escobar-Flores, Jonathan G.; Lopez-Sanchez, Carlos A.; Sandoval, Sarahi; Marquez-Linares, Marco A.; Wehenkel, Christian"	Predicting Pinus monophylla forest cover in the Baja California Desert by remote sensing	"Environmental, Other"	DNN	Classification	PeerJ	6		e4603	10.7717/peerj.4603	https://peerj.com/articles/4603	"The Californian single-leaf pinyon (Pinus monophylla var. californiarum), a subspecies of the single-leaf pinyon (the world’s only one-needled pine), inhabits semi-arid zones of the Mojave Desert (southern Nevada and southeastern California, US) and also of northern Baja California (Mexico). This tree is distributed as a relict subspecies, at elevations of between 1,010 and 1,631 m in the geographically isolated arid Sierra La Asamblea, an area characterized by mean annual precipitation levels of between 184 and 288 mm. The aim of this research was (i) to estimate the distribution of P. monophylla var. californiarum in Sierra La Asamblea by using Sentinel-2 images, and (ii) to test and describe the relationship between the distribution of P. monophylla and five topographic and 18 climate variables. We hypothesized that (i) Sentinel-2 images can be used to predict the P. monophylla distribution in the study site due to the finer resolution (_3) and greater number of bands (_2) relative to Landsat-8 data, which is publically available free of charge and has been demonstrated to be useful for estimating forest cover, and (ii) the topographical variables aspect, ruggedness and slope are particularly important because they represent important microhabitat factors that can determine the sites where conifers can become established and persist. An atmospherically corrected a 12-bit Sentinel-2A MSI image with 10 spectral bands in the visible, near infrared, and short-wave infrared light region was used in combination with the normalized differential vegetation index (NDVI). Supervised classification of this image was carried out using a backpropagation-type artificial neural network algorithm. Stepwise multiple linear binominal logistical regression and Random Forest classification including cross validation were used to model the associations between presence/absence of P. monophylla and the five topographical and 18 climate variables. Using supervised classification of Sentinel-2 satellite images, we estimated that P. monophylla covers 6,653 ± 319 ha in the isolated Sierra La Asamblea. The NDVI was one of the variables that contributed most to the prediction and clearly separated the forest cover (NDVI > 0.35) from the other vegetation cover (NDVI < 0.20). Ruggedness was the most influential environmental predictor variable, indicating that the probability of occurrence of P. monophylla was greater than 50% when the degree of ruggedness terrain ruggedness index was greater than 17.5 m. The probability of occurrence of the species decreased when the mean temperature in the warmest month increased from 23.5 to 25.2 °C. Ruggedness is known to create microclimates and provides shade that minimizes evapotranspiration from pines in desert environments. Identification of the P. monophylla stands in Sierra La Asamblea as the most southern populations represents an opportunity for research on climatic tolerance and community responses to climate variability and change."																				
2018	"Fanioudakis, Eleftherios; Geismar, Matthias; Potamitis, Ilyas"	Mosquito wingbeat analysis and classification using deep learning	Sound	DNN	Classification	2018 26th European Signal Processing Conference (EUSIPCO)			2410-2414	10.23919/EUSIPCO.2018.8553542	https://ieeexplore.ieee.org/document/8553542/	"We examine the signal and the attributes of mosquitoes' wingbeat. Subsequently we carryon large-scale classification experiments based on optical recordings of mosquitoes' wingbeat of the following species: Aedesaegypti, Aedes albopictus, Anopheles arabiensis, Anopheles gambiae, Culex pipiens, Culex quinquefasciatus. We report 96% classification accuracy on the species level for a database of 279,566 flight recording cases using top-tier deep learning techniques. The database and the associated code are offered open. The longstanding goal is to run prediction models, perform risk assessments, issue warnings and make historical analysis based on wingbeats acquired through suction traps deployed in the field."																				
2018	"Figueroa-Mata, Geovanni; Mata-Montero, Erick; Valverde-Otarola, Juan Carlos; Arias-Aguilar, Dagoberto"	Using Deep Convolutional Networks for Species Identification of Xylotheque Samples	Images	CNN	Classification	2018 IEEE International Work Conference on Bioinspired Intelligence (IWOBI)			9-Jan	10.1109/IWOBI.2018.8464216	https://ieeexplore.ieee.org/document/8464216/	"Forest species identification is critical to scientifically support many environmental, commercial, forensic, archaeological, and paleontological actividades. Therefore, it is very important to develop fast and accurate identification systems. We present a deep CNN for automated forest species identification based on macroscopic images of wood cuts. We first implement and study a modified version of the LeNet convolutional network, which is trained from scratch with a database of macroscopic images of 41 forest species of the Brazilian flora. With this network we achieve a top-1 accuracy of 93.6%. Additionally, we fine-tune the Resnet50 model with pre-trained weights on Imagenet to reach a top-1 accuracy of 98.03%, which improves previous published results of research on the same image database."																				
2018	"Fuentes, Alvaro F.; Yoon, Sook; Lee, Jaesu; Park, Dong Sun"	High-Performance Deep Neural Network-Based Tomato Plant Diseases and Pests Diagnosis System With Refinement Filter Bank	Images	CNN	Classification	Frontiers in Plant Science	9		1162	10.3389/fpls.2018.01162	https://www.frontiersin.org/article/10.3389/fpls.2018.01162/full	"A fundamental problem that confronts deep neural networks is the requirement of a large amount of data for a system to be efficient in complex applications. Promising results of this problem are made possible through the use of techniques such as data augmentation or transfer learning of pre-trained models in large datasets. But the problem still persists when the application provides limited or unbalanced data. In addition, the number of false positives resulting from training a deep model significantly cause a negative impact on the performance of the system. This study aims to address the problem of false positives and class unbalance by implementing a Refinement Filter Bank framework for Tomato Plant Diseases and Pests Recognition. The system consists of three main units: First, a Primary Diagnosis Unit (Bounding Box Generator) generates the bounding boxes that contain the location of the infected area and class. The promising boxes belonging to each class are then used as input to a Secondary Diagnosis Unit (CNN Filter Bank) for verification. In this second unit, misclassified samples are filtered through the training of independent CNN classifiers for each class. The result of the CNN Filter Bank is a decision of whether a target belongs to the category as it was detected (True) or not (False) otherwise. Finally, an integration unit combines the information from the primary and secondary units while keeping the True Positive samples and eliminating the False Positives that were misclassified in the first unit. By this implementation, the proposed approach is able to obtain a recognition rate of approximately 96%, which represents an improvement of 13% compared to our previous work in the complex task of tomato diseases and pest recognition. Furthermore, our system is able to deal with the false positives generated by the bounding box generator, and class unbalances that appear especially on datasets with limited data."																				
2018	"Ghosal, Sambuddha; Blystone, David; Singh, Asheesh K.; Ganapathysubramanian, Baskar; Singh, Arti; Sarkar, Soumik"	An explainable deep machine vision framework for plant stress phenotyping	Images	CNN	"Classification, Regression"	Proceedings of the National Academy of Sciences	115	18	4613-4618	10.1073/pnas.1716999115	https://www.pnas.org/doi/10.1073/pnas.1716999115	"Significance  Plant stress identification based on visual symptoms has predominately remained a manual exercise performed by trained pathologists, primarily due to the occurrence of confounding symptoms. However, the manual rating process is tedious, is time-consuming, and suffers from inter- and intrarater variabilities. Our work resolves such issues via the concept of explainable deep machine learning to automate the process of plant stress identification, classification, and quantification. We construct a very accurate model that can not only deliver trained pathologist-level performance but can also explain which visual symptoms are used to make predictions. We demonstrate that our method is applicable to a large variety of biotic and abiotic stresses and is transferable to other imaging conditions and plants."																				
2018	"Hay, Edouard A.; Parthasarathy, Raghuveer"	Performance of convolutional neural networks for identification of bacteria in 3D microscopy datasets	Images	CNN	Classification	PLOS Computational Biology	14	12	e1006628	10.1371/journal.pcbi.1006628	https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006628	"Three-dimensional microscopy is increasingly prevalent in biology due to the development of techniques such as multiphoton, spinning disk confocal, and light sheet fluorescence microscopies. These methods enable unprecedented studies of life at the microscale, but bring with them larger and more complex datasets. New image processing techniques are therefore called for to analyze the resulting images in an accurate and efficient manner. Convolutional neural networks are becoming the standard for classification of objects within images due to their accuracy and generalizability compared to traditional techniques. Their application to data derived from 3D imaging, however, is relatively new and has mostly been in areas of magnetic resonance imaging and computer tomography. It remains unclear, for images of discrete cells in variable backgrounds as are commonly encountered in fluorescence microscopy, whether convolutional neural networks provide sufficient performance to warrant their adoption, especially given the challenges of human comprehension of their classification criteria and their requirements of large training datasets. We therefore applied a 3D convolutional neural network to distinguish bacteria and non-bacterial objects in 3D light sheet fluorescence microscopy images of larval zebrafish intestines. We find that the neural network is as accurate as human experts, outperforms random forest and support vector machine classifiers, and generalizes well to a different bacterial species through the use of transfer learning. We also discuss network design considerations, and describe the dependence of accuracy on dataset size and data augmentation. We provide source code, labeled data, and descriptions of our analysis pipeline to facilitate adoption of convolutional neural network analysis for three-dimensional microscopy data."																				
2018	"Huang, Lei; Wu, Tong"	Novel neural network application for bacterial colony classification	Images	CNN	Classification	Theoretical Biology and Medical Modelling	15	1	22	10.1186/s12976-018-0093-x	https://doi.org/10.1186/s12976-018-0093-x	"Bacterial colony morphology is the first step of classifying the bacterial species before sending them to subsequent identification process with devices, such as VITEK 2 automated system and mass spectrometry microbial identification system. It is essential as a pre-screening process because it can greatly reduce the scope of possible bacterial species and will make the subsequent identification more specific and increase work efficiency in clinical bacteriology. But this work needs adequate clinical laboratory expertise of bacterial colony morphology, which is especially difficult for beginners to handle properly. This study presents automatic programs for bacterial colony classification task, by applying the deep convolutional neural networks (CNN), which has a widespread use of digital imaging data analysis in hospitals. The most common 18 bacterial colony classes from Peking University First Hospital were used to train this framework, and other images out of these training dataset were utilized to test the performance of this classifier."																				
2018	"Ibrahim, Ali K.; Zhuang, Hanqi; Chérubin, Laurent M.; Schärer-Umpierre, Michelle T.; Erdol, Nurgun"	Automatic classification of grouper species by their sounds using deep neural networks	Sound	"CNN, RNN"	Classification	The Journal of the Acoustical Society of America	144	3	EL196-EL202	10.1121/1.5054911	https://asa.scitation.org/doi/10.1121/1.5054911	"In this paper, the effectiveness of deep learning for automatic classification of grouper species by their vocalizations has been investigated. In the proposed approach, wavelet denoising is used to reduce ambient ocean noise, and a deep neural network is then used to classify sounds generated by different species of groupers. Experimental results for four species of groupers show that the proposed approach achieves a classification accuracy of around 90% or above in all of the tested cases, a result that is significantly better than the one obtained by a previously reported method for automatic classification of grouper calls."																				
2018	"Javer, Avelino; Brown, Andre E X; Kokkinos, Iasonas"	Identification of C. elegans strains using a fully convolutional neural network on behavioural dynamics	Video	CNN	Classification	Computer Vision – ECCV 2018 Workshops	11134		455-464	10.1007/978-3-030-11024-6_35	https://link.springer.com/chapter/10.1007/978-3-030-11024-6_35	"The nematode C. elegans is a promising model organism to understand the genetic basis of behaviour due to its anatomical simplicity. In this work, we present a deep learning model capable of discerning genetically diverse strains based only on their recorded spontaneous activity, and explore how its performance changes as different embeddings are used as input. The model outperforms hand-crafted features on strain classification when trained directly on time series of worm postures."																				
2018	"Kalafi, E Yousef; Town, C; Dhillon, S Kaur"	How automated image analysis techniques help scientists in species identification and classification?	NA	NA	Review	Folia Morphologica	77	2	15	10.5603/FM.a2017.0079	https://journals.viamedica.pl/folia_morphologica/article/view/54300	"Identification of taxonomy at a specific level is time consuming and reliant upon expert ecologists. Hence the demand for automated species identification incre_ased over the last two decades. Automation of data classification is primarily focussed on images while incorporating and analysing image data has recently become easier due to developments in computational technology. Research ef_forts on identification of species include specimens’ image processing, extraction of identical features, followed by classifying them into correct categories. In this paper, we discuss recent automated species identification systems, mainly for categorising and evaluating their methods. We reviewed and compared different methods in step by step scheme of automated identification and classification systems of species images. The selection of methods is influenced by many variables such as level of classification, number of training data and complexity of images. The aim of writing this paper is to provide researchers and scientists an extensive background study on work related to automated species identification, focusing on pattern recognition techniques in building such systems for biodiversity studies. (Folia Morphol 2018; 77, 2: 179–193)"																				
2018	"Kamilaris, Andreas; Prenafeta-Boldú, Francesc X."	Deep learning in agriculture: A survey	NA	NA	Review	Computers and Electronics in Agriculture	147		70-90	10.1016/j.compag.2018.02.016	https://linkinghub.elsevier.com/retrieve/pii/S0168169917308803	"Deep learning constitutes a recent, modern technique for image processing and data analysis, with promising results and large potential. As deep learning has been successfully applied in various domains, it has recently entered also the domain of agriculture. In this paper, we perform a survey of 40 research efforts that employ deep learning techniques, applied to various agricultural and food production challenges. We examine the particular agricultural problems under study, the specific models and frameworks employed, the sources, nature and pre-processing of data used, and the overall performance achieved according to the metrics used at each work under study. Moreover, we study comparisons of deep learning with other existing popular techniques, in respect to differences in classification or regression performance. Our findings indicate that deep learning provides high accuracy, outperforming existing commonly used image processing techniques."																				
2018	"Keçeli, Ali Seydi; Kaya, Aydın; Keçeli, Seda Uzunçimen"	Classification of radiolarian images with hand-crafted and deep features	Images	CNN	Classification	Computers & Geosciences	109		67-74	10.1016/j.cageo.2017.08.011	https://www.sciencedirect.com/science/article/pii/S0098300417302133	"Radiolarians are planktonic protozoa and are important biostratigraphic and paleoenvironmental indicators for paleogeographic reconstructions. Radiolarian paleontology still remains as a low cost and the one of the most convenient way to obtain dating of deep ocean sediments. Traditional methods for identifying radiolarians are time-consuming and cannot scale to the granularity or scope necessary for large-scale studies. Automated image classification will allow making these analyses promptly. In this study, a method for automatic radiolarian image classification is proposed on Scanning Electron Microscope (SEM) images of radiolarians to ease species identification of fossilized radiolarians. The proposed method uses both hand-crafted features like invariant moments, wavelet moments, Gabor features, basic morphological features and deep features obtained from a pre-trained Convolutional Neural Network (CNN). Feature selection is applied over deep features to reduce high dimensionality. Classification outcomes are analyzed to compare hand-crafted features, deep features, and their combinations. Results show that the deep features obtained from a pre-trained CNN are more discriminative comparing to hand-crafted ones. Additionally, feature selection utilizes to the computational cost of classification algorithms and have no negative effect on classification accuracy."																				
2018	"Kern, Andrew D; Schrider, Daniel R"	diploS/HIC: An Updated Approach to Classifying Selective Sweeps	Molecular	CNN	Classification	G3 Genes|Genomes|Genetics	8	6	1959-1970	10.1534/g3.118.200262	https://www.g3journal.org/content/8/6/1959	"Identifying selective sweeps in populations that have complex demographic histories remains a difficult problem in population genetics. We previously introduced a supervised machine learning approach, S\/HIC, for finding both hard and soft selective sweeps in genomes on the basis of patterns of genetic variation surrounding a window of the genome. While S\/HIC was shown to be both powerful and precise, the utility of S\/HIC was limited by the use of phased genomic data as input. In this report we describe a deep learning variant of our method, diploS\/HIC, that uses unphased genotypes to accurately classify genomic windows. diploS\/HIC is shown to be quite powerful even at moderate to small sample sizes."																				
2018	"Körschens, Matthias; Barz, Björn; Denzler, Joachim"	Towards Automatic Identification of Elephants in the Wild	Images	CNN	Classification	arXiv:1812.04418 [cs]				10.48550/arXiv.1812.04418	http://arxiv.org/abs/1812.04418	"Identifying animals from a large group of possible individuals is very important for biodiversity monitoring and especially for collecting data on a small number of particularly interesting individuals, as these have to be identified first before this can be done. Identifying them can be a very time-consuming task. This is especially true, if the animals look very similar and have only a small number of distinctive features, like elephants do. In most cases the animals stay at one place only for a short period of time during which the animal needs to be identified for knowing whether it is important to collect new data on it. For this reason, a system supporting the researchers in identifying elephants to speed up this process would be of great benefit. In this paper, we present such a system for identifying elephants in the face of a large number of individuals with only few training images per individual. For that purpose, we combine object part localization, off-the-shelf CNN features, and support vector machine classification to provide field researches with proposals of possible individuals given new images of an elephant. The performance of our system is demonstrated on a dataset comprising a total of 2078 images of 276 individual elephants, where we achieve 56% top-1 test accuracy and 80% top-10 accuracy. To deal with occlusion, varying viewpoints, and different poses present in the dataset, we furthermore enable the analysts to provide the system with multiple images of the same elephant to be identified and aggregate confidence values generated by the classifier. With that, our system achieves a top-1 accuracy of 74% and a top-10 accuracy of 88% on the held-out test dataset."																				
2018	"Krause, Jonas; Sugita, Gavin; Baek, Kyungim; Lim, Lipyeow"	WTPlant (What's That Plant?): A Deep Learning System for Identifying Plants in Natural Images	Images	CNN	Classification	Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval			517-520	10.1145/3206025.3206089	https://dl.acm.org/doi/10.1145/3206025.3206089	"Despite the availability of dozens of plant identification mobile applications, identifying plants from a natural image remains a challenging problem - most of the existing applications do not address the complexity of natural images, the large number of plant species, and the multi-scale nature of natural images. In this technical demonstration, we present the WTPlant system for identifying plants in natural images. WTPlant is based on deep learning approaches. Specifically, it uses stacked Convolutional Neural Networks for image segmentation, a novel preprocessing stage for multi-scale analyses, and deep convolutional networks to extract the most discriminative features. WTPlant employs different classification architectures for plants and flowers, thus enabling plant identification throughout all the seasons. The user interface also shows, in an interactive way, the most representative areas in the image that are used to predict each plant species. The first version of WTPlant is trained to classify 100 different plant species present in the campus of the University of Hawai'i at Manoa. First experiments support the hypothesis that an initial segmentation process helps guide the extraction of representative samples and, consequently, enables Convolutional Neural Networks to better recognize objects of different scales in natural images. Future versions aim to extend the recognizable species to cover the land-based flora of the Hawaiian Islands."																				
2018	"Kress, W John; Garcia-Robledo, Carlos; Soares, João V B; Jacobs, David; Wilson, Katharine; Lopez, Ida C; Belhumeur, Peter N"	Citizen Science and Climate Change: Mapping the Range Expansions of Native and Exotic Plants with the Mobile App Leafsnap	NA	NA	Other	BioScience	68	5	348-358	10.1093/biosci/biy019	https://doi.org/10.1093/biosci/biy019	"The mobile iPhone app Leafsnap, designed for the automatic identification of 220 tree species from the northeastern United States, was released to the public in 2011. In the first 3 years of its use, the app was downloaded by more than 1,500,000 users from five continents and 181 countries who recorded over 3,056,684 leaf images. The high levels of accuracy of Leafsnap identifications, as were confirmed by expert botanists, were used to map the geographic distribution of native and exotic species at a scale previously unachievable without this technology and without the aid of citizen scientists. Species demonstrated northerly migrations, southerly migrations, or little change from their estimated distributions in the 1950s. These results suggest that this tool carried on the phones of millions may potentially collect invaluable data that can be used to monitor the effects of climate change and exotic species on tree distributions at broad geographic scales."																				
2018	"Kroodsma, David A.; Mayorga, Juan; Hochberg, Timothy; Miller, Nathan A.; Boerder, Kristina; Ferretti, Francesco; Wilson, Alex; Bergman, Bjorn; White, Timothy D.; Block, Barbara A.; Woods, Paul; Sullivan, Brian; Costello, Christopher; Worm, Boris"	Tracking the global footprint of fisheries	Other	CNN	Classification	Science	359	6378	904-908	10.1126/science.aao5646	https://www.sciencemag.org/lookup/doi/10.1126/science.aao5646	"More than half the fish in the sea   As the human population has grown in recent decades, our dependence on ocean-supplied protein has rapidly increased. Kroodsma et al.  took advantage of the automatic identification system installed on all industrial fishing vessels to map and quantify fishing efforts across the world (see the Perspective by Poloczanska). More than half of the world's oceans are subject to industrial-scale harvest, spanning an area four times that covered by terrestrial agriculture. Furthermore, fishing efforts seem not to depend on economic or environmental drivers, but rather social and political schedules. Thus, more active measures will likely be needed to ensure sustainable use of ocean resources.   Science  , this issue p. 904  ; see also p. 864"																				
2018	"Laan, Andres; Iglesias-Julios, Marta; de Polavieja, Gonzalo G."	Zebrafish aggression on the sub-second time scale: evidence for mutual motor coordination and multi-functional attack manoeuvres	Video	CNN	Classification	Royal Society Open Science	5	8	180679	10.1098/rsos.180679	https://royalsocietypublishing.org/doi/10.1098/rsos.180679	"Most animals fight by repeating complex stereotypic behaviours, yet the internal structure of these behaviours has rarely been dissected in detail. We characterized the internal structure of fighting behaviours by developing a machine learning pipeline that measures and classifies the behaviour of individual unmarked animals on a sub-second time scale. This allowed us to quantify several previously hidden features of zebrafish fighting strategies. We found strong correlations between the velocity of the attacker and the defender, indicating a dynamic matching of approach and avoidance efforts. While velocity matching was ubiquitous, the spatial dynamics of attacks showed phase-specific differences. Contest-phase attacks were characterized by a paradoxical sideways attraction of the retreating animal towards the attacker, suggesting that the defender combines avoidance manoeuvres with display-like manoeuvres. Post-resolution attacks lacked display-like features and the defender was avoidance focused. From the perspective of the winner, game-theory modelling further suggested that highly energetically costly post-resolution attacks occurred because the winner was trying to increase its relative dominance over the loser. Overall, the rich structure of zebrafish motor coordination during fighting indicates a greater complexity and layering of strategies than has previously been recognized."																				
2018	"Labuguen (P), Rollyn; Gaurav, Vishal; Blanco, Salvador Negrete; Matsumoto, Jumpei; Inoue, Kenichi; Shibata, Tomohiro"	Monkey Features Location Identification Using Convolutional Neural Networks	Images	CNN	Classification	bioRxiv				10.1101/377895	http://biorxiv.org/lookup/doi/10.1101/377895	"Understanding animal behavior in its natural habitat is a challenging task. One of the primary step for analyzing animal behavior is feature detection. In this study, we propose the use of deep convolutional neural network (CNN) to locate monkey features from raw RGB images of monkey in its natural environment. We train the model to identify features such as the nose and shoulders of the monkey at about 0.01 model loss."																				
2018	"Lim, Suchang; Kim, Seunghyun; Park, Sungwook; Kim, Doyeon"	Development of Application for Forest Insect Classification using CNN	Images	CNN	Classification	"2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)"			1128-1131	10.1109/ICARCV.2018.8581103	https://ieeexplore.ieee.org/document/8581103/	"Insect identification has the disadvantage that it is difficult for non-experts to carry out due to the specificity of insects. Therefore, it is necessary for the general user to use auxiliary tools such as books to identify insects for education such as ecological learning. In recent years, researches using Deep Learning in fields such as object detection, behavior recognition, voice recognition as well as cancer detection in medical field have been actively conducted and show excellent results. In this paper, we developed a classification application that can be used in mobile phones with high automation and portability to solve the above insect classification problems. Experiments were conducted on 30 insect species selected for observable insects irrespective of environmental factors such as habitat and season, and the transform learning were applied to ResNet, which showed excellent performance in ILSVRC to classify forest insect. Our system achieved an average insect classification accuracy of 94%, an insect classification speed of 0.03 sec, and an insect photo transmission of 0.5 sec to output this information. This has proven that non-experts provide the appropriate performance to use."																				
2018	"Ma, Jianzhu; Yu, Michael Ku; Fong, Samson; Ono, Keiichiro; Sage, Eric; Demchak, Barry; Sharan, Roded; Ideker, Trey"	Using deep learning to model the hierarchical structure and function of a cell	Molecular	Other	Modeling	Nature Methods	15	4	290-298	10.1038/nmeth.4627	http://www.nature.com/articles/nmeth.4627	"Insect identification has the disadvantage that it is difficult for non-experts to carry out due to the specificity of insects. Therefore, it is necessary for the general user to use auxiliary tools such as books to identify insects for education such as ecological learning. In recent years, researches using Deep Learning in fields such as object detection, behavior recognition, voice recognition as well as cancer detection in medical field have been actively conducted and show excellent results. In this paper, we developed a classification application that can be used in mobile phones with high automation and portability to solve the above insect classification problems. Experiments were conducted on 30 insect species selected for observable insects irrespective of environmental factors such as habitat and season, and the transform learning were applied to ResNet, which showed excellent performance in ILSVRC to classify forest insect. Our system achieved an average insect classification accuracy of 94%, an insect classification speed of 0.03 sec, and an insect photo transmission of 0.5 sec to output this information. This has proven that non-experts provide the appropriate performance to use."																				
2018	"Mac Aodha, Oisin; Gibb, Rory; Barlow, Kate E.; Browning, Ella; Firman, Michael; Freeman, Robin; Harder, Briana; Kinsey, Libby; Mead, Gary R.; Newson, Stuart E.; Pandourski, Ivan; Parsons, Stuart; Russ, Jon; Szodoray-Paradi, Abigel; Szodoray-Paradi, Farkas; Tilova, Elena; Girolami, Mark; Brostow, Gabriel; Jones, Kate E."	Bat detective—Deep learning tools for bat acoustic signal detection	Sound	CNN	Classification	PLOS Computational Biology	14	3	e1005995	10.1371/journal.pcbi.1005995	https://dx.plos.org/10.1371/journal.pcbi.1005995	"Passive acoustic sensing has emerged as a powerful tool for quantifying anthropogenic impacts on biodiversity, especially for echolocating bat species. To better assess bat population trends there is a critical need for accurate, reliable, and open source tools that allow the detection and classification of bat calls in large collections of audio recordings. The majority of existing tools are commercial or have focused on the species classification task, neglecting the important problem of first localizing echolocation calls in audio which is particularly problematic in noisy recordings. We developed a convolutional neural network based open-source pipeline for detecting ultrasonic, full-spectrum, search-phase calls produced by echolocating bats. Our deep learning algorithms were trained on full-spectrum ultrasonic audio collected along road-transects across Europe and labelled by citizen scientists from www.batdetective.org. When compared to other existing algorithms and commercial systems, we show significantly higher detection performance of search-phase echolocation calls with our test sets. As an example application, we ran our detection pipeline on bat monitoring data collected over five years from Jersey (UK), and compared results to a widely-used commercial system. Our detection pipeline can be used for the automatic detection and monitoring of bat populations, and further facilitates their use as indicator species on a large scale. Our proposed pipeline makes only a small number of bat specific design decisions, and with appropriate training data it could be applied to detecting other species in audio. A crucial novelty of our work is showing that with careful, non-trivial, design and implementation considerations, state-of-the-art deep learning methods can be used for accurate and efficient monitoring in audio."																				
2018	"Marques, Alan Caio R.; M. Raimundo, Marcos; B. Cavalheiro, Ellen Marianne; F. P. Salles, Luis; Lyra, Christiano; J. Von Zuben, Fernando"	Ant genera identification using an ensemble of convolutional neural networks	Images	CNN	Classification	PLOS ONE	13	1	e0192011	10.1371/journal.pone.0192011	https://dx.plos.org/10.1371/journal.pone.0192011	"Works requiring taxonomic knowledge face several challenges, such as arduous identification of many taxa and an insufficient number of taxonomists to identify a great deal of collected organisms. Machine learning tools, particularly convolutional neural networks (CNNs), are then welcome to automatically generate high-performance classifiers from available data. Supported by the image datasets available at the largest online database on ant biology, the AntWeb (www.antweb.org), we propose here an ensemble of CNNs to identify ant genera directly from the head, profile and dorsal perspectives of ant images. Transfer learning is also considered to improve the individual performance of the CNN classifiers. The performance achieved by the classifiers is diverse enough to promote a reduction in the overall classification error when they are combined in an ensemble, achieving an accuracy rate of over 80% on top-1 classification and an accuracy of over 90% on top-3 classification."																				
2018	"Mathis, Alexander; Mamidanna, Pranav; Cury, Kevin M.; Abe, Taiga; Murthy, Venkatesh N.; Mathis, Mackenzie Weygandt; Bethge, Matthias"	DeepLabCut: markerless pose estimation of user-defined body parts with deep learning	Video	CNN	Classification	Nature Neuroscience	21	9	1281-1289	10.1038/s41593-018-0209-y	http://www.nature.com/articles/s41593-018-0209-y	"Quantifying behavior is crucial for many applications in neuroscience. Videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. In motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, but markers are intrusive, and the number and location of the markers must be determined a priori. Here we present an efficient method for markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results with minimal training data. We demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors. Remarkably, even when only a small number of frames are labeled (~200), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy."																				
2018	"Moen, Endre; Handegard, Nils Olav; Allken, Vaneeda; Albert, Ole Thomas; Harbitz, Alf; Malde, Ketil"	Automatic interpretation of otoliths using deep learning	Images	CNN	Classification	PLOS ONE	13	12	e0204713	10.1371/journal.pone.0204713	https://dx.plos.org/10.1371/journal.pone.0204713	"The age structure of a fish population has important implications for recruitment processes and population fluctuations, and is a key input to fisheries-assessment models. The current method of determining age structure relies on manually reading age from otoliths, and the process is labor intensive and dependent on specialist expertise. Recent advances in machine learning have provided methods that have been remarkably successful in a variety of settings, with potential to automate analysis that previously required manual curation. Machine learning models have previously been successfully applied to object recognition and similar image analysis tasks. Here we investigate whether deep learning models can also be used for estimating the age of otoliths from images. We adapt a pre-trained convolutional neural network designed for object recognition, to estimate the age of fish from otolith images. The model is trained and validated on a large collection of images of Greenland halibut otoliths. We show that the model works well, and that its precision is comparable to documented precision obtained by human experts. Automating this analysis may help to improve consistency, lower cost, and increase the extent of age estimation. Given that adequate data are available, this method could also be used to estimate age of other species using images of otoliths or fish scales."																				
2018	"Nguyen, Thi Thanh Nhan; Le, Thi-Lan; Vu, Hai; Hoang, Van-Sam; Tran, Thanh-Hai"	Crowdsourcing for botanical data collection towards to automatic plant identification: A review	NA	NA	Review	Computers and Electronics in Agriculture	155		412-425	10.1016/j.compag.2018.10.042	https://linkinghub.elsevier.com/retrieve/pii/S0168169917309535	"Nowadays, a number of crowdsourcing systems are available, with community-driven forums contributing both visual datasets of flora and assisting members in determining species names of a given visual observation. However, crowdsourced problem has not clearly analyzed, particularly, in terms of providing data resources for establishing a powerful vision-based plant identification. In this paper, we carry out a comprehensive survey on various crowdsourcing systems for botanical data collecting. We first analyze six systems with respect of their focus, platforms, advantages as well as drawbacks. We then conduct questionnaire-based evaluations with a number of subjects having different expertise levels in botany. The evaluation results show that (1) the current systems have been accepted by a large number of users and (2) automatic plant identification based on images plays an important role in attracting the use of these systems. However, in order to make these systems be used in worldwide level, several issues still need to address. One of these issues is to improve the automatic plant identification. In order to understand the factors that affects identification performance, we have conducted several experiments with the state-of-the-art method based on deep learning techniques on different datasets. Results from these experiments show the crucial role of crowdsourcing system in collecting visual data for developing robust and effective plant identification."																				
2018	"Niemi, Juha; Tanttu, Juha T."	Deep Learning Case Study for Automatic Bird Identification	"Images, Other"	CNN	Classification	Applied Sciences	8	11	2089	10.3390/app8112089	https://www.mdpi.com/2076-3417/8/11/2089	"An automatic bird identification system is required for offshore wind farms in Finland. Indubitably, a radar is the obvious choice to detect flying birds, but external information is required for actual identification. We applied visual camera images as external data. The proposed system for automatic bird identification consists of a radar, a motorized video head and a single-lens reflex camera with a telephoto lens. A convolutional neural network trained with a deep learning algorithm is applied to the image classification. We also propose a data augmentation method in which images are rotated and converted in accordance with the desired color temperatures. The final identification is based on a fusion of parameters provided by the radar and the predictions of the image classifier. The sensitivity of this proposed system, on a dataset containing 9312 manually taken original images resulting in 2.44 _ 106 augmented data set, is 0.9463 as an image classifier. The area under receiver operating characteristic curve for two key bird species is 0.9993 (the White-tailed Eagle) and 0.9496 (The Lesser Black-backed Gull), respectively. We proposed a novel system for automatic bird identification as a real world application. We demonstrated that our data augmentation method is suitable for image classification problem and it significantly increases the performance of the classifier."																				
2018	"Norouzzadeh, Mohammad Sadegh; Nguyen, Anh; Kosmala, Margaret; Swanson, Alexandra; Palmer, Meredith S.; Packer, Craig; Clune, Jeff"	"Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning"	Images	CNN	Classification	Proceedings of the National Academy of Sciences	115	25	E5716-E5725	10.1073/pnas.1719367115	http://www.pnas.org/lookup/doi/10.1073/pnas.1719367115	"Significance  Motion-sensor cameras in natural habitats offer the opportunity to inexpensively and unobtrusively gather vast amounts of data on animals in the wild. A key obstacle to harnessing their potential is the great cost of having humans analyze each image. Here, we demonstrate that a cutting-edge type of artificial intelligence called deep neural networks can automatically extract such invaluable information. For example, we show deep learning can automate animal identification for 99.3% of the 3.2 million-image Snapshot Serengeti dataset while performing at the same 96.6% accuracy of crowdsourced teams of human volunteers. Automatically, accurately, and inexpensively collecting such data could help catalyze the transformation of many fields of ecology, wildlife biology, zoology, conservation biology, and animal behavior into “big data” sciences."																				
2018	"Patrício, Diego Inácio; Rieder, Rafael"	Computer vision and artificial intelligence in precision agriculture for grain crops: A systematic review	NA	NA	Review	Computers and Electronics in Agriculture	153		69-81	10.1016/j.compag.2018.08.001	https://linkinghub.elsevier.com/retrieve/pii/S0168169918305829	"Grain production plays an important role in the global economy. In this sense, the demand for efficient and safe methods of food production is increasing. Information Technology is one of the tools to that end. Among the available tools, we highlight computer vision solutions combined with artificial intelligence algorithms that achieved important results in the detection of patterns in images. In this context, this work presents a systematic review that aims to identify the applicability of computer vision in precision agriculture for the production of the five most produced grains in the world: maize, rice, wheat, soybean, and barley. In this sense, we present 25 papers selected in the last five years with different approaches to treat aspects related to disease detection, grain quality, and phenotyping. From the results of the systematic review, it is possible to identify great opportunities, such as the exploitation of GPU (Graphics Processing Unit) and advanced artificial intelligence techniques, such as DBN (Deep Belief Networks) in the construction of robust methods of computer vision applied to precision agriculture."																				
2018	"Poplin, Ryan; Chang, Pi-Chuan; Alexander, David; Schwartz, Scott; Colthurst, Thomas; Ku, Alexander; Newburger, Dan; Dijamco, Jojo; Nguyen, Nam; Afshar, Pegah T; Gross, Sam S; Dorfman, Lizzie; McLean, Cory Y; DePristo, Mark A"	A universal SNP and small-indel variant caller using deep neural networks	Molecular	CNN	Classification	Nature Biotechnology	36	10	983-987	10.1038/nbt.4235	http://www.nature.com/articles/nbt.4235	"Grain production plays an important role in the global economy. In this sense, the demand for efficient and safe methods of food production is increasing. Information Technology is one of the tools to that end. Among the available tools, we highlight computer vision solutions combined with artificial intelligence algorithms that achieved important results in the detection of patterns in images. In this context, this work presents a systematic review that aims to identify the applicability of computer vision in precision agriculture for the production of the five most produced grains in the world: maize, rice, wheat, soybean, and barley. In this sense, we present 25 papers selected in the last five years with different approaches to treat aspects related to disease detection, grain quality, and phenotyping. From the results of the systematic review, it is possible to identify great opportunities, such as the exploitation of GPU (Graphics Processing Unit) and advanced artificial intelligence techniques, such as DBN (Deep Belief Networks) in the construction of robust methods of computer vision applied to precision agriculture."																				
2018	"Priyadarshani, Nirosha; Marsland, Stephen; Castro, Isabel"	Automated birdsong recognition in complex acoustic environments: a review	NA	NA	Review	Journal of Avian Biology	49	5	jav-01447	10.1111/jav.01447	http://doi.wiley.com/10.1111/jav.01447	"Conservationists are increasingly using autonomous acoustic recorders to determine the presence/absence and the abundance of bird species. Unlike humans, these recorders can be left in the field for extensive periods of time in any habitat. Although data acquisition is automated, manual processing of recordings is labour intensive, tedious, and prone to bias due to observer variations. Hence automated birdsong recognition is an efficient alternative. However, only few ecologists and conservationists utilise the existing birdsong recognisers to process unattended field recordings because the software calibration time is exceptionally high and requires considerable knowledge in signal processing and underlying systems, making the tools less user-friendly. Even allowing for these difficulties, getting accurate results is exceedingly hard. In this review we examine the state-of-the-art, summarising and discussing the methods currently available for each of the essential parts of a birdsong recogniser, and also available software. The key reasons behind poor automated recognition are that field recordings are very noisy, calls from birds that are a long way from the recorder can be faint or corrupted, and there are overlapping calls from many different birds. In addition, there can be large numbers of different species calling in one recording, and therefore the method has to scale to large numbers of species, or at least avoid misclassifying another species as one of particular interest. We found that these areas of importance, particularly the question of noise reduction, are amongst the least researched. In cases where accurate recognition of individual species is essential, such as in conservation work, we suggest that specialised (species-specific) methods of passive acoustic monitoring are required. We also believe that it is important that comparable measures, and datasets, are used to enable methods to be compared. "																				
2018	"Qiao, Mu; Zhang, Tony; Segalin, Cristina; Sam, Sarah; Perona, Pietro; Meister, Markus"	Mouse Academy: high-throughput automated training and trial-by-trial behavioral analysis during learning	Video	CNN	Regression	bioRxiv				10.1101/467878	http://biorxiv.org/lookup/doi/10.1101/467878	"Progress in understanding how individual animals learn will require high-throughput standardized methods for behavioral training but also advances in the analysis of the resulting behavioral data. In the course of training with multiple trials, an animal may change its behavior abruptly, and capturing such events calls for a trial-by-trial analysis of the animal’s strategy. To address this challenge, we developed an integrated platform for automated animal training and analysis of behavioral data. A low-cost and space-efficient apparatus serves to train entire cohorts of mice on a decision-making task under identical conditions. A generalized linear model (GLM) analyzes each animal’s performance at single-trial resolution. This model infers the momentary decision-making strategy and can predict the animal’s choice on each trial with an accuracy of ~80%. We also assess the animal’s detailed trajectories and body poses within the apparatus. Unsupervised analysis of these features revealed unusual trajectories that represent hesitation in the response. This integrated hardware\/software platform promises to accelerate the understanding of animal learning."																				
2018	"Raitoharju, Jenni; Riabchenko, Ekaterina; Ahmad, Iftikhar; Iosifidis, Alexandros; Gabbouj, Moncef; Kiranyaz, Serkan; Tirronen, Ville; Ärje, Johanna; Kärkkäinen, Salme; Meissner, Kristian"	Benchmark database for fine-grained image classification of benthic macroinvertebrates	Images	CNN	Classification	Image and Vision Computing	78		73-83	10.1016/j.imavis.2018.06.005	https://www.sciencedirect.com/science/article/pii/S026288561830101X	"Managing the water quality of freshwaters is a crucial task worldwide. One of the most used methods to biomonitor water quality is to sample benthic macroinvertebrate communities, in particular to examine the presence and proportion of certain species. This paper presents a benchmark database for automatic visual classification methods to evaluate their ability for distinguishing visually similar categories of aquatic macroinvertebrate taxa. We make publicly available a new database, containing 64 types of freshwater macroinvertebrates, ranging in number of images per category from 7 to 577. The database is divided into three datasets, varying in number of categories (64, 29, and 9 categories). Furthermore, in order to accomplish a baseline evaluation performance, we present the classification results of Convolutional Neural Networks (CNNs) that are widely used for deep learning tasks in large databases. Besides CNNs, we experimented with several other well-known classification methods using deep features extracted from the data."																				
2018	"Ravindran, Prabu; Costa, Adriana; Soares, Richard; Wiedenhoeft, Alex C."	Classification of CITES-listed and other neotropical Meliaceae wood images using convolutional neural networks	Images	CNN	Classification	Plant Methods	14	1	25	10.1186/s13007-018-0292-9	https://doi.org/10.1186/s13007-018-0292-9	"The current state-of-the-art for field wood identification to combat illegal logging relies on experienced practitioners using hand lenses, specialized identification keys, atlases of woods, and field manuals. Accumulation of this expertise is time-consuming and access to training is relatively rare compared to the international demand for field wood identification. A reliable, consistent and cost effective field screening method is necessary for effective global scale enforcement of international treaties such as the Convention on the International Trade in Endagered Species (CITES) or national laws (e.g. the US Lacey Act) governing timber trade and imports."																				
2018	"Rocchini, Duccio; Luque, Sandra; Pettorelli, Nathalie; Bastin, Lucy; Doktor, Daniel; Faedi, Nicolò; Feilhauer, Hannes; Féret, Jean-Baptiste; Foody, Giles M.; Gavish, Yoni; Godinho, Sergio; Kunin, William E.; Lausch, Angela; Leitão, Pedro J.; Marcantonio, Matteo; Neteler, Markus; Ricotta, Carlo; Schmidtlein, Sebastian; Vihervaara, Petteri; Wegmann, Martin; Nagendra, Harini"	Measuring _-diversity by remote sensing: A challenge for biodiversity monitoring	Other	DNN	Modeling	Methods in Ecology and Evolution	9	8	1787-1798	10.1111/2041-210X.12941	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12941	"Biodiversity includes multiscalar and multitemporal structures and processes, with different levels of functional organization, from genetic to ecosystemic levels. One of the mostly used methods to infer biodiversity is based on taxonomic approaches and community ecology theories. However, gathering extensive data in the field is difficult due to logistic problems, especially when aiming at modelling biodiversity changes in space and time, which assumes statistically sound sampling schemes. In this context, airborne or satellite remote sensing allows information to be gathered over wide areas in a reasonable time. Most of the biodiversity maps obtained from remote sensing have been based on the inference of species richness by regression analysis. On the contrary, estimating compositional turnover (_-diversity) might add crucial information related to relative abundance of different species instead of just richness. Presently, few studies have addressed the measurement of species compositional turnover from space. Extending on previous work, in this manuscript, we propose novel techniques to measure _-diversity from airborne or satellite remote sensing, mainly based on: (1) multivariate statistical analysis, (2) the spectral species concept, (3) self-organizing feature maps, (4) multidimensional distance matrices, and the (5) Rao's Q diversity. Each of these measures addresses one or several issues related to turnover measurement. This manuscript is the first methodological example encompassing (and enhancing) most of the available methods for estimating _-diversity from remotely sensed imagery and potentially relating them to species diversity in the field."																				
2018	"Schneider, Stefan; Taylor, Graham W.; Kremer, Stefan C."	Deep Learning Object Detection Methods for Ecological Camera Trap Data	Images	CNN	"Classification, Regression"	arXiv:1803.10842 [cs]				10.48550/arXiv.1803.10842	http://arxiv.org/abs/1803.10842	"Deep learning methods for computer vision tasks show promise for automating the data analysis of camera trap images. Ecological camera traps are a common approach for monitoring an ecosystem's animal population, as they provide continual insight into an environment without being intrusive. However, the analysis of camera trap images is expensive, labour intensive, and time consuming. Recent advances in the field of deep learning for object detection show promise towards automating the analysis of camera trap images. Here, we demonstrate their capabilities by training and comparing two deep learning object detection classifiers, Faster R-CNN and YOLO v2.0, to identify, quantify, and localize animal species within camera trap images using the Reconyx Camera Trap and the self-labeled Gold Standard Snapshot Serengeti data sets. When trained on large labeled datasets, object recognition methods have shown success. We demonstrate their use, in the context of realistically sized ecological data sets, by testing if object detection methods are applicable for ecological research scenarios when utilizing transfer learning. Faster R-CNN outperformed YOLO v2.0 with average accuracies of 93.0\% and 76.7\% on the two data sets, respectively. Our findings show promising steps towards the automation of the labourious task of labeling camera trap images, which can be used to improve our understanding of the population dynamics of ecosystems across the planet."																				
2018	"Schrider, Daniel R.; Kern, Andrew D."	Supervised Machine Learning for Population Genetics: A New Paradigm	NA	NA	Review	Trends in Genetics	34	4	301-312	10.1016/j.tig.2017.12.005	https://linkinghub.elsevier.com/retrieve/pii/S0168952517302251	"As population genomic datasets grow in size, researchers are faced with the daunting task of making sense of a flood of information. To keep pace with this explosion of data, computational methodologies for population genetic inference are rapidly being developed to best utilize genomic sequence data. In this review we discuss a new paradigm that has emerged in computational population genomics: that of supervised machine learning (ML). We review the fundamentals of ML, discuss recent applications of supervised ML to population genetics that outperform competing methods, and describe promising future directions in this area. Ultimately, we argue that supervised ML is an important and underutilized tool that has considerable potential for the world of evolutionary genomics."																				
2018	"Seo, Jeong-Kweon; Baik, Seongbok; Lee, Sang-Hee"	Simulating the architecture of a termite incipient nest using a convolutional neural network	Other	CNN	Modeling	Ecological Informatics	44		94-100	10.1016/j.ecoinf.2018.02.003	https://www.sciencedirect.com/science/article/pii/S1574954117302595	"Subterranean termites form colonies containing thousands of individuals, and maintain these colonies by consuming wood and other materials containing cellulose. In this consumption process, they cause serious damage to wooden structures. Information on the population size of termites is an important factor in developing strategies aimed at controlling termites. In this study, we provide a reasonable possibility of estimating the population of an incipient nest dug by a colony that has not yet discovered any food source. We build an agent-based model to simulate termite tunnel patterns in which the behavior of simulated termites (agents) is governed by simple rules based on empirical data. The simulated termites do not communicate with each other using pheromones. They move towards the ends of tunnels, excavate when their progress in that direction is blocked, and transport the excavated soil. Using simulations, we determine termite tunnel patterns according to three parameters: the number of simulated termites (N), the passing probability of two encountering termites (P), and the distance moved by termites to deposit soil parcels during tunneling activity (D). We train a convolutional neural network (CNN) using 80% of the tunnel patterns and apply the CNN to the remaining patterns to estimate the value of N. The application results show that the validation accuracy is approximately 41% and the training accuracy of the CNN is approximately 51%. Although the validation accuracy is not high, the estimation failures occur near the correct N values."																				
2018	"Shen, Yufeng; Zhou, Huiling; Li, Jiangtao; Jian, Fuji; Jayas, Digvir S."	Detection of stored-grain insects using deep learning	Images	CNN	Classification	Computers and Electronics in Agriculture	145		319-325	10.1016/j.compag.2017.11.039	https://linkinghub.elsevier.com/retrieve/pii/S016816991730769X	"A detection and identification method for stored-grain insects was developed by applying deep neural network. Adults of following six species of common stored-grain insects mixed with grain and dockage were artificially added into the developed insect-trapping device: Cryptoleste Pusillus(S.), Sitophilus Oryzae(L.), Oryzaephilus Surinamensis(L.), Tribolium Confusum(Jaquelin Du Val), Rhizopertha Dominica(F.). Database of Red Green and Blue (RGB) images of these live insects was established. We used Faster R-CNN to extract areas which might contain the insects in these images and classify the insects in these areas. An improved inception network was developed to extract feature maps. Excellent results for the detection and classification of these insects were achieved. The test results showed that the developed method could detect and identify insects under stored grain condition, and its mean Average Precision (mAP) reached 88."																				
2018	"Signoroni, Alberto; Savardi, Mattia; Pezzoni, Mario; Guerrini, Fabrizio; Arrigoni, Simone; Turra, Giovanni"	Combining the use of CNN classification and strength-driven compression for the robust identification of bacterial species on hyperspectral culture plate images	Other	CNN	Classification	IET Computer Vision	12	7	941-949	10.1049/iet-cvi.2018.5237	https://onlinelibrary.wiley.com/doi/abs/10.1049/iet-cvi.2018.5237	"Huge streams of diagnostic images are expected to be produced daily in the emerging field of digital microbiology imaging because of the ongoing worldwide spread of Full Laboratory Automation systems. This is redefining the way microbiologists execute diagnostic tasks. In this context, the authors want to assess the suitability and effectiveness of a deep learning approach to solve the diagnostically relevant but visually challenging task of directly identifying pathogens on bacterial growing plates. In particular, starting from hyperspectral acquisitions in the VNIR range and spatial-spectral processing of cultured plates, they approach the identification problem as the classification of computed spectral signatures of the bacterial colonies. In a highly relevant clinical context (urinary tract infections) and on a database of acquired hyperspectral images, they designed and trained a convolutional neural network for pathogen identification, assessing its performance and comparing it against conventional classification solutions. At the same time, given the expected data flow and possible conservation and transmission needs, they are interested in evaluating the combined use of classification and lossy data compression. To this end, after selecting a suitable wavelet-based compression technology, they test coding strength-driven operating points looking for configurations able to provably prevent any classification performance degradation."																				
2018	"Sixt, Leon; Wild, Benjamin; Landgraf, Tim"	RenderGAN: Generating Realistic Labeled Data	Video	GAN	Modeling	Frontiers in Robotics and AI	5		66	10.3389/frobt.2018.00066	https://www.frontiersin.org/article/10.3389/frobt.2018.00066/full	"Deep Convolutional Neuronal Networks (DCNNs) are showing remarkable performance on many computer vision tasks. Due to their large parameter space, they require many labeled samples when trained in a supervised setting. The costs of annotating data manually can render the use of DCNNs infeasible. We present a novel framework called RenderGAN that can generate large amounts of realistic, labeled images by combining a 3D model and the Generative Adversarial Network framework. In our approach, image augmentations (e.g., lighting, background, and detail) are learned from unlabeled data such that the generated images are strikingly realistic while preserving the labels known from the 3D model. We apply the RenderGAN framework to generate images of barcode-like markers that are attached to honeybees. Training a DCNN on data generated by the RenderGAN yields considerably better performance than training it on various baselines."																				
2018	"Srinivasan, Karthik; Duvvur, Vikram; Hess, Daniel"	Prediction of Algal Blooms in the Great Lakes through a Convolution Neural Network of Remote Sensing Data	Images	CNN	Classification	bioRxiv				10.1101/450551	http://biorxiv.org/lookup/doi/10.1101/450551	"Harmful algal blooms (HABs) are the proliferation of algae due to eutrophication and have severe repercussions to the ecological balance in many water bodies, due to the toxins the algae produce. Additionally, the identification and prediction of these HABs has been a challenge in the scientific community due to the interactions between both biological and physical processes that cause the HABs. Here, we used remote sensing data to bypass these issues; remote sensing data provides significant information about the coverage of chlorophyll which can be used to locate HABs. Using this indicator of HABs, we trained a Convolution Neural Network (CNN) to identify nine types of algal blooms, using 25 epochs of 900 images, which can predict algal bloom shapes with an 80 percent accuracy. This approach of HAB identification can easily be applied to other aquatic ecosystems where remote sensing data is present."																				
2018	"Sun, Yu; Liu, Xuanxin; Yuan, Mingshuai; Ren, Lili; Wang, Jianxin; Chen, Zhibo"	Automatic in-trap pest detection using deep learning for pheromone-based Dendroctonus valens monitoring	Images	CNN	"Classification, Regression"	Biosystems Engineering	176		140-150	10.1016/j.biosystemseng.2018.10.012	https://www.sciencedirect.com/science/article/pii/S1537511018307815	"Dendroctonus valens LeConte, the red turpentine beetle (RTB) is an invasive pest which is severely threatening pine species in China. Traditional pheromone-based RTB monitoring depends on a manual count, which is not only time consuming but also error-prone. This study proposes a deep learning detection method for counting adult RTBs directly in the pheromone trap. The images of bark beetles were captured by a digital camera embedded in the collection cup of the pheromone trap. The state-of-the-art one-stage deep learning detector RetinaNet was further downsized by the depthwise separable convolution and feature pyramid tailoring, which was feasible to run on embedded devices. To enable the fine-grained identification of bark beetles, the downsized detector was enhanced by k-means anchor optimisation and residual classification subnet. The models were trained end-to-end on a GPU workstation with data augmentation and then deployed on embedded devices with minimal preprocessing. Experiments demonstrated that the object level average precision (AP) was 0.746 and the average runtime on the Jetson TX2 and Raspberry Pi 3b were 0.448s and 23.44s, respectively. The in-trap detector was capable of distinguishing the most aggressive RTBs from other five species of bark beetles attracted by pheromone with unconstrained size, pose, orientation, integrity, and position. The proposed method showed promising performance both qualitatively and quantitatively within limited computational budgets, which has introduced a practical and applicable solution for early warning of RTB outbreaks."																				
2018	"Taghavi Namin, Sarah; Esmaeilzadeh, Mohammad; Najafi, Mohammad; Brown, Tim B.; Borevitz, Justin O."	Deep phenotyping: deep learning for temporal phenotype/genotype classification	Images	"CNN, RNN"	Classification	Plant Methods	14	1	66	10.1186/s13007-018-0333-4	https://plantmethods.biomedcentral.com/articles/10.1186/s13007-018-0333-4	"Background: High resolution and high throughput genotype to phenotype studies in plants are underway to accelerate breeding of climate ready crops. In the recent years, deep learning techniques and in particular Convolutional Neural Networks (CNNs), Recurrent Neural Networks and Long-Short Term Memories (LSTMs), have shown great success in visual data recognition, classification, and sequence learning tasks. More recently, CNNs have been used for plant classification and phenotyping, using individual static images of the plants. On the other hand, dynamic behavior of the plants as well as their growth has been an important phenotype for plant biologists, and this motivated us to study the potential of LSTMs in encoding these temporal information for the accession classification task, which is useful in automation of plant production and care. Methods: In this paper, we propose a CNN-LSTM framework for plant classification of various genotypes. Here, we exploit the power of deep CNNs for automatic joint feature and classifier learning, compared to using hand-crafted features. In addition, we leverage the potential of LSTMs to study the growth of the plants and their dynamic behaviors as important discriminative phenotypes for accession classification. Moreover, we collected a dataset of time-series image sequences of four accessions of Arabidopsis, captured in similar imaging conditions, which could be used as a standard benchmark by researchers in the field. We made this dataset publicly available. Conclusion: The results provide evidence of the benefits of our accession classification approach over using traditional hand-crafted image analysis features and other accession classification frameworks. We also demonstrate that utilizing temporal information using LSTMs can further improve the performance of the system. The proposed framework can be used in other applications such as in plant classification given the environment conditions or in distinguishing diseased plants from healthy ones."																				
2018	"Tan, Jing wei; Chang, Siow-Wee; Abdul-Kareem, Sameem; Yap, Hwa Jen; Yong, Kien-Thai"	Deep Learning for Plant Species Classification Using Leaf Vein Morphometric	Images	"DNN, CNN"	Classification	IEEE/ACM Transactions on Computational Biology and Bioinformatics	17	1	82-90	10.1109/TCBB.2018.2848653	https://ieeexplore.ieee.org/document/8388220	"An automated plant species identification system could help botanists and layman in identifying plant species rapidly. Deep learning is robust for feature extraction as it is superior in providing deeper information of images. In this research, a new CNN-based method named D-Leaf was proposed. The leaf images were pre-processed and the features were extracted by using three different Convolutional Neural Network (CNN) models namely pre-trained AlexNet, fine-tuned AlexNet, and D-Leaf. These features were then classified by using five machine learning techniques, namely, Support Vector Machine (SVM), Artificial Neural Network (ANN), k-Nearest-Neighbor (k-NN), Naïve-Bayes (NB), and CNN. A conventional morphometric method computed the morphological measurements based on the Sobel segmented veins was employed for benchmarking purposes. The D-Leaf model achieved a comparable testing accuracy of 94.88 percent as compared to AlexNet (93.26 percent) and fine-tuned AlexNet (95.54 percent) models. In addition, CNN models performed better than the traditional morphometric measurements (66.55 percent). The features extracted from the CNN are found to be fitted well with the ANN classifier."																				
2018	"Tao, Dan; Wang, Zhengrong; Li, Guanglin; Qiu, Guangying"	Accurate Identification of the Sex and Species of Silkworm Pupae Using Near Infrared Spectroscopy	Other	Unknown	Classification	Journal of Applied Spectroscopy	85	5	949-952	10.1007/s10812-018-0744-z	https://doi.org/10.1007/s10812-018-0744-z	"The present study proposes a novel method to discriminate the sex and species of silkworm pupae using NIR spectroscopy (800–2778 nm). The spectra from 840 silkworm pupae were collected then divided into a calibration set (700) and a test set (140) using the Kennard–Stone (KS) algorithm. The recognition models were built using the radial basis function and neural network (RBF–NN) and support vector machine (SVM) approaches. The species and sex identification results using the RBF–NN and SVM models based on full spectral data achieved a low accuracy of 5% and 33.57%, respectively. To improve the accuracy and decrease the processing time, both principal component analysis (PCA) and linear discriminant analysis (LDA) were used to reduce the data dimensions. The performance of the optimized SVM model (92.14%) was much better than the RBF–NN model (19.29%) based on PCA. Overall, the best discrimination results were obtained using the RBF–NN and SVM models based on LDA, providing an accuracy of 100%. These promising results have shown that the LDA–SVM and LDA–RBF–NN models can accurately recognize the sex and species of silkworm pupae using NIR spectroscopy."																				
2018	"Teng, Haotian; Cao, Minh Duc; Hall, Michael B; Duarte, Tania; Wang, Sheng; Coin, Lachlan J M"	Chiron: translating nanopore raw signal directly into nucleotide sequence using deep learning	Molecular	CNN	Classification	GigaScience	7	5	giy037	10.1093/gigascience/giy037	https://academic.oup.com/gigascience/article/doi/10.1093/gigascience/giy037/4966989	"Sequencing by translocating DNA fragments through an array of nanopores is a rapidly maturing technology that offers faster and cheaper sequencing than other approaches. However, accurately deciphering the DNA sequence from the noisy and complex electrical signal is challenging. Here, we report Chiron, the first deep learning model to achieve end-to-end basecalling and directly translate the raw signal to DNA sequence without the error-prone segmentation step. Trained with only a small set of 4,000 reads, we show that our model provides state-of-the-art basecalling accuracy, even on previously unseen species. Chiron achieves basecalling speeds of more than 2,000 bases per second using desktop computer graphics processing units."																				
2018	"Van Horn, Grant; Mac Aodha, Oisin; Song, Yang; Cui, Yin; Sun, Chen; Shepard, Alex; Adam, Hartwig; Perona, Pietro; Belongie, Serge"	The iNaturalist Species Classification and Detection Dataset	Images	CNN	Classification	arXiv:1707.06642 [cs]				10.48550/arXiv.1707.06642	http://arxiv.org/abs/1707.06642	"Existing image classification datasets used in computer vision tend to have a uniform distribution of images across object categories. In contrast, the natural world is heavily imbalanced, as some species are more abundant and easier to photograph than others. To encourage further progress in challenging real world conditions we present the iNaturalist species classification and detection dataset, consisting of 859,000 images from over 5,000 different species of plants and animals. It features visually similar species, captured in a wide variety of situations, from all over the world. Images were collected with different camera types, have varying image quality, feature a large class imbalance, and have been verified by multiple citizen scientists. We discuss the collection of the dataset and present extensive baseline experiments using state-of-the-art computer vision classification and detection models. Results show that current non-ensemble based methods achieve only 67% top one classification accuracy, illustrating the difficulty of the dataset. Specifically, we observe poor results for classes with small numbers of training examples suggesting more attention is needed in low-shot learning."																				
2018	"Villon, Sébastien; Mouillot, David; Chaumont, Marc; Darling, Emily S.; Subsol, Gérard; Claverie, Thomas; Villéger, Sébastien"	A Deep learning method for accurate and fast identification of coral reef fishes in underwater images	Images	CNN	Classification	Ecological Informatics	48		238-244	10.1016/j.ecoinf.2018.09.007	https://linkinghub.elsevier.com/retrieve/pii/S1574954118300694	"Identifying and counting fish individuals on photos and videos is a crucial task to cost-effectively monitor marine biodiversity, yet it remains difficult and time-consuming. In this paper, we present a method to assist the identification of fish species on underwater images, and we compare our model performances to human ability in terms of speed and accuracy. We first tested the performance of a convolutional neural network (CNN) trained with different photographic databases while accounting for different post-processing decision rules to identify 20 fish species. Finally, we compared the performance of species identification of our best CNN model with that of humans on a test database of 1197 fish images representing nine species. The best CNN was the one trained with 900,000 images including (i) whole fish bodies, (ii) partial fish bodies and (iii) the environment (e.g. reef bottom or water). The rate of correct identification was 94.9%, greater than the rate of correct identification by humans (89.3%). The CNN was also able to identify fish individuals partially hidden behind corals or behind other fish and was more effective than humans to identify fish on smallest or blurry images while humans were better to identify fish individuals in unusual positions (e.g. twisted body). On average, each identification by our best CNN using a common hardware took 0.06 s. Deep Learning methods can thus perform efficient fish identification on underwater images and offer promises to build-up new video-based protocols for monitoring fish biodiversity cheaply and effectively."																				
2018	"Wäldchen, Jana; Mäder, Patrick"	Machine learning for image based species identification	NA	NA	Review	Methods in Ecology and Evolution	9	11	2216-2225	10.1111/2041-210X.13075	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13075	"Accurate species identification is the basis for all aspects of taxonomic research and is an essential component of workflows in biological research. Biologists are asking for more efficient methods to meet the identification demand. Smart mobile devices, digital cameras as well as the mass digitisation of natural history collections led to an explosion of openly available image data depicting living organisms. This rapid increase in biological image data in combination with modern machine learning methods, such as deep learning, offers tremendous opportunities for automated species identification. In this paper, we focus on deep learning neural networks as a technology that enabled breakthroughs in automated species identification in the last 2 years. In order to stimulate more work in this direction, we provide a brief overview of machine learning frameworks applicable to the species identification problem. We review selected deep learning approaches for image based species identification and introduce publicly available applications. Eventually, this article aims to provide insights into the current state-of-the-art in automated identification and to serve as a starting point for researchers willing to apply novel machine learning techniques in their biological studies. While modern machine learning approaches only slowly pave their way into the field of species identification, we argue that we are going to see a proliferation of these techniques being applied to the problem in the future. Artificial intelligence systems will provide alternative tools for taxonomic identification in the near future.  "																				
2018	"Wäldchen, Jana; Mäder, Patrick"	Plant Species Identification Using Computer Vision Techniques: A Systematic Literature Review	NA	NA	Review	Archives of Computational Methods in Engineering	25	2	507-543	10.1007/s11831-016-9206-z	http://link.springer.com/10.1007/s11831-016-9206-z	"Species knowledge is essential for protecting biodiversity. The identification of plants by conventional keys is complex, time consuming, and due to the use of specific botanical terms frustrating for non-experts. This creates a hard to overcome hurdle for novices interested in acquiring species knowledge. Today, there is an increasing interest in automating the process of species identification. The availability and ubiquity of relevant technologies, such as, digital cameras and mobile devices, the remote access to databases, new techniques in image processing and pattern recognition let the idea of automated species identification become reality. This paper is the first systematic literature review with the aim of a thorough analysis and comparison of primary studies on computer vision approaches for plant species identification. We identified 120 peer-reviewed studies, selected through a multi-stage process, published in the last 10 years (2005–2015). After a careful analysis of these studies, we describe the applied methods categorized according to the studied plant organ, and the studied features, i.e., shape, texture, color, margin, and vein structure. Furthermore, we compare methods based on classification accuracy achieved on publicly available datasets. Our results are relevant to researches in ecology as well as computer vision for their ongoing research. The systematic and concise overview will also be helpful for beginners in those research fields, as they can use the comparable analyses of applied methods as a guide in this complex activity."																				
2018	"Wäldchen, Jana; Rzanny, Michael; Seeland, Marco; Mäder, Patrick"	Automated plant species identification—Trends and future directions	NA	NA	Review	PLOS Computational Biology	14	4	e1005993	10.1371/journal.pcbi.1005993	https://dx.plos.org/10.1371/journal.pcbi.1005993	"Current rates of species loss triggered numerous attempts to protect and conserve biodiversity. Species conservation, however, requires species identification skills, a competence obtained through intensive training and experience. Field researchers, land managers, educators, civil servants, and the interested public would greatly benefit from accessible, up-to-date tools automating the process of species identification. Currently, relevant technologies, such as digital cameras, mobile devices, and remote access to databases, are ubiquitously available, accompanied by significant advances in image processing and pattern recognition. The idea of automated species identification is approaching reality. We review the technical status quo on computer vision approaches for plant species identification, highlight the main research challenges to overcome in providing applicable tools, and conclude with a discussion of open and future research thrusts."																				
2018	"Weinstein, Ben G."	Scene-specific convolutional neural networks for video-based biodiversity detection	Video	CNN	Classification	Methods in Ecology and Evolution	9	6	1435-1441	10.1111/2041-210X.13011	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13011	"Finding, counting and identifying animals is a central challenge in ecology. Most studies are limited by the time and cost of fieldwork by human observers. To increase the spatial and temporal breadth of sampling, ecologists are adopting passive image-based monitoring approaches. While passive monitoring can expand data collection, a remaining obstacle is finding the small proportion of images containing ecological objects among the majority of frames containing only background scenes. I proposed a scene-specific convolutional neural network for detecting animals of interest within long duration time-lapse videos. Convolutional neural networks are a type of deep learning algorithm that have recently made significant advances in image classification. The approach was tested on videos of floral visitation by hummingbirds. Despite low frame rates, poor image quality, and complex video conditions, the model correctly classified over 90% of frames containing hummingbirds. Combining motion detection and image classification can substantially reduce the time investment in scoring images from passive monitoring studies. These results underscore the promise of deep learning to lead ecology into greater automation using passive image analysis. To help facilitate future applications, I created a desktop executable that can be used to apply pre-trained models to videos, as well as reproducible scripts for training new models on local and cloud environments."																				
2018	"Weinstein, Ben G."	Scene_specific convolutional neural networks for video_based biodiversity detection	Video	CNN	Classification	Methods in Ecology and Evolution	9	6	1435-1441	10.1111/2041-210X.13011	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13011	"Finding, counting and identifying animals is a central challenge in ecology. Most studies are limited by the time and cost of fieldwork by human observers. To increase the spatial and temporal breadth of sampling, ecologists are adopting passive image-based monitoring approaches. While passive monitoring can expand data collection, a remaining obstacle is finding the small proportion of images containing ecological objects among the majority of frames containing only background scenes.I proposed a scene-specific convolutional neural network for detecting animals of interest within long duration time-lapse videos. Convolutional neural networks are a type of deep learning algorithm that have recently made significant advances in image classification. The approach was tested on videos of floral visitation by hummingbirds. Despite low frame rates, poor image quality, and complex video conditions, the model correctly classified over 90% of frames containing hummingbirds. Combining motion detection and image classification can substantially reduce the time investment in scoring images from passive monitoring studies. These results underscore the promise of deep learning to lead ecology into greater automation using passive image analysis. To help facilitate future applications, I created a desktop executable that can be used to apply pre-trained models to videos, as well as reproducible scripts for training new models on local and cloud environments."																				
2018	"Wild, Benjamin; Sixt, Leon; Landgraf, Tim"	Automatic localization and decoding of honeybee markers using deep convolutional neural networks	Images	CNN	Classification	arXiv:1802.04557 [cs]				10.48550/arXiv.1802.04557	http://arxiv.org/abs/1802.04557	"The honeybee is a fascinating model animal to investigate how collective behavior emerges from (inter-)actions of thousands of individuals. Bees may acquire unique memories throughout their lives. These experiences affect social interactions even over large time frames. Tracking and identifying all bees in the colony over their lifetimes therefore may likely shed light on the interplay of individual differences and colony behavior. This paper proposes a software pipeline based on two deep convolutional neural networks for the localization and decoding of custom binary markers that honeybees carry from their first to the last day in their life. We show that this approach outperforms similar systems proposed in recent literature. By opening this software for the public, we hope that the resulting datasets will help advancing the understanding of honeybee collective intelligence."																				
2018	"Willi, Marco; Pitman, Ross T.; Cardoso, Anabelle W.; Locke, Christina; Swanson, Alexandra; Boyer, Amy; Veldthuis, Marten; Fortson, Lucy"	Identifying animal species in camera trap images using deep learning and citizen science	Images	CNN	Classification	Methods in Ecology and Evolution	10	1	80-91	10.1111/2041-210X.13099	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13099	"Ecologists often study wildlife populations by deploying camera traps. Large datasets are generated using this approach which can be difficult for research teams to manually evaluate. Researchers increasingly enlist volunteers from the general public as citizen scientists to help classify images. The growing number of camera trap studies, however, makes it ever more challenging to find enough volunteers to process all projects in a timely manner. Advances in machine learning, especially deep learning, allow for accurate automatic image classification. By training models using existing datasets of images classified by citizen scientists and subsequent application of such models on new studies, human effort may be reduced substantially. The goals of this study were to (a) assess the accuracy of deep learning in classifying camera trap data, (b) investigate how to process datasets with only a few classified images that are generally difficult to model, and (c) apply a trained model on a live online citizen science project. Convolutional neural networks (CNNs) were used to differentiate among images of different animal species, images of humans or vehicles, and empty images (no animals, vehicles, or humans). We used four different camera trap datasets featuring a wide variety of species, different habitats, and a varying number of images. All datasets were labelled by citizen scientists on Zooniverse. Accuracies for identifying empty images across projects ranged between 91.2% and 98.0%, whereas accuracies for identifying specific species were between 88.7% and 92.7%. Transferring information from CNNs trained on large datasets (“transfer-learning”) was increasingly beneficial as the size of the training dataset decreased and raised accuracy by up to 10.3%. Removing low-confidence predictions increased model accuracies to the level of citizen scientists. By combining a trained model with classifications from citizen scientists, human effort was reduced by 43% while maintaining overall accuracy for a live experiment running on Zooniverse. Ecology researchers can significantly reduce image classification time and manual effort by combining citizen scientists and CNNs, enabling faster processing of data from large camera trap studies."																				
2018	"Xia, Denan; Chen, Peng; Wang, Bing; Zhang, Jun; Xie, Chengjun"	Insect Detection and Classification Based on an Improved Convolutional Neural Network	Images	CNN	Classification	Sensors	18	12	4169	10.3390/s18124169	http://www.mdpi.com/1424-8220/18/12/4169	"Regarding the growth of crops, one of the important factors affecting crop yield is insect disasters. Since most insect species are extremely similar, insect detection on field crops, such as rice, soybean and other crops, is more challenging than generic object detection. Presently, distinguishing insects in crop fields mainly relies on manual classification, but this is an extremely time-consuming and expensive process. This work proposes a convolutional neural network model to solve the problem of multi-classification of crop insects. The model can make full use of the advantages of the neural network to comprehensively extract multifaceted insect features. During the regional proposal stage, the Region Proposal Network is adopted rather than a traditional selective search technique to generate a smaller number of proposal windows, which is especially important for improving prediction accuracy and accelerating computations. Experimental results show that the proposed method achieves a heightened accuracy and is superior to the state-of-the-art traditional insect classification algorithms."																				
2018	"Xiao, Qingguo; Li, Guangyao; Xie, Li; Chen, Qiaochuan"	Real-world plant species identification based on deep convolutional neural networks and visual attention	Images	CNN	Classification	Ecological Informatics	48		117-124	10.1016/j.ecoinf.2018.09.001	https://www.sciencedirect.com/science/article/pii/S1574954118301717	"This paper investigates the issue of real-world identification to fulfill better species protection. We focus on plant species identification as it is a classic and hot issue. In tradition plant species identification the samples are scanned specimen and the background is simple. However, real-world species recognition is more challenging. We first systematically investigate what is realistic species recognition and the difference from tradition plant species recognition. To deal with the challenging task, an interdisciplinary collaboration is presented based on the latest advances in computer science and technology. We propose a novel framework and an effective data augmentation method for deep learning in this paper. We first crop the image in terms of visual attention before general recognition. Besides, we apply it as a data augmentation method. We call the novel data augmentation approach attention cropping (AC). Deep convolutional neural networks are trained to predict species from a large amount of data. Extensive experiments on traditional dataset and specific dataset for real-world recognition are conducted to evaluate the performance of our approach. Experiments first demonstrate that our approach achieves state-of-the-art results on different types of datasets. Besides, we also evaluate the performance of data augmentation method AC. Results show that AC provides superior performance. Compared with the precision of methods without AC, the results with AC achieve substantial improvement."																				
2018	"Younis, Sohaib; Weiland, Claus; Hoehndorf, Robert; Dressler, Stefan; Hickler, Thomas; Seeger, Bernhard; Schmidt, Marco"	Taxon and trait recognition from digitized herbarium specimens using deep convolutional neural networks	Images	CNN	Classification	Botany Letters	165	4-Mar	377-383	10.1080/23818107.2018.1446357	https://www.tandfonline.com/doi/full/10.1080/23818107.2018.1446357	"Herbaria worldwide are housing a treasure of hundreds of millions of herbarium specimens, which are increasingly being digitized and thereby more accessible to the scientific community. At the same time, deep-learning algorithms are rapidly improving pattern recognition from images and these techniques are more and more being applied to biological objects. In this study, we are using digital images of herbarium specimens in order to identify taxa and traits of these collection objects by applying convolutional neural networks (CNN). Images of the 1000 species most frequently documented by herbarium specimens on GBIF have been downloaded and combined with morphological trait data, preprocessed and divided into training and test datasets for species and trait recognition. Good performance in both domains suggests substantial potential of this approach for supporting taxonomy and natural history collection management. Trait recognition is also promising for applications in functional ecology."																				
2018	"Zhang, Changzhen; Cai, Jiahao; Xiao, Deqin; Ye, Yaowen; Chehelamirani, Mohammad"	Research on Vegetable Pest Warning System Based on Multidimensional Big Data	"Images, Other"	DNN	Classification	Insects	9	2	66	10.3390/insects9020066	https://www.mdpi.com/2075-4450/9/2/66	"Pest early warning technology is part of the prerequisite for the timely and effective control of pest outbreaks. Traditional pest warning system with artificial mathematical statistics, radar, and remote sensing has some deficiency in many aspects, such as higher cost, weakness of accuracy, low efficiency, and so on. In this study, Pest image data was collected and information about four major vegetable pests (Bemisia tabaci (Gennadius), Phyllotreta striolata (Fabricius), Plutella xylostella (Linnaeus), and Frankliniella occidentalis (Pergande) (Thysanoptera, Thripidae)) in southern China was extracted. A multi-sensor network system was constructed to collect small-scale environmental data on vegetable production sites. The key factors affecting the distribution of pests were discovered by multi-dimensional information, such as soil, environment, eco-climate, and meteorology of vegetable fields, and finally, the vegetable pest warning system that is based on multidimensional big data (VPWS-MBD) was implemented. Pest and environmental data from Guangzhou Dongsheng Bio-Park were collected from June 2017 to February 2018. The number of pests is classified as level I (0–56), level II (57–131), level III (132–299), and level IV (above 300) by K-Means algorithm. The Pearson correlation coefficient and the grey relational analysis algorithm were used to calculate the five key influence factors of rainfall, soil temperature, air temperature, leaf surface humidity, and soil moisture. Finally, Back Propagation (BP) Neural Network was used for classification prediction. The result shows: I-level warning accuracy was 96.14%, recall rate was 97.56%; II-level pest warning accuracy was 95.34%, the recall rate was 96.45%; III-level pest warning accuracy of 100%, the recall rate was 96.28%; IV-level pest warning accuracy of 100%, recall rate was 100%. It proves that the early warning system can effectively predict vegetable pests and achieve the early warning of vegetable pest’s requirements, with high availability."																				
2018	"Zhang, Yuzuo; Li, Boyi"	Wild plant data collection system based on distributed location	Images	CNN	Classification	Journal of Computational Science	28		389-397	10.1016/j.jocs.2017.04.013	https://www.sciencedirect.com/science/article/pii/S1877750317304313	"Building accurate knowledge of the identity, the geographic distribution and the evolution of living species is very essential for sustainable development of the biodiversity as well as the whole society. However, basic information is often partially accessible for scientists to do research, plant data collection is one of the problems. To make plants collection become more available especially in the field environment with weak network signal, this paper proposed a novel method that combines plant recognition with distributed location information and designed a corresponding method based on Bayesian estimation to analyze plants with sick disease and unknown parts. A mobile application system has been designed and implemented which uploads plant photos to the cloud server for recognition based on the established plant library and speed up the process with the distributed location information. Meanwhile, to solve weak signal problem in the wild field, the library buffer of neighboring area where recent searching items exist are proposed in the mobile client be therefore that the application can finish matching locally and reduce the network bandwidth requirement. To illustrate the availability and practicability, different set of plants with leaves or flowers have been collected and the results show that the average recognizing accuracy via traditional method is larger than 84% and recognition time is less than 1.5s, and the accuracy will soar to more than 90% if neural network is used."																				
2018	"Zhong, Yuanhong; Gao, Junyuan; Lei, Qilun; Zhou, Yao"	A Vision-Based Counting and Recognition System for Flying Insects in Intelligent Agriculture	Images	CNN	"Classification, Regression"	Sensors	18	5	1489	10.3390/s18051489	http://www.mdpi.com/1424-8220/18/5/1489	"Rapid and accurate counting and recognition of flying insects are of great importance, especially for pest control. Traditional manual identification and counting of flying insects is labor intensive and inefficient. In this study, a vision-based counting and classification system for flying insects is designed and implemented. The system is constructed as follows: firstly, a yellow sticky trap is installed in the surveillance area to trap flying insects and a camera is set up to collect real-time images. Then the detection and coarse counting method based on You Only Look Once (YOLO) object detection, the classification method and fine counting based on Support Vector Machines (SVM) using global features are designed. Finally, the insect counting and recognition system is implemented on Raspberry PI. Six species of flying insects including bee, fly, mosquito, moth, chafer and fruit fly are selected to assess the effectiveness of the system. Compared with the conventional methods, the test results show promising performance. The average counting accuracy is 92.50% and average classifying accuracy is 90.18% on Raspberry PI. The proposed system is easy-to-use and provides efficient and accurate recognition data, therefore, it can be used for intelligent agriculture applications"																				
2018	"Zhu, Heyan; Liu, Qinglin; Qi, Yuankai; Huang, Xinyuan; Jiang, Feng; Zhang, Shengping"	Plant identification based on very deep convolutional neural networks	Images	CNN	Classification	Multimedia Tools and Applications	77	22	29779-29797	10.1007/s11042-017-5578-9	https://doi.org/10.1007/s11042-017-5578-9	"Plant identification is a critical step in protecting plant diversity. However, many existing identification systems prohibitively rely on hand-crafted features for plant species identification. In this paper, a deep learning method is employed to extract discriminative features from plant images along with a linear SVM for plant identification. To offer a self-learning feature representation for different plant organs, we choose a very deep convolutional neural networks (CNNs), which consists of sixteen convolutional layers followed by three Fully-Connected (FC) layers and a final soft-max layer. Five max-pooling layers are performed over a 2_2 pixel window with stride 2. Extensive experiments on several plant datasets demonstrate the remarkable performance of the very deep neural network compared to the hand-crafted features."																				
2018	"Zhu, Xiaolong; Zhu, Meng; Ren, Honge"	Method of plant leaf recognition based on improved deep convolutional neural network	Images	CNN	Classification	Cognitive Systems Research	52		223-233	10.1016/j.cogsys.2018.06.008	https://www.sciencedirect.com/science/article/pii/S1389041717303480	"The identification of plant species mainly depends on the recognition of plant leaf characteristics. However, most recognition systems show the weak performance on detecting small objects like plant leaves in the complicated background. In order to improve the recognition ability of plant leaves in the complex environment, this paper proposes an improved deep convolutional neural network, which takes advantage of the Inception V2 with batch normalization (BN) instead of convolutional neural layers in the faster region convolutional neural network (Faster RCNN) offering multiscale image features to the region proposal network (RPN). In addition, the original images first are cut into the specified size according to the numerical order, and the segmented images are loaded into the proposed network sequentially. After the precise classification through softmax and bounding box regressor, the segmented images with identification labels are spliced together as final output images. The experimental results show that the proposed approach has higher recognition accuracy than Faster RCNN in recognizing leaf species in the complex background."																				
2019	"Abeysinghe, Tharindu; Simic Milas, Anita; Arend, Kristin; Hohman, Breann; Reil, Patrick; Gregory, Andrew; Vázquez-Ortega, Angélica"	Mapping Invasive Phragmites australis in the Old Woman Creek Estuary Using UAV Remote Sensing and Machine Learning Classifiers	Other	Unknown	Classification	Remote Sensing	11	11	1380	10.3390/rs11111380	https://www.mdpi.com/2072-4292/11/11/1380	"Unmanned aerial vehicles (UAV) are increasingly used for spatiotemporal monitoring of invasive plants in coastal wetlands. Early identification of invasive species is necessary in planning, restoring, and managing wetlands. This study assessed the effectiveness of UAV technology to identify invasive Phragmites australis in the Old Woman Creek (OWC) estuary using machine learning (ML) algorithms: Neural network (NN), support vector machine (SVM), and k-nearest neighbor (kNN). The ML algorithms were compared with the parametric maximum likelihood classifier (MLC) using pixel- and object-based methods. Pixel-based NN was identified as the best classifier with an overall accuracy of 94.80% and the lowest error of omission of 1.59%, the outcome desirable for effective eradication of Phragmites. The results were reached combining Sequoia multispectral imagery (green, red, red edge, and near-infrared bands) combined with the canopy height model (CHM) acquired in the mid-growing season and normalized difference vegetation index (NDVI) acquired later in the season. The sensitivity analysis, using various vegetation indices, image texture, CHM, and principal components (PC), demonstrated the impact of various feature layers on the classifiers. The study emphasizes the necessity of a suitable sampling and cross-validation methods, as well as the importance of optimum classification parameters."																				
2019	"Abrams, Jesse F.; Vashishtha, Anand; Wong, Seth T.; Nguyen, An; Mohamed, Azlan; Wieser, Sebastian; Kuijper, Arjan; Wilting, Andreas; Mukhopadhyay, Anirban"	Habitat-Net: Segmentation of habitat images using deep learning	Images	CNN	Classification	Ecological Informatics	51		121-128	10.1016/j.ecoinf.2019.01.009	https://linkinghub.elsevier.com/retrieve/pii/S1574954118302759	"Understanding environmental factors that influence forest health, as well as the occurrence and abundance of wildlife, is a central topic in forestry and ecology. However, the manual processing of field habitat data is time-consuming and months are often needed to progress from data collection to data interpretation. To shorten the time to process the data we propose here Habitat-Net: a novel deep learning application based on Convolutional Neural Networks (CNN) to segment habitat images of tropical rainforests. Habitat-Net takes color images as input and after multiple layers of convolution and deconvolution, produces a binary segmentation of the input image. We worked on two different types of habitat datasets that are widely used in ecological studies to characterize the forest conditions: canopy closure and understory vegetation. We trained the model with 800 canopy images and 700 understory images separately and then used 149 canopy and 172 understory images to test the performance of Habitat-Net. We compared the performance of Habitat-Net to the performance of a simple threshold based method, manual processing by a second researcher and a CNN approach called U-Net, upon which Habitat-Net is based. Habitat-Net, U-Net and simple thresholding reduced total processing time to milliseconds per image, compared to 45 s per image for manual processing. However, the higher mean Dice coefficient of Habitat-Net (0.94 for canopy and 0.95 for understory) indicates that accuracy of Habitat-Net is higher than that of both the simple thresholding (0.64, 0.83) and U-Net (0.89, 0.94). Habitat-Net will be of great relevance for ecologists and foresters, who need to monitor changes in their forest structures. The automated workflow not only reduces the time, it also standardizes the analytical pipeline and, thus, reduces the degree of uncertainty that would be introduced by manual processing of images by different people (either over time or between study sites)."																				
2019	"Ahmed, Ahmed; Yousif, Hayder; Kays, Roland; He, Zhihai"	Semantic region of interest and species classification in the deep neural network feature domain	Images	CNN	Regression	Ecological Informatics	52		57-68	10.1016/j.ecoinf.2019.05.006	https://www.sciencedirect.com/science/article/pii/S1574954118301481	"In this paper, we focus on animal object detection and species classification in camera-trap images collected in highly cluttered natural scenes. Using a deep neural network (DNN) model training for animal- background image classification, we analyze the input camera-trap images to generate a multi-level visual representation of the input image. We detect semantic regions of interest for animals from this representation using k-mean clustering and graph cut in the DNN feature domain. These animal regions are then classified into animal species using multi-class deep neural network model. According the experimental results, our method achieves 99.75% accuracy for classifying animals and background and 90.89% accuracy for classifying 26 animal species on the Snapshot Serengeti dataset, outperforming existing image classification methods."																				
2019	"Allken, Vaneeda; Handegard, Nils Olav; Rosen, Shale; Schreyeck, Tiffanie; Mahiout, Thomas; Malde, Ketil"	Fish species identification using a convolutional neural network trained on synthetic data	Images	CNN	Classification	ICES Journal of Marine Science	76	1	342-349	10.1093/icesjms/fsy147	https://doi.org/10.1093/icesjms/fsy147	"Acoustic-trawl surveys are an important tool for marine stock management and environmental monitoring of marine life. Correctly assigning the acoustic signal to species or species groups is a challenge, and recently trawl camera systems have been developed to support interpretation of acoustic data. Examining images from known positions in the trawl track provides high resolution ground truth for the presence of species. Here, we develop and deploy a deep learning neural network to automate the classification of species present in images from the Deep Vision trawl camera system. To remedy the scarcity of training data, we developed a novel training regime based on realistic simulation of Deep Vision images. We achieved a classification accuracy of 94% for blue whiting, Atlantic herring, and Atlantic mackerel, showing that automatic species classification is a viable and efficient approach, and further that using synthetic data can effectively mitigate the all too common lack of training data."																				
2019	"Amin, Noorul; McGrath, Annette; Chen, Yi-Ping Phoebe"	Evaluation of deep learning in non-coding RNA classification	NA	NA	Review	Nature Machine Intelligence	1	5	246-256	10.1038/s42256-019-0051-2	https://www.nature.com/articles/s42256-019-0051-2	"Non-coding (nc) RNA plays a vital role in biological processes and has been associated with diseases such as cancer. Classification of ncRNAs is necessary for understanding the underlying mechanisms of the diseases and to design effective treatments. Recently, deep learning has been employed for ncRNA identification and classification and has shown promising results. In this study, we review the progress of ncRNA type classification, specifically lncRNA, lincRNA, circular RNA and small ncRNA, and present a comprehensive comparison of six deep learning based classification methods published in the past two years. We identify research gaps and challenges of ncRNA types, such as the classification of subclasses of lncRNA, transcript length and compositional variation, dependency on database searches and the high false positive rate of existing approaches. We suggest future directions for cross-species performance deviation, deep learning model selection and sequence intrinsic features."																				
2019	"Ärje, Johanna; Raitoharju, Jenni; Iosifidis, Alexandros; Tirronen, Ville; Meissner, Kristian; Gabbouj, Moncef; Kiranyaz, Serkan; Kärkkäinen, Salme"	Human experts vs. machines in taxa recognition	Images	CNN	Classification	Signal Processing: Image Communication	87		115917	10.1016/j.image.2020.115917	https://www.sciencedirect.com/science/article/pii/S0923596520301132?via%3Dihub	"The step of expert taxa recognition currently slows down the response time of many bioassessments. Shifting to quicker and cheaper state-of-the-art machine learning approaches is still met with expert scepticism towards the ability and logic of machines. In our study, we investigate both the differences in accuracy and in the identification logic of taxonomic experts and machines. We propose a systematic approach utilizing deep Convolutional Neural Nets and extensively evaluate it over a multi-pose taxonomic dataset with hierarchical labels specifically created for this comparison. We also study the prediction accuracy on different ranks of taxonomic hierarchy in detail. We compare the results of Convolutional Neural Networks to human experts and support vector machines. Our results revealed that human experts using actual specimens yield the lowest classification error (CE = 6.1%). However, a much faster, automated approach using deep Convolutional Neural Nets comes close to human accuracy (CE = 11.4%) when a typical flat classification approach is used. Contrary to previous findings in the literature, we find that for machines following a typical flat classification approach commonly used in machine learning performs better than forcing machines to adopt a hierarchical, local per parent node approach used by human taxonomic experts (CE = 13.8%). Finally, we publicly share our unique dataset to serve as a public benchmark dataset in this field."																				
2019	"Aronica, S.; Fontana, I.; Giacalone, G.; Lo Bosco, G.; Rizzo, R.; Mazzola, S.; Basilone, G.; Ferreri, R.; Genovese, S.; Barra, M.; Bonanno, A."	Identifying small pelagic Mediterranean fish schools from acoustic and environmental data using optimized artificial neural networks	"Sound, Environmental"	"DNN, CNN"	Classification	Ecological Informatics	50		149-161	10.1016/j.ecoinf.2018.12.007	https://www.sciencedirect.com/science/article/pii/S1574954118301882	"The Common Fisheries Policy of the European Union aims to exploit fish stocks at a level of Maximum Sustainable Yield by 2020 at the latest. At the Mediterranean level, the General Fisheries Commission for the Mediterranean (GFCM) has highlighted the importance of reversing the observed declining trend of fish stocks. In this complex context, it is important to obtain reliable biomass estimates to support scientifically sound advice for sustainable management of marine resources. This paper presents a machine learning methodology for the classification of pelagic species schools from acoustic and environmental data. In particular, the methodology was tuned for the recognition of anchovy, sardine and horse mackerel. These species have a central role in the fishing industry of Mediterranean countries and they are also of considerable importance in the trophic web because they occupy the so-called middle trophic level. The proposed methodology consists of a classifier based on an optimized two layer feed-forward neural network. Morphological, bathymetric, energetic and positional features, extracted from acoustic data, are used as input, together with other environmental data features. The classifier uses an optimal number of neurons in the hidden layer, and a feature selection strategy based on a genetic algorithm. Working on a dataset of 2565 fish schools, the proposed methodology permitted us to identify the these three fish species with an accuracy of around 95%."																				
2019	"Arsenovic, Marko; Karanovic, Mirjana; Sladojevic, Srdjan; Anderla, Andras; Stefanovic, Darko"	Solving Current Limitations of Deep Learning Based Approaches for Plant Disease Detection	Images	CNN	Classification	Symmetry	11	7	939	10.3390/sym11070939	https://www.mdpi.com/2073-8994/11/7/939	"Plant diseases cause great damage in agriculture, resulting in significant yield losses. The recent expansion of deep learning methods has found its application in plant disease detection, offering a robust tool with highly accurate results. The current limitations and shortcomings of existing plant disease detection models are presented and discussed in this paper. Furthermore, a new dataset containing 79,265 images was introduced with the aim to become the largest dataset containing leaf images. Images were taken in various weather conditions, at different angles, and daylight hours with an inconsistent background mimicking practical situations. Two approaches were used to augment the number of images in the dataset: traditional augmentation methods and state-of-the-art style generative adversarial networks. Several experiments were conducted to test the impact of training in a controlled environment and usage in real-life situations to accurately identify plant diseases in a complex background and in various conditions including the detection of multiple diseases in a single leaf. Finally, a novel two-stage architecture of a neural network was proposed for plant disease classification focused on a real environment. The trained model achieved an accuracy of 93.67%."																				
2019	"Ba_cıo_lu, Murat; Fricker, Martina; Johler, Sophia; Ehling-Schulz, Monika"	"Detection and Identification of Bacillus cereus, Bacillus cytotoxicus, Bacillus thuringiensis, Bacillus mycoides and Bacillus weihenstephanensis via Machine Learning Based FTIR Spectroscopy"	Images	DNN	Classification	Frontiers in Microbiology	10			10.3389/fmicb.2019.00902	https://www.frontiersin.org/article/10.3389/fmicb.2019.00902	"The Bacillus cereus group comprises genetical closely related species with variable toxigenic characteristics. However, detection and differentiation of the B. cereus group species in routine diagnostics can be difficult, expensive and laborious since current species designation is linked to specific phenotypic characteristic or the presence of species-specific genes. Especially the differentiation of Bacillus cereus and Bacillus thuringiensis, the identification of psychrotolerant Bacillus mycoides and Bacillus weihenstephanensis, as well as the identification of emetic B. cereus and Bacillus cytotoxicus, which are both producing highly potent toxins, is of high importance in food microbiology. Thus, we investigated the use of a machine learning approach, based on artificial neural network (ANN) assisted Fourier transform infrared (FTIR) spectroscopy, for discrimination of B. cereus group members. The deep learning tool box of Matlab was employed to construct a one-level ANN, allowing the discrimination of the aforementioned B. cereus group members. This model resulted in 100% correct identification for the training set and 99.5% correct identification overall. The established ANN was applied to investigate the composition of B. cereus group members in soil, as a natural habitat of B. cereus, and in food samples originating from foodborne outbreaks. These analyses revealed a high complexity of B. cereus group populations, not only in soil samples but also in the samples from the foodborne outbreaks, highlighting the importance of taking multiple isolates from samples implicated in food poisonings. Notable, in contrast to the soil samples, no bacteria belonging to the psychrotolerant B. cereus group members were detected in the food samples linked to foodborne outbreaks, while the overall abundancy of B. thuringiensis did not significantly differ between the sample categories. None of the isolates was classified as B. cytotoxicus, fostering the hypothesis that the latter species is linked to very specific ecological niches. Overall, our work shows that machine learning assisted (FTIR) spectroscopy is suitable for identification of B. cereus group members in routine diagnostics and outbreak investigations. In addition, it is a promising tool to explore the natural habitats of B. cereus group, such as soil."																				
2019	"Barbedo, Jayme G.A.; Castro, Guilherme B."	Influence of image quality on the identification of psyllids using convolutional neural networks	Images	CNN	Classification	Biosystems Engineering	182		151-158	10.1016/j.biosystemseng.2019.04.007	https://linkinghub.elsevier.com/retrieve/pii/S153751101930282X	"Convolutional Neural Networks (CNNs) usually require large datasets to be properly trained. Although techniques such as transfer learning can relax those requirements, gathering sufficient labelled data to cover all the variability associated to the problem at hand is often costly and time consuming. A way to minimise this challenge would be gathering the training data under laboratory conditions, using high quality sensors capable of generating images with superior resolution, sharpness and contrast. The downside of this approach is that the resulting dataset will most likely lack the variety that can be found under more realistic conditions. This work investigates this trade-off between image quality and dataset representativeness, that is, if a CNN trained with images captured by a scanner in laboratory would be able to reliably recognise psyllids in smartphone images captured under more realistic conditions. A total of 1276 images were used in the experiments, half acquired using a flatbed scanner and half acquired using two different brands of smartphones. Experiments were carried out using Squeezenet CNNs and a 10-fold cross-validation strategy. Accuracies ranged from less than 70% using only scanned images, to around 90% when only smartphone images were employed, indicating that more realistic conditions are essential to guarantee the robustness of the trained network. Scanned images were useful when the training set containing realistic images was not enough to cover all the variability found in the experiments, but were otherwise innocuous."																				
2019	"Bayr, Ulrike; Puschmann, Oskar"	Automatic detection of woody vegetation in repeat landscape photographs using a convolutional neural network	Images	CNN	Classification	Ecological Informatics	50		220-233	10.1016/j.ecoinf.2019.01.012	https://www.sciencedirect.com/science/article/pii/S1574954118303121	"Repeat photography is an efficient method for documenting long-term landscape changes. So far, the usage of repeat photographs for quantitative analyses is limited to approaches based on manual classification. In this paper, we demonstrate the application of a convolutional neural network (CNN) for the automatic detection and classification of woody regrowth vegetation in repeat landscape photographs. We also tested if the classification results based on the automatic approach can be used for quantifying changes in woody vegetation cover between image pairs. The CNN was trained with 50___50 pixel tiles of woody vegetation and non-woody vegetation. We then tested the classifier on 17 pairs of repeat photographs to assess the model performance on unseen data. Results show that the CNN performed well in differentiating woody vegetation from non-woody vegetation (accuracy_=_87.7%), but accuracy varied strongly between individual images. The very similar appearance of woody vegetation and herbaceous species in photographs made this a much more challenging task compared to the classification of vegetation as a single class (accuracy_=_95.2%). In this regard, image quality was identified as one important factor influencing classification accuracy. Although the automatic classification provided good individual results on most of the 34 test photographs, change statistics based on the automatic approach deviated from actual changes. Nevertheless, the automatic approach was capable of identifying clear trends in increasing or decreasing woody vegetation in repeat photographs. Generally, the use of repeat photography in landscape monitoring represents a significant added value to other quantitative data retrieved from remote sensing and field measurements. Moreover, these photographs are able to raise awareness on landscape change among policy makers and public as well as they provide clear feedback on the effects of land management."																				
2019	"Bergler, Christian; Schröter, Hendrik; Cheng, Rachael Xi; Barth, Volker; Weber, Michael; Nöth, Elmar; Hofer, Heribert; Maier, Andreas"	ORCA-SPOT: An Automatic Killer Whale Sound Detection Toolkit Using Deep Learning	Sound	CNN	Classification	Scientific Reports	9	1	10997	10.1038/s41598-019-47335-w	http://www.nature.com/articles/s41598-019-47335-w	"Large bioacoustic archives of wild animals are an important source to identify reappearing communication patterns, which can then be related to recurring behavioral patterns to advance the current understanding of intra-specific communication of non-human animals. A main challenge remains that most large-scale bioacoustic archives contain only a small percentage of animal vocalizations and a large amount of environmental noise, which makes it extremely difficult to manually retrieve sufficient vocalizations for further analysis – particularly important for species with advanced social systems and complex vocalizations. In this study deep neural networks were trained on 11,509 killer whale (Orcinus orca) signals and 34,848 noise segments. The resulting toolkit ORCA-SPOT was tested on a large-scale bioacoustic repository – the Orchive – comprising roughly 19,000 hours of killer whale underwater recordings. An automated segmentation of the entire Orchive recordings (about 2.2 years) took approximately 8 days. It achieved a time-based precision or positive-predictive-value (PPV) of 93.2% and an area-under-the-curve (AUC) of 0.9523. This approach enables an automated annotation procedure of large bioacoustics databases to extract killer whale sounds, which are essential for subsequent identification of significant communication patterns. The code will be publicly available in October 2019 to support the application of deep learning to bioaoucstic research. ORCA-SPOT can be adapted to other animal species."																				
2019	"Bermant, Peter C.; Bronstein, Michael M.; Wood, Robert J.; Gero, Shane; Gruber, David F."	Deep Machine Learning Techniques for the Detection and Classification of Sperm Whale Bioacoustics	Sound	"CNN, RNN"	Classification	Scientific Reports	9	1	12588	10.1038/s41598-019-48909-4	https://www.nature.com/articles/s41598-019-48909-4	"We implemented Machine Learning (ML) techniques to advance the study of sperm whale (Physeter macrocephalus) bioacoustics. This entailed employing Convolutional Neural Networks (CNNs) to construct an echolocation click detector designed to classify spectrograms generated from sperm whale acoustic data according to the presence or absence of a click. The click detector achieved 99.5% accuracy in classifying 650 spectrograms. The successful application of CNNs to clicks reveals the potential of future studies to train CNN-based architectures to extract finer-scale details from cetacean spectrograms. Long short-term memory and gated recurrent unit recurrent neural networks were trained to perform classification tasks, including (1) “coda type classification” where we obtained 97.5% accuracy in categorizing 23 coda types from a Dominica dataset containing 8,719 codas and 93.6% accuracy in categorizing 43 coda types from an Eastern Tropical Pacific (ETP) dataset with 16,995 codas; (2) “vocal clan classification” where we obtained 95.3% accuracy for two clan classes from Dominica and 93.1% for four ETP clan types; and (3) “individual whale identification” where we obtained 99.4% accuracy using two Dominica sperm whales. These results demonstrate the feasibility of applying ML to sperm whale bioacoustics and establish the validity of constructing neural networks to learn meaningful representations of whale vocalizations."																				
2019	"Bertran, Marta; Alsina-Pagès, Rosa Ma; Tena, Elena"	Pipistrellus pipistrellus and Pipistrellus pygmaeus in the Iberian Peninsula: An Annotated Segmented Dataset and a Proof of Concept of a Classifier in a Real Environment	Sound	"DNN, CNN"	Classification	Applied Sciences	9	17	3467	10.3390/app9173467	https://www.mdpi.com/2076-3417/9/17/3467	"Bats have an important role in the ecosystem, and therefore an effective detection of their prevalence can contribute to their conservation. At present, the most commonly methodology used in the study of bats is the analysis of echolocation calls. However, many other ultrasound signals can be simultaneously recorded, and this makes species location and identification a long and difficult task. This field of research could be greatly improved through the use of bioacoustics which provide a more accurate automated detection, identification and count of the wildlife of a particular area. We have analyzed the calls of two bat species—Pipistrellus pipistrellus and Pipistrellus pygmaeus—both of which are common types of bats frequently found in the Iberian Peninsula. These two cryptic species are difficult to identify by their morphological features, but are more easily identified by their echolocation calls. The real-life audio files have been obtained by an Echo Meter Touch Pro 1 bat detector. Time-expanded recordings of calls were first classified manually by means of their frequency, duration and interpulse interval. In this paper, we first detail the creation of a dataset with three classes, which are the two bat species but also the silent intervals. This dataset can be useful to work in mixed species environment. Afterwards, two automatic bat detection and identification machine learning approaches are described, in a laboratory environment, which represent the previous step to real-life in an urban scenario. The priority in that approaches design is the identification using short window analysis in order to detect each bat pulse. However, given that we are concerned with the risks of automatic identification, the main aim of the project is to accelerate the manual ID process for the specialists in the field. The dataset provided will help researchers develop automatic recognition systems for a more accurate identification of the bat species in a laboratory environment, and in a near future, in an urban environment, where those two bat species are common."																				
2019	"Bojamma, A. M.; Shastry, Chandrasekar"	A study on the machine learning techniques for automated plant species identification: current trends and challenges	NA	NA	Review	International Journal of Information Technology				10.1007/s41870-019-00379-7	http://link.springer.com/10.1007/s41870-019-00379-7	"Plant identification plays a crucial role in sustaining the balance of the environment and protecting the biodiversity of a region. Recognizing different species of plants using conventional methods for conservation purposes is a tedious task. Today there is a cumulative effort made by computer scientists and botanists to automate the entire process of plant identification with leaf being a key feature for distinguishing different species of plants. With the advancement and utilization of relevant technologies like digital cameras, mobile cameras, newer techniques in image processing, pattern recognition, machine learning, automation of this system has been a reality. In this paper we have reviewed the current status of research on computer vision methodologies for taxonomical identification of plants and have also focused on the research challenges such as the diversity of the taxa to be identified, morphological variation in plants belonging to the same species, smaller interspecies variations, the challenges in acquisition of high quality images and standard datasets. The future trends in use of new technologies, creation of standard databases and interdisciplinary aspect of research is also discussed."																				
2019	"Borowicz, Alex; Le, Hieu; Humphries, Grant; Nehls, Georg; Höschle, Caroline; Kosarev, Vladislav; Lynch, Heather J."	Aerial-trained deep learning networks for surveying cetaceans from satellite imagery	Images	CNN	Classification	PLOS ONE	14	10	e0212532	10.1371/journal.pone.0212532	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0212532	"Most cetacean species are wide-ranging and highly mobile, creating significant challenges for researchers by limiting the scope of data that can be collected and leaving large areas un-surveyed. Aerial surveys have proven an effective way to locate and study cetacean movements but are costly and limited in spatial extent. Here we present a semi-automated pipeline for whale detection from very high-resolution (sub-meter) satellite imagery that makes use of a convolutional neural network (CNN). We trained ResNet, and DenseNet CNNs using down-scaled aerial imagery and tested each model on 31 cm-resolution imagery obtained from the WorldView-3 sensor. Satellite imagery was tiled and the trained algorithms were used to classify whether or not a tile was likely to contain a whale. Our best model correctly classified 100% of tiles with whales, and 94% of tiles containing only water. All model architectures performed well, with learning rate controlling performance more than architecture. While the resolution of commercially-available satellite imagery continues to make whale identification a challenging problem, our approach provides the means to efficiently eliminate areas without whales and, in doing so, greatly accelerates ocean surveys for large cetaceans."																				
2019	"Cai, Jiahao; Xiao, Deqin; Lv, Lishan; Ye, Yaowen"	An early warning model for vegetable pests based on multidimensional data	Environmental	DNN	Regression	Computers and Electronics in Agriculture	156		217-226	10.1016/j.compag.2018.11.019	https://www.sciencedirect.com/science/article/pii/S0168169918307476	"Based on the research of sensor networks, pest monitoring equipment and systematic research, we mainly studied the major pests of south China vegetables, such as Bemisia Tabaci, Beetles, Plutellaxy Lostella and Thrips Tabaci. Using the multi-sensor network system, we collected the multi-dimensional information of the number of pests, soil, environment, ecological climate and meteorological factors in real time, on which a multi-dimensional big data based vegetable pest early warning model was constructed. According to the number of pests, the model used k-means algorithm to classify the damage into four levels: Mild, Moderate, Moderately Severe, and Severe. The correlation coefficient and gray relational degree were used to find out the key factors between the number of pests and the multi-dimensional information such as the vegetable soil, environment, ecology climate and meteorology, and based on BP neural network model, the key impact factors were trained, we find out five key impact factors: Rainfall Volume, Carbon Dioxide Concentration, Soil Temperature, Air Temperature and Foliar Humidity from June 2016 to February 2017. Finally, the selected characteristic data were normalized and then learned by BP Neural Network. The results showed that the recognition rate of the pests in southern vegetables was 96.7%. The algorithm is proved to be of high availability, meets the needs of early warning of pests and has a broad application prospect."																				
2019	"Cao, Kaidi; Wei, Colin; Gaidon, Adrien; Arechiga, Nikos; Ma, Tengyu"	Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss	Images	CNN	Classification	arXiv				10.48550/arxiv.1906.07413	http://arxiv.org/abs/1906.07413	"Deep learning algorithms can fare poorly when the training dataset suffers from heavy class-imbalance but the testing criterion requires good generalization on less frequent classes. We design two novel methods to improve performance in such scenarios. First, we propose a theoretically-principled label-distribution-aware margin (LDAM) loss motivated by minimizing a margin-based generalization bound. This loss replaces the standard cross-entropy objective during training and can be applied with prior strategies for training with class-imbalance such as re-weighting or re-sampling. Second, we propose a simple, yet effective, training schedule that defers re-weighting until after the initial stage, allowing the model to learn an initial representation while avoiding some of the complications associated with re-weighting or re-sampling. We test our methods on several benchmark vision tasks including the real-world imbalanced dataset iNaturalist 2018. Our experiments show that either of these methods alone can already improve over existing techniques and their combination achieves even better performance gains."																				
2019	"Chen, Ruilong; Little, Ruth; Mihaylova, Lyudmila; Delahay, Richard; Cox, Ruth"	Wildlife surveillance using deep learning methods	Images	CNN	Classification	Ecology and Evolution	9	17	9453-9466	10.1002/ece3.5410	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.5410	"Wildlife conservation and the management of human–wildlife conflicts require cost-effective methods of monitoring wild animal behavior. Still and video camera surveillance can generate enormous quantities of data, which is laborious and expensive to screen for the species of interest. In the present study, we describe a state-of-the-art, deep learning approach for automatically identifying and isolating species-specific activity from still images and video data. We used a dataset consisting of 8,368 images of wild and domestic animals in farm buildings, and we developed an approach firstly to distinguish badgers from other species (binary classification) and secondly to distinguish each of six animal species (multiclassification). We focused on binary classification of badgers first because such a tool would be relevant to efforts to manage Mycobacterium bovis (the cause of bovine tuberculosis) transmission between badgers and cattle. We used two deep learning frameworks for automatic image recognition. They achieved high accuracies, in the order of 98.05% for binary classification and 90.32% for multiclassification. Based on the deep learning framework, a detection process was also developed for identifying animals of interest in video footage, which to our knowledge is the first application for this purpose. The algorithms developed here have wide applications in wildlife monitoring where large quantities of visual data require screening for certain species."																				
2019	"Christin, Sylvain; Hervet, Éric; Lecomte, Nicolas"	Applications for deep learning in ecology	NA	NA	Review	Methods in Ecology and Evolution	10	10	1632-1644	10.1111/2041-210X.13256	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13256	"A lot of hype has recently been generated around deep learning, a novel group of artificial intelligence approaches able to break accuracy records in pattern recognition. Over the course of just a few years, deep learning has revolutionized several research fields such as bioinformatics and medicine with its flexibility and ability to process large and complex datasets. As ecological datasets are becoming larger and more complex, we believe these methods can be useful to ecologists as well. In this paper, we review existing implementations and show that deep learning has been used successfully to identify species, classify animal behaviour and estimate biodiversity in large datasets like camera-trap images, audio recordings and videos. We demonstrate that deep learning can be beneficial to most ecological disciplines, including applied contexts, such as management and conservation. We also identify common questions about how and when to use deep learning, such as what are the steps required to create a deep learning network, which tools are available to help, and what are the requirements in terms of data and computer power. We provide guidelines, recommendations and useful resources, including a reference flowchart to help ecologists get started with deep learning. We argue that at a time when automatic monitoring of populations and ecosystems generates a vast amount of data that cannot be effectively processed by humans anymore, deep learning could become a powerful reference tool for ecologists."																				
2019	"Chulu, Francis; Phiri, Jackson; O.Y., Phillip; Nyirenda, Mayumbo; M.Kabemba, Monica; H.Sohati, Philemon"	A Convolutional Neural Network for Automatic Identification and Classification of Fall Army Worm Moth	Images	CNN	Classification	International Journal of Advanced Computer Science and Applications	10	7		10.14569/IJACSA.2019.0100717	http://thesai.org/Publications/ViewPaper?Volume=10&Issue=7&Code=IJACSA&SerialNo=17	"To combat the problem caused by the Fall Army Worm in the country there is a need to come up with robust early warning and monitoring systems as the current manual system is labor intensive and time consuming. The automation of the identification and classification of the insect is one of the novel methods that can be undertaken. Therefore this paper presents the results of training a Convolutional Neural Network model using Google’s Tensorflow Deep Learning Framework for the identification and classification of the Fall Army worm moth. Due to lack of enough training dataset and good computing power, we used transfer learning, which is the process of reusing a model trained on one task as a starting point for a model on a second task. Googles pre-trained InceptionV3 model was used as the underlying model. Data was collected from four sources namely the field, Lab setup, by crawling the internet and using Data Augmentation. We Present results of the best three trials in terms of training accuracy after several attempts to get the best metrics in terms of learning rate and training steps. The best model gave a prediction average accuracy of 82% and a 32% average prediction accuracy on false positives. The results shows that it is possible to automate the identification and classification of the Fall Army worm Moth using Convolutional Neural Networks."																				
2019	"Clauwaert, Jim; Menschaert, Gerben; Waegeman, Willem"	DeepRibo: a neural network for precise gene annotation of prokaryotes by combining ribosome profiling signal and binding site patterns	Molecular	CNN	Classification	Nucleic Acids Research	47	6	e36	10.1093/nar/gkz061	https://doi.org/10.1093/nar/gkz061	"Annotation of gene expression in prokaryotes often finds itself corrected due to small variations of the annotated gene regions observed between different (sub)-species. It has become apparent that traditional sequence alignment algorithms, used for the curation of genomes, are not able to map the full complexity of the genomic landscape. We present DeepRibo, a novel neural network utilizing features extracted from ribosome profiling information and binding site sequence patterns that shows to be a precise tool for the delineation and annotation of expressed genes in prokaryotes. The neural network combines recurrent memory cells and convolutional layers, adapting the information gained from both the high-throughput ribosome profiling data and ribosome binding translation initiation sequence region into one model. DeepRibo is designed as a single model trained on a variety of ribosome profiling experiments, used for the identification of open reading frames in prokaryotes without a priori knowledge of the translational landscape. Through extensive validation of the model trained on various sets of data, multiple species sequence similarity, mass spectrometry and Edman degradation verified proteins, the effectiveness of DeepRibo is highlighted."																				
2019	"Corcoran, Evangeline; Denman, Simon; Hanger, Jon; Wilson, Bree; Hamilton, Grant"	Automated detection of koalas using low-level aerial surveillance and machine learning	Other	CNN	Regression	Scientific Reports	9	1	3208	10.1038/s41598-019-39917-5	https://www.nature.com/articles/s41598-019-39917-5	"Effective wildlife management relies on the accurate and precise detection of individual animals. These can be challenging data to collect for many cryptic species, particularly those that live in complex structural environments. This study introduces a new automated method for detection using published object detection algorithms to detect their heat signatures in RPAS-derived thermal imaging. As an initial case study we used this new approach to detect koalas (Phascolarctus cinereus), and validated the approach using ground surveys of tracked radio-collared koalas in Petrie, Queensland. The automated method yielded a higher probability of detection (68–100%), higher precision (43–71%), lower root mean square error (RMSE), and lower mean absolute error (MAE) than manual assessment of the RPAS-derived thermal imagery in a comparable amount of time. This new approach allows for more reliable, less invasive detection of koalas in their natural habitat. This new detection methodology has great potential to inform and improve management decisions for threatened species, and other difficult to survey species."																				
2019	"Derkarabetian, Shahan; Castillo, Stephanie; Koo, Peter K.; Ovchinnikov, Sergey; Hedin, Marshal"	A demonstration of unsupervised machine learning in species delimitation	Molecular	VAE	Classification	Molecular Phylogenetics and Evolution	139		106562	10.1016/j.ympev.2019.106562	https://linkinghub.elsevier.com/retrieve/pii/S1055790319301721	"One major challenge to delimiting species with genetic data is successfully differentiating population structure from species-level divergence, an issue exacerbated in taxa inhabiting naturally fragmented habitats. Many fields of science are now using machine learning, and in evolutionary biology supervised machine learning has recently been used to infer species boundaries. These supervised methods require training data with associated labels. Conversely, unsupervised machine learning (UML) uses inherent data structure and does not require user-specified training labels, potentially providing more objectivity in species delimitation. In the context of integrative taxonomy, we demonstrate the utility of three UML approaches (random forests, variational autoencoders, t-distributed stochastic neighbor embedding) for species delimitation in an arachnid taxon with high population genetic structure (Opiliones, Laniatores, Metanonychus). We find that UML approaches successfully cluster samples according to species-level divergences and not high levels of population structure, while model-based validation methods severely over-split putative species. UML offers intuitive data visualization in two-dimensional space, the ability to accommodate various data types, and has potential in many areas of systematic and evolutionary biology. We argue that machine learning methods are ideally suited for species delimitation and may perform well in many natural systems and across taxa with diverse biological characteristics"																				
2019	"dos Santos Ferreira, Alessandro; Freitas, Daniel Matte; da Silva, Gercina Gonçalves; Pistori, Hemerson; Folhes, Marcelo Theophilo"	Unsupervised deep learning and semi-automatic data labeling in weed discrimination	Images	CNN	Modeling	Computers and Electronics in Agriculture	165		104963	10.1016/j.compag.2019.104963	https://www.sciencedirect.com/science/article/pii/S0168169919313237	"In recent years, supervised Deep Neural Networks have achieved the state-of-the-art in image recognition and this success has spread in many areas. In agricultural field, several researches have been conducted using architectures such as Convolutional Neural Networks. Despite this success, these works are still highly dependent on very time–costly manual data labeling. In contrast to this scenario, Unsupervised Deep Learning has no dependency on data labeling and is targeted as the future of the area, but after a promising start has been obfuscated by the success of supervised networks. Meanwhile, the low-cost of acquisition of field crop imagery using Unnamed Aerial Vehicles could be largely boosted in real-world applications if these images could be annotated without the need for a human specialist. In this work, we tested two recent unsupervised deep clustering algorithms, Joint Unsupervised Learning of Deep Representations and Image Clusters (JULE) and Deep Clustering for Unsupervised Learning of Visual Features (DeepCluster), using two public weed datasets. The first dataset was captured in a soybean plantation in Brazil and discriminates weeds between grass and broadleaf. The second dataset consists of 17,509 labeled images of eight nationally significant weed species native to Australia. We evaluated the purely unsupervised clustering performance using the NMI and Unsupervised Clustering Accuracy metrics and analysed the effects of techniques like data augmentation and transfer learning to improve clustering quality in a broad discussion that can be useful for unsupervised deep clustering in general. We also propose the usage of semi-automatic data labeling which greatly reduces the cost of manual data labeling and can be easily replicated to different datasets. This approach achieved 97% accuracy in discrimination of grass and broadleaf while reducing the number of manual annotations by 100 times, using a custom set of training images, without images labeled using inaccurate clusters."																				
2019	"Duhart, Clement; Dublon, Gershon; Mayton, Brian; Davenport, Glorianna; Paradiso, Joseph A"	Deep Learning for Wildlife Conservation and Restoration Efforts	"Images, Sound"	Other	Classification	36th International Conference on Machine Learning (ICML)				NA	https://www.climatechange.ai/papers/icml2019/31/paper.pdf	"Climate change and environmental degradation are causing species extinction worldwide. Automatic wildlife sensing is an urgent requirement to track biodiversity losses on Earth. Recent improvements in machine learning can accelerate the development of large-scale monitoring systems that would help track conservation outcomes and target efforts. In this paper, we present one such system we developed. ’Tidzam’ is a Deep Learning framework for wildlife detection, identification, and geolocalization, designed for the Tidmarsh Wildlife Sanctuary, the site of the largest freshwater wetland restoration in Massachusetts."																				
2019	"Dujon, Antoine M.; Schofield, Gail"	Importance of machine learning for enhancing ecological studies using information-rich imagery	Images	CNN	Classification	Endangered Species Research	39		91-104	10.3354/esr00958	https://www.int-res.com/abstracts/esr/v39/p91-104/	"There is increasing demand for efficient ways to process large volumes of data from visual-based remote-technology, such as unmanned aerial vehicles (UAVs) in ecology and conservation, with machine learning methods representing a promising avenue to address varying user demands. Here, we evaluated current trends in how machine learning and UAVs are used to process imagery data for detecting animals and vegetation across habitats, placing emphasis on their utility for endangered species. We reviewed 213 publications that used UAVs at 256 study sites, of which just 89 (42%) used machine learning to assess the visual data. We evaluated geographical and temporal trends and identified how each technology is used at a global scale. We also identified the most commonly encountered machine-learning methods, including potential reasons for their limited use in ecology and possible solutions. Thirteen out of the 17 habitats defined by the International Union for Conservation of Nature (IUCN) habitat classification scheme were monitored using UAVs, while 12 habitats were monitored using both UAVs and machine learning. Our results show that, while machine learning is already being used across many habitat types, it is primarily restricted to more uniform habitats at present. Out of 173 plant and animal species monitored using UAV surveys, 30 were of conservation concern, with machine learning being used to assess UAV imagery data for 9 of these species. In conclusion, we anticipate that the joint use of UAVs and machine learning for ecological research and conservation will expand as machine learning methods become more accessible."																				
2019	"Dwivedi, Ashok Kumar; Chouhan, Usha"	Classification of Hot and Cold Recombination Regions in Saccharomyces cerevisiae: Comparative Analysis of Two Machine Learning Techniques	Molecular	Unknown	Classification	"Proceedings of the National Academy of Sciences, India Section A: Physical Sciences"	89	2	249-256	10.1007/s40010-017-0427-9	https://doi.org/10.1007/s40010-017-0427-9	"Recombination plays a crucial role generating natural genetic variations. Nevertheless, the recombination does not occur randomly in the genome, but with higher allure in some genomic regions while low in other regions, former are called hot recombination regions and later are called cold regions for recombination. With the advancement of genome sequencing techniques, computational methods are required which can efficiently classify the recombination regions. For this we have developed artificial neural network based model which uses amino acid composition features of DNA sequences. Compositional features were used to incorporate its local or short range sequence order information. High accuracy and sensitivity indicates that this model may become a useful tool for identifying the recombination hotspots. Moreover we compared the performance artificial neural network model with support vector machine model with the target class as hot and cold. We found that compositional features gives good classification result which probably reflect the structural and functional characteristics of hot and cold spots."																				
2019	"Eli-Chukwu, N. C."	Applications of Artificial Intelligence in Agriculture: A Review	NA	NA	Review	"Engineering, Technology & Applied Science Research"	9	4	4377-4383	10.48084/etasr.2756	http://etasr.com/index.php/ETASR/article/view/2756	"The application of Artificial Intelligence (AI) has been evident in the agricultural sector recently. The sector faces numerous challenges in order to maximize its yield including improper soil treatment, disease and pest infestation, big data requirements, low output, and knowledge gap between farmers and technology. The main concept of AI in agriculture is its flexibility, high performance, accuracy, and cost-effectiveness. This paper presents a review of the applications of AI in soil management, crop management, weed management and disease management. A special focus is laid on the strength and limitations of the application and the way in utilizing expert systems for higher productivity."																				
2019	"Eraslan, Gökcen; Avsec, _iga; Gagneur, Julien; Theis, Fabian J."	Deep learning: new computational modelling techniques for genomics	NA	NA	Review	Nature Reviews Genetics	20	7	389-403	10.1038/s41576-019-0122-6	https://www.nature.com/articles/s41576-019-0122-6	"As a data-driven science, genomics largely utilizes machine learning to capture dependencies in data and derive novel biological hypotheses. However, the ability to extract new insights from the exponentially increasing volume of genomics data requires more expressive machine learning models. By effectively leveraging large data sets, deep learning has transformed fields such as computer vision and natural language processing. Now, it is becoming the method of choice for many genomics modelling tasks, including predicting the impact of genetic variation on gene regulatory mechanisms such as DNA accessibility and splicing."																				
2019	"Ezray, Briana D.; Wham, Drew C.; Hill, Carrie E.; Hines, Heather M."	Unsupervised machine learning reveals mimicry complexes in bumblebees occur along a perceptual continuum	Images	CNN	Modeling	Proceedings of the Royal Society B: Biological Sciences	286	1910	20191501	10.1098/rspb.2019.1501	https://royalsocietypublishing.org/doi/10.1098/rspb.2019.1501	"Müllerian mimicry theory states that frequency-dependent selection should favour geographical convergence of harmful species onto a shared colour pattern. As such, mimetic patterns are commonly circumscribed into discrete mimicry complexes, each containing a predominant phenotype. Outside a few examples in butterflies, the location of transition zones between mimicry complexes and the factors driving mimicry zones has rarely been examined. To infer the patterns and processes of Müllerian mimicry, we integrate large-scale data on the geographical distribution of colour patterns of social bumblebees across the contiguous United States and use these to quantify colour pattern mimicry using an innovative, unsupervised machine-learning approach based on computer vision. Our data suggest that bumblebees exhibit geographically clustered, but sometimes imperfect colour patterns, and that mimicry patterns gradually transition spatially rather than exhibit discrete boundaries. Additionally, examination of colour pattern transition zones of three comimicking, polymorphic species, where active selection is driving phenotype frequencies, revealed that their transition zones differ in location within a broad region of poor mimicry. Potential factors influencing mimicry transition zone dynamics are discussed."																				
2019	"Ezray, Briana D.; Wham, Drew C.; Hill, Carrie; Hines, Heather M."	Müllerian mimicry in bumble bees is a transient continuum	Images	CNN	Regression	bioRxiv			513275	10.1101/513275v2	https://www.biorxiv.org/content/10.1101/513275v2	"Müllerian mimicry theory states that frequency dependent selection should favour geographic convergence of harmful species onto a shared colour pattern. As such, mimetic patterns are commonly circumscribed into discrete mimicry complexes each containing a predominant phenotype. Outside a few examples in butterflies, the location of transition zones between mimicry complexes and the factors driving them has rarely been examined. To infer the patterns and processes of Müllerian mimicry, we integrate large-scale data on the geographic distribution of colour patterns of all social bumble bees across the contiguous United States and use these to quantify colour pattern mimicry using an innovative machine learning approach based on computer vision and image recognition. Our data suggests that bumble bees exhibit a manifold of similar, but imperfect colour patterns, that continuously transition across the United States, supporting the idea that mimicry is not discrete. We propose that bumble bees are mimicking a perceptual colour pattern average that is evolutionarily transient. We examine three comimicking polymorphic species, Bombus flavifrons, B. melanopygus, and B. bifarius, where active selection is driving colour pattern frequencies and determine that their colour pattern transition zones differ in location and breadth within a broad region of poor mimicry. Furthermore, we explore factors driving these differences such as mimicry selection dynamics and climate."																				
2019	"Falk, Thorsten; Mai, Dominic; Bensch, Robert; Çiçek, Özgün; Abdulkadir, Ahmed; Marrakchi, Yassine; Böhm, Anton; Deubner, Jan; Jäckel, Zoe; Seiwald, Katharina; Dovzhenko, Alexander; Tietz, Olaf; Dal Bosco, Cristina; Walsh, Sean; Saltukoglu, Deniz; Tay, Tuan Leng; Prinz, Marco; Palme, Klaus; Simons, Matias; Diester, Ilka; Brox, Thomas; Ronneberger, Olaf"	"U-Net: deep learning for cell counting, detection, and morphometry"	Images	CNN	Classification	Nature Methods	16	1	67-70	10.1038/s41592-018-0261-2	https://www.nature.com/articles/s41592-018-0261-2	U-Net is a generic deep-learning solution for frequently occurring quantification tasks such as cell detection and shape measurements in biomedical image data. We present an ImageJ plugin that enables non-machine-learning experts to analyze their data with U-Net on either a local computer or a remote server/cloud service. The plugin comes with pretrained models for single-cell segmentation and allows for U-Net to be adapted to new tasks on the basis of a few annotated samples.																				
2019	"Falzon, Greg; Lawson, Christopher; Cheung, Ka-Wai; Vernes, Karl; Ballard, Guy A.; Fleming, Peter J. S.; Glen, Alistair S.; Milne, Heath; Mather-Zardain, Atalya; Meek, Paul D."	ClassifyMe: A Field-Scouting Software for the Identification of Wildlife in Camera Trap Images	Images	CNN	Classification	Animals	10	1	58	10.3390/ani10010058	https://www.mdpi.com/2076-2615/10/1/58	"We present ClassifyMe a software tool for the automated identification of animal species from camera trap images. ClassifyMe is intended to be used by ecologists both in the field and in the office. Users can download a pre-trained model specific to their location of interest and then upload the images from a camera trap to a laptop or workstation. ClassifyMe will identify animals and other objects (e.g., vehicles) in images, provide a report file with the most likely species detections, and automatically sort the images into sub-folders corresponding to these species categories. False Triggers (no visible object present) will also be filtered and sorted. Importantly, the ClassifyMe software operates on the user’s local machine (own laptop or workstation)—not via internet connection. This allows users access to state-of-the-art camera trap computer vision software in situ, rather than only in the office. The software also incurs minimal cost on the end-user as there is no need for expensive data uploads to cloud services. Furthermore, processing the images locally on the users’ end-device allows them data control and resolves privacy issues surrounding transfer and third-party access to users’ datasets."																				
2019	"Fang, Zhencheng; Tan, Jie; Wu, Shufang; Li, Mo; Xu, Congmin; Xie, Zhongjie; Zhu, Huaiqiu"	PPR-Meta: a tool for identifying phages and plasmids from metagenomic fragments using deep learning	Molecular	CNN	Classification	GigaScience	8	6	giz066	10.1093/gigascience/giz066	https://academic.oup.com/gigascience/article/8/6/giz066/5521157	"BACKGROUND: Phages and plasmids are the major components of mobile genetic elements, and fragments from such elements generally co-exist with chromosome-derived fragments in sequenced metagenomic data. However, there is a lack of efficient methods that can simultaneously identify phages and plasmids in metagenomic data, and the existing tools identifying either phages or plasmids have not yet presented satisfactory performance. FINDINGS: We present PPR-Meta, a 3-class classifier that allows simultaneous identification of both phage and plasmid fragments from metagenomic assemblies. PPR-Meta consists of several modules for predicting sequences of different lengths. Using deep learning, a novel network architecture, referred to as the Bi-path Convolutional Neural Network, is designed to improve the performance for short fragments. PPR-Meta demonstrates much better performance than currently available similar tools individually for phage or plasmid identification, while testing on both artificial contigs and real metagenomic data. PPR-Meta is freely available via http://cqb.pku.edu.cn/ZhuLab/PPR_Meta or https://github.com/zhenchengfang/PPR-Meta. CONCLUSIONS: To the best of our knowledge, PPR-Meta is the first tool that can simultaneously identify phage and plasmid fragments efficiently and reliably. The software is optimized and can be easily run on a local PC by non-computer professionals. We developed PPR-Meta to promote the research on mobile genetic elements and horizontal gene transfer."																				
2019	"Fearey, J.; Elwen, S. H.; James, B. S.; Gridley, T."	Identification of potential signature whistles from free-ranging common dolphins (Delphinus delphis) in South Africa	Sound	Unknown	Modeling	Animal Cognition	22	5	777-789	10.1007/s10071-019-01274-1	https://link.springer.com/article/10.1007/s10071-019-01274-1	"Conveying identity is important for social animals to maintain individually based relationships. Communication of identity information relies on both signal encoding and perception. Several delphinid species use individually distinctive signature whistles to transmit identity information, best described for the common bottlenose dolphin (Tursiops truncatus). In this study, we investigate signature whistle use in wild common dolphins (Delphinus delphis). Acoustic recordings were analysed from 11 encounters from three locations in South Africa (Hout Bay, False Bay, and Plettenberg Bay) during 2009, 2016 and 2017. The frequency contours of whistles were visually categorised, with 29 signature whistle types (SWTs) identified through contour categorisation and a bout analysis approach developed specifically to identify signature whistles in bottlenose dolphins (SIGID). Categorisation verification was conducted using an unsupervised neural network (ARTwarp) at both a 91% and 96% vigilance parameter. For this, individual SWTs were analysed type by type and then in a ‘global’ analysis whereby all 497 whistle contours were categorised simultaneously. Overall the analysis demonstrated high stereotypy in the structure and temporal production of whistles, consistent with signature whistle use. We suggest that individual identity information may be encoded in these whistle contours. However, the large group sizes and high degree of vocal activity characteristic of this dolphin species generate a cluttered acoustic environment with high potential for masking from conspecific vocalisations. Therefore, further investigation into the mechanisms of identity perception in such acoustically cluttered environments is required to demonstrate the function of these stereotyped whistle types in common dolphins."																				
2019	"Flagel, Lex; Brandvain, Yaniv; Schrider, Daniel R"	The Unreasonable Effectiveness of Convolutional Neural Networks in Population Genetic Inference	Molecular	CNN	Modeling	Molecular Biology and Evolution	36	2	220-238	10.1093/molbev/msy224	https://academic.oup.com/mbe/article/36/2/220/5229930	"Population-scale genomic data sets have given researchers incredible amounts of information from which to infer evolutionary histories. Concomitant with this flood of data, theoretical and methodological advances have sought to extract information from genomic sequences to infer demographic events such as population size changes and gene flow among closely related populations/species, construct recombination maps, and uncover loci underlying recent adaptation. To date, most methods make use of only one or a few summaries of the input sequences and therefore ignore potentially useful information encoded in the data. The most sophisticated of these approaches involve likelihood calculations, which require theoretical advances for each new problem, and often focus on a single aspect of the data (e.g., only allele frequency information) in the interest of mathematical and computational tractability. Directly interrogating the entirety of the input sequence data in a likelihood-free manner would thus offer a fruitful alternative. Here, we accomplish this by representing DNA sequence alignments as images and using a class of deep learning methods called convolutional neural networks (CNNs) to make population genetic inferences from these images. We apply CNNs to a number of evolutionary questions and find that they frequently match or exceed the accuracy of current methods. Importantly, we show that CNNs perform accurate evolutionary model selection and parameter estimation, even on problems that have not received detailed theoretical treatments. Thus, when applied to population genetic alignments, CNNs are capable of outperforming expert-derived statistical methods and offer a new path forward in cases where no likelihood approach exists."																				
2019	"Francisco, Fritz A.; Nührenberg, Paul; Jordan, Alex"	"High-resolution, non-invasive animal tracking and reconstruction of local environment in aquatic ecosystems"	Video	CNN	Classification	Movement Ecology	8	1	27	10.1186/s40462-020-00214-w	https://movementecologyjournal.biomedcentral.com/articles/10.1186/s40462-020-00214-w	"Acquiring high resolution quantitative behavioural data underwater often involves installation of costly infrastructure, or capture and manipulation of animals. Aquatic movement ecology can therefore be limited in taxonomic range and ecological coverage."																				
2019	"Frankenhuis, Willem E.; Panchanathan, Karthik; Barto, Andrew G."	Enriching behavioral ecology with reinforcement learning methods	NA	NA	Review	Behavioural Processes	161		94-100	10.1016/j.beproc.2018.01.008	https://linkinghub.elsevier.com/retrieve/pii/S0376635717303637	"This article focuses on the division of labor between evolution and development in solving sequential, state-dependent decision problems. Currently, behavioral ecologists tend to use dynamic programming methods to study such problems. These methods are successful at predicting animal behavior in a variety of contexts. However, they depend on a distinct set of assumptions. Here, we argue that behavioral ecology will benefit from drawing more than it currently does on a complementary collection of tools, called reinforcement learning methods. These methods allow for the study of behavior in highly complex environments, which conventional dynamic programming methods do not feasibly address. In addition, reinforcement learning methods are well-suited to studying how biological mechanisms solve developmental and learning problems. For instance, we can use them to study simple rules that perform well in complex environments. Or to investigate under what conditions natural selection favors fixed, non-plastic traits (which do not vary across individuals), cue-driven-switch plasticity (innate instructions for adaptive behavioral development based on experience), or developmental selection (the incremental acquisition of adaptive behavior based on experience). If natural selection favors developmental selection, which includes learning from environmental feedback, we can also make predictions about the design of reward systems. Our paper is written in an accessible manner and for a broad audience, though we believe some novel insights can be drawn from our discussion. We hope our paper will help advance the emerging bridge connecting the fields of behavioral ecology and reinforcement learning."																				
2019	"Fricker, Geoffrey A.; Ventura, Jonathan D.; Wolf, Jeffrey A.; North, Malcolm P.; Davis, Frank W.; Franklin, Janet"	A Convolutional Neural Network Classifier Identifies Tree Species in Mixed-Conifer Forest from Hyperspectral Imagery	Other	CNN	Classification	Remote Sensing	11	19	2326	10.3390/rs11192326	https://www.mdpi.com/2072-4292/11/19/2326	"In this study, we automate tree species classification and mapping using field-based training data, high spatial resolution airborne hyperspectral imagery, and a convolutional neural network classifier (CNN). We tested our methods by identifying seven dominant trees species as well as dead standing trees in a mixed-conifer forest in the Southern Sierra Nevada Mountains, CA (USA) using training, validation, and testing datasets composed of spatially-explicit transects and plots sampled across a single strip of imaging spectroscopy. We also used a three-band ‘Red-Green-Blue’ pseudo true-color subset of the hyperspectral imagery strip to test the classification accuracy of a CNN model without the additional non-visible spectral data provided in the hyperspectral imagery. Our classifier is pixel-based rather than object based, although we use three-dimensional structural information from airborne Light Detection and Ranging (LiDAR) to identify trees (points > 5 m above the ground) and the classifier was applied to image pixels that were thus identified as tree crowns. By training a CNN classifier using field data and hyperspectral imagery, we were able to accurately identify tree species and predict their distribution, as well as the distribution of tree mortality, across the landscape. Using a window size of 15 pixels and eight hidden convolutional layers, a CNN model classified the correct species of 713 individual trees from hyperspectral imagery with an average F-score of 0.87 and F-scores ranging from 0.67–0.95 depending on species. The CNN classification model performance increased from a combined F-score of 0.64 for the Red-Green-Blue model to a combined F-score of 0.87 for the hyperspectral model. The hyperspectral CNN model captures the species composition changes across ~700 meters (1935 to 2630 m) of elevation from a lower-elevation mixed oak conifer forest to a higher-elevation fir-dominated coniferous forest. High resolution tree species maps can support forest ecosystem monitoring and management, and identifying dead trees aids landscape assessment of forest mortality resulting from drought, insects and pathogens. We publicly provide our code to apply deep learning classifiers to tree species identification from geospatial imagery and field training data."																				
2019	"Geuther, Brian Q.; Deats, Sean P.; Fox, Kai J.; Murray, Steve A.; Braun, Robert E.; White, Jacqueline K.; Chesler, Elissa J.; Lutz, Cathleen M.; Kumar, Vivek"	Robust mouse tracking in complex environments using neural networks	Video	CNN	Classification	Communications Biology	2	1	124	10.1038/s42003-019-0362-1	http://www.nature.com/articles/s42003-019-0362-1	"The ability to track animals accurately is critical for behavioral experiments. For video-based assays, this is often accomplished by manipulating environmental conditions to increase contrast between the animal and the background in order to achieve proper foreground/background detection (segmentation). Modifying environmental conditions for experimental scalability opposes ethological relevance. The biobehavioral research community needs methods to monitor behaviors over long periods of time, under dynamic environmental conditions, and in animals that are genetically and behaviorally heterogeneous. To address this need, we applied a state-of-the-art neural network-based tracker for single mice. We compare three different neural network architectures across visually diverse mice and different environmental conditions. We find that an encoder-decoder segmentation neural network achieves high accuracy and speed with minimal training data. Furthermore, we provide a labeling interface, labeled training data, tuned hyperparameters, and a pretrained network for the behavior and neuroscience communities."																				
2019	"Gibb, Rory; Browning, Ella; Glover-Kapfer, Paul; Jones, Kate E."	Emerging opportunities and challenges for passive acoustics in ecological assessment and monitoring	NA	NA	Review	Methods in Ecology and Evolution	10	2	169-185	10.1111/2041-210X.13101	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13101	"High-throughput environmental sensing technologies are increasingly central to global monitoring of the ecological impacts of human activities. In particular, the recent boom in passive acoustic sensors has provided efficient, noninvasive, and taxonomically broad means to study wildlife populations and communities, and monitor their responses to environmental change. However, until recently, technological costs and constraints have largely confined research in passive acoustic monitoring (PAM) to a handful of taxonomic groups (e.g., bats, cetaceans, birds), often in relatively small-scale, proof-of-concept studies. The arrival of low-cost, open-source sensors is now rapidly expanding access to PAM technologies, making it vital to evaluate where these tools can contribute to broader efforts in ecology and biodiversity research. Here, we synthesise and critically assess the current emerging opportunities and challenges for PAM for ecological assessment and monitoring of both species populations and communities. We show that terrestrial and marine PAM applications are advancing rapidly, facilitated by emerging sensor hardware, the application of machine learning innovations to automated wildlife call identification, and work towards developing acoustic biodiversity indicators. However, the broader scope of PAM research remains constrained by limited availability of reference sound libraries and open-source audio processing tools, especially for the tropics, and lack of clarity around the accuracy, transferability and limitations of many analytical methods. In order to improve possibilities for PAM globally, we emphasise the need for collaborative work to develop standardised survey and analysis protocols, publicly archived sound libraries, multiyear audio datasets, and a more robust theoretical and analytical framework for monitoring vocalising animal communities."																				
2019	"Gómez-Ríos, Anabel; Tabik, Siham; Luengo, Julián; Shihavuddin, A. S. M.; Herrera, Francisco"	Coral species identification with texture or structure images using a two-level classifier based on Convolutional Neural Networks	Images	CNN	Classification	Knowledge-Based Systems	184		104891	10.1016/j.knosys.2019.104891	https://www.sciencedirect.com/science/article/pii/S0950705119303569	"Corals are crucial animals as they support a large part of marine life. The automatic classification of corals species based on underwater images is important as it can help experts to track and detect threatened and vulnerable coral species. However, this classification is complicated due to the nature of coral underwater images and the fact that current underwater coral datasets are unrealistic as they contain only texture images, while the images taken by autonomous underwater vehicles show the complete coral structure. The objective of this paper is two-fold. The first is to build a dataset that is representative of the problem of classifying underwater coral images, the StructureRSMAS dataset. The second is to build a classifier capable of resolving the real problem of classifying corals, based either on texture or structure images. We have achieved this by using a two-level classifier composed of three ResNet models. The first level recognizes whether the input image is a texture or a structure image. Then, the second level identifies the coral species. To do this, we have used a known texture dataset, RSMAS, and StructureRSMAS."																				
2019	"Graving, Jacob M; Chae, Daniel; Naik, Hemal; Li, Liang; Koger, Benjamin; Costelloe, Blair R; Couzin, Iain D"	"DeepPoseKit, a software toolkit for fast and robust animal pose estimation using deep learning"	Images	CNN	Classification	eLife	8		e47994	10.7554/eLife.47994	https://elifesciences.org/articles/47994	"Quantitative behavioral measurements are important for answering questions across scientific disciplines—from neuroscience to ecology. State-of-the-art deep-learning methods offer major advances in data quality and detail by allowing researchers to automatically estimate locations of an animal’s body parts directly from images or videos. However, currently available animal pose estimation methods have limitations in speed and robustness. Here, we introduce a new easy-to-use software toolkit, DeepPoseKit, that addresses these problems using an efficient multi-scale deep-learning model, called Stacked DenseNet, and a fast GPU-based peak-detection algorithm for estimating keypoint locations with subpixel precision. These advances improve processing speed &gt;2x with no loss in accuracy compared to currently available methods. We demonstrate the versatility of our methods with multiple challenging animal pose estimation tasks in laboratory and field settings—including groups of interacting individuals. Our work reduces barriers to using advanced tools for measuring behavior and has broad applicability across the behavioral sciences."																				
2019	"Gray, Patrick C.; Bierlich, Kevin C.; Mantell, Sydney A.; Friedlaender, Ari S.; Goldbogen, Jeremy A.; Johnston, David W."	Drones and convolutional neural networks facilitate automated and accurate cetacean species identification and photogrammetry	Images	CNN	"Classification, Regression"	Methods in Ecology and Evolution	10	9	1490-1500	10.1111/2041-210X.13246	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13246	"The flourishing application of drones within marine science provides more opportunity to conduct photogrammetric studies on large and varied populations of many different species. While these new platforms are increasing the size and availability of imagery datasets, established photogrammetry methods require considerable manual input, allowing individual bias in techniques to influence measurements, increasing error and magnifying the time required to apply these techniques. Here, we introduce the next generation of photogrammetry methods utilizing a convolutional neural network to demonstrate the potential of a deep learning-based photogrammetry system for automatic species identification and measurement. We then present the same data analysed using conventional techniques to validate our automatic methods. Our results compare favorably across both techniques, correctly predicting whale species with 98% accuracy (57/58) for humpback whales, minke whales, and blue whales. Ninety percent of automated length measurements were within 5% of manual measurements, providing sufficient resolution to inform morphometric studies and establish size classes of whales automatically. The results of this study indicate that deep learning techniques applied to survey programs that collect large archives of imagery may help researchers and managers move quickly past analytical bottlenecks and provide more time for abundance estimation, distributional research, and ecological assessments."																				
2019	"Gray, Patrick C.; Fleishman, Abram B.; Klein, David J.; McKown, Matthew W.; Bézy, Vanessa S.; Lohmann, Kenneth J.; Johnston, David W."	A Convolutional Neural Network for Detecting Sea Turtles in Drone Imagery	Images	CNN	Classification	Methods in Ecology and Evolution			2041-210X.13132	10.1111/2041-210X.13132	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13132	"Marine megafauna are difficult to observe and count because many species travel widely and spend large amounts of time submerged. As such, management programmes seeking to conserve these species are often hampered by limited information about population levels. Unoccupied aircraft systems (UAS, aka drones) provide a potentially useful technique for assessing marine animal populations, but a central challenge lies in analysing the vast amounts of data generated in the images or video acquired during each flight. Neural networks are emerging as a powerful tool for automating object detection across data domains and can be applied to UAS imagery to generate new population-level insights. To explore the utility of these emerging technologies in a challenging field setting, we used neural networks to enumerate olive ridley turtles Lepidochelys olivacea in drone images acquired during a mass-nesting event on the coast of Ostional, Costa Rica. Results revealed substantial promise for this approach; specifically, our model detected 8% more turtles than manual counts while effectively reducing the manual validation burden from 2,971,554 to 44,822 image windows. Our detection pipeline was trained on a relatively small set of turtle examples (N = 944), implying that this method can be easily bootstrapped for other applications, and is practical with real-world UAS datasets. Our findings highlight the feasibility of combining UAS and neural networks to estimate population levels of diverse marine animals and suggest that the automation inherent in these techniques will soon permit monitoring over spatial and temporal scales that would previously have been impractical."																				
2019	"Guirado, Emilio; Tabik, Siham; Rivas, Marga L.; Alcaraz-Segura, Domingo; Herrera, Francisco"	Whale counting in satellite and aerial images with deep learning	Images	CNN	Classification	Scientific Reports	9	1	14259	10.1038/s41598-019-50795-9	http://www.nature.com/articles/s41598-019-50795-9	"Despite their interest and threat status, the number of whales in world’s oceans remains highly uncertain. Whales detection is normally carried out from costly sighting surveys, acoustic surveys or through high-resolution images. Since deep convolutional neural networks (CNNs) are achieving great performance in several computer vision tasks, here we propose a robust and generalizable CNN-based system for automatically detecting and counting whales in satellite and aerial images based on open data and tools. In particular, we designed a two-step whale counting approach, where the first CNN finds the input images with whale presence, and the second CNN locates and counts each whale in those images. A test of the system on Google Earth images in ten global whale-watching hotspots achieved a performance (F1-measure) of 81% in detecting and 94% in counting whales. Combining these two steps increased accuracy by 36% compared to a baseline detection model alone. Applying this cost-effective method worldwide could contribute to the assessment of whale populations to guide conservation actions. Free and global access to high-resolution imagery for conservation purposes would boost this process."																				
2019	"Günel, Semih; Rhodin, Helge; Morales, Daniel; Campagnolo, João; Ramdya, Pavan; Fua, Pascal"	"DeepFly3D, a deep learning-based approach for 3D limb and appendage tracking in tethered, adult Drosophila"	Video	CNN	Regression	eLife	8		e48571	10.7554/eLife.48571	https://elifesciences.org/articles/48571	"Studying how neural circuits orchestrate limbed behaviors requires the precise measurement of the positions of each appendage in three-dimensional (3D) space. Deep neural networks can estimate two-dimensional (2D) pose in freely behaving and tethered animals. However, the unique challenges associated with transforming these 2D measurements into reliable and precise 3D poses have not been addressed for small animals including the fly, Drosophila melanogaster. Here, we present DeepFly3D, a software that infers the 3D pose of tethered, adult Drosophila using multiple camera images. DeepFly3D does not require manual calibration, uses pictorial structures to automatically detect and correct pose estimation errors, and uses active learning to iteratively improve performance. We demonstrate more accurate unsupervised behavioral embedding using 3D joint angles rather than commonly used 2D pose data. Thus, DeepFly3D enables the automated acquisition of Drosophila behavioral measurements at an unprecedented level of detail for a variety of biological applications."																				
2019	"Hartling, Sean; Sagan, Vasit; Sidike, Paheding; Maimaitijiang, Maitiniyazi; Carron, Joshua"	Urban Tree Species Classification Using a WorldView-2/3 and LiDAR Data Fusion Approach and Deep Learning	Other	CNN	Classification	Sensors	19	6	1284	10.3390/s19061284	https://www.mdpi.com/1424-8220/19/6/1284	"Urban areas feature complex and heterogeneous land covers which create challenging issues for tree species classification. The increased availability of high spatial resolution multispectral satellite imagery and LiDAR datasets combined with the recent evolution of deep learning within remote sensing for object detection and scene classification, provide promising opportunities to map individual tree species with greater accuracy and resolution. However, there are knowledge gaps that are related to the contribution of Worldview-3 SWIR bands, very high resolution PAN band and LiDAR data in detailed tree species mapping. Additionally, contemporary deep learning methods are hampered by lack of training samples and difficulties of preparing training data. The objective of this study was to examine the potential of a novel deep learning method, Dense Convolutional Network (DenseNet), to identify dominant individual tree species in a complex urban environment within a fused image of WorldView-2 VNIR, Worldview-3 SWIR and LiDAR datasets. DenseNet results were compared against two popular machine classifiers in remote sensing image analysis, Random Forest (RF) and Support Vector Machine (SVM). Our results demonstrated that: (1) utilizing a data fusion approach beginning with VNIR and adding SWIR, LiDAR, and panchromatic (PAN) bands increased the overall accuracy of the DenseNet classifier from 75.9% to 76.8%, 81.1% and 82.6%, respectively. (2) DenseNet significantly outperformed RF and SVM for the classification of eight dominant tree species with an overall accuracy of 82.6%, compared to 51.8% and 52% for SVM and RF classifiers, respectively. (3) DenseNet maintained superior performance over RF and SVM classifiers under restricted training sample quantities which is a major limiting factor for deep learning techniques. Overall, the study reveals that DenseNet is more effective for urban tree species classification as it outperforms the popular RF and SVM techniques when working with highly complex image scenes regardless of training sample size."																				
2019	"He, Chunyang; Liu, Zhifeng; Gou, Siyuan; Zhang, Qiaofeng; Zhang, Jinshui; Xu, Linlin"	Detecting global urban expansion over the last three decades using a fully convolutional network	Other	CNN	Classification	Environmental Research Letters	14	3	34008	10.1088/1748-9326/aaf936	https://doi.org/10.1088/1748-9326/aaf936	"The effective detection of global urban expansion is the basis of understanding urban sustainability. We propose a fully convolutional network (FCN) and employ it to detect global urban expansion from 1992–2016. We found that the global urban land area increased from 274.7 thousand km2–621.1 thousand km2, which is an increase of 346.4 thousand km2 and a growth by 1.3 times. The results display a relatively high accuracy with an average kappa index of 0.5, which is 0.3 higher than those of existing global urban expansion datasets. Three major advantages of the proposed FCN contribute to the improved accuracy, including the integration of multi-source remotely sensed data, the combination of features at multiple scales, and the ability to address the lack of training samples for historical urban land. Thus, the proposed FCN has great potential to effectively detect global urban expansion."																				
2019	"He, Tuo; Jiao, Lichao; Wiedenhoeft, Alex C.; Yin, Yafang"	Machine learning approaches outperform distance- and tree-based methods for DNA barcoding of Pterocarpus wood	Molecular	DNN	Classification	Planta	249	5	1617-1625	10.1007/s00425-019-03116-3	https://link.springer.com/article/10.1007/s00425-019-03116-3	Main conclusion Machine-learning approaches (MLAs) for DNA barcoding outperform distance- and tree-based methods on identifcation accuracy and cost-efectiveness to arrive at species-level identifcation of wood.																				
2019	"He, Tuo; Marco, João; Soares, Richard; Yin, Yafang; Wiedenhoeft, Alex C."	Machine Learning Models with Quantitative Wood Anatomy Data Can Discriminate between Swietenia macrophylla and Swietenia mahagoni	Other	DNN	Classification	Forests	11	1	36	10.3390/f11010036	https://www.mdpi.com/1999-4907/11/1/36	"Illegal logging and associated trade aggravate the over-exploitation of Swietenia species, of which S. macrophylla King, S. mahagoni (L.) Jacq, and S. humilis Zucc. have been listed in Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES) Appendix _. Implementation of CITES necessitates the development of efficient forensic tools to identify wood species accurately, and ideally ones readily deployable in wood anatomy laboratories across the world. Herein, a method using quantitative wood anatomy data in combination with machine learning models to discriminate between three Swietenia species is presented, in addition to a second model focusing only on the two historically more important species S. mahagoni and S. macrophylla. The intra- and inter-specific variations in nine quantitative wood anatomical characters were measured and calculated based on 278 wood specimens, and four machine learning classifiers—Decision Tree C5.0, Naïve Bayes (NB), Support Vector Machine (SVM), and Artificial Neural Network (ANN)—were used to discriminate between the species. Among these species, S. macrophylla exhibited the largest intraspecific variation, and all three species showed at least partly overlapping values for all nine characters. SVM performed the best of all the classifiers, with an overall accuracy of 91.4% and a per-species correct identification rate of 66.7%, 95.0%, and 80.0% for S. humilis, S. macrophylla, and S. mahagoni, respectively. The two-species model discriminated between S. macrophylla and S. mahagoni with accuracies of over 90.0% using SVM. These accuracies are lower than perfect forensic certainty but nonetheless demonstrate that quantitative wood anatomy data in combination with machine learning models can be applied as an efficient tool to discriminate anatomically between similar species in the wood anatomy laboratory. It is probable that a range of previously anatomically inseparable species may become identifiable by incorporating in-depth analysis of quantitative characters and appropriate statistical classifiers."																				
2019	"Hill, Tom; Unckless, Robert L."	A Deep Learning Approach for Detecting Copy Number Variation in Next-Generation Sequencing Data	Molecular	CNN	Classification	G3&amp;#58; Genes|Genomes|Genetics	9	11	3575-3582	10.1534/g3.119.400596	https://academic.oup.com/g3journal/article/9/11/3575-3582/6026731	"Copy number variants (CNV) are associated with phenotypic variation in several species. However, properly detecting changes in copy numbers of sequences remains a difficult problem, especially in lower quality or lower coverage next-generation sequencing data. Here, inspired by recent applications of machine learning in genomics, we describe a method to detect duplications and deletions in short-read sequencing data. In low coverage data, machine learning appears to be more powerful in the detection of CNVs than the gold-standard methods of coverage estimation alone, and of equal power in high coverage data. We also demonstrate how replicating training sets allows a more precise detection of CNVs, even identifying novel CNVs in two genomes previously surveyed thoroughly for CNVs using long read data."																				
2019	"Hoyal Cuthill, Jennifer F.; Guttenberg, Nicholas; Ledger, Sophie; Crowther, Robyn; Huertas, Blanca"	Deep learning on butterfly phenotypes tests evolution’s oldest mathematical model	Images	CNN	Modeling	Science Advances	5	8	eaaw4967	10.1126/sciadv.aaw4967	https://www.science.org/doi/10.1126/sciadv.aaw4967	Artificial intelligence validates evolution’s oldest mathematical model by learning about butterfly mimicry.																				
2019	"Hsiang, Allison Y.; Brombacher, Anieke; Rillo, Marina C.; Mleneck_Vautravers, Maryline J.; Conn, Stephen; Lordsmith, Sian; Jentzen, Anna; Henehan, Michael J.; Metcalfe, Brett; Fenton, Isabel S.; Wade, Bridget S.; Fox, Lyndsey; Meilland, Julie; Davis, Catherine V.; Baranowski, Ulrike; Groeneveld, Jeroen; Edgar, Kirsty M.; Movellan, Aurore; Aze, Tracy; Dowsett, Harry J.; Miller, C. Giles; Rios, Nelson; Hull, Pincelli M."	"Endless Forams: >34,000 Modern Planktonic Foraminiferal Images for Taxonomic Training and Automated Species Recognition Using Convolutional Neural Networks"	Images	CNN	Classification	Paleoceanography and Paleoclimatology	34	7	1157-1177	10.1029/2019PA003612	https://onlinelibrary.wiley.com/doi/abs/10.1029/2019PA003612	"Planktonic foraminiferal species identification is central to many paleoceanographic studies, from selecting species for geochemical research to elucidating the biotic dynamics of microfossil communities relevant to physical oceanographic processes and interconnected phenomena such as climate change. However, few resources exist to train students in the difficult task of discerning amongst closely related species, resulting in diverging taxonomic schools that differ in species concepts and boundaries. This problem is exacerbated by the limited number of taxonomic experts. Here we document our initial progress toward removing these confounding and/or rate-limiting factors by generating the first extensive image library of modern planktonic foraminifera, providing digital taxonomic training tools and resources, and automating species-level taxonomic identification of planktonic foraminifera via machine learning using convolution neural networks. Experts identified 34,640 images of modern (extant) planktonic foraminifera to the species level. These images are served as species exemplars through the online portal Endless Forams (endlessforams.org) and a taxonomic training portal hosted on the citizen science platform Zooniverse (zooniverse.org/projects/ahsiang/endless-forams/). A supervised machine learning classifier was then trained with ~27,000 images of these identified planktonic foraminifera. The best-performing model provided the correct species name for an image in the validation set 87.4% of the time and included the correct name in its top three guesses 97.7% of the time. Together, these resources provide a rigorous set of training tools in modern planktonic foraminiferal taxonomy and a means of rapidly generating assemblage data via machine learning in future studies for applications such as paleotemperature reconstruction."																				
2019	"Kalkatawi, Manal; Magana-Mora, Arturo; Jankovic, Boris; Bajic, Vladimir B"	DeepGSR: an optimized deep-learning structure for the recognition of genomic signals and regions	Molecular	CNN	Classification	Bioinformatics	35	7	1125-1132	10.1093/bioinformatics/bty752	https://doi.org/10.1093/bioinformatics/bty752	"Recognition of different genomic signals and regions (GSRs) in DNA is crucial for understanding genome organization, gene regulation, and gene function, which in turn generate better genome and gene annotations. Although many methods have been developed to recognize GSRs, their pure computational identification remains challenging. Moreover, various GSRs usually require a specialized set of features for developing robust recognition models. Recently, deep-learning (DL) methods have been shown to generate more accurate prediction models than ‘shallow’ methods without the need to develop specialized features for the problems in question. Here, we explore the potential use of DL for the recognition of GSRs.We developed DeepGSR, an optimized DL architecture for the prediction of different types of GSRs. The performance of the DeepGSR structure is evaluated on the recognition of polyadenylation signals (PAS) and translation initiation sites (TIS) of different organisms: human, mouse, bovine and fruit fly. The results show that DeepGSR outperformed the state-of-the-art methods, reducing the classification error rate of the PAS and TIS prediction in the human genome by up to 29% and 86%, respectively. Moreover, the cross-organisms and genome-wide analyses we performed, confirmed the robustness of DeepGSR and provided new insights into the conservation of examined GSRs across species.DeepGSR is implemented in Python using Keras API; it is available as open-source software and can be obtained at https://doi.org/10.5281/zenodo.1117159.Supplementary data are available at Bioinformatics online."																				
2019	"Kattenborn, Teja; Eichel, Jana; Fassnacht, Fabian Ewald"	"Convolutional Neural Networks enable efficient, accurate and fine-grained segmentation of plant species and communities from high-resolution UAV imagery"	Images	CNN	Classification	Scientific Reports	9	1	17656	10.1038/s41598-019-53797-9	https://www.nature.com/articles/s41598-019-53797-9	"Recent technological advances in remote sensing sensors and platforms, such as high-resolution satellite imagers or unmanned aerial vehicles (UAV), facilitate the availability of fine-grained earth observation data. Such data reveal vegetation canopies in high spatial detail. Efficient methods are needed to fully harness this unpreceded source of information for vegetation mapping. Deep learning algorithms such as Convolutional Neural Networks (CNN) are currently paving new avenues in the field of image analysis and computer vision. Using multiple datasets, we test a CNN-based segmentation approach (U-net) in combination with training data directly derived from visual interpretation of UAV-based high-resolution RGB imagery for fine-grained mapping of vegetation species and communities. We demonstrate that this approach indeed accurately segments and maps vegetation species and communities (at least 84% accuracy). The fact that we only used RGB imagery suggests that plant identification at very high spatial resolutions is facilitated through spatial patterns rather than spectral information. Accordingly, the presented approach is compatible with low-cost UAV systems that are easy to operate and thus applicable to a wide range of users."																				
2019	"Kaya, Aydin; Keceli, Ali Seydi; Catal, Cagatay; Yalic, Hamdi Yalin; Temucin, Huseyin; Tekinerdogan, Bedir"	Analysis of transfer learning for deep neural network based plant classification models	Images	CNN	Classification	Computers and Electronics in Agriculture	158		20-29	10.1016/j.compag.2019.01.041	https://www.sciencedirect.com/science/article/pii/S0168169918315308	"Plant species classification is crucial for biodiversity protection and conservation. Manual classification is time-consuming, expensive, and requires experienced experts who are often limited available. To cope with these issues, various machine learning algorithms have been proposed to support the automated classification of plant species. Among these machine learning algorithms, Deep Neural Networks (DNNs) have been applied to different data sets. DNNs have been however often applied in isolation and no effort has been made to reuse and transfer the knowledge of different applications of DNNs. Transfer learning in the context of machine learning implies the usage of the results of multiple applications of DNNs. In this article, the results of the effect of four different transfer learning models for deep neural network-based plant classification is investigated on four public datasets. Our experimental study demonstrates that transfer learning can provide important benefits for automated plant identification and can improve low-performance plant classification models."																				
2019	"Lee, Heera; Seo, Bumsuk; Koellner, Thomas; Lautenbach, Sven"	Mapping cultural ecosystem services 2.0 – Potential and shortcomings from unlabeled crowd sourced images	"Images, Other"	CNN	Classification	Ecological Indicators	96		505-515	10.1016/j.ecolind.2018.08.035	https://linkinghub.elsevier.com/retrieve/pii/S1470160X1830637X	"The volume of accessible geotagged crowdsourced photos has increased. Such data include spatial, temporal, and thematic information on recreation and outdoor activities, thus can be used to quantify the demand for cultural ecosystem services (CES). So far photo content has been analyzed based on user-labeled tags or the manual labeling of photos. Both approaches are challenged with respect to consistency and cost-efficiency, especially for large-scale studies with an enormous volume of photos. In this study, we aim at developing a new method to analyze the content of large volumes of photos and to derive indicators of socio-cultural usage of landscapes. The method uses machine-learning and network analysis to identify clusters of photo content that can be used as an indicator of cultural services provided by landscapes. The approach was applied in the Mulde river basin in Saxony, Germany. All public Flickr photos (n = 12,635) belonging to the basin were tagged by deep convolutional neural networks through a cloud computing platform, Clarifai. The machine-predicted tags were analyzed by a network analysis that leads to nine hierarchical clusters. Those clusters were used to distinguish between photos related to CES (65%) and not related to CES (35%). Among the nine clusters, two clusters were related to CES: ‘landscape aesthetics’ and ‘existence’. This step allowed mapping of different aspects of CES and separation of non-relevant photos from further analysis. We further analyzed the impact of protected areas on the spatial pattern of CES and not-related CES photos. The presence of protected areas had a significant positive impact on the areas with both ‘landscape aesthetics’ and ‘existence’ photos: the total number of days in each mapping unit where at least one photo was taken by a user (‘photo-user-day’) increased with the share of protected areas around the location. The presented approach has shown its potential for reliable mapping of socio-cultural uses of landscapes. It is expected to scale well with large numbers of photos and to be easily transferable to different regions."																				
2019	"Li, Heng"	Identifying centromeric satellites with dna-brnn	Molecular	RNN	Classification	Bioinformatics	35	21	4408-4410	10.1093/bioinformatics/btz264	https://academic.oup.com/bioinformatics/article/35/21/4408/5466455?login=false	"Summary Human alpha satellite and satellite 2\/3 contribute to several percent of the human genome. However, identifying these sequences with traditional algorithms is computationally intensive. Here we develop dna-brnn, a recurrent neural network to learn the sequences of the two classes of centromeric repeats. It achieves high similarity to RepeatMasker and is times faster. Dna-brnn explores a novel application of deep learning and may accelerate the study of the evolution of the two repeat classes. Availability and implementation https:\/\/github.com\/lh3\/dna-nn"																				
2019	"Li, Rui; Wang, Rujing; Xie, Chengjun; Liu, Liu; Zhang, Jie; Wang, Fangyuan; Liu, Wancai"	A coarse-to-fine network for aphid recognition and detection in the field	Images	CNN	Classification	Biosystems Engineering	187		39-52	10.1016/j.biosystemseng.2019.08.013	https://linkinghub.elsevier.com/retrieve/pii/S1537511019308086	"The volume of accessible geotagged crowdsourced photos has increased. Such data include spatial, temporal, and thematic information on recreation and outdoor activities, thus can be used to quantify the demand for cultural ecosystem services (CES). So far photo content has been analyzed based on user-labeled tags or the manual labeling of photos. Both approaches are challenged with respect to consistency and cost-efficiency, especially for large-scale studies with an enormous volume of photos. In this study, we aim at developing a new method to analyze the content of large volumes of photos and to derive indicators of socio-cultural usage of landscapes. The method uses machine-learning and network analysis to identify clusters of photo content that can be used as an indicator of cultural services provided by landscapes. The approach was applied in the Mulde river basin in Saxony, Germany. All public Flickr photos (n = 12,635) belonging to the basin were tagged by deep convolutional neural networks through a cloud computing platform, Clarifai. The machine-predicted tags were analyzed by a network analysis that leads to nine hierarchical clusters. Those clusters were used to distinguish between photos related to CES (65%) and not related to CES (35%). Among the nine clusters, two clusters were related to CES: ‘landscape aesthetics’ and ‘existence’. This step allowed mapping of different aspects of CES and separation of non-relevant photos from further analysis. We further analyzed the impact of protected areas on the spatial pattern of CES and not-related CES photos. The presence of protected areas had a significant positive impact on the areas with both ‘landscape aesthetics’ and ‘existence’ photos: the total number of days in each mapping unit where at least one photo was taken by a user (‘photo-user-day’) increased with the share of protected areas around the location. The presented approach has shown its potential for reliable mapping of socio-cultural uses of landscapes. It is expected to scale well with large numbers of photos and to be easily transferable to different regions."																				
2019	"Lin, Tsung-Yu; Winner, Kevin; Bernstein, Garrett; Mittal, Abhay; Dokter, Adriaan M.; Horton, Kyle G.; Nilsson, Cecilia; Van Doren, Benjamin M.; Farnsworth, Andrew; La Sorte, Frank A.; Maji, Subhransu; Sheldon, Daniel"	MistNet: Measuring historical bird migration in the US using archived weather radar data and convolutional neural networks	Other	CNN	Classification	Methods in Ecology and Evolution	10	11	1908-1922	10.1111/2041-210X.13280	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13280	"Large networks of weather radars are comprehensive instruments for studying bird migration. For example, the US WSR-88D network covers the entire continental US and has archived data since the 1990s. The data can quantify both broad and fine-scale bird movements to address a range of migration ecology questions. However, the problem of automatically discriminating precipitation from biology has significantly limited the ability to conduct biological analyses with historical radar data. We develop MistNet, a deep convolutional neural network to discriminate precipitation from biology in radar scans. Unlike prior machine learning approaches, MistNet makes fine-scaled predictions and can collect biological information from radar scans that also contain precipitation. MistNet is based on neural networks for images, and includes several architecture components tailored to the unique characteristics of radar data. To avoid a massive human labelling effort, we train MistNet using abundant noisy labels obtained from dual polarization radar data. In historical and contemporary WSR-88D data, MistNet identifies at least 95.9% of all biomass with a false discovery rate of 1.3%. Dual polarization training data and our radar-specific architecture components are effective. By retaining biomass that co-occurs with precipitation in a single radar scan, MistNet retains 15% more biomass than traditional whole-scan approaches to screening. MistNet is fully automated and can be applied to datasets of millions of radar scans to produce fine-grained predictions that enable a range of applications, from continent-scale mapping to local analysis of airspace usage. Radar ornithology is advancing rapidly and leading to significant discoveries about continent-scale patterns of bird movements. General-purpose and empirically validated methods to quantify biological signals in radar data are essential to the future development of this field. MistNet can enable large-scale, long-term, and reproducible measurements of whole migration systems."																				
2019	"Liu, Liu; Wang, Rujing; Xie, Chengjun; Yang, Po; Wang, Fangyuan; Sudirman, Sud; Liu, Wancai"	PestNet: An End-to-End Deep Learning Approach for Large-Scale Multi-Class Pest Detection and Classification	Images	"CNN, Other"	Classification	IEEE Access	7		45301-45312	10.1109/ACCESS.2019.2909522	https://ieeexplore.ieee.org/document/8682057	"Multi-class pest detection is one of the crucial components in pest management involving localization in addition to classification which is much more difficult than generic object detection because of the apparent differences among pest species. This paper proposes a region-based end-to-end approach named PestNet for large-scale multi-class pest detection and classification based on deep learning. PestNet consists of three major parts. First, a novel module channel-spatial attention (CSA) is proposed to be fused into the convolutional neural network (CNN) backbone for feature extraction and enhancement. The second one is called region proposal network (RPN) that is adopted for providing region proposals as potential pest positions based on extracted feature maps from images. Position-sensitive score map (PSSM), the third component, is used to replace fully connected (FC) layers for pest classification and bounding box regression. Furthermore, we apply contextual regions of interest (RoIs) as contextual information of pest features to improve detection accuracy. We evaluate PestNet on our newly collected large-scale pests' image dataset, Multi-class Pests Dataset 2018 (MPD2018) captured by our designed task-specific image acquisition equipment, covering more than 80k images with over 580k pests labeled by agricultural experts and categorized in 16 classes. The experimental results show that the proposed PestNet performs well on multi-class pest detection with 75.46% mean average precision (mAP), which outperforms the state-of-the-art methods."																				
2019	"Liu, Zac Yung-Chun; Moxley, Jerry H.; Kanive, Paul; Gleiss, Adrian C.; Maughan, Thom; Bird, Larry; Jewell, Oliver J. D.; Chapple, Taylor K.; Gagne, Tyler; White, Connor F.; Jorgensen, Salvador J."	Deep learning accurately predicts white shark locomotor activity from depth data	Images	DNN	Classification	Animal Biotelemetry	7	1	14	10.1186/s40317-019-0175-5	https://animalbiotelemetry.biomedcentral.com/articles/10.1186/s40317-019-0175-5	"Background: The study of bioenergetics, kinematics, and behavior in free-ranging animals has been transformed through the increasing use of biologging devices that sample motion intensively with high-resolution sensors. Overall dynamic body acceleration (ODBA) derived from biologging tags has been validated as a proxy of locomotor energy expenditure has been calibrated in a range of terrestrial and aquatic taxa. The increased temporal resolution required to discern fine-scale processes and infer energetic expenditure, however, is associated with increased power and memory requirements, as well as the logistical challenges of recovering data from archival instruments. This limits the duration and spatial extent of studies, potentially excluding relevant ecological processes that occur over larger scales. Method: Here, we present a procedure that uses deep learning to estimate locomotor activity solely from vertical movement patterns. We trained artificial neural networks (ANNs) to predict ODBA from univariate depth (pressure) data from two free-swimming white sharks (Carcharodon carcharias). Results: Following 1 h of training data from an individual shark, ANN enabled robust predictions of ODBA from 1 Hz pressure sensor data at multiple temporal scales. These predictions consistently out-performed a null central-tendency model and generalized predictions more accurately than other machine learning techniques tested. The ANN prediction accuracy of ODBA integrated overtime periods ≥ 10 min was consistently high (~ 90% accuracy, > 10% improvement over null) for the same shark and equivalently generalizable across individuals (> 75% accuracy). Instantaneous ODBA estimates were more variable (R2 = 0.54 for shark 1, 0.24 for shark 2). Prediction accuracy was insensitive to the volume of training data, no observable gains were achieved in predicting 6 h of test data beyond 1–3 h of training. Conclusions: Augmenting simple depth metrics with energetic and kinematic information from comparatively short-lived, high-resolution datasets greatly expands the potential inference that can be drawn from more common and widely deployed time-depth recorder (TDR) datasets. Future research efforts will focus on building a broadly generalized model that leverages archives of full motion sensor biologging data sets with the greatest number of individuals encompassing diverse habitats, behaviors, and attachment methods."																				
2019	"Liu, Ziwei; Miao, Zhongqi; Zhan, Xiaohang; Wang, Jiayun; Gong, Boqing; Yu, Stella X."	Large-scale long-tailed recognition in an open world	NA	NA	Review	2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)			2532-2541	10.1109/CVPR.2019.00264	https://ieeexplore.ieee.org/document/8953407	"Real world data often have a long-tailed and open-ended distribution. A practical recognition system must classify among majority and minority classes, generalize from a few known instances, and acknowledge novelty upon a never seen instance. We define Open Long-Tailed Recognition (OLTR) as learning from such naturally distributed data and optimizing the classification accuracy over a balanced test set which include head, tail, and open classes. OLTR must handle imbalanced classification, few-shot learning, and open-set recognition in one integrated algorithm, whereas existing classification approaches focus only on one aspect and deliver poorly over the entire class spectrum. The key challenges are how to share visual knowledge between head and tail classes and how to reduce confusion between tail and open classes. We develop an integrated OLTR algorithm that maps an image to a feature space such that visual concepts can easily relate to each other based on a learned metric that respects the closed-world classification while acknowledging the novelty of the open world. Our so-called dynamic meta-embedding combines a direct image feature and an associated memory feature, with the feature norm indicating the familiarity to known classes. On three large-scale OLTR datasets we curate from object-centric ImageNet, scene-centric Places, and face-centric MS1M data, our method consistently outperforms the state-of-the-art. Our code, datasets, and models enable future OLTR research and are publicly available at \url{https://liuziwei7.github.io/projects/LongTail.html}."																				
2019	"Lorieul, Titouan; Pearson, Katelin D.; Ellwood, Elizabeth R.; Goëau, Hervé; Molino, Jean_Francois; Sweeney, Patrick W.; Yost, Jennifer M.; Sachs, Joel; Mata_Montero, Erick; Nelson, Gil; Soltis, Pamela S.; Bonnet, Pierre; Joly, Alexis"	"Toward a large_scale and deep phenological stage annotation of herbarium specimens: Case studies from temperate, tropical, and equatorial floras"	Images	CNN	Classification	Applications in Plant Sciences	7	3	e01233	10.1002/aps3.1233	https://onlinelibrary.wiley.com/doi/abs/10.1002/aps3.1233	"Premise of the Study: Phenological annotation models computed on large-scale herbarium data sets were developed and tested in this study. Methods: Herbarium specimens represent a significant resource with which to study plant phenology. Nevertheless, phenological annotation of herbarium specimens is time-consuming, requires substantial human investment, and is difficult to mobilize at large taxonomic scales. We created and evaluated new methods based on deep learning techniques to automate annotation of phenological stages and tested these methods on four herbarium data sets representing temperate, tropical, and equatorial American floras. Results: Deep learning allowed correct detection of fertile material with an accuracy of 96.3%. Accuracy was slightly decreased for finer-scale information (84.3% for flower and 80.5% for fruit detection). Discussion: The method described has the potential to allow fine-grained phenological annotation of herbarium specimens at large ecological scales. Deeper investigation regarding the taxonomic scalability of this approach is needed."																				
2019	"Luo, Ziyi; Zhang, Linying; Chen, Tianbing; Liu, Muhua; Chen, Jinyin; Zhou, Huamao; Yao, Mingyin"	Rapid identification of rice species by laser-induced breakdown spectroscopy combined with pattern recognition	Other	DNN	Classification	Applied Optics	58	7	1631-1638	10.1364/AO.58.001631	https://opg.optica.org/ao/abstract.cfm?uri=ao-58-7-1631	"Laser-induced breakdown spectroscopy (LIBS) combined with pattern recognition was proposed to discriminate rice species. LIBS spectra in the range of 210&#x2013;480&#x00A0;nm wavelength from 11 different rice species were collected and preprocessed. Principal component analysis was applied to extract the characteristic variables from LIBS spectral data. Three pattern recognition methods, discriminant analysis, radial basis function neural network, and multi-layer perceptron neural network (MLP) were performed to compare the precision in identifying rice species. The results showed that the performance of the MLP model was better. The average identification rate of rice species reached 100% and 97.9% in the training and test sets, respectively, with MLP. The highest and lowest percentages for correct identification were 100% for early indica rice, Huai rice 5, Yan japonica 6, Lian japonica 8, Xuhan 1, Lvhan 1, Sheng rice 16, Yang japonica 687, and Fenghan 30, and 77.8% for Wuyu japonica rice in test sets. The overall results demonstrate that LIBS combined with MLP could be utilized to rapidly discriminate rice species."																				
2019	"Mac Aodha, Oisin; Cole, Elijah; Perona, Pietro"	Presence-Only Geographical Priors for Fine-Grained Image Classification	Images	CNN	Classification	arXiv:1906.05272 [cs]				10.48550/arXiv.1906.05272	http://arxiv.org/abs/1906.05272	"Appearance information alone is often not sufficient to accurately differentiate between fine-grained visual categories. Human experts make use of additional cues such as where, and when, a given image was taken in order to inform their final decision. This contextual information is readily available in many online image collections but has been underutilized by existing image classifiers that focus solely on making predictions based on the image contents. We propose an efficient spatio-temporal prior, that when conditioned on a geographical location and time, estimates the probability that a given object category occurs at that location. Our prior is trained from presence-only observation data and jointly models object categories, their spatio-temporal distributions, and photographer biases. Experiments performed on multiple challenging image classification datasets show that combining our prior with the predictions from image classifiers results in a large improvement in final classification performance"																				
2019	"Machraoui, Ahmed Nejmedine; Diouani, Mohamed Fethi; Mouelhi, Aymen; Jaouadi, Kaouther; Ghrab, Jamila; Abdelmelek, Hafedh; Sayadi, Mounir"	Automatic identification and behavioral analysis of phlebotomine sand flies using trajectory features	Video	CNN	"Classification, Regression"	The Visual Computer	35	5	721-738	10.1007/s00371-018-1506-x	https://link.springer.com/article/10.1007/s00371-018-1506-x	"The present paper reports an automated approach for the characterization and analysis of the behavioral of sand flies; the method used is based on Gaussian mixture model and Kalman filter for the detection and tracking of sand flies, and then the extraction of an optimized set of features from the trajectory of flight is performed for the classification process. So, we propose here two optimized sets of features; the first one is used to identify sand flies among other insects, and the second is employed for the characterization of the behavioral change in the sand flies in the presence of a repulsive odor. These features are tested on three different classifiers; artificial neural network, support vector machine and K-nearest neighbor (KNN), and the results show an important improvement in the classification accuracy and confirm the effectiveness of our approach; the accuracy rate of the proposed method reached 88.6% for the identification of sand flies and 93.4% for the detection of their behavior change. Instead of the excessive use of pesticides over wide areas, the presented investigation is a key pillar of the development of an ecological way for a statistical information gathering about sand flies in order to fight against disease carried by those insects especially leishmaniosis and pappataci fever."																				
2019	"Mascanzoni, Elisa; Perego, Alessia; Marchi, Niccolò; Scarabel, Laura; Panozzo, Silvia; Ferrero, Aldo; Acutis, Marco; Sattin, Maurizio"	Epidemiology and agronomic predictors of herbicide resistance in rice at a large scale	Other	DNN	Classification	Agronomy for Sustainable Development	38	6	68	10.1007/s13593-018-0548-9	https://link.springer.com/article/10.1007/s13593-018-0548-9	"Herbicide resistance is a major weed control issue that threatens the sustainability of rice cropping systems. Its epidemiology at large scale is largely unknown. Several rice weed species have evolved resistant populations in Italy, including multiple resistant ones. The study objectives were to analyze the impact in Italian rice fields of major agronomic factors on the epidemiology of herbicide resistance and to generate a large-scale resistance risk map. The Italian Herbicide Resistance Working Group database was used to generate herbicide resistance maps. The distribution of resistant weed populations resulted as not homogeneous in the area studied, with two pockets where resistance had not been detected. To verify the situation, random sampling was done in the pockets where resistance had never been reported. Based on data from 230 Italian municipalities, three different statistics, stepwise discriminant analysis, stepwise logistic regression, and neural network, were used to correlate resistance distribution in the main Italian rice growing area with seeding type, rotation rate, and soil texture. Through the integration of complaint monitoring, mapping, and neural network analyses, we prove that a high risk of resistance evolution is associated with traditional rice cropping systems with intense monoculture rates and where water-seeding is widespread. This is the first study that determines the degree of association between herbicide resistance and a few important predictors at large scale. It also demonstrates that resistance is present in areas where it had never been reported through extensive complaint monitoring. However, these resistant populations cause medium-low density infestations, likely not alarming rice farmers. This highlights the importance of integrated agronomic techniques at cropping system level to prevent the diffusion and impact of herbicide resistance or limit it to an acceptable level. The identification of concise, yet informative, agronomic predictors of herbicide resistance diffusion can significantly facilitate effective management and improve sustainability."																				
2019	"Melo-Santos, Gabriel; Rodrigues, Angélica Lúcia Figueiredo; Tardin, Rodrigo Hipólito; Maciel, Israel de Sá; Marmontel, Miriam; Silva, Maria Luisa Da; May-Collado, Laura Johanna"	"The newly described Araguaian river dolphins, Inia araguaiaensis (Cetartiodactyla, Iniidae), produce a diverse repertoire of acoustic signals"	Sound	Other	Modeling	PeerJ	7		e6670	10.7717/peerj.6670	https://peerj.com/articles/6670	"The recent discovery of the Araguaian river dolphin (Inia araguaiaensis) highlights how little we know about the diversity and biology of river dolphins. In this study, we described the acoustic repertoire of this newly discovered species in concert with their behaviour. We analysed frequency contours of 727 signals (sampled at 10 ms temporal resolution). These contours were analyzed using an adaptive resonance theory neural network combined with dynamic time-warping (ARTwarp). Using a critical similarity value of 96%, frequency contours were categorized into 237 sound-types. The most common types were emitted when calves were present suggesting a key role in mother-calf communication. Our findings show that the acoustic repertoire of river dolphins is far from simple. Furthermore, the calls described here are similar in acoustic structure to those produced by social delphinids, such as orcas and pilot whales. Uncovering the context in which these signals are produced may help understand the social structure of this species and contribute to our understanding of the evolution of acoustic communication in whales."																				
2019	"Mendez, Kevin M.; Broadhurst, David I.; Reinke, Stacey N."	The application of artificial neural networks in metabolomics: a historical perspective	NA	NA	Review	Metabolomics	15	11	142	10.1007/s11306-019-1608-0	http://link.springer.com/10.1007/s11306-019-1608-0	"Background: Metabolomics data, with its complex covariance structure, is typically modelled by projection-based machine learning (ML) methods such as partial least squares (PLS) regression, which project data into a latent structure. Biological data are often non-linear, so it is reasonable to hypothesize that metabolomics data may also have a non-linear latent structure, which in turn would be best modelled using non-linear equations. A non-linear ML method with a similar projection equation structure to PLS is artificial neural networks (ANNs). While ANNs were first applied to metabolic profiling data in the 1990s, the lack of community acceptance combined with limitations in computational capacity and the lack of volume of data for robust non-linear model optimisation inhibited their widespread use. Due to recent advances in computational power, modelling improvements, community acceptance, and the more demanding needs for data science, ANNs have made a recent resurgence in interest across research communities, including a small yet growing usage in metabolomics. As metabolomics experiments become more complex and start to be integrated with other omics data, there is potential for ANNs to become a viable alternative to linear projection methods. Aim of review: We aim to first describe ANNs and their structural equivalence to linear projection-based methods, including PLS regression. We then review the historical, current, and future uses of ANNs in the field of metabolomics. Key scientific concept of review: Is metabolomics ready for the return of artificial neural networks?"																				
2019	"Miao, Zhongqi; Gaynor, Kaitlyn M.; Wang, Jiayun; Liu, Ziwei; Muellerklein, Oliver; Norouzzadeh, Mohammad Sadegh; McInturff, Alex; Bowie, Rauri C. K.; Nathan, Ran; Yu, Stella X.; Getz, Wayne M."	Insights and approaches using deep learning to classify wildlife	Images	CNN	Classification	Scientific Reports	9	1	8137	10.1038/s41598-019-44565-w	https://www.nature.com/articles/s41598-019-44565-w	"The implementation of intelligent software to identify and classify objects and individuals in visual fields is a technology of growing importance to operatives in many fields, including wildlife conservation and management. To non-experts, the methods can be abstruse and the results mystifying. Here, in the context of applying cutting edge methods to classify wildlife species from camera-trap data, we shed light on the methods themselves and types of features these methods extract to make efficient identifications and reliable classifications. The current state of the art is to employ convolutional neural networks (CNN) encoded within deep-learning algorithms. We outline these methods and present results obtained in training a CNN to classify 20 African wildlife species with an overall accuracy of 87.5% from a dataset containing 111,467 images. We demonstrate the application of a gradient-weighted class-activation-mapping (Grad-CAM) procedure to extract the most salient pixels in the final convolution layer. We show that these pixels highlight features in particular images that in some cases are similar to those used to train humans to identify these species. Further, we used mutual information methods to identify the neurons in the final convolution layer that consistently respond most strongly across a set of images of one particular species. We then interpret the features in the image where the strongest responses occur, and present dataset biases that were revealed by these extracted features. We also used hierarchical clustering of feature vectors (i.e., the state of the final fully-connected layer in the CNN) associated with each image to produce a visual similarity dendrogram of identified species. Finally, we evaluated the relative unfamiliarity of images that were not part of the training set when these images were one of the 20 species “known” to our CNN in contrast to images of the species that were “unknown” to our CNN."																				
2019	"Mifsud, Clare Marie; Vella, Adriana"	Acoustic characterization of bats from Malta: setting a baseline for monitoring and conservation of bat populations	Sound	DNN	Classification	Bioacoustics	28	5	427-442	10.1080/09524622.2018.1474138	https://doi.org/10.1080/09524622.2018.1474138	"Bioacoustic research has made several advancements in developing systems to record extensive acoustic data and classify bat echolocation calls to species level using automated classifiers. These systems are useful as echolocation calls give valuable information on bat behaviour and ecology and hence are widely used for research and conservation of bat populations. Despite the challenges associated with automated classifiers, due to the interspecific differences in call characteristics of bat species found in the Maltese Islands, the use of a quantitative and automated approach is investigated. The sound analysis pipeline involved the use of an algorithm to clean sound files from background noise and measure temporal and spectral parameters of bat echolocation calls. These parameters were then fed to a trained and validated artificial neural network using a bat call library built from reference bat calls from Malta. The automatic classifier achieved an overall correct classification rate of 98%. This high correct classification rate for reliable species identification may have benefitted from the absence of typically problematic species, such as species in the genus Myotis, in the analyses. This study’s results pave the way for efficient and reliable bat acoustic surveys in Malta in aid of necessary monitoring and conservation by providing an updated bat species list and their echolocation characteristics."																				
2019	"Mitra, R.; Marchitto, T. M.; Ge, Q.; Zhong, B.; Kanakiya, B.; Cook, M. S.; Fehrenbacher, J. S.; Ortiz, J. D.; Tripati, A.; Lobaton, E."	"Automated species-level identification of planktic foraminifera using convolutional neural networks, with comparison to human performance"	Images	CNN	Classification	Marine Micropaleontology	147		16-24	10.1016/j.marmicro.2019.01.005	https://www.sciencedirect.com/science/article/pii/S0377839818301105	"Picking foraminifera from sediment samples is an essential, but repetitive and low-reward task that is well-suited for automation. The first step toward building a picking robot is the development of an automated identification system. We use machine learning techniques to train convolutional neural networks (CNNs) to identify six species of extant planktic foraminifera that are widely used by paleoceanographers, and to distinguish the six species from other taxa. We employ CNNs that were previously built and trained for image classification. Foraminiferal training and identification use reflected light microscope digital images taken at 16 different illumination angles using a light-emitting diode (LED) ring. Overall machine accuracy, as a combination of precision and recall, is better than 80% even with limited training. We compare machine performance to that of human pickers (six experts and five novices) by tasking each with the identification of 540 specimens based on images. Experts achieved comparable precision but poorer recall relative to the machine, with an average accuracy of 63%. Novices scored lower than experts on both precision and recall, for an overall accuracy of 53%. The machine achieved fairly uniform performance across the six species, while participants' scores were strongly species-dependent, commensurate with their past experience and expertise. The machine was also less sensitive to specimen orientation (umbilical versus spiral views) than the humans. These results demonstrate that our approach can provide a versatile ‘brain’ for an eventual automated robotic picking system."																				
2019	"Montserrat, Daniel Mas; Bustamante, Carlos; Ioannidis, Alexander"	Class-Conditional VAE-GAN for Local-Ancestry Simulation	Molecular	VAE-GAN	Regression	"arXiv:1911.13220 [cs, q-bio, stat]"			1911.1322	10.48550/arXiv.1911.13220	http://arxiv.org/abs/1911.13220	"Local ancestry inference (LAI) allows identification of the ancestry of all chromosomal segments in admixed individuals, and it is a critical step in the analysis of human genomes with applications from pharmacogenomics and precision medicine to genome-wide association studies. In recent years, many LAI techniques have been developed in both industry and academic research. However, these methods require large training data sets of human genomic sequences from the ancestries of interest. Such reference data sets are usually limited, proprietary, protected by privacy restrictions, or otherwise not accessible to the public. Techniques to generate training samples that resemble real haploid sequences from ancestries of interest can be useful tools in such scenarios, since a generalized model can often be shared, but the unique human sample sequences cannot. In this work we present a class-conditional VAE-GAN to generate new human genomic sequences that can be used to train local ancestry inference (LAI) algorithms. We evaluate the quality of our generated data by comparing the performance of a state-of-the-art LAI method when trained with generated versus real data. "																				
2019	"Motta, Daniel; Santos, Alex Álisson Bandeira; Winkler, Ingrid; Machado, Bruna Aparecida Souza; Pereira, Daniel André Dias Imperial; Cavalcanti, Alexandre Morais; Fonseca, Eduardo Oyama Lins; Kirchner, Frank; Badaró, Roberto"	Application of convolutional neural networks for classification of adult mosquitoes in the field	Images	CNN	Classification	PLOS ONE	14	1	e0210829	10.1371/journal.pone.0210829	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0210829	"Dengue, chikungunya and Zika are arboviruses transmitted by mosquitos of the genus Aedes and have caused several outbreaks in world over the past ten years. Morphological identification of mosquitos is currently restricted due to the small number of adequately trained professionals. We implemented a computational model based on a convolutional neural network (CNN) to extract features from mosquito images to identify adult mosquitoes from the species Aedes aegypti, Aedes albopictus and Culex quinquefasciatus. To train the CNN to perform automatic morphological classification of mosquitoes, we used a dataset that included 4,056 mosquito images. Three neural networks, including LeNet, AlexNet and GoogleNet, were used. During the validation phase, the accuracy of the mosquito classification was 57.5% using LeNet, 74.7% using AlexNet and 83.9% using GoogleNet. During the testing phase, the best result (76.2%) was obtained using GoogleNet; results of 52.4% and 51.2% were obtained using LeNet and AlexNet, respectively. Significantly, accuracies of 100% and 90% were achieved for the classification of Aedes and Culex, respectively. A classification accuracy of 82% was achieved for Aedes females. Our results provide information that is fundamental for the automatic morphological classification of adult mosquito species in field. The use of CNN's is an important method for autonomous identification and is a valuable and accessible resource for health workers and taxonomists for the identification of some insects that can transmit infectious agents to humans."																				
2019	"Orozco-Arias, Simon; Isaza, Gustavo; Guyot, Romain"	"Retrotransposons in Plant Genomes: Structure, Identification, and Classification through Bioinformatics and Machine Learning"	NA	NA	Review	International Journal of Molecular Sciences	20	15	3837	10.3390/ijms20153837	https://www.mdpi.com/1422-0067/20/15/3837	"Transposable elements (TEs) are genomic units able to move within the genome of virtually all organisms. Due to their natural repetitive numbers and their high structural diversity, the identification and classification of TEs remain a challenge in sequenced genomes. Although TEs were initially regarded as “junk DNA”, it has been demonstrated that they play key roles in chromosome structures, gene expression, and regulation, as well as adaptation and evolution. A highly reliable annotation of these elements is, therefore, crucial to better understand genome functions and their evolution. To date, much bioinformatics software has been developed to address TE detection and classification processes, but many problematic aspects remain, such as the reliability, precision, and speed of the analyses. Machine learning and deep learning are algorithms that can make automatic predictions and decisions in a wide variety of scientific applications. They have been tested in bioinformatics and, more specifically for TEs, classification with encouraging results. In this review, we will discuss important aspects of TEs, such as their structure, importance in the evolution and architecture of the host, and their current classifications and nomenclatures. We will also address current methods and their limitations in identifying and classifying TEs."																				
2019	"Partel, Victor; Nunes, Leon; Stansly, Phil; Ampatzidis, Yiannis"	Automated vision-based system for monitoring Asian citrus psyllid in orchards utilizing artificial intelligence	Images	CNN	Classification	Computers and Electronics in Agriculture	162		328-336	10.1016/j.compag.2019.04.022	https://linkinghub.elsevier.com/retrieve/pii/S016816991930554X	"Specialty crop growers face challenges from numerous diseases and pests. For example, the Asian citrus psyllid (ACP) is a key pest of citrus due to its role as vector of huanglongbing (HLB) (greening disease). There is no known cure for HLB, but vector management is critical, both for slowing spread and attenuating symptoms in infected trees. Therefore, monitoring ACP population, as well as other pest populations, is an essential management component for timing and assessment of control actions. Manual crop scouting is often labor intensive and time consuming. In this work, an automated system was developed and evaluated utilizing machine vision and artificial intelligence to monitor ACP in groves. This system comprised a tapping mechanism to collect insects from the tree’s branches and a board with a grid of cameras for image acquisition. A software was developed using two convolutional neural-networks to accurately detect and distinguish psyllids from other insects and debris fallen from the tree. A GPS was utilized to automatically record individual tree position to facilitate data assessment on large groves. A precision and recall of 80% and 95%, respectively, was obtained on detecting ACPs on a sample of 90 young citrus trees. The system proved a great potential to automate scouting procedures in citrus and to be extended to other crop insects."																				
2019	"Patel, Maharshi; Jernigan, Shaphan; Richardson, Rob; Ferguson, Scott; Buckner, Gregory"	Autonomous Robotics for Identification and Management of Invasive Aquatic Plant Species	Video	CNN	Classification	Applied Sciences	9	12	2410	10.3390/app9122410	https://www.mdpi.com/2076-3417/9/12/2410	"Invasive aquatic plant species can expand rapidly throughout water bodies and cause severely adverse economic and ecological impacts. While mechanical, chemical, and biological methods exist for the identification and treatment of these invasive species, they are manually intensive, inefficient, costly, and can cause collateral ecological damage. To address current deficiencies in aquatic weed management, this paper details the development of a small fleet of fully autonomous boats capable of subsurface hydroacoustic imaging (to scan aquatic vegetation), machine learning (for automated weed identification), and herbicide deployment (for vegetation control). These capabilities aim to minimize manual labor and provide more efficient, safe (reduced chemical exposure to personnel), and timely weed management. Geotagged hydroacoustic imagery of three aquatic plant varieties (Hydrilla, Cabomba, and Coontail) was collected and used to create a software pipeline for subsurface aquatic weed classification and distribution mapping. Employing deep learning, the novel software achieved a classification accuracy of 99.06% after training."																				
2019	"Peng, Chengbin; Duarte, Carlos M.; Costa, Daniel P.; Guinet, Christophe; Harcourt, Robert G.; Hindell, Mark A.; McMahon, Clive R.; Muelbert, Monica; Thums, Michele; Wong, Ka-Chun; Zhang, Xiangliang"	Deep Learning Resolves Representative Movement Patterns in a Marine Predator Species	Temporal	RNN	"Classification, Regression"	Applied Sciences	9	14	2935	10.3390/app9142935	https://www.mdpi.com/2076-3417/9/14/2935	"The analysis of animal movement from telemetry data provides insights into how and why animals move. While traditional approaches to such analysis mostly focus on predicting animal states during movement, we describe an approach that allows us to identify representative movement patterns of different animal groups. To do this, we propose a carefully designed recurrent neural network and combine it with telemetry data for automatic feature extraction and identification of non-predefined representative patterns. In the experiment, we consider a particular marine predator species, the southern elephant seal, as an example. With our approach, we identify that the male seals in our data set share similar movement patterns when they are close to land. We identify this pattern recurring in a number of distant locations, consistent with alternative approaches from previous research."																				
2019	"Pereira, Carlos S.; Morais, Raul; Reis, Manuel J. C. S."	Deep Learning Techniques for Grape Plant Species Identification in Natural Images	Images	CNN	Classification	Sensors	19	22	4850	10.3390/s19224850	https://www.mdpi.com/1424-8220/19/22/4850	"Frequently, the vineyards in the Douro Region present multiple grape varieties per parcel and even per row. An automatic algorithm for grape variety identification as an integrated software component was proposed that can be applied, for example, to a robotic harvesting system. However, some issues and constraints in its development were highlighted, namely, the images captured in natural environment, low volume of images, high similarity of the images among different grape varieties, leaf senescence, and significant changes on the grapevine leaf and bunch images in the harvest seasons, mainly due to adverse climatic conditions, diseases, and the presence of pesticides. In this paper, the performance of the transfer learning and fine-tuning techniques based on AlexNet architecture were evaluated when applied to the identification of grape varieties. Two natural vineyard image datasets were captured in different geographical locations and harvest seasons. To generate different datasets for training and classification, some image processing methods, including a proposed four-corners-in-one image warping algorithm, were used. The experimental results, obtained from the application of an AlexNet-based transfer learning scheme and trained on the image dataset pre-processed through the four-corners-in-one method, achieved a test accuracy score of 77.30%. Applying this classifier model, an accuracy of 89.75% on the popular Flavia leaf dataset was reached. The results obtained by the proposed approach are promising and encouraging in helping Douro wine growers in the automatic task of identifying grape varieties."																				
2019	"Pereira, Talmo D.; Aldarondo, Diego E.; Willmore, Lindsay; Kislin, Mikhail; Wang, Samuel S.-H.; Murthy, Mala; Shaevitz, Joshua W."	Fast animal pose estimation using deep neural networks	Video	CNN	Classification	Nature Methods	16	1	117-125	10.1038/s41592-018-0234-5	http://www.nature.com/articles/s41592-018-0234-5	"The need for automated and efficient systems for tracking full animal pose has increased with the complexity of behavioral data and analyses. Here we introduce LEAP (LEAP estimates animal pose), a deep-learning-based method for predicting the positions of animal body parts. This framework consists of a graphical interface for labeling of body parts and training the network. LEAP offers fast prediction on new data, and training with as few as 100 frames results in 95% of peak performance. We validated LEAP using videos of freely behaving fruit flies and tracked 32 distinct points to describe the pose of the head, body, wings and legs, with an error rate of <3% of body length. We recapitulated reported findings on insect gait dynamics and demonstrated LEAP’s applicability for unsupervised behavioral classification. Finally, we extended the method to more challenging imaging situations and videos of freely moving mice."																				
2019	"Petso, Tinao; Jamisola, Rodrigo S.; Mpoeleng, Dimane"	Review on methods used for wildlife species and individual identification	NA	NA	Review	European Journal of Wildlife Research	68	1	3	10.1007/s10344-021-01549-4	https://doi.org/10.1007/s10344-021-01549-4	"This work presented a literature review on animal species and individual identification tools, as well as animal monitoring capabilities. We gathered the literature to cover different aspects of technologies that are widely in use for animal identification, from the traditional up to the latest methods. This study includes species and individual animal identification attributes namely body patterns, footprints, facial features, and sound for identification purposes. The large volume of data collected could be automatically processed using machine learning and deep learning techniques to achieve both species and individual animal identification more efficiently as compared to the human workforce. It is a much faster and accurate approach considering the large volume of data, than manual processing, which is extremely expensive, time-consuming, tedious, and monotonous. We established that machine learning and advancements in deep learning hold significant promise to high-accuracy identification of both species and individual animal. Methods used for individual identification are mainly implemented in endangered species by the conservation management. The traditional methods such as the use of footprints, drawings of animal biometrics are integrated into the recent growth of technology to eliminate the human skill needed to achieve species and individual identification through the use of machine learning and deep learning algorithms for automatic identification purposes."																				
2019	"Pichler, Maximilian; Boreux, Virginie; Klein, Alexandra-Maria; Schleuning, Matthias; Hartig, Florian"	Machine learning algorithms to infer trait-matching and predict species interactions in ecological networks	Other	"DNN, CNN"	Modeling	Methods in Ecology and Evolution	11	2	281-293	10.1111/2041-210X.13329	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13329	"Ecologists have long suspected that species are more likely to interact if their traits match in a particular way. For example, a pollination interaction may be more likely if the proportions of a bee's tongue fit a plant's flower shape. Empirical estimates of the importance of trait-matching for determining species interactions, however, vary significantly among different types of ecological networks. Here, we show that ambiguity among empirical trait-matching studies may have arisen at least in parts from using overly simple statistical models. Using simulated and real data, we contrast conventional generalized linear models (GLM) with more flexible Machine Learning (ML) models (Random Forest, Boosted Regression Trees, Deep Neural Networks, Convolutional Neural Networks, Support Vector Machines, naïve Bayes, and k-Nearest-Neighbor), testing their ability to predict species interactions based on traits, and infer trait combinations causally responsible for species interactions. We found that the best ML models can successfully predict species interactions in plant–pollinator networks, outperforming GLMs by a substantial margin. Our results also demonstrate that ML models can better identify the causally responsible trait-matching combinations than GLMs. In two case studies, the best ML models successfully predicted species interactions in a global plant–pollinator database and inferred ecologically plausible trait-matching rules for a plant–hummingbird network from Costa Rica, without any prior assumptions about the system. We conclude that flexible ML models offer many advantages over traditional regression models for understanding interaction networks. We anticipate that these results extrapolate to other ecological network types. More generally, our results highlight the potential of machine learning and artificial intelligence for inference in ecology, beyond standard tasks such as image or pattern recognition."																				
2019	"Picon, Artzai; Alvarez-Gila, Aitor; Seitz, Maximiliam; Ortiz-Barredo, Amaia; Echazarra, Jone; Johannes, Alexander"	Deep convolutional neural networks for mobile capture device-based crop disease classification in the wild	Images	CNN	Classification	Computers and Electronics in Agriculture	161		280-290	10.1016/j.compag.2018.04.002	https://linkinghub.elsevier.com/retrieve/pii/S0168169917312619	"Fungal infection represents up to 50% of yield losses, making it necessary to apply effective and cost efficient fungicide treatments, whose efficacy depends on infestation type, situation and time. In these cases, a correct and early identification of the specific infection is mandatory to minimize yield losses and increase the efficacy and efficiency of the treatments. Over the last years, a number of image analysis-based methodologies have been proposed for automatic image disease identification. Among these methods, the use of Deep Convolutional Neural Networks (CNNs) has proven tremendously successful for different visual classification tasks. In this work we extend previous work by Johannes et al. (2017) with an adapted Deep Residual Neural Network-based algorithm to deal with the detection of multiple plant diseases in real acquisition conditions where different adaptions for early disease detection have been proposed. This work analyses the performance of early identification of three relevant European endemic wheat diseases: Septoria (Septoria triciti), Tan Spot (Drechslera triciti-repentis) and Rust (Puccinia striiformis & Puccinia recondita). The analysis was done using different mobile devices, and more than 8178 images were captured in two pilot sites in Spain and Germany during 2014,2015 and 2016. Obtained results reveal an overall improvement of the balanced accuracy from 0.78 (Johannes et al., 2017) up to 0.87 under exhaustive testing, and balanced accuracies greater than 0.96 on a pilot test performed in Germany."																				
2019	"Ramcharan, Amanda; McCloskey, Peter; Baranowski, Kelsee; Mbilinyi, Neema; Mrisho, Latifa; Ndalahwa, Mathias; Legg, James; Hughes, David P."	A Mobile-Based Deep Learning Model for Cassava Disease Diagnosis	"Images, Video"	CNN	Classification	Frontiers in Plant Science	10		272	10.3389/fpls.2019.00272	https://www.frontiersin.org/article/10.3389/fpls.2019.00272/full	"Convolutional neural network (CNN) models have the potential to improve plant disease phenotyping where the standard approach is visual diagnostics requiring specialized training. In scenarios where a CNN is deployed on mobile devices, models are presented with new challenges due to lighting and orientation. It is essential for model assessment to be conducted in real world conditions if such models are to be reliably integrated with computer vision products for plant disease phenotyping. We train a CNN object detection model to identify foliar symptoms of diseases in cassava (Manihot esculenta Crantz). We then deploy the model in a mobile app and test its performance on mobile images and video of 720 diseased leaflets in an agricultural field in Tanzania. Within each disease category we test two levels of severity of symptoms-mild and pronounced, to assess the model performance for early detection of symptoms. In both severities we see a decrease in performance for real world images and video as measured with the F-1 score. The F-1 score dropped by 32% for pronounced symptoms in real world images (the closest data to the training data) due to a decrease in model recall. If the potential of mobile CNN models are to be realized our data suggest it is crucial to consider tuning recall in order to achieve the desired performance in real world settings. In addition, the varied performance related to different input data (image or video) is an important consideration for design in real world applications."																				
2019	"Rammer, Werner; Seidl, Rupert"	Harnessing Deep Learning in Ecology: An Example Predicting Bark Beetle Outbreaks	Environmental	CNN	Regression	Frontiers in Plant Science	10		1327	10.3389/fpls.2019.01327	https://www.frontiersin.org/article/10.3389/fpls.2019.01327/full	"Addressing current global challenges such as biodiversity loss, global change, and increasing demands for ecosystem services requires improved ecological prediction. Recent increases in data availability, process understanding, and computing power are fostering quantitative approaches in ecology. However, flexible methodological frameworks are needed to utilize these developments towards improved ecological prediction. Deep learning is a rapidly evolving branch of machine learning, yet has received only little attention in ecology to date. It refers to the training of deep neural networks (DNNs), i.e. artificial neural networks consisting of many layers and a large number of neurons. We here provide a reproducible example (including code and data) of designing, training, and applying DNNs for ecological prediction. Using bark beetle outbreaks in conifer-dominated forests as an example, we show that DNNs are well able to predict both short-term infestation risk at the local scale and long-term outbreak dynamics at the landscape level. We furthermore highlight that DNNs have better overall performance than more conventional approaches to predicting bark beetle outbreak dynamics. We conclude that DNNs have high potential to form the backbone of a comprehensive disturbance forecasting system. More broadly, we argue for an increased utilization of the predictive power of DNNs for a wide range of ecological problems. "																				
2019	"Rauf, Hafiz Tayyab; Lali, M. Ikram Ullah; Zahoor, Saliha; Shah, Syed Zakir Hussain; Rehman, Abd Ur; Bukhari, Syed Ahmad Chan"	Visual features based automated identification of fish species using deep convolutional neural networks	Images	CNN	Classification	Computers and Electronics in Agriculture	167		105075	10.1016/j.compag.2019.105075	https://www.sciencedirect.com/science/article/pii/S0168169919313523	"Morphological based fish species identification is an erroneous and time-consuming process. There are numerous fish species and due to their close resemblance with each other, it is difficult to classify them by external characters. Recently, computer vision and deep learning-based identification of different animal species is being widely used by the researchers. Convolutional Neural Network (CNN) is one of the most analytically powerful tools in deep learning architecture for the image classification based on visual features. This work aims to propose a deep learning framework based on the CNN method for fish species identification. The proposed CNN architecture contains 32 deep layers that are considerably deep to derive valuable and discriminating features from the image. The deep supervision is inflicted on the VGGNet architecture to increase the classification performance by instantly adding four convolutional layers to the training of each level in the network. To test the performance of proposed 32-Layer CNN architecture, we developed a dataset termed as Fish-Pak and is publicly available at Mendeley data (Fish-Pak: https://doi.org/10.17632/n3ydw29sbz.3#folder-6b024354-bae3-460a-a758-352685ba0e38). Fish-Pak contains 915 images with six distinct classes; Ctenopharyngodon idella (Grass carp), Cyprinus carpio (Common carp), Cirrhinus mrigala (Mori), Labeo rohita (Rohu), Hypophthalmichthys molitrix (Silver carp), and Catla catla (Thala) and three different image views (head region, body shape, and scale). To ensure the superior performance of proposed CNN architecture, we have carried out the experimental comparison with other deep learning frameworks involving VGG-16 for transfer learning, one block VGG, two block VGG, three block VGG, LeNet-5, AlexNet, GoogleNet, and ResNet-50 on the Fish-Pak data set. Comprehensive empirical analyses reveal that the proposed method achieves state of the art performance and outperforms existing methods."																				
2019	"Rustia, Dan Jeric Arcega; Chao, Jun-Jee; Chung, Jui-Yung; Lin, Ta-Te"	An Online Unsupervised Deep Learning Approach for an Automated Pest Insect Monitoring System	Images	CNN	Classification	"2019 Boston, Massachusetts July 7- July 10, 2019"				10.13031/aim.201900477	http://elibrary.asabe.org/abstract.asp?JID=5&AID=50319&CID=bos2019&T=1	"This paper proposes an online unsupervised deep learning approach for automatically collecting new image data for continuously training more accurate image classifier models of a multi-class insect identification algorithm. Once images are collected by the sticky paper trap image monitoring system, insect images are cropped from the images and screened out based on an unsupervised data collection technique. The proposed unsupervised data collection technique uses reference models trained with supervision for the collection of images based on different classification probability threshold settings. After testing 15 months of data, it was found that reference models trained with 8 months of image data could consistently perform unsupervised data collection with minimal collection error. After 7 months of the unsupervised online training cycle, the technique was able to improve the average F1-score of the classifier models from 0.88 to 0.926, close to the 0.94 F1-score achieved with supervision. The proposed technique reduces the effort required to train new image classifier models, as it does not require the traditional manual collection of new images. The presented technique can be applied to not only insect identification, but also other image monitoring applications."																				
2019	"Rzanny, Michael; Mäder, Patrick; Deggelmann, Alice; Chen, Minqian; Wäldchen, Jana"	"Flowers, leaves or both? How to obtain suitable images for automated plant identification"	Images	CNN	Classification	Plant Methods	15	1	77	10.1186/s13007-019-0462-4	https://plantmethods.biomedcentral.com/articles/10.1186/s13007-019-0462-4	"Deep learning algorithms for automated plant identification need large quantities of precisely labelled images in order to produce reliable classification results. Here, we explore what kind of perspectives and their combinations contain more characteristic information and therefore allow for higher identification accuracy."																				
2019	"Sabattini, Julián Alberto; Sabattini, Rafael Alberto; Urteaga-Omar, Alicia Florencia; Velázquez-Martí, Borja"	Classification of successional stages in native forests of the Argentine Spinal through neural networks	Environmental	"DNN, Other"	Classification	Land Degradation & Development	30	17	2064-2072	10.1002/ldr.3409	https://onlinelibrary.wiley.com/doi/abs/10.1002/ldr.3409	"Native forests are subject to variations in the structure of the different strata. These modifications can have a natural origin due to phenomena such as climate variation, fires, or floods; or they can be anthropic, due to the unsustainable use of forest resources. In general, according to the dominance of the different strata, the forests are classified as virgin, successional, or renoval. In the realization of inventories, there are situations in which the operator can offer a doubtful classification with a high degree of subjectivity. The purpose of this work has been to provide to technicians an objective tool for the classification of successional status in native forests. In this work, it has been found that there is a relationship between the presence of combinations of different plant species, both arboreal and shrub, related to the classification of forests. This relationship has been analyzed through the application of neural networks in two steps: First, a perceptron was applied, then a probabilistic neural network. The analysis through an artificial neuronal network of these two stages has allowed us to develop equations that through the presence/absence of 16 species allows to classify objectively the successional state. This analysis demonstrated an agreement of 83% with the subjective classification of trained field assessors."																				
2019	"Sagar, V; Sachin, R; Chandrashekara, K; Ganeshaiah, K N"	Identification of Indian butterflies and moths with deep convolutional neural networks	Images	CNN	Classification	CURRENT SCIENCE	118	9	8	10.18520/cs/v118/i9/1456-1462	https://www.currentscience.ac.in/Volumes/118/09/1456.pdf	"This paper reports our efforts to use artificial intelligence based on deep convolutional neural network (CNN) as a tool to identify Indian butterflies and moths. We compiled a dataset of over 170,000 images for 800 Indian butterfly species and 500 Indian moth species from diverse sources. We adopted the EfficientNet-B6 architecture for our CNN model, with about 44 million learnable parameters. We trained an ensemble of 5 such models on different subsets of the images in our data, employing artificial image augmentation techniques and transfer learning. This ensemble achieved a balanced top-1 accuracy of 86.5%, top-3 accuracy of 94.7%, and top-5 accuracy of 96.4% on the 1300 species, and a mean F1 score of 0.867. Thus, our efforts demonstrate artificial intelligence can be effectively used for identifying these biological species that would substantially enhance the work efficiency of field level biologists in several spheres of investigations."																				
2019	"Sakoda, Kazuma; Watanabe, Tomoya; Sukemura, Shun; Kobayashi, Shunzo; Nagasaki, Yuichi; Tanaka, Yu; Shiraiwa, Tatsuhiko"	Genetic Diversity in Stomatal Density among Soybeans Elucidated Using High-throughput Technique Based on an Algorithm for Object Detection	Images	CNN	Regression	Scientific Reports	9	1	7610	10.1038/s41598-019-44127-0	https://www.nature.com/articles/s41598-019-44127-0	"The stomatal density (SD) can be a promising target to improve the leaf photosynthesis in soybeans (Glycine max (L.) Merr). In a conventional SD evaluation, the counting process of the stomata during a manual operation can be time-consuming. We aimed to develop a high-throughput technique for evaluating the SD and elucidating the variation in the SD among various soybean accessions. The central leaflet of the first trifoliolate was sampled, and microscopic images of the leaflet replica were obtained among 90 soybean accessions. The Single Shot MultiBox Detector, an algorithm for an object detection based on deep learning, was introduced to develop an automatic detector of the stomata in the image. The developed detector successfully recognized the stomata in the microscopic image with high-throughput. Using this technique, the value of R2 reached 0.90 when the manually and automatically measured SDs were compared in the 150 images. This technique discovered a variation in SD from 93_±_3 to 166_±_4_mm_2 among the 90 accessions. Our detector can be a powerful tool for a SD evaluation with a large-scale population in crop species, accelerating the identification of useful alleles related to the SD in future breeding programs."																				
2019	"Schneider, Stefan; Taylor, Graham W.; Linquist, Stefan; Kremer, Stefan C."	"Past, present and future approaches using computer vision for animal re_identification from camera trap data"	NA	NA	Review	Methods in Ecology and Evolution	10	4	461-470	10.1111/2041-210X.13133	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13133	"The ability of a researcher to re-identify (re-ID) an individual animal upon re-encounter is fundamental for addressing a broad range of questions in the study of ecosystem function, community and population dynamics and behavioural ecology. Tagging animals during mark and recapture studies is the most common method for reliable animal re-ID; however, camera traps are a desirable alternative, requiring less labour, much less intrusion and prolonged and continuous monitoring into an environment. Despite these advantages, the analyses of camera traps and video for re-ID by humans are criticized for their biases related to human judgement and inconsistencies between analyses. In this review, we describe a brief history of camera traps for re-ID, present a collection of computer vision feature engineering methodologies previously used for animal re-ID, provide an introduction to the underlying mechanisms of deep learning relevant to animal re-ID, highlight the success of deep learning methods for human re-ID, describe the few ecological studies currently utilizing deep learning for camera trap analyses and our predictions for near future methodologies based on the rapid development of deep learning methods. For decades, ecologists with expertise in computer vision have successfully utilized feature engineering to extract meaningful features from camera trap images to improve the statistical rigor of individual comparisons and remove human bias from their camera trap analyses. Recent years have witnessed the emergence of deep learning systems which have demonstrated the accurate re-ID of humans based on image and video data with near perfect accuracy. Despite this success, ecologists have yet to utilize these approaches for animal re-ID.By utilizing novel deep learning methods for object detection and similarity comparisons, ecologists can extract animals from an image/video data and train deep learning classifiers to re-ID animal individuals beyond the capabilities of a human observer. This methodology will allow ecologists with camera/video trap data to reidentify individuals that exit and re-enter the camera frame. Our expectation is that this is just the beginning of a major trend that could stand to revolutionize the analysis of camera trap data and, ultimately, our approach to animal ecology. "																				
2019	"Schofield, Daniel; Nagrani, Arsha; Zisserman, Andrew; Hayashi, Misato; Matsuzawa, Tetsuro; Biro, Dora; Carvalho, Susana"	Chimpanzee face recognition from videos in the wild using deep learning	Video	CNN	Classification	Science Advances	5	9	eaaw0736	10.1126/sciadv.aaw0736	https://www.science.org/doi/10.1126/sciadv.aaw0736	Wild ape face recognition using artificial intelligence opens the way for fully automated analysis of large-scale video datasets.																				
2019	"Seeland, Marco; Rzanny, Michael; Boho, David; Wäldchen, Jana; Mäder, Patrick"	Image-based classification of plant genus and family for trained and untrained plant species	Images	CNN	Classification	BMC Bioinformatics	20	1	4	10.1186/s12859-018-2474-x	https://doi.org/10.1186/s12859-018-2474-x	"Modern plant taxonomy reflects phylogenetic relationships among taxa based on proposed morphological and genetic similarities. However, taxonomical relation is not necessarily reflected by close overall resemblance, but rather by commonality of very specific morphological characters or similarity on the molecular level. It is an open research question to which extent phylogenetic relations within higher taxonomic levels such as genera and families are reflected by shared visual characters of the constituting species. As a consequence, it is even more questionable whether the taxonomy of plants at these levels can be identified from images using machine learning techniques."																				
2019	"Seijas, Cesar; Montilla, Guillermo; Frassato, Luigi"	Identification of Rodent Species Using Deep Learning	Images	CNN	Classification	Computación y Sistemas	23	1	257	10.13053/cys-23-1-2906	https://cys.cic.ipn.mx/ojs/index.php/CyS/article/view/2906	"In this article, we describe a rodent species identification system using computational tools of the deep learning paradigm. The identified species are 4 different types of rodents and the identification is achieved using artificial intelligence techniques applied to images of these rodents in their natural habitat. These images were captured, using camera systems activatedin automatic mode, hidden in the natural habitat of the species under study, under both daylight and nighttime conditions and labeled by experts. The collected imageset constitutes the data set for supervised training of 1411 images of 4 classes. The identifier developed is a multiclass classifier, based on the deep learning paradigm of the broad topic of machine learning, which allows to build a high performance system. The classifier consists of three stages connected in cascade, being the first stage, a pre-processing stage, then, there is a convolutional neural network (CNN) for feature extraction, implemented with a pre-trained architecture using the method of learning by transfer; specifically, the CNN used is the well-known VGG-16; to this second stage, a support vector machine (SVM) is connected as the next and final stage, which acts as the classification stage. For comparative purposes, the results are contrasted against automatic identification models previously published, the results achieved with our identifier are significantly higher than those achieved in previous research on the subject."																				
2019	"Shorten, Connor; Khoshgoftaar, Taghi M."	A survey on image data augmentation for deep learning	NA	NA	Review	Journal of Big Data	6	1	60	10.1186/s40537-019-0197-0	https://doi.org/10.1186/s40537-019-0197-0	"Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data."																				
2019	"Siddiqui, Shoaib Ahmed; Salman, Ahmad; Malik, Muhammad Imran; Shafait, Faisal; Mian, Ajmal; Shortis, Mark R; Harvey, Euan S"	Automatic fish species classification in underwater videos: exploiting pre-trained deep neural network models to compensate for limited labelled data	Video	CNN	Classification	ICES Journal of Marine Science	75	1	374-389	10.1093/icesjms/fsx109	https://academic.oup.com/icesjms/article/75/1/374/3924506	"There is a need for automatic systems that can reliably detect, track and classify fish and other marine species in underwater videos without human intervention. Conventional computer vision techniques do not perform well in underwater conditions where the background is complex and the shape and textural features of fish are subtle. Data-driven classification models like neural networks require a huge amount of labelled data, otherwise they tend to over-fit to the training data and fail on unseen test data which is not involved in training. We present a state-of-the-art computer vision method for fine-grained fish species classification based on deep learning techniques. A cross-layer pooling algorithm using a pre-trained Convolutional Neural Network as a generalized feature detector is proposed, thus avoiding the need for a large amount of training data. Classification on test data is performed by a SVM on the features computed through the proposed method, resulting in classification accuracy of 94.3% for fish species from typical underwater video imagery captured off the coast of Western Australia. This research advocates that the development of automated classification systems which can identify fish from underwater video imagery is feasible and a cost-effective alternative to manual identification by humans."																				
2019	"Silva, Jose Cleydson F.; Teixeira, Ruan M.; Silva, Fabyano F.; Brommonschenkel, Sergio H.; Fontes, Elizabeth P. B."	Machine learning approaches and their current application in plant molecular biology: A systematic review	NA	NA	Review	Plant Science	284		37-47	10.1016/j.plantsci.2019.03.020	https://www.sciencedirect.com/science/article/pii/S0168945218315802	"Machine learning (ML) is a field of artificial intelligence that has rapidly emerged in molecular biology, thus allowing the exploitation of Big Data concepts in plant genomics. In this context, the main challenges are given in terms of how to analyze massive datasets and extract new knowledge in all levels of cellular systems research. In summary, ML techniques allow complex interactions to be inferred in several biological systems. Despite its potential, ML has been underused due to complex computational algorithms and definition terms. Therefore, a systematic review to disentangle ML approaches is relevant for plant scientists and has been considered in this study. We presented the main steps for ML development (from data selection to evaluation of classification/prediction models) with a respective discussion approaching functional genomics mainly in terms of pathogen effector genes in plant immunity. Additionally, we also considered how to access public source databases under an ML framework towards advancing plant molecular biology and introduced novel powerful tools, such as deep learning."																				
2019	"Song, Yupeng; He, Fazhi; Zhang, Xiying"	To Identify Tree Species With Highly Similar Leaves Based on a Novel Attention Mechanism for CNN	Images	CNN	Classification	IEEE Access	7		163277-163286	10.1109/ACCESS.2019.2951607	https://ieeexplore.ieee.org/document/8891701	"Image identification technology has great significance for forestry production and forestry management. Highly similar object identification tasks, such as tree species with similar leaves, are extremely challenging. Simply using typical Convolutional Neural Networks (CNNs) or simply adding more convolutional layers still performs poorly in the above tasks. In this paper, we present a novel attention mechanism to enhance the CNN for identification of tree species with highly similar leaves. This paper presents a highly discriminative network, namely attention branch based convolutional neural networks (ABCNN), to better distinguish the differences between leaves features. Firstly, we proposed a novel structure, in which an attention branch is added in all block layers of network besides the typical normal branch. Secondly, our attention branch adopts a condensation process to obtain a region of interest (ROI) from global information of input and designs a reconstruction process to amplify the features difference to focus on the ROI. Thirdly, we design a fusion process, which carefully combines the attention branch with a normal branch to improve the network performance in the training process. The proposed ABCNN is tested on special dataset of Leafsnap with highly similar tree leaves. Our approach achieved 91.43% classification accuracy, which is higher than previous methods. Furthermore, ABCNN is also tested on general data set of SVHN and obtains 98.27% classification accuracy, which is the most competitive when considering the lower computational resources for ordinary applications. Both above experiments demonstrate the discrimination and robustness of the proposed method."																				
2019	"Souza, Fernando Henrique Santos de; Perez, Manolo Fernandez; Bertollo, Luiz Antônio Carlos; Oliveira, Ezequiel Aguiar de; Lavoué, Sebastien; Gestich, Carla Cristina; Ráb, Petr; Ezaz, Tariq; Liehr, Thomas; Viana, Patrik Ferreira; Feldberg, Eliana; Cioffi, Marcelo de Bello"	"Interspecific Genetic Differences and Historical Demography in South American Arowanas (Osteoglossiformes, Osteoglossidae, Osteoglossum)"	Molecular	CNN	Modeling	Genes	10	9	693	10.3390/genes10090693	https://www.mdpi.com/2073-4425/10/9/693	"The South American arowanas (Osteoglossiformes, Osteoglossidae, Osteoglossum) are emblematic species widely distributed in the Amazon and surrounding basins. Arowana species are under strong anthropogenic pressure as they are extensively exploited for ornamental and food purposes. Until now, limited genetic and cytogenetic information has been available, with only a few studies reporting to their genetic diversity and population structure. In the present study, cytogenetic and DArTseq-derived single nucleotide polymorphism (SNP) data were used to investigate the genetic diversity of the two Osteoglossum species, the silver arowana O. bicirrhosum, and the black arowana O. ferreirai. Both species differ in their 2n (with 2n = 54 and 56 for O. ferreirai and O. bicirrhosum, respectively) and in the composition and distribution of their repetitive DNA content, consistent with their taxonomic status as different species. Our genetic dataset was coupled with contemporary and paleogeographic niche modeling, to develop concurrent demographic models that were tested against each other with a deep learning approach in O. bicirrhosum. Our genetic results reveal that O. bicirrhosum colonized the Tocantins-Araguaia basin from the Amazon basin about one million years ago. In addition, we highlighted a higher genetic diversity of O. bicirrhosum in the Amazon populations in comparison to those from the Tocantins-Araguaia basin."																				
2019	"Souza, Witenberg S. R.; Alves, Adao Nunes; Borges, Dibio Leandro"	A Deep Learning Model for Recognition of Pest Insects in Maize Plantations	Images	CNN	Classification	"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)"			2285-2290	10.1109/SMC.2019.8914428	https://ieeexplore.ieee.org/document/8914428/	"This work approaches recognition of insect pests in maize plantations. It presents a novel dataset of field-based images for primary and secondary insect pests, with original and augmented images to be used for supervised classification. It also proposes a modification on a residual deep learning model (Inception-V3), called Inception-V3* here, which provides faster learning and better accuracy than the original model. Tests are run for two experiments, primary pests and all (primary and secondary). Pre-trained weights from ImageNet are used via transfer learning and AlexNet and residual models (Inception-V3 and modified Inception-V3*) are evaluated. On average, using cross-validation, the proposed Inception-V3* model achieved the best accuracy rate of 97.0% for all insect pests classes."																				
2019	"Sumsion, G. Rex; Bradshaw, Michael S.; Hill, Kimball T.; Pinto, Lucas D. G.; Piccolo, Stephen R."	Remote sensing tree classification with a multilayer perceptron	Other	DNN	Classification	PeerJ	7		e6101	10.7717/peerj.6101	https://peerj.com/articles/6101	"To accelerate scientific progress on remote tree classification—as well as biodiversity and ecology sampling—The National Institute of Science and Technology created a community-based competition where scientists were invited to contribute informatics methods for classifying tree species and genus using crown-level images of trees. We classified tree species and genus at the pixel level using hyperspectral and LiDAR observations. We compared three algorithms that have been implemented extensively across a broad range of research applications: support vector machines, random forests, and multilayer perceptron. At the pixel level, the multilayer perceptron algorithm classified species or genus with high accuracy (92.7% and 95.9%, respectively) on the training data and performed better than the other two algorithms (85.8–93.5%). This indicates promise for the use of the multilayer perceptron (MLP) algorithm for tree-species classification based on hyperspectral and LiDAR observations and coincides with a growing body of research in which neural network-based algorithms outperform other types of classification algorithm for machine vision. To aggregate patterns across the images, we used an ensemble approach that averages the pixel-level outputs of the MLP algorithm to classify species at the crown level. The average accuracy of these classifications on the test set was 68.8% for the nine species."																				
2019	"Suvorov, Anton; Hochuli, Joshua; Schrider, Daniel R"	Accurate Inference of Tree Topologies from Multiple Sequence Alignments Using Deep Learning	Molecular	CNN	Classification	Systematic Biology			syz060	10.1093/sysbio/syz060	https://academic.oup.com/sysbio/advance-article/doi/10.1093/sysbio/syz060/5559282	"Reconstructing the phylogenetic relationships between species is one of the most formidable tasks in evolutionary biology. Multiple methods exist to reconstruct phylogenetic trees, each with their own strengths and weaknesses. Both simulation and empirical studies have identified several “zones” of parameter space where accuracy of some methods can plummet, even for four-taxon trees. Further, some methods can have undesirable statistical properties such as statistical inconsistency and\/or the tendency to be positively misleading (i.e. assert strong support for the incorrect tree topology). Recently, deep learning techniques have made inroads on a number of both new and longstanding problems in biological research. In this study, we designed a deep convolutional neural network (CNN) to infer quartet topologies from multiple sequence alignments. This CNN can readily be trained to make inferences using both gapped and ungapped data. We show that our approach is highly accurate on simulated data, often outperforming traditional methods, and is remarkably robust to bias-inducing regions of parameter space such as the Felsenstein zone and the Farris zone. We also demonstrate that the confidence scores produced by our CNN can more accurately assess support for the chosen topology than bootstrap and posterior probability scores from traditional methods. Although numerous practical challenges remain, these findings suggest that the deep learning approaches such as ours have the potential to produce more accurate phylogenetic inferences."																				
2019	"Tabak, Michael A.; Norouzzadeh, Mohammad S.; Wolfson, David W.; Sweeney, Steven J.; Vercauteren, Kurt C.; Snow, Nathan P.; Halseth, Joseph M.; Di Salvo, Paul A.; Lewis, Jesse S.; White, Michael D.; Teton, Ben; Beasley, James C.; Schlichting, Peter E.; Boughton, Raoul K.; Wight, Bethany; Newkirk, Eric S.; Ivan, Jacob S.; Odell, Eric A.; Brook, Ryan K.; Lukacs, Paul M.; Moeller, Anna K.; Mandeville, Elizabeth G.; Clune, Jeff; Miller, Ryan S."	Machine learning to classify animal species in camera trap images: Applications in ecology	Images	CNN	Classification	Methods in Ecology and Evolution	10	4	585-590	10.1111/2041-210X.13120	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13120	"Motion-activated cameras (“camera traps”) are increasingly used in ecological and management studies for remotely observing wildlife and are amongst the most powerful tools for wildlife research. However, studies involving camera traps result in millions of images that need to be analysed, typically by visually observing each image, in order to extract data that can be used in ecological analyses.We trained machine learning models using convolutional neural networks with the ResNet-18 architecture and 3,367,383 images to automatically classify wildlife species from camera trap images obtained from five states across the United States. We tested our model on an independent subset of images not seen during training from the United States and on an out-of-sample (or “out-of-distribution” in the machine learning literature) dataset of ungulate images from Canada. We also tested the ability of our model to distinguish empty images from those with animals in another out-of-sample dataset from Tanzania, containing a faunal community that was novel to the model. The trained model classified approximately 2,000 images per minute on a laptop computer with 16 gigabytes of RAM. The trained model achieved 98% accuracy at identifying species in the United States, the highest accuracy of such a model to date. Out-of-sample validation from Canada achieved 82% accuracy and correctly identified 94% of images containing an animal in the dataset from Tanzania. We provide an r package (Machine Learning for Wildlife Image Classification) that allows the users to (a) use the trained model presented here and (b) train their own model using classified images of wildlife from their studies. The use of machine learning to rapidly and accurately classify wildlife in camera trap images can facilitate non-invasive sampling designs in ecological studies by reducing the burden of manually analysing images. Our r package makes these methods accessible to ecologists."																				
2019	"Tan, Kiat Chuan; Liu, Yulong; Ambrose, Barbara; Tulig, Melissa; Belongie, Serge"	The Herbarium Challenge 2019 Dataset	NA	NA	Other	arXiv			1906.05372	10.48550/arXiv.1906.05372	http://arxiv.org/abs/1906.05372	"Herbarium sheets are invaluable for botanical research, and considerable time and effort is spent by experts to label and identify specimens on them. In view of recent advances in computer vision and deep learning, developing an automated approach to help experts identify specimens could significantly accelerate research in this area. Whereas most existing botanical datasets comprise photos of specimens in the wild, herbarium sheets exhibit dried specimens, which poses new challenges. We present a challenge dataset of herbarium sheet images labeled by experts, with the intent of facilitating the development of automated identification techniques for this challenging scenario."																				
2019	"Tao, Dan; Qiu, Guangying; Li, Guanglin"	A Novel Model for Sex Discrimination of Silkworm Pupae From Different Species	Other	CNN	Classification	IEEE Access	7		165328-165335	10.1109/ACCESS.2019.2953040	https://ieeexplore.ieee.org/document/8896916	"Sex determination of silkworm pupae is important for silkworm industry. Multivariate analysis methods have been widely applied in hyperspectral imaging spectroscopy for classification. However, these methods require essential steps containing spectra preprocessing or feature extraction, which were not easy determined. Convolutional neural networks (CNNs), which have been employed in image recognition, could effectively learn interpretable presentations of the sample without the need of ad-hoc preprocessing steps. The species of silkworm pupae are usually up to hundreds. Conventional classifiers based on one species of silkworm pupae could not give high performance when explored to other species that not participating in the model building, resulting in bad generalization ability. In this study, a CNN model was trained to automatically identify the sex of silkworm pupae from different years and species based on the hyperspectral spectra. The results were compared with the frequently used conventional machine classifiers including support vector machine (SVM) and K nearest neighbors (KNN). The results showed that CNN outperformed SVM and KNN in terms of accuracy when applied to the raw spectra with 98.03%. However, the performance of CNN decreased to 95.09% when combined with the preprocessed data. Then principal component analysis (PCA) was adopted to reduce data dimensionality and extract features. CNN gave higher accuracy than SVM and KNN based on PCA. The discussion section revealed that CNN had high generalization ability that could classify silkworm pupae from different species with a rather well performance. It demonstrated that HSI technology in combination with CNN was useful in determining the sex of silkworm pupae."																				
2019	"Thenmozhi, K.; Srinivasulu Reddy, U."	Crop pest classification based on deep convolutional neural network and transfer learning	Images	CNN	Classification	Computers and Electronics in Agriculture	164		104906	10.1016/j.compag.2019.104906	https://linkinghub.elsevier.com/retrieve/pii/S0168169919310695	"The growth of most important field crops such as rice, wheat, maize, soybean, and sugarcane are affected due to attack of various pests and the crop production is reduced due to different types of insects. The classification and identification of all types of crop insects correctly is a difficult task for the farmers due to the similar appearance in the earlier stage of crop growth. To address this issue, Convolutional neural network (CNN) with deep architectures is being applied as it performs automatic feature extraction and learns complex high-level features in image classification applications. This study proposed an efficient deep CNN model to classify insect species on three publicly available insect datasets. The National Bureau of Agricultural Insect Resources (NBAIR) dataset used as first insect dataset that consists of 40 classes of field crop insect images, while the second and third dataset (Xie1, Xie2) contains 24 and 40 classes of insects respectively. The proposed model was evaluated and compared with pre-trained deep learning architectures such as AlexNet, ResNet, GoogLeNet and VGGNet for insect classification. Transfer learning was applied to fine-tune the pre-trained models. The data augmentation techniques such as reflection, scaling, rotation, and translation are also applied to prevent the network from overfitting. The effectiveness of hyperparameters was analysed in the proposed model to improve accuracy. The highest classification accuracy of 96.75, 97.47, and 95.97% was achieved in proposed CNN model for NBAIR insect dataset (40 classes), Xie1 (24 classes) insect dataset and Xie2 (40 classes) insect dataset respectively. The results demonstrated that the proposed CNN model is effective in classifying various types of insects in field crops than pre-trained models and can be implemented in the agriculture sector for crop protection."																				
2019	"Thompson, Jaron; Johansen, Renee; Dunbar, John; Munsky, Brian"	Machine learning to predict microbial community functions: An analysis of dissolved organic carbon from litter decomposition	"Molecular, Other"	DNN	Regression	PLOS ONE	14	7	e0215502	10.1371/journal.pone.0215502	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0215502	"Microbial communities are ubiquitous and often influence macroscopic properties of the ecosystems they inhabit. However, deciphering the functional relationship between specific microbes and ecosystem properties is an ongoing challenge owing to the complexity of the communities. This challenge can be addressed, in part, by integrating the advances in DNA sequencing technology with computational approaches like machine learning. Although machine learning techniques have been applied to microbiome data, use of these techniques remains rare, and user-friendly platforms to implement such techniques are not widely available. We developed a tool that implements neural network and random forest models to perform regression and feature selection tasks on microbiome data. In this study, we applied the tool to analyze soil microbiome (16S rRNA gene profiles) and dissolved organic carbon (DOC) data from a 44-day plant litter decomposition experiment. The microbiome data includes 1709 total bacterial operational taxonomic units (OTU) from 300+ microcosms. Regression analysis of predicted and actual DOC for a held-out test set of 51 samples yield Pearson’s correlation coefficients of.636 and.676 for neural network and random forest approaches, respectively. Important taxa identified by the machine learning techniques are compared to results from a standard tool (indicator species analysis) widely used by microbial ecologists. Of 1709 bacterial taxa, indicator species analysis identified 285 taxa as significant determinants of DOC concentration. Of the top 285 ranked features determined by machine learning methods, a subset of 86 taxa are common to all feature selection techniques. Using this subset of features, prediction results for random permutations of the data set are at least equally accurate compared to predictions determined using the entire feature set. Our results suggest that integration of multiple methods can aid identification of a robust subset of taxa within complex communities that may drive specific functional outcomes of interest."																				
2019	"Torada, Luis; Lorenzon, Lucrezia; Beddis, Alice; Isildak, Ulas; Pattini, Linda; Mathieson, Sara; Fumagalli, Matteo"	ImaGene: a convolutional neural network to quantify natural selection from genomic data	Molecular	CNN	Classification	BMC Bioinformatics	20	S9	337	10.1186/s12859-019-2927-x	https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2927-x	"Background The genetic bases of many complex phenotypes are still largely unknown, mostly due to the polygenic nature of the traits and the small effect of each associated mutation. An alternative approach to classic association studies to determining such genetic bases is an evolutionary framework. As sites targeted by natural selection are likely to harbor important functionalities for the carrier, the identification of selection signatures in the genome has the potential to unveil the genetic mechanisms underpinning human phenotypes. Popular methods of detecting such signals rely on compressing genomic information into summary statistics, resulting in the loss of information. Furthermore, few methods are able to quantify the strength of selection. Here we explored the use of deep learning in evolutionary biology and implemented a program, called , to apply convolutional neural networks on population genomic data for the detection and quantification of natural selection. Results enables genomic information from multiple individuals to be represented as abstract images. Each image is created by stacking aligned genomic data and encoding distinct alleles into separate colors. To detect and quantify signatures of positive selection, implements a convolutional neural network which is trained using simulations. We show how the method implemented in can be affected by data manipulation and learning strategies. In particular, we show how sorting images by row and column leads to accurate predictions. We also demonstrate how the misspecification of the correct demographic model for producing training data can influence the quantification of positive selection. We finally illustrate an approach to estimate the selection coefficient, a continuous variable, using multiclass classification techniques. Conclusions While the use of deep learning in evolutionary genomics is in its infancy, here we demonstrated its potential to detect informative patterns from large-scale genomic data. We implemented methods to process genomic data for deep learning in a user-friendly program called . The joint inference of the evolutionary history of mutations and their functional impact will facilitate mapping studies and provide novel insights into the molecular mechanisms associated with human phenotypes."																				
2019	"Torney, Colin J.; Lloyd_Jones, David J.; Chevallier, Mark; Moyer, David C.; Maliti, Honori T.; Mwita, Machoke; Kohi, Edward M.; Hopcraft, Grant C."	A comparison of deep learning and citizen science techniques for counting wildlife in aerial survey images	Images	CNN	Classification	Methods in Ecology and Evolution	10	6	779-787	10.1111/2041-210X.13165	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13165	"Fast and accurate estimates of wildlife abundance are an essential component of efforts to conserve ecosystems in the face of rapid environmental change. A widely used method for estimating species abundance involves flying aerial transects, taking photographs, counting animals within the images and then inferring total population size based on a statistical estimate of species density in the region. The intermediate task of manually counting the aerial images is highly labour intensive and is often the limiting step in making a population estimate. Here, we assess the use of two novel approaches to perform this task by deploying both citizen scientists and deep learning to count aerial images of the 2015 survey of wildebeest (Connochaetes taurinus) in Serengeti National Park, Tanzania. Through the use of the online platform Zooniverse, we collected multiple non-expert counts by citizen scientists and used three different aggregation methods to obtain a single count for the survey images. We also counted the images by developing a bespoke deep learning method via the use of a convolutional neural network. The results of both approaches were then compared. After filtering of the citizen science counts, both approaches provided highly accurate total estimates. The deep learning method was far faster and appears to be a more reliable and predictable approach; however, we note that citizen science volunteers played an important role when creating training data for the algorithm. Notably, our results show that accurate, species-specific, automated counting of aerial wildlife images is now possible."																				
2019	"Torroja, Carlos; Sanchez-Cabo, Fatima"	Digitaldlsorter: Deep-Learning on scRNA-Seq to Deconvolute Gene Expression Data	Molecular	DNN	Regression	Frontiers in Genetics	10			10.3389/fgene.2019.00978	https://www.frontiersin.org/article/10.3389/fgene.2019.00978	"The development of single cell transcriptome sequencing has allowed researchers the possibility to dig inside the role of the individual cell types in a plethora of disease scenarios. It also expands to the whole transcriptome what before was only possible for a few tenths of antibodies in cell population analysis. More importantly, it allows resolving the permanent question of whether the changes observed in a particular bulk experiment are a consequence of changes in cell type proportions or an aberrant behavior of a particular cell type. However, single cell experiments are still complex to perform and expensive to sequence making bulk RNA-Seq experiments yet more common. scRNA-Seq data is proving highly relevant information for the characterization of the immune cell repertoire in different diseases ranging from cancer to atherosclerosis. In particular, as scRNA-Seq becomes more widely used, new types of immune cell populations emerge and their role in the genesis and evolution of the disease opens new avenues for personalized immune therapies. Immunotherapy have already proven successful in a variety of tumors such as breast, colon and melanoma and its value in other types of disease is being currently explored. From a statistical perspective, single-cell data are particularly interesting due to its high dimensionality, overcoming the limitations of the “skinny matrix” that traditional bulk RNA-Seq experiments yield. With the technological advances that enable sequencing hundreds of thousands of cells, scRNA-Seq data have become especially suitable for the application of Machine Learning algorithms such as Deep Learning (DL). We present here a DL based method to enumerate and quantify the immune infiltration in colorectal and breast cancer bulk RNA-Seq samples starting from scRNA-Seq. Our method makes use of a Deep Neural Network (DNN) model that allows quantification not only of lymphocytes as a general population but also of specific CD8+, CD4Tmem, CD4Th and CD4Tregs subpopulations, as well as B-cells and Stromal content. Moreover, the signatures are built from scRNA-Seq data from the tumor, preserving the specific characteristics of the tumor microenvironment as opposite to other approaches in which cells were isolated from blood. Our method was applied to synthetic bulk RNA-Seq and to samples from the TCGA project yielding very accurate results in terms of quantification and survival prediction."																				
2019	"V, Sathya; H, Rafidha; G, Sumitha Rani"	Fruit and Leaves Disease Prediction Using Deep Learning Algorithm	Images	CNN	Classification	International Research Journal of Multidisciplinary Technovation	1	5	16-Aug	10.34256/irjmt1952	https://journals.iorpress.org/index.php/irjmt/article/view/347	"The purpose of Agriculture is not only to feed ever growing population but it’s an important source of energy and a solution to solve the problem of global warming. Plant diseases are extremely significant, as that can adversely affect both quality and quantity of crops in agriculture production. Plant disease diagnosis is very essential in earlier stage in order to cure and control them. Generally the naked eye method is used to identify the diseases. In this method experts are involved who have the ability to detect the changes in leaf color. This method involves lots of efforts, takes long time and also not practical for the large fields. Many times different experts identify the same disease as the different disease. This method is expensive as it requires continuous monitoring of experts. Tree leaves and fruit diseases can increase the cost of agricultural production and may extend to total economic disaster of a producer if not cured appropriately at early stages. The producers need to monitor their crops and detect the first symptoms in order to prevent the spread of a plant disease, with low cost and save the major part of the production. Hiring professional agriculturists may not be affordable especially in remote isolated geographic regions. Machine learning algorithm in image can offer an alternative solution in plant monitoring and such an approach may anyway be controlled by a professional to offer his services with lower cost. It includes image segmentation and image classification approach to predict various types of diseases using Otsu thresholding method and convolutional neural network method."																				
2019	"Valan, Miroslav; Makonyi, Karoly; Maki, Atsuto; Vondrá_ek, Dominik; Ronquist, Fredrik"	Automated Taxonomic Identification of Insects with Expert-Level Accuracy Using Effective Feature Transfer from Convolutional Networks	Images	CNN	Classification	Systematic Biology	68	6	876-895	10.1093/sysbio/syz014	https://academic.oup.com/sysbio/article/68/6/876/5368535	"Rapid and reliable identification of insects is important in many contexts, from the detection of disease vectors and invasive species to the sorting of material from biodiversity inventories. Because of the shortage of adequate expertise, there has long been an interest in developing automated systems for this task. Previous attempts have been based on laborious and complex handcrafted extraction of image features, but in recent years it has been shown that sophisticated convolutional neural networks (CNNs) can learn to extract relevant features automatically, without human intervention. Unfortunately, reaching expert-level accuracy in CNN identifications requires substantial computational power and huge training data sets, which are often not available for taxonomic tasks. This can be addressed using feature transfer: a CNN that has been pretrained on a generic image classification task is exposed to the taxonomic images of interest, and information about its perception of those images is used in training a simpler, dedicated identification system. Here, we develop an effective method of CNN feature transfer, which achieves expert-level accuracy in taxonomic identification of insects with training sets of 100 images or less per category, depending on the nature of data set. Specifically, we extract rich representations of intermediate to high-level image features from the CNN architecture VGG16 pretrained on the ImageNet data set. This information is submitted to a linear support vector machine classifier, which is trained on the target problem. We tested the performance of our approach on two types of challenging taxonomic tasks: 1) identifying insects to higher groups when they are likely to belong to subgroups that have not been seen previously and 2) identifying visually similar species that are difficult to separate even for experts. For the first task, our approach reached $CDATA[$CDATA[$&amp;gt;$$92% accuracy on one data set (884 face images of 11 families of Diptera, all specimens representing unique species), and $CDATA[$CDATA[$&amp;gt;$$96% accuracy on another (2936 dorsal habitus images of 14 families of Coleoptera, over 90% of specimens belonging to unique species). For the second task, our approach outperformed a leading taxonomic expert on one data set (339 images of three species of the Coleoptera genus Oxythyrea; 97% accuracy), and both humans and traditional automated identification systems on another data set (3845 images of nine species of Plecoptera larvae; 98.6 % accuracy). Reanalyzing several biological image identification tasks studied in the recent literature, we show that our approach is broadly applicable and provides significant improvements over previous methods, whether based on dedicated CNNs, CNN feature transfer, or more traditional techniques. Thus, our method, which is easy to apply, can be highly successful in developing automated taxonomic identification systems even when training data sets are small and computational budgets limited. We conclude by briefly discussing some promising CNN-based research directions in morphological systematics opened up by the success of these techniques in providing accurate diagnostic tools."																				
2019	"Washburn, Jacob D.; Mejia-Guerra, Maria Katherine; Ramstein, Guillaume; Kremling, Karl A.; Valluru, Ravi; Buckler, Edward S.; Wang, Hai"	Evolutionarily informed deep learning methods for predicting relative transcript abundance from DNA sequence	Molecular	CNN	Regression	Proceedings of the National Academy of Sciences	116	12	5542-5549	10.1073/pnas.1814551116	https://www.pnas.org/doi/10.1073/pnas.1814551116	"Significance  Machine learning methodologies can be applied readily to biological problems, but standard training and testing methods are not designed to control for evolutionary relatedness or other biological phenomena. In this article, we propose, implement, and test two methods to control for and utilize evolutionary relatedness within a predictive deep learning framework. The methods are tested and applied within the context of predicting mRNA expression levels from whole-genome DNA sequence data and are applicable across biological organisms. Potential use cases for the methods include plant and animal breeding, disease research, gene editing, and others."																				
2019	"Wearn, Oliver R.; Freeman, Robin; Jacoby, David M. P."	Responsible AI for conservation	NA	NA	Review	Nature Machine Intelligence	1	2	72-73	10.1038/s42256-019-0022-7	http://www.nature.com/articles/s42256-019-0022-7	NA																				
2019	"Wertheimer, Davis; Hariharan, Bharath"	Few-Shot Learning With Localization in Realistic Settings	Images	CNN	Classification	2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)				10.1109/CVPR.2019.00672	https://ieeexplore.ieee.org/document/8954404/	"Traditional recognition methods typically require large, artiﬁcially-balanced training classes, while few-shot learning methods are tested on artiﬁcially small ones. In contrast to both extremes, real world recognition problems exhibit heavy-tailed class distributions, with cluttered scenes and a mix of coarse and ﬁne-grained class distinctions. We show that prior methods designed for few-shot learning do not work out of the box in these challenging conditions, based on a new “meta-iNat” benchmark. We introduce three parameter-free improvements: (a) better training procedures based on adapting cross-validation to metalearning, (b) novel architectures that localize objects using limited bounding box annotations before classiﬁcation, and (c) simple parameter-free expansions of the feature space based on bilinear pooling. Together, these improvements double the accuracy of state-of-the-art models on meta-iNat while generalizing to prior benchmarks, complex neural architectures, and settings with substantial domain shift."																				
2019	"Wick, Ryan R.; Judd, Louise M.; Holt, Kathryn E."	Performance of neural network basecalling tools for Oxford Nanopore sequencing	Molecular	RNN	Classification	Genome Biology	20	1	129	10.1186/s13059-019-1727-y	https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1727-y	"Background: Basecalling, the computational process of translating raw electrical signal to nucleotide sequence, is of critical importance to the sequencing platforms produced by Oxford Nanopore Technologies (ONT). Here, we examine the performance of different basecalling tools, looking at accuracy at the level of bases within individual reads and at majority-rule consensus basecalls in an assembly. We also investigate some additional aspects of basecalling: training using a taxon-specific dataset, using a larger neural network model and improving consensus basecalls in an assembly by additional signal-level analysis with Nanopolish. Results: Training basecallers on taxon-specific data results in a significant boost in consensus accuracy, mostly due to the reduction of errors in methylation motifs. A larger neural network is able to improve both read and consensus accuracy, but at a cost to speed. Improving consensus sequences (‘polishing’) with Nanopolish somewhat negates the accuracy differences in basecallers, but pre-polish accuracy does have an effect on post-polish accuracy. Conclusions: Basecalling accuracy has seen significant improvements over the last 2 years. The current version of ONT’s Guppy basecaller performs well overall, with good accuracy and fast performance. If higher accuracy is required, users should consider producing a custom model using a larger neural network and/or training data from the same species."																				
2019	"Wu, Bizhi; Zhang, Hangxiao; Lin, Limei; Wang, Huiyuan; Gao, Yubang; Zhao, Liangzhen; Chen, Yi-Ping Phoebe; Chen, Riqing; Gu, Lianfeng"	A Similarity Searching System for Biological Phenotype Images Using Deep Convolutional Encoder-decoder Architecture	Images	Other	Regression	Current Bioinformatics	14	7	628-639	10.2174/1574893614666190204150109	https://www.eurekaselect.com/article/96353	"Background: The BLAST (Basic Local Alignment Search Tool) algorithm has been widely used for sequence similarity searching. Analogously, the public phenotype images must be efficiently retrieved using biological images as queries and identify the phenotype with high similarity. Due to the accumulation of genotype-phenotype-mapping data, a system of searching for similar phenotypes is not available due to the bottleneck of image processing. Objective: In this study, we focus on the identification of similar query phenotypic images by searching the biological phenotype database, including information about loss-of-function and gain-of-function. Methods: We propose a deep convolutional autoencoder architecture to segment the biological phenotypic images and develop a phenotype retrieval system to enable a better understanding of genotype–phenotype correlation. Results: This study shows how deep convolutional autoencoder architecture can be trained on images from biological phenotypes to achieve state-of-the-art performance in a phenotypic images retrieval system. Conclusion: Taken together, the phenotype analysis system can provide further information on the correlation between genotype and phenotype. Additionally, it is obvious that the neural network model of image segmentation and the phenotype retrieval system is equally suitable for any species, which has enough phenotype images to train the neural network."																				
2019	"Wu, Danzi; Han, Xue; Wang, Guan; Sun, Yu; Zhang, Haiyan; Fu, Hongping"	Deep Learning with Taxonomic Loss for Plant Identification	Images	CNN	Classification	Computational Intelligence and Neuroscience	2019		8-Jan	10.1155/2019/2015017	https://www.hindawi.com/journals/cin/2019/2015017/	"Plant identification is a fine-grained classification task which aims to identify the family, genus, and species according to plant appearance features. Inspired by the hierarchical structure of taxonomic tree, the taxonomic loss was proposed, which could encode the hierarchical relationships among multilevel labels into the deep learning objective function by simple group and sum operation. By training various neural networks on PlantCLEF 2015 and PlantCLEF 2017 datasets, the experimental results demonstrated that the proposed loss function was easy to implement and outperformed the most commonly adopted cross-entropy loss. Eight neural networks were trained, respectively, by two different loss functions on PlantCLEF 2015 dataset, and the models trained by taxonomic loss led to significant performance improvements. On PlantCLEF 2017 dataset with 10,000 species, the SENet-154 model trained by taxonomic loss achieved the accuracies of 84.07%, 79.97%, and 73.61% at family, genus and species levels, which improved those of model trained by cross-entropy loss by 2.23%, 1.34%, and 1.08%, respectively. The taxonomic loss could further facilitate the fine-grained classification task with hierarchical labels."																				
2019	"Wu, Leihong; Liu, Zhichao; Bera, Tanmay; Ding, Hongjian; Langley, Darryl A.; Jenkins-Barnes, Amy; Furlanello, Cesare; Maggio, Valerio; Tong, Weida; Xu, Joshua"	A deep learning model to recognize food contaminating beetle species based on elytra fragments	Images	CNN	Classification	Computers and Electronics in Agriculture	166		105002	10.1016/j.compag.2019.105002	https://linkinghub.elsevier.com/retrieve/pii/S0168169918312821	"Insect pests are often associated with food contamination and public health risks. Accurate and timely species-specific identification of pests is a key step to scale impacts, trace back the contamination process and promptly set intervention measures, which usually have serious economic impact. The current procedure involves visual inspection by human analysts of pest fragments recovered from food samples, a time-consuming and error-prone process. Deep Learning models have been widely applied for image recognition, outperforming other machine learning algorithms; however only few studies have applied deep learning for food contamination detection. In this paper, we describe our solution for automatic identification of 15 storage product beetle species frequently detected in food inspection. Our approach is based on a convolutional neural network trained on a dataset of 6900 microscopic images of elytra fragments, obtaining an overall accuracy of 83.8% in cross validation. Notably, the classification performance is obtained without the need of designing and selecting domain specific image features, thus demonstrating the promising prospects of Deep Learning models in detecting food contamination."																				
2019	"Wu, Xiaoping; Zhan, Chi; Lai, Yu-Kun; Cheng, Ming-Ming; Yang, Jufeng"	IP102: A Large-Scale Benchmark Dataset for Insect Pest Recognition	Images	CNN	Classification	2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)			8779-8788	10.1109/CVPR.2019.00899	https://ieeexplore.ieee.org/document/8954351/	"Insect pests are one of the main factors affecting agricultural product yield. Accurate recognition of insect pests facilitates timely preventive measures to avoid economic losses. However, the existing datasets for the visual classification task mainly focus on common objects, e.g., flowers and dogs. This limits the application of powerful deep learning technology on specific domains like the agricultural field. In this paper, we collect a large-scale dataset named IP102 for insect pest recognition. Specifically, it contains more than 75, 000 images belonging to 102 categories, which exhibit a natural long-tailed distribution. In addition, we annotate about 19, 000 images with bounding boxes for object detection. The IP102 has a hierarchical taxonomy and the insect pests which mainly affect one specific agricultural product are grouped into the same upperlevel category. Furthermore, we perform several baseline experiments on the IP102 dataset, including handcrafted and deep feature based classification methods. Experimental results show that this dataset has the challenges of interand intra- class variance and data imbalance. We believe our IP102 will facilitate future research on practical insect pest control, fine-grained visual classification, and imbalanced learning fields. We make the dataset and pre-trained models publicly available at https://github.com/xpwu95/IP102."																				
2019	"Xie, Jiangjian; Li, Anqi; Zhang, Junguo; Cheng, Zhean"	An Integrated Wildlife Recognition Model Based on Multi-Branch Aggregation and Squeeze-And-Excitation Network	Images	CNN	Classification	Applied Sciences	9	14	2794	10.3390/app9142794	https://www.mdpi.com/2076-3417/9/14/2794	"Infrared camera trapping, which helps capture large volumes of wildlife images, is a widely-used, non-intrusive monitoring method in wildlife surveillance. This method can greatly reduce the workload of zoologists through automatic image identification. To achieve higher accuracy in wildlife recognition, the integrated model based on multi-branch aggregation and Squeeze-and-Excitation network is introduced. This model adopts multi-branch aggregation transformation to extract features, and uses Squeeze-and-Excitation block to adaptively recalibrate channel-wise feature responses based on explicit self-mapped interdependencies between channels. The efficacy of the integrated model is tested on two datasets: the Snapshot Serengeti dataset and our own dataset. From experimental results on the Snapshot Serengeti dataset, the integrated model applies to the recognition of 26 wildlife species, with the highest accuracies in Top-1 (when the correct class is the most probable class) and Top-5 (when the correct class is within the five most probable classes) at 95.3% and 98.8%, respectively. Compared with the ROI-CNN algorithm and ResNet (Deep Residual Network), on our own dataset, the integrated model, shows a maximum improvement of 4.4% in recognition accuracy."																				
2019	"Yang, Hao-Wen; Hsu, Hao-Chun; Yang, Chih-Kai; Tsai, Ming-Jer; Kuo, Yan-Fu"	Differentiating between morphologically similar species in genus Cinnamomum (Lauraceae) using deep convolutional neural networks	Images	CNN	Classification	Computers and Electronics in Agriculture	162		739-748	10.1016/j.compag.2019.05.003	https://www.sciencedirect.com/science/article/pii/S0168169918315916	"Plant adulteration is a rising problem in the forest industry. Cinnamomum osmophloeum Kanehira (Lauraceae) is an evergreen plant that yields cinnamaldehyde. Although two other species—C. burmannii (Nees & T. Nees) Blume and C. insularimontanum Hayata— morphologically resemble C. osmophloeum, they produce a minimum amount of cinnamaldehyde, and thus have lower economical values. The adulteration of C. osmophloeum using C. burmannii has been reported. However, even for experts, differentiating between the three species on the basis of their appearance is challenging due to their high degree of similarity in appearance. This study proposed to identify the three Cinnamomum species using leaf images and deep convolutional neural networks (CNN). In this study, leaf images of the three species were acquired using flatbed scanners. Leaf patches around the blade center of the leaves were extracted. Classifiers based on deep CNN models, VGG16, Inception-V3, and NASNet, were then developed using the leaf images or patches as inputs. Score fusion was then applied to improve the performance of the developed CNN classifiers. The fused CNN classifiers reached a test accuracy as high as 96.7%. A performance comparison indicated that three developed deep CNN classifiers outperformed support vector machine classifiers."																				
2019	"Yigit, Enes; Sabanci, Kadir; Toktas, Abdurrahim; Kayabasi, Ahmet"	A study on visual features of leaves in plant identification using artificial intelligence techniques	Images	DNN	Classification	Computers and Electronics in Agriculture	156		369-377	10.1016/j.compag.2018.11.036	https://www.sciencedirect.com/science/article/pii/S0168169918308524	"In this paper, artificial intelligence techniques (AIT) such as artificial neural network, naive bayes algorithm, random forest algorithm, K-nearest neighborhood (KNN) and support vector machine (SVM) are implemented to design an automatic identifier for the plant leaves. For this purpose, data of 637 healthy leaves consisting of 32 different plant species are used. 22 visual features (VF) of each leaf are extracted by using image processing techniques. These 22 VF are considered in 4 groups including dimension (D#6), color (C#6), texture (T#5) and pattern (P#5). In order to investigate the effects of these groups on the classifying performance, 15 possible different combinations from the 4 groups are constituted. The models are then trained via the data of 510 leaves, and their accuracy are tested through the data of 127 leaves. From the results of the test, SVM model with the accuracy of 92.91% is found to be the most successful identifier for combination including all groups. The next best result is achieved with the accuracy of 87.40% for the combination of D#6, C#6 and P#5 groups. Since the most important issue in the classification process is the use of the minimum number of VF, 16 most effective VF on the identification are determined by means of correlation-based feature selection (CFS) method. The best result for these 16 VF is also achieved with the accuracy of 94.49% by the SVM model. Then the performance of the proposed method is tested to identify the diseased and defected leaves. Therefore, 637 healthy and 33 diseased/defected leaves are put together. Randomly selected 536 leaves corresponding to 80% of all leaves are used for training and the remaining 134 leaves are used for testing, and identified with the accuracy of 92.53% by the SVM model. With this study, it is numerically revealed that the P#5 is the most effective feature group. Moreover, it has been determined that the most effective feature in the P#5 group is the feature of edge Fourier transform. The results point out that, if AIT models are properly modelled and trained, they can be successfully and effectively applied to the identification of the plants even if there are diseased and defected samples."																				
2019	"Yuwana, R. Sandra; Suryawati, Endang; Zilvan, Vicky; Ramdan, Ade; Pardede, Hilman F.; Fauziah, Fani"	Multi-Condition Training on Deep Convolutional Neural Networks for Robust Plant Diseases Detection	Images	CNN	Classification	"2019 International Conference on Computer, Control, Informatics and its Applications (IC3INA)"			30-35	10.1109/IC3INA48034.2019.8949580	https://ieeexplore.ieee.org/document/8949580/	"Currently, deep learning has become prominent technology for many computer vision tasks. However, while deep learning achieves satisfactory performance when evaluated with data from identical distributions, it still suffers when data are distorted. In many cases, it would be difficult and costly to collect data on all possible conditions. To deal with it, we propose Multi-condition training (MCT) to train more robust deep convolutional neural networks. MCT works by corrupting the existing “ideal” data with various possible environmental conditions. We evaluated the method on tea diseases dataset. Our results confirms that MCT produces more robust deep learning systems and is shown effective to deal with distorted images."																				
2019	"Zhang, Shanwen; Huang, Wenzhun; Zhang, Chuanlei"	Three-channel convolutional neural networks for vegetable leaf disease recognition	Images	CNN	Classification	Cognitive Systems Research	53		31-41	10.1016/j.cogsys.2018.04.006	https://linkinghub.elsevier.com/retrieve/pii/S1389041717303236	"The color information of diseased leaf is the main basis for leaf based plant disease recognition. To make use of color information, a novel three-channel convolutional neural networks (TCCNN) model is constructed by combining three color components for vegetable leaf disease recognition. In the model, each channel of TCCNN is fed by one of three color components of RGB diseased leaf image, the convolutional feature in each CNN is learned and transmitted to the next convolutional layer and pooling layer in turn, then the features are fused through a fully connected fusion layer to get a deep-level disease recognition feature vector. Finally, a softmax layer makes use of the feature vector to classify the input images into the predefined classes. The proposed method can automatically learn the representative features from the complex diseased leaf images, and effectively recognize vegetable diseases. The experimental results validate that the proposed method outperforms the state-of-the-art methods of the vegetable leaf disease recognition"																				
2019	"Zhao, Zhong-Qiu; Zheng, Peng; Xu, Shou-Tao; Wu, Xindong"	Object Detection With Deep Learning: A Review	NA	NA	Review	IEEE Transactions on Neural Networks and Learning Systems	30	11	3212-3232	10.1109/TNNLS.2018.2876865	https://ieeexplore.ieee.org/document/8627998/	"Due to object detection's close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles that combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy, and optimization function. In this paper, we provide a review of deep learning-based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely, the convolutional neural network. Then, we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection, and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network-based learning systems."																				
2019	"Zou, James; Huss, Mikael; Abid, Abubakar; Mohammadi, Pejman; Torkamani, Ali; Telenti, Amalio"	A primer on deep learning in genomics	NA	NA	Review	Nature Genetics	51	1	18-Dec	10.1038/s41588-018-0295-5	http://www.nature.com/articles/s41588-018-0295-5	"Deep learning methods are a class of machine learning techniques capable of identifying highly complex patterns in large datasets. Here, we provide a perspective and primer on deep learning applications for genome analysis. We discuss successful applications in the fields of regulatory genomics, variant calling and pathogenicity scores. We include general guidance for how to effectively use deep learning methods as well as a practical guide to tools and resources. This primer is accompanied by an interactive online tutorial."																				
2019	"Zou, Zhengting; Zhang, Hongjiu; Guan, Yuanfang; Zhang, Jianzhi"	Deep residual neural networks resolve quartet molecular phylogenies	Molecular	CNN	Classification	Molecular Biology and Evolution	37	5	1495–1507	10.1093/molbev/msz307	https://academic.oup.com/mbe/article/37/5/1495/5685817	"Phylogenetic inference is of fundamental importance to evolutionary as well as other fields of biology, and molecular sequences have emerged as the primary data for this task. Although many phylogenetic methods have been developed to explicitly take into account substitution models of sequence evolution, such methods could fail due to model misspecification or insufficiency, especially in the face of heterogeneities in substitution processes across sites and among lineages. In this study, we propose to infer topologies of four-taxon trees using deep residual neural networks, a machine learning approach needing no explicit modeling of the subject system and having a record of success in solving complex nonlinear inference problems. We train residual networks on simulated protein sequence data with extensive amino acid substitution heterogeneities. We show that the well-trained residual network predictors can outperform existing state-of-the-art inference methods such as the maximum likelihood method on diverse simulated test data, especially under extensive substitution heterogeneities. Reassuringly, residual network predictors generally agree with existing methods in the trees inferred from real phylogenetic data with known or widely believed topologies. Furthermore, when combined with the quartet puzzling algorithm, residual network predictors can be used to reconstruct trees with more than four taxa. We conclude that deep learning represents a powerful new approach to phylogenetic reconstruction, especially when sequences evolve via heterogeneous substitution processes. We present our best trained predictor in a freely available program named Phylogenetics by Deep Learning (PhyDL, https:\/\/gitlab.com\/ztzou\/phydl; last accessed January 3, 2020)."																				
2020	"Abe, Takashi; Akazawa, Yu; Toyoda, Atsushi; Niki, Hironori; Baba, Tomoya"	Batch-Learning Self-Organizing Map Identifies Horizontal Gene Transfer Candidates and Their Origins in Entire Genomes	Molecular	DNN	Modeling	Frontiers in Microbiology	11			10.3389/fmicb.2020.01486	https://www.frontiersin.org/article/10.3389/fmicb.2020.01486	"Horizontal gene transfer (HGT) has been widely suggested to play a critical role in the environmental adaptation of microbes; however, the number and origin of the genes in microbial genomes obtained through HGT remain unknown as the frequency of detected HGT events is generally underestimated, particularly in the absence of information on donor sequences. As an alternative to phylogeny-based methods that rely on sequence alignments, we have developed an alignment-free clustering method on the basis of an unsupervised neural network “Batch-Learning Self-Organizing Map (BLSOM)” in which sequence fragments are clustered based solely on oligonucleotide similarity without taxonomical information, to detect HGT candidates and their origin in entire genomes. By mapping the microbial genomic sequences on large-scale BLSOMs constructed with nearly all prokaryotic genomes, HGT candidates can be identified, and their origin assigned comprehensively, even for microbial genomes that exhibit high novelty. By focusing on two types of Alphaproteobacteria, specifically psychrotolerant Sphingomonas strains from an Antarctic lake, we detected HGT candidates using BLSOM and found higher proportions of HGT candidates from organisms belonging to Betaproteobacteria in the genomes of these two Antarctic strains compared with those of continental strains. Further, an origin difference was noted in the HGT candidates found in the two Antarctic strains. Although their origins were highly diversified, gene functions related to the cell wall or membrane biogenesis were shared among the HGT candidates. Moreover, analyses of amino acid frequency suggested that housekeeping genes and some HGT candidates of the Antarctic strains exhibited different characteristics to other continental strains. Lys, Ser, Thr, and Val were the amino acids found to be increased in the Antarctic strains, whereas Ala, Arg, Glu, and Leu were decreased. Our findings strongly suggest a low-temperature adaptation process for microbes that may have arisen convergently as an independent evolutionary strategy in each Antarctic strain. Hence, BLSOM analysis could serve as a powerful tool in not only detecting HGT candidates and their origins in entire genomes, but also in providing novel perspectives into the environmental adaptations of microbes."																				
2020	"Adrion, Jeffrey R; Galloway, Jared G; Kern, Andrew D"	Predicting the landscape of recombination using deep learning	Molecular	RNN	Classification	Molecular Biology and Evolution	37	6	1790-1808	10.1093/molbev/msaa038	https://academic.oup.com/mbe/article/37/6/1790/5741419	"Accurately inferring the genome-wide landscape of recombination rates in natural populations is a central aim in genomics, as patterns of linkage influence everything from genetic mapping to understanding evolutionary history. Here, we describe recombination landscape estimation using recurrent neural networks (ReLERNN), a deep learning method for estimating a genome-wide recombination map that is accurate even with small numbers of pooled or individually sequenced genomes. Rather than use summaries of linkage disequilibrium as its input, ReLERNN takes columns from a genotype alignment, which are then modeled as a sequence across the genome using a recurrent neural network. We demonstrate that ReLERNN improves accuracy and reduces bias relative to existing methods and maintains high accuracy in the face of demographic model misspecification, missing genotype calls, and genome inaccessibility. We apply ReLERNN to natural populations of African Drosophila melanogaster and show that genome-wide recombination landscapes, although largely correlated among populations, exhibit important population-specific differences. Lastly, we connect the inferred patterns of recombination with the frequencies of major inversions segregating in natural Drosophila populations."																				
2020	"Akbarian, Sina; Cawston, Tania; Moreno, Laurent; Patel, Samir; Allen, Vanessa; Dolatabadi, Elham"	A Computer Vision Approach to Combat Lyme Disease	Images	CNN	Classification	"arXiv:2009.11931 [cs, eess]"				10.48550/arXiv.2009.11931	http://arxiv.org/abs/2009.11931	"Lyme disease is an infectious disease transmitted to humans by a bite from an infected Ixodes species (blacklegged ticks). It is one of the fastest growing vector-borne illness in North America and is expanding its geographic footprint. Lyme disease treatment is time-sensitive, and can be cured by administering an antibiotic (prophylaxis) to the patient within 72 hours after a tick bite by the Ixodes species. However, the laboratory-based identification of each tick that might carry the bacteria is time-consuming and labour intensive and cannot meet the maximum turn-around-time of 72 hours for an effective treatment. Early identification of blacklegged ticks using computer vision technologies is a potential solution in promptly identifying a tick and administering prophylaxis within a crucial window period. In this work, we build an automated detection tool that can differentiate blacklegged ticks from other ticks species using advanced deep learning and computer vision approaches. We demonstrate the classification of tick species using Convolution Neural Network (CNN) models, trained end-to-end from tick images directly. Advanced knowledge transfer techniques within teacher-student learning frameworks are adopted to improve the performance of classification of tick species. Our best CNN model achieves 92% accuracy on test set. The tool can be integrated with the geography of exposure to determine the risk of Lyme disease infection and need for prophylaxis treatment."																				
2020	"Akçay, Hüseyin Gökhan; Kabasakal, Bekir; Aksu, Duygugül; Demir, Nusret; Öz, Melih; Erdo_an, Ali"	Automated Bird Counting with Deep Learning for Regional Bird Distribution Mapping	Images	CNN	Regression	Animals	10	7	1207	10.3390/ani10071207	https://www.mdpi.com/2076-2615/10/7/1207	"A challenging problem in the field of avian ecology is deriving information on bird population movement trends. This necessitates the regular counting of birds which is usually not an easily-achievable task. A promising attempt towards solving the bird counting problem in a more consistent and fast way is to predict the number of birds in different regions from their photos. For this purpose, we exploit the ability of computers to learn from past data through deep learning which has been a leading sub-field of AI for image understanding. Our data source is a collection of on-ground photos taken during our long run of birding activity. We employ several state-of-the-art generic object-detection algorithms to learn to detect birds, each being a member of one of the 38 identified species, in natural scenes. The experiments revealed that computer-aided counting outperformed the manual counting with respect to both accuracy and time. As a real-world application of image-based bird counting, we prepared the spatial bird order distribution and species diversity maps of Turkey by utilizing the geographic information system (GIS) technology. Our results suggested that deep learning can assist humans in bird monitoring activities and increase citizen scientists’ participation in large-scale bird surveys."																				
2020	"Almryad, Ayad Saad; Kutucu, Hakan"	Automatic identification for field butterflies by convolutional neural networks	Images	CNN	Classification	"Engineering Science and Technology, an International Journal"	23	1	189-195	10.1016/j.jestch.2020.01.006	https://www.sciencedirect.com/science/article/pii/S2215098619326011	"In today’s competitive conditions, producing fast, inexpensive and reliable solutions are an objective for engineers. Development of artificial intelligence and the introduction of this technology to almost all areas have created a need to minimize the human factor by using artificial intelligence in the field of image processing, as well as to make a profit in terms of time and labor. In this paper, we propose an automated butterfly species identification model using deep neural networks. We collected 44,659 images of 104 different butterfly species taken with different positions of butterflies, the shooting angle, butterfly distance, occlusion and background complexity in the field in Turkey. Since many species have a few image samples we constructed a field-based dataset of 17,769 butterflies with 10 species. Convolutional Neural Networks (CNNs) were used for the identification of butterfly species. Comparison and evaluation of the experimental results obtained using three different network structures are conducted. Experimental results on 10 common butterfly species showed that our method successfully identified various butterfly species."																				
2020	"Ärje, Johanna; Melvad, Claus; Jeppesen, Mads Rosenhøj; Madsen, Sigurd Agerskov; Raitoharju, Jenni; Rasmussen, Maria Strandgård; Iosifidis, Alexandros; Tirronen, Ville; Gabbouj, Moncef; Meissner, Kristian; Høye, Toke Thomas"	Automatic image_based identification and biomass estimation of invertebrates	Images	CNN	Classification	Methods in Ecology and Evolution	11	8	922-931	10.1111/2041-210X.13428	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13428	"Understanding how biological communities respond to environmental changes is a key challenge in ecology and ecosystem management. The apparent decline of insect populations necessitates more biomonitoring but the time-consuming sorting and expert-based identification of taxa pose strong limitations on how many insect samples can be processed. In turn, this affects the scale of efforts to map and monitor invertebrate diversity altogether. Given recent advances in computer vision, we propose to enhance the standard human expert-based identification approach involving manual sorting and identification with an automatic image-based technology. We describe a robot-enabled image-based identification machine, which can automate the process of invertebrate sample sorting, specimen identification and biomass estimation. We use the imaging device to generate a comprehensive image database of terrestrial arthropod species which is then used to test classification accuracy, that is, how well the species identity of a specimen can be predicted from images taken by the machine. We also test sensitivity of the classification accuracy to the camera settings (aperture and exposure time) to move forward with the best possible image quality. We use state-of-the-art Resnet-50 and InceptionV3 convolutional neural networks for the classification task. The results for the initial dataset are very promising as we achieved an average classification accuracy of 0.980. While classification accuracy is high for most species, it is lower for species represented by less than 50 specimens. We found significant positive relationships between mean area of specimens derived from images and their dry weight for three species of Diptera. The system is general and can easily be used for other groups of invertebrates as well. As such, our results pave the way for generating more data on spatial and temporal variation in invertebrate abundance, diversity and biomass. "																				
2020	"Auslander, Noam; Gussow, Ayal B.; Benler, Sean; Wolf, Yuri I.; Koonin, Eugene V."	Seeker: alignment-free identification of bacteriophage genomes by deep learning	Molecular	RNN	Classification	Nucleic Acids Research	48	21	e121	10.1093/nar/gkaa856	https://academic.oup.com/nar/article/48/21/e121/5921300	"Recent advances in metagenomic sequencing have enabled discovery of diverse, distinct microbes and viruses. Bacteriophages, the most abundant biological entity on Earth, evolve rapidly, and therefore, detection of unknown bacteriophages in sequence datasets is a challenge. Most of the existing detection methods rely on sequence similarity to known bacteriophage sequences, impeding the identification and characterization of distinct, highly divergent bacteriophage families. Here we present Seeker, a deep-learning tool for alignment-free identification of phage sequences. Seeker allows rapid detection of phages in sequence datasets and differentiation of phage sequences from bacterial ones, even when those phages exhibit little sequence similarity to established phage families. We comprehensively validate Seeker's ability to identify previously unidentified phages, and employ this method to detect unknown phages, some of which are highly divergent from the known phage families. We provide a web portal (seeker.pythonanywhere.com) and a user-friendly Python package (github.com/gussow/seeker) allowing researchers to easily apply Seeker in metagenomic studies, for the detection of diverse unknown bacteriophages."																				
2020	"Ayala-Berdon, Jorge; Medina-Bello, Kevin I.; López-Cuamatzi, Issachar L.; Vázquez-Fuerte, Rommy; MacSwiney G., M. Cristina; Orozco-Lugo, Lorena; Iñiguez-Dávalos, Ignacio; Guillén-Servent, Antonio; Martínez-Gómez, Margarita"	Random forest is the best species predictor for a community of insectivorous bats inhabiting a mountain ecosystem of central Mexico	Sound	DNN	Classification	Bioacoustics	30	5	608-628	10.1080/09524622.2020.1835539	https://www.tandfonline.com/doi/abs/10.1080/09524622.2020.1835539	"Bats are nocturnal animals that can be identified by recording and analysing quantitatively their echolocation calls. For this task, many studies have used both parametric and non-parametric approximations with a variety of results. This urges the necessity of developing more call libraries, that should be analysed using the different statistical approaches to test their performance. This could be relevant in countries holding high biodiversity where the knowledge of the variation in the call structure among species is still scarce. We constructed and validated a call library from bats inhabiting a mountain ecosystem of central Mexico using the Linear Discriminant Function, Artificial Neural Network and Random Forest approaches. We recorded and analysed 2,325 pulses from 114 individuals and 16 bat species of the families Vespertilionidae, Mormoopidae, Molossidae, and Natalidae. The Random forest model (81.3%) was the better species predictor over the artificial neural network and the discriminant function analysis (69% and 62.1%, respectively). Our work is one of the few attempts to do this exercise that has been conducted in Mexico. The library can be useful as a starting point of research in other regions of the highlands in central Mexico where the information is still scarce."																				
2020	"Baek, Sang-Soo; Pyo, JongCheol; Pachepsky, Yakov; Park, Yongeun; Ligaray, Mayzonee; Ahn, Chi-Yong; Kim, Young-Hyo; Ahn Chun, Jong; Hwa Cho, Kyung"	Identification and enumeration of cyanobacteria species using a deep neural network	Images	CNN	"Classification, Regression"	Ecological Indicators	115		106395	10.1016/j.ecolind.2020.106395	https://www.sciencedirect.com/science/article/pii/S1470160X20303320	"Cell classification and cell counting are essential for the detection, monitoring, forecasting, and management of harmful algae populations. Conventional methods of algae classification and cell counting are known to be time-consuming, labor-intensive, and subjective, depending on the expertise of the observers. The objectives of this study were to classify and quantify five cyanobacteria using the deep learning techniques of a fast regional convolutional neural network (R-CNN) and convolutional neural network (CNN). Water samples taken from the Haman weir of Nakdong River and Baekje weir of the Geum River were observed under the optical microscope. The images captured by the microscope were used to classify cyanobacteria species using the fast R-CNN model. Post-processing of the classified images generated by the model reduced the noises of the cell features, thereby improving the accuracy of the CNN model in quantifying cyanobacteria cells. The distinctive morphological features of the five species were extracted by the fast R-CNN model. This model was able to achieve a reasonable agreement with the manual classification results, yielding average precision (AP) values of 0.929, 0.973, 0.829, 0.890, and 0.890 for Microcystis aeruginosa, Microcystis wesenbergii, Dolichospermum, Oscillatoria, and Aphanizomenon, respectively. The CNN model for the Microcystis species obtained an R2 value of 0.775 and RMSE value of 26 cells for training, and an R2 of 0.854 and RMSE of 23 cells for validation. A minor underestimation and overestimation for a population with <50 cells and >250 cells were observed, respectively, which are due to the overlapping of cells and the presence of blurry regions in the input images. In conclusion, this study was able to demonstrate the reliable performance of cyanobacteria classification and cell counting using deep learning approaches."																				
2020	"Bala, Praneet C.; Eisenreich, Benjamin R.; Yoo, Seng Bum Michael; Hayden, Benjamin Y.; Park, Hyun Soo; Zimmermann, Jan"	Automated markerless pose estimation in freely moving macaques with OpenMonkeyStudio	Video	CNN	Classification	Nature Communications	11	1	4560	10.1038/s41467-020-18441-5	http://www.nature.com/articles/s41467-020-18441-5	"The rhesus macaque is an important model species in several branches of science, including neuroscience, psychology, ethology, and medicine. The utility of the macaque model would be greatly enhanced by the ability to precisely measure behavior in freely moving conditions. Existing approaches do not provide sufficient tracking. Here, we describe OpenMonkeyStudio, a deep learning-based markerless motion capture system for estimating 3D pose in freely moving macaques in large unconstrained environments. Our system makes use of 62 machine vision cameras that encircle an open 2.45_m___2.45_m___2.75_m enclosure. The resulting multiview image streams allow for data augmentation via 3D-reconstruction of annotated images to train a robust view-invariant deep neural network. This view invariance represents an important advance over previous markerless 2D tracking approaches, and allows fully automatic pose inference on unconstrained natural motion. We show that OpenMonkeyStudio can be used to accurately recognize actions and track social interactions."																				
2020	"Banan, Ashkan; Nasiri, Amin; Taheri-Garavand, Amin"	Deep learning-based appearance features extraction for automated carp species identification	Images	CNN	Classification	Aquacultural Engineering	89		102053	10.1016/j.aquaeng.2020.102053	https://www.sciencedirect.com/science/article/pii/S0144860919302195	"Fish species identification is vital for aquaculture and fishery industries, stock management of water bodies and environmental monitoring of aquatics. Traditional fish species identification approaches are costly, time consuming, expert-based and unsuitable for large-scale applications. Hence, in this study, a deep learning neural network as a smart, real-time and non-destructive method was developed and applied to automate the identification of four economically important carp species namely common carp (Cyprinus carpio), grass carp (Ctenopharingodon idella), bighead carp (Hypophtalmichthys nobilis) and silver carp (Hypophthalmichthys molitrix). The obtained results proved that our approach, evaluated through 5-fold cross-validation, achieved the highest possible accuracy of 100 %. The achieved high level of classification accuracy was due to the ability of the suggested deep model to build a hierarchy of self-learned features, which was in accordance with the hierarchy of these fish’s identification keys. In conclusion, the proposed convolutional neural network (CNN)-based method has a single and generic trained architecture with promising performance for fish species identification."																				
2020	"Battey, Cj; Ralph, Peter L; Kern, Andrew D"	Predicting geographic location from genetic variation with deep neural networks	Molecular	DNN	Regression	eLife	9		e54507	10.7554/eLife.54507	https://elifesciences.org/articles/54507	"Most organisms are more closely related to nearby than distant members of their species, creating spatial autocorrelations in genetic data. This allows us to predict the location of origin of a genetic sample by comparing it to a set of samples of known geographic origin. Here, we describe a deep learning method, which we call Locator, to accomplish this task faster and more accurately than existing approaches. In simulations, Locator infers sample location to within 4.1 generations of dispersal and runs at least an order of magnitude faster than a recent model-based approach. We leverage Locator’s computational efficiency to predict locations separately in windows across the genome, which allows us to both quantify uncertainty and describe the mosaic ancestry and patterns of geographic mixing that characterize many populations. Applied to whole-genome sequence data from Plasmodium parasites, Anopheles mosquitoes, and global human populations, this approach yields median test errors of 16.9km, 5.7km, and 85km, respectively."																				
2020	"Benkendorf, Donald J.; Hawkins, Charles P."	Effects of sample size and network depth on a deep learning approach to species distribution modeling	Environmental	DNN	Modeling	Ecological Informatics	60		101137	10.1016/j.ecoinf.2020.101137	https://linkinghub.elsevier.com/retrieve/pii/S157495412030087X	"Deep learning algorithms have improved predictive model performance in a variety of disciplines because of their ability to approximate complex functions. However, the amount of data and depth of the neural network needed to improve model performance is not well understood and may depend on many factors associated with the specific field of research. In ecology, ecologists rely on accurate species distribution models to inform conservation and management efforts. Here, we present the first study to systematically examine the effects of sample size and network depth on the performance of species distribution models built with artificial neural networks. We found that one or several deeper network architectures (>1 hidden layer) consistently led to slightly higher model performance than a shallow neural network on validation data when trained with a large sample size (10,000 sites). However, comparing deep network model performance with random forest model performance showed that random forest generally performed as well or slightly better. There was no clear or consistent benefit of using deep neural networks with smaller sample sizes (100 and 1000 sites). Our results suggest that, given sufficiently big data, increasing the number of hidden layers in a neural network can potentially improve species distribution model performance. As datasets become larger and high performance computing resources become more available, a deep learning approach to species distribution modeling is likely to be used more frequently."																				
2020	"Bhattacharjee, Ananya; Bayzid, Md. Shamsuzzoha"	Machine learning based imputation techniques for estimating phylogenetic trees from incomplete distance matrices	Molecular	VAE	Modeling	BMC Genomics	21	1	497	10.1186/s12864-020-06892-5	https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-06892-5	"With the rapid growth rate of newly sequenced genomes, species tree inference from genes sampled throughout the whole genome has become a basic task in comparative and evolutionary biology. However, substantial challenges remain in leveraging these large scale molecular data. One of the foremost challenges is to develop efficient methods that can handle missing data. Popular distance-based methods, such as NJ (neighbor joining) and UPGMA (unweighted pair group method with arithmetic mean) require complete distance matrices without any missing data."																				
2020	"Bohlen, Marc; Sujarwo, Wawan"	Machine Learning in Ethnobotany	NA	NA	Review	"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)"			108-113	10.1109/SMC42975.2020.9283069	https://ieeexplore.ieee.org/document/9283069/	"We describe new opportunities created by bring A.I. to the field of ethnobotany. In particular we describe a novel approach to ethnobotany documentation that harnesses machine learning opportunities, specifically for the documentation of traditional ecological knowledge with mobile phones in emerging economies. Using a case study on the island of Bali as a departure point, the project maps out machine learning approaches to documentation and responds to technology and capital gradients between research contexts in the global north and south in an attempt to capture knowledge that might otherwise not be represented."																				
2020	"Bollis, Edson; Pedrini, Helio; Avila, Sandra"	Weakly Supervised Learning Guided by Activation Mapping Applied to a Novel Citrus Pest Benchmark	Images	CNN	Classification	2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)			310-319	10.1109/CVPRW50498.2020.00043	https://ieeexplore.ieee.org/document/9150704/	"Pests and diseases are relevant factors for production losses in agriculture and, therefore, promote a huge investment in the prevention and detection of its causative agents. In many countries, Integrated Pest Management is the most widely used process to prevent and mitigate the damages caused by pests and diseases in citrus crops. However, its results are credited by humans who visually inspect the orchards in order to identify the disease symptoms, insects and mite pests. In this context, we design a weakly supervised learning process guided by saliency maps to automatically select regions of interest in the images, significantly reducing the annotation task. In addition, we create a large citrus pest benchmark composed of positive samples (six classes of mite species) and negative samples. Experiments conducted on two large datasets demonstrate that our results are very promising for the problem of pest and disease classification in the agriculture field."																				
2020	"Bonetta, Rosalin; Valentino, Gianluca"	Machine learning techniques for protein function prediction	NA	NA	Review	"Proteins: Structure, Function, and Bioinformatics"	88	3	397-413	10.1002/prot.25832	https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.25832	"Proteins play important roles in living organisms, and their function is directly linked with their structure. Due to the growing gap between the number of proteins being discovered and their functional characterization (in particular as a result of experimental limitations), reliable prediction of protein function through computational means has become crucial. This paper reviews the machine learning techniques used in the literature, following their evolution from simple algorithms such as logistic regression to more advanced methods like support vector machines and modern deep neural networks. Hyperparameter optimization methods adopted to boost prediction performance are presented. In parallel, the metamorphosis in the features used by these algorithms from classical physicochemical properties and amino acid composition, up to text-derived features from biomedical literature and learned feature representations using autoencoders, together with feature selection and dimensionality reduction techniques, are also reviewed. The success stories in the application of these techniques to both general and specific protein function prediction are discussed."																				
2020	"Brattoli, Biagio; Büchler, Uta; Dorkenwald, Michael; Reiser, Philipp; Filli, Linard; Helmchen, Fritjof; Wahl, Anna-Sophia; Ommer, Björn"	Unsupervised behaviour analysis and magnification (uBAM) using deep learning	Images	"CNN, VAE"	Modeling	Nature Machine Intelligence	3	6	495-506	10.1038/s42256-021-00326-x	https://www.nature.com/articles/s42256-021-00326-x	"Motor behaviour analysis is essential to biomedical research and clinical diagnostics as it provides a non-invasive strategy for identifying motor impairment and its change caused by interventions. State-of-the-art instrumented movement analysis is time- and cost-intensive, because it requires the placement of physical or virtual markers. As well as the effort required for marking the keypoints or annotations necessary for training or fine-tuning a detector, users need to know the interesting behaviour beforehand to provide meaningful keypoints. Here, we introduce unsupervised behaviour analysis and magnification (uBAM), an automatic deep learning algorithm for analysing behaviour by discovering and magnifying deviations. A central aspect is unsupervised learning of posture and behaviour representations to enable an objective comparison of movement. Besides discovering and quantifying deviations in behaviour, we also propose a generative model for visually magnifying subtle behaviour differences directly in a video without requiring a detour via keypoints or annotations. Essential for this magnification of deviations, even across different individuals, is a disentangling of appearance and behaviour. Evaluations on rodents and human patients with neurological diseases demonstrate the wide applicability of our approach. Moreover, combining optogenetic stimulation with our unsupervised behaviour analysis shows its suitability as a non-invasive diagnostic tool correlating function to brain plasticity."																				
2020	"Brautaset, Olav; Waldeland, Anders Ueland; Johnsen, Espen; Malde, Ketil; Eikvil, Line; Salberg, Arnt-Børre; Handegard, Nils Olav"	Acoustic classification in multifrequency echosounder data using deep convolutional neural networks	Video	CNN	Regression	ICES Journal of Marine Science	77	4	1391-1400	10.1093/icesjms/fsz235	https://doi.org/10.1093/icesjms/fsz235	"Acoustic target classification is the process of assigning observed acoustic backscattering intensity to an acoustic category. A deep learning strategy for acoustic target classification using a convolutional network is developed, consisting of an encoder and a decoder, which allow the network to use pixel information and more abstract features. The network can learn features directly from data, and the learned feature space may include both frequency response and school morphology. We tested the method on multifrequency data collected between 2007 and 2018 during the Norwegian sandeel survey. The network was able to distinguish between sandeel schools, schools of other species, and background pixels (including seabed) in new survey data with an F1 score of 0.87 when tested against manually labelled schools. The network separated schools of sandeel and schools of other species with an F1 score of 0.94. A traditional school classification algorithm obtained substantially lower F1 scores (0.77 and 0.82) when tested against the manually labelled schools. To train the network, it was necessary to develop sampling and preprocessing strategies to account for unbalanced classes, inaccurate annotations, and biases in the training data. This is a step towards a method to be applied across a range of acoustic trawl surveys."																				
2020	"Breiman, Leo"	Statistical Modeling: The Two Cultures	NA	NA	Review	Statistical Science	16	3	199-231	10.1214/ss/1009213726	https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.full	"There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools"																				
2020	"Bryant, Simon R.; Shreeve, Tim G."	The use of artificial neural networks in ecological analysis: estimating microhabitat temperature	Images	DNN	Classification	Ecological Entomology	27	4	424-432	10.1046/j.1365-2311.2002.00422.x	https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1365-2311.2002.00422.x	"1. The thermal environment at the scale in which most species exist is largely unknown, and thus the majority of physiological models is based on meteorological measures of ambient temperature. 2. The use of artificial neural networks in ecological analysis is promoted by using them to model microhabitat temperature. 3. The performance of conventional multiple linear regression is compared with that of artificial neural networks in predicting the temperature profiles of two different microhabitats using ambient temperature, solar radiation, and wind speed as input (independent) variables. 4. In both cases, the artificial neural networks showed a lower mean absolute residual error than multiple linear regression (0.95 °C compared with 1.41 °C, and 0.29 °C compared with 0.50 °C) and a higher correlation (r2) between predicted and observed values (0.832 compared with 0.668, and 0.884 compared with 0.670). 5. An artificial neural network developed to include a microhabitat patch description based on height within patch, substrate, and four classes of per cent vegetation cover performed well (r2 = 0.933, prediction error 95% confidence limits =± 2.5 °C). 6. It is suggested that artificial neural networks are more appropriate than conventional regression-based approaches for estimating microhabitat temperature."																				
2020	"Burbrink, Frank T; Grazziotin, Felipe G; Pyron, R Alexander; Cundall, David; Donnellan, Steve; Irish, Frances; Keogh, J Scott; Kraus, Fred; Murphy, Robert W; Noonan, Brice; Raxworthy, Christopher J; Ruane, Sara; Lemmon, Alan R; Lemmon, Emily Moriarty; Zaher, Hussam"	"Interrogating Genomic-Scale Data for Squamata (Lizards, Snakes, and Amphisbaenians) Shows no Support for Key Traditional Morphological Relationships"	Molecular	DNN	Regression	Systematic Biology	69	3	502-520	10.1093/sysbio/syz062	https://academic.oup.com/sysbio/article/69/3/502/5573126	"Genomics is narrowing uncertainty in the phylogenetic structure for many amniote groups. For one of the most diverse and species-rich groups, the squamate reptiles (lizards, snakes, and amphisbaenians), an inverse correlation between the number of taxa and loci sampled still persists across all publications using DNA sequence data and reaching a consensus on the relationships among them has been highly problematic. In this study, we use high-throughput sequence data from 289 samples covering 75 families of squamates to address phylogenetic affinities, estimate divergence times, and characterize residual topological uncertainty in the presence of genome-scale data. Importantly, we address genomic support for the traditional taxonomic groupings Scleroglossa and Macrostomata using novel machine-learning techniques. We interrogate genes using various metrics inherent to these loci, including parsimony-informative sites (PIS), phylogenetic informativeness, length, gaps, number of substitutions, and site concordance to understand why certain loci fail to find previously well-supported molecular clades and how they fail to support species-tree estimates. We show that both incomplete lineage sorting and poor gene-tree estimation (due to a few undesirable gene properties, such as an insufficient number of PIS), may account for most gene and species-tree discordance. We find overwhelming signal for Toxicofera, and also show that none of the loci included in this study supports Scleroglossa or Macrostomata. We comment on the origins and diversification of Squamata throughout the Mesozoic and underscore remaining uncertainties that persist in both deeper parts of the tree (e.g., relationships between Dibamia, Gekkota, and remaining squamates; among the three toxicoferan clades Iguania, Serpentes, and Anguiformes) and within specific clades (e.g., affinities among gekkotan, pleurodont iguanians, and colubroid families)."																				
2020	"Buschbacher, Keanu; Ahrens, Dirk; Espeland, Marianne; Steinhage, Volker"	Image-based species identification of wild bees using convolutional neural networks	Images	CNN	Classification	Ecological Informatics	55		101017	10.1016/j.ecoinf.2019.101017	https://www.sciencedirect.com/science/article/pii/S1574954119303280	"Monitoring insect populations is vital for estimating the health of ecosystems. Recently, insect population decline has been highlighted both in the scientific world and the media. Investigating such decline requires monitoring which includes adequate sampling and correctly identifying sampled taxa. This task requires extensive manpower and is time consuming and hard, even for experts, if the process is not automated. Here we propose DeepABIS based on the concepts of the successful Automated Bee Identification System (ABIS), which allowed mobile field investigations including species identification of live bees in field. DeepABIS features three important advancements. First, DeepABIS reduces the efforts of training the system significantly by employing automated feature generation using deep convolutional networks (CNN). Second, DeepABIS enables participatory sensing scenarios employing mobile smart phones and a cloud-based platform for data collection and communication. Third, DeepABIS is adaptable and transferable to other taxa beyond Hymenoptera, i.e., butterflies, flies, etc. Current results show identification results with an average top-1 accuracy of 93.95% and a top-5 accuracy of 99.61% applied to data material of the ABIS project. Adapting DeepABIS to a butterfly dataset showing morphologically difficult to separate populations of the same species of butterfly yields identification results with an average top-1 accuracy of 96.72% and a top-5 accuracy of 99.99%."																				
2020	"Buschbacher, Keanu; Steinhage, Volker"	On the extraction and relevance ranking of visual morphological traits for taxon identification	Images	CNN	Classification	Ecological Informatics	60		101138	10.1016/j.ecoinf.2020.101138	https://www.sciencedirect.com/science/article/pii/S1574954120300881	"Deep Neural Networks have proven to be exceptionally successful in applications such as image or speech recognition, yielding prediction results with high accuracy and precision. But due to their black-box nature, Deep Neural Networks are criticized to yield non-transparent and non-explainable results. In the field of taxonomic identification, explainability of the identification results derived by automated image-based identification approaches should rely on common observable morphological traits and their relevance to the derived results. Extending previous work on the deep learning-based Automated Bee Identification System DeepABIS, an approach is presented that equips DeepABIS with a relevance ranking of morphological traits according to their contributions to the prediction results of the automated image-based species identification. The approach shows three steps: (1) Using Visual Backpropagation, a relevance map is generated that maps each pixel of an input image to a relevance score indicating its relevance to the identification result. (2) A deep neural network for semantic segmentation is employed to extract regions of the input image that depict morphological traits (in this work veins, cells and junctions of bee wings). (3) In the fusing step, the morphological traits are assigned aggregated relevance scores using the pixel-wise relevance map obtained in the first step. Experimental results confirm the obtained relevance rankings of the morphological traits by an evaluation using the model-agnostic importance metric Single Feature Importance (SFI)."																				
2020	"Cai, Kewei; Miao, Xinying; Wang, Wei; Pang, Hongshuai; Liu, Ying; Song, Jinyan"	A modified YOLOv3 model for fish detection based on MobileNetv1 as backbone	Images	CNN	"Classification, Regression"	Aquacultural Engineering	91		102117	10.1016/j.aquaeng.2020.102117	https://www.sciencedirect.com/science/article/pii/S0144860920301631	"This paper proposes a new approach combining YOLOv3 with MobileNetv1 for fish detection in real breeding farm. The feature maps of MobileNet are reselected as per their receptive fields for better fish detection instead of fixed chosen strategy in the original YOLOv3 framework. A set of fish image data acquired in breeding farm is used to evaluate the proposed method. The high accuracy of detection results is achieved to confirm the effectiveness of the proposed method. Furthermore, taking the place of “ImageNet”, a slighter dataset including fish images with 16 species for backbone network pretraining is picked out from “ImageNet” to extract fish features. On this basis, the effect of detection of the model is further improved due to that the extracted features are more closed to fish objects. Therefore, the proposed method is proved to have the capability of providing necessary and accurate number of fish, which will then be used to determine the breeding actions accordingly."																				
2020	"Carl, Christin; Schönfeld, Fiona; Profft, Ingolf; Klamm, Alisa; Landgraf, Dirk"	Automated detection of European wild mammal species in camera trap images with an existing and pre-trained computer vision model	Images	CNN	"Classification, Regression"	European Journal of Wildlife Research	66	4	62	10.1007/s10344-020-01404-y	https://link.springer.com/article/10.1007/s10344-020-01404-y	"The use of camera traps is a nonintrusive monitoring method to obtain valuable information about the appearance and behavior of wild animals. However, each study generates thousands of pictures and extracting information remains mostly an expensive, time-consuming manual task. Nevertheless, image recognition and analyzing technologies combined with machine learning algorithms, particularly deep learning models, improve and speed up the analysis process. Therefore, we tested the usability of a pre-trained deep learning model available on the TensorFlow hub–FasterRCNN+InceptionResNet V2 network applied to images of ten different European wild mammal species such as wild boar (Sus scrofa), roe deer (Capreolus capreolus), or red fox (Vulpes vulpes) in color as well as black and white infrared images. We found that the detection rate of the correct region of interest (region of the animal) was 94%. The classification accuracy was 71% for the correct species’ name as mammals and 93% for the correct species or higher taxonomic ranks such as “carnivore” as order. In 7% of cases, the classification was incorrect as the wrong species’ name was classified. In this technical note, we have shown the potential of an existing and pre-trained image classification model for wildlife animal detection, classification, and analysis. A specific training of the model on European wild mammal species could further increase the detection and classification accuracy of the models. Analysis of camera trap images could thus become considerably faster, less expensive, and more efficient."																				
2020	"Carvalho, L. E.; Fauth, G.; Baecker Fauth, S.; Krahl, G.; Moreira, A. C.; Fernandes, C. P.; von Wangenheim, A."	Automated Microfossil Identification and Segmentation using a Deep Learning Approach	Other	CNN	Classification	Marine Micropaleontology	158		101890	10.1016/j.marmicro.2020.101890	https://www.sciencedirect.com/science/article/pii/S0377839819300830	"Computational analysis applicability to paleontological images ranges from the study of the evolution of animals, plants and microorganisms to the habitat simulation of living beings from a specific epoch. It can also be applied in several niches, e.g. oil exploration, where several factors can be analyzed in order to minimize costs related to oil extraction. One specific factor is the characterization of the environment to be explored. This analysis can occur in several ways: use of probes, samples extraction, correlation with logs of other drilling wells and so on. During the samples extraction phase, the Computed Tomography (CT) is of extreme importance, since it preserves the sample and makes it available for several analyses. Based on 3D images generated by CT, analyses and simulations can be performed, and processes currently performed manually and exhaustively, can be automated. In this work, we propose and validate a method for fully automated microfossil identification and segmentation. A pipeline is proposed that begins with scanning and ends with the microfossil segmentation process. For the microfossil segmentation, a Deep Learning approach was developed, which resulted in a high rate of correct microfossil segmentation (98% IOU). The validation was performed both through an automated quantitative analysis and visual inspection. The study was performed on a limited dataset, but the results provide evidence that our approach has potential to be generalized to other carbonatic rock substrates. To the extent of the authors' knowledge, this paper presents the first fully annotated MicroCT acquired microfossils dataset made publicly available."																				
2020	"Chang, Chung-Liang; Chung, Sheng-Cheng"	Improved Deep Learning-based Approach for Real-time Plant Species Recognition on the Farm	Images	CNN	Classification	"2020 12th International Symposium on Communication Systems, Networks and Digital Signal Processing (CSNDSP)"			5-Jan	10.1109/CSNDSP49049.2020.9249558	https://ieeexplore.ieee.org/document/9249558/	"In this paper, a plant species recognition framework that combination of plant feature extractor and deep neural network is proposed. The morphology-based image processing technique is used to generate annotated feature of plant images, which are used to train deep classifier. In addition, geometrical transformation method is employed to augment the training data. Comprehensive experiments on training dataset with and without image pre-processing for plant species recognition are conducted to evaluate the performance of proposed approach. The results illustrate that the use of image pre-processing method can faster achieve a average loss than the method of not using pre-processing. Finally, the classifier utilizes images captured by various embedded cameras in the cultivation field and processes them through graphics processing units (GPUs) in real-time system. The experimental results demonstrate that the deep classifier can effectively recognize three plants, including Lollo Rosso lettuce, leaf lettuce and Djulis, which can apply to different scenarios around growth areas of plant in the cultivation field."																				
2020	"Charpentier, M. J. E.; Harté, M.; Poirotte, C.; de Bellefon, J. Meric; Laubi, B.; Kappeler, P. M.; Renoult, J. P."	"Same father, same face: Deep learning reveals selection for signaling kinship in a wild primate"	Images	CNN	Regression	Science Advances	6	22	eaba3274	10.1126/sciadv.aba3274	https://www.science.org/doi/10.1126/sciadv.aba3274	"Using artificial intelligence, we show that facial resemblance has been kin-selected to signal paternal kinship in a primate."																				
2020	"Chege, Herman Njoroge"	Rapid prototyping of species classifiers using deep learning: a guide for non-experts	NA	NA	Other	Authorea				10.22541/au.158316446.65534248	https://doi.org/10.22541%2Fau.158316446.65534248	"Deep learning algorithms are revolutionizing how hypothesis generation, pattern recognition, and prediction occurs in the sciences. In the life sciences, particularly biology and its subfields, the use of deep learning is slowly but steadily increasing. However, prototyping or development of tools for practical applications remains in the domain of experienced coders. Furthermore, many tools can be quite costly and difficult to put together without expertise in Artificial intelligence (AI) computing. We built a biological species classifier that leverages existing open-source tools and libraries. We designed the corresponding tutorial for users with basic skills in python and a small, but well-curated image dataset. We included annotated code in form of a Jupyter Notebook that can be adapted to any image dataset, ranging from satellite images, animals to bacteria, or even data such as song or echolocation recordings transformed into images. The prototype developer is publicly available and can be adapted for citizen science as well as other applications not envisioned in this paper. We illustrate our approach with a case study of 219 images of 3 three seastar species. We show that with minimal parameter tuning of the AI pipeline we can create a classifier with 87% accuracy. We include additional approaches to understand the misclassified images and to curate the dataset to increase accuracy. The power of AI approaches is becoming increasingly accessible. We can now readily build and prototype species classifiers that can have a great impact on research that requires species identification and other types of image analysis. Such tools have implications for citizen science, biodiversity monitoring, and a wide range of ecological applications."																				
2020	"Chen, Mengmeng; Ke, Yinghai; Bai, Junhong; Li, Peng; Lyu, Mingyuan; Gong, Zhaoning; Zhou, Demin"	"Monitoring early stage invasion of exotic Spartina alterniflora using deep-learning super-resolution techniques based on multisource high-resolution satellite imagery: A case study in the Yellow River Delta, China"	"Images, Other"	CNN	Regression	International Journal of Applied Earth Observation and Geoinformation	92		102180	10.1016/j.jag.2020.102180	https://www.sciencedirect.com/science/article/pii/S0303243419313649	"Over the past decades, Spartina alterniflora, one of the top exotic invasive plants in China, has expanded throughout coastal China. In the Yellow River Delta (YRD), the rapid expansion of S. alterniflora has caused serious negative ecological effects. Current studies have concentrated primarily on mapping the distribution of S. alterniflora with medium-resolution satellite imagery at the regional or landscape scale, which have a limited capability in early detection and monitoring of the invasive process at the patch scale. In this study, we proposed a framework for monitoring the early stage invasion of S. alterniflora patches in the YRD using multiyear multisource high-spatial-resolution satellite imagery with various ground sampling distances (WorldView-2, SPOT-6, GaoFen-1, GaoFen-2, and GaoFen-6 from 2012 to 2019). First, we proposed to use deep-learning-based image super-resolution models to enhance all images to submeter (0.5_m) resolution. Then, we adopted stepwise evolution analysis-based image segmentation and object-based classification rules to detect and delineate S. alterniflora patches from the super-resolved imagery. By investigating Super-Resolution Convolutional Neural Networks (SRCNN) and Fast Super-Resolution Convolutional Neural Networks (FSRCNN) and comparing these methods with the conventional bicubic interpolation method for image resolution enhancement, we concluded that FSRCNN was superior in constructing spectral and structural details from the 1_m/1.5_m/2_m resolution images to 0.5_m resolution. FSRCNN, in particular, was more effective and efficient in discerning and estimating the size of small S. alterniflora patches (<50 m2). Using our method, 76 of 83 field-measured small patches were accurately detected and the delineated S. alterniflora patch perimeters agreed well with the field-measured patch perimeters (root mean square error [RMSE]_=_8.29_m, mean absolute percentage error [MAPE]_=_23.46 %). The invasion process showed fast expansion from 2012 to 2015 and slow growth from 2016 to 2019. We observed that the landward limits of S. alterniflora patches were influenced by elevation and vicinity to tidal creeks."																				
2020	"Chen, Peng; Swarup, Pranjal; Matkowski, Wojciech Michal; Kong, Adams Wai Kin; Han, Su; Zhang, Zhihe; Rong, Hou"	A study on giant panda recognition based on images of a large proportion of captive pandas	Images	CNN	"Classification, Regression"	Ecology and Evolution	10	7	3561-3573	10.1002/ece3.6152	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.6152	"As a highly endangered species, the giant panda (panda) has attracted significant attention in the past decades. Considerable efforts have been put on panda conservation and reproduction, offering the promising outcome of maintaining the population size of pandas. To evaluate the effectiveness of conservation and management strategies, recognizing individual pandas is critical. However, it remains a challenging task because the existing methods, such as traditional tracking method, discrimination method based on footprint identification, and molecular biology method, are invasive, inaccurate, expensive, or challenging to perform. The advances of imaging technologies have led to the wide applications of digital images and videos in panda conservation and management, which makes it possible for individual panda recognition in a noninvasive manner by using image-based panda face recognition method. In recent years, deep learning has achieved great success in the field of computer vision and pattern recognition. For panda face recognition, a fully automatic deep learning algorithm which consists of a sequence of deep neural networks (DNNs) used for panda face detection, segmentation, alignment, and identity prediction is developed in this study. To develop and evaluate the algorithm, the largest panda image dataset containing 6,441 images from 218 different pandas, which is 39.78% of captive pandas in the world, is established. The algorithm achieved 96.27% accuracy in panda recognition and 100% accuracy in detection. This study shows that panda faces can be used for panda recognition. It enables the use of the cameras installed in their habitat for monitoring their population and behavior. This noninvasive approach is much more cost-effective than the approaches used in the previous panda surveys."																				
2020	"Chen, Xing; Zhao, Jun; Chen, Yan-hua; Zhou, Wei; Hughes, Alice C."	Automatic standardized processing and identification of tropical bat calls using deep learning approaches	Sound	CNN	Classification	Biological Conservation	241		108269	10.1016/j.biocon.2019.108269	https://linkinghub.elsevier.com/retrieve/pii/S0006320719308961	"Consistent and comparable metrics to automatically monitor biodiversity across the landscape remain a gold-standard for biodiversity research, yet such approaches have frequently been limited to a very small selection of species for which visual approaches (e.g., camera traps) make continuous monitoring possible. Acoustic-based methods have been widely applied in the monitoring of bats and some other taxa across extended spatial scales, but are have yet to be applied to diverse tropical communities. In this study, we developed a software program “Waveman” and prepared a reference library using over 880 audio-files from 36 Asian bat species. The software incorporated a novel network “BatNet” and a re-checking strategy (ReChk) to maximize accuracy. In Waveman, BatNet outperforms three other published networks: CNNFULL, VggNet and ResNet_v2, with over 90% overall accuracy and 0.94 AUC on the ROC plot. The classification accuracy rates for all 36 species are at least 86% when analysed in combination. Moreover, our library preparation and ReChk greatly improved the sensitivity and reduced the false positive rate, when tested with 15 species for which more detailed and situationally diverse records were available. Finally, BatNet was successfully used to identify Hipposideros larvatus and Rhinolophus siamensis from three different environments. We hope this pipeline is useful tool to process bioacoustic data accurately, effectively and automatically, therefore allowing for greater standardization and comparability for researchers to understand bat activities across space and time and therefore provide a consistent tool for monitoring biodiversity for management and conservation."																				
2020	"Chicco, Davide; Jurman, Giuseppe"	The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation	NA	NA	Review	BMC Genomics	21	1	6	10.1186/s12864-019-6413-7	https://doi.org/10.1186/s12864-019-6413-7	"To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets."																				
2020	"Choi, Taeyeong; Pyenson, Benjamin; Liebig, Juergen; Pavlic, Theodore P."	Identification of Abnormal States in Videos of Ants Undergoing Social Phase Change	Video	CNN	Classification	"arXiv:2009.08626 [cs, eess]"				10.48550/arXiv.2009.08626	http://arxiv.org/abs/2009.08626	"Biology is both an important application area and a source of motivation for development of advanced machine learning techniques. Although much attention has been paid to large and complex data sets resulting from high-throughput sequencing, advances in high-quality video recording technology have begun to generate similarly rich data sets requiring sophisticated techniques from both computer vision and time-series analysis. Moreover, just as studying gene expression patterns in one organism can reveal general principles that apply to other organisms, the study of complex social interactions in an experimentally tractable model system, such as a laboratory ant colony, can provide general principles about the dynamics of other social groups. Here, we focus on one such example from the study of reproductive regulation in small laboratory colonies of more than 50 Harpegnathos ants. These ants can be artificially induced to begin a ~20 day process of hierarchy reformation. Although the conclusion of this process is conspicuous to a human observer, it remains unclear which behaviors during the transient period are contributing to the process. To address this issue, we explore the potential application of One-class Classification (OC) to the detection of abnormal states in ant colonies for which behavioral data is only available for the normal societal conditions during training. Specifically, we build upon the Deep Support Vector Data Description (DSVDD) and introduce the Inner-Outlier Generator (IO-GEN) that synthesizes fake ""inner outlier"" observations during training that are near the center of the DSVDD data description. We show that IO-GEN increases the reliability of the final OC classifier relative to other DSVDD baselines. This method can be used to screen video frames for which additional human observation is needed."																				
2020	"Clapham, Melanie; Miller, Ed; Nguyen, Mary; Darimont, Chris T."	Automated facial recognition for wildlife that lack unique markings: A deep learning approach for brown bears	Images	CNN	Classification	Ecology and Evolution	10	23	12883-12892	10.1002/ece3.6840	https://onlinelibrary.wiley.com/doi/10.1002/ece3.6840	"Emerging technologies support a new era of applied wildlife research, generating data on scales from individuals to populations. Computer vision methods can process large datasets generated through image-based techniques by automating the detection and identification of species and individuals. With the exception of primates, however, there are no objective visual methods of individual identification for species that lack unique and consistent body markings. We apply deep learning approaches of facial recognition using object detection, landmark detection, a similarity comparison network, and an support vector machine-based classifier to identify individuals in a representative species, the brown bear Ursus arctos. Our open-source application, BearID, detects a bear’s face in an image, rotates and extracts the face, creates an “embedding” for the face, and uses the embedding to classify the individual. We trained and tested the application using labeled images of 132 known individuals collected from British Columbia, Canada, and Alaska, USA. Based on 4,674 images, with an 80/20% split for training and testing, respectively, we achieved a facial detection (ability to find a face) average precision of 0.98 and an individual classification (ability to identify the individual) accuracy of 83.9%. BearID and its annotated source code provide a replicable methodology for applying deep learning methods of facial recognition applicable to many other species that lack distinguishing markings. Further analyses of performance should focus on the influence of certain parameters on recognition accuracy, such as age and body size. Combining BearID with camera trapping could facilitate fine-scale behavioral research such as individual spatiotemporal activity patterns, and a cost-effective method of population monitoring through mark–recapture studies, with implications for species and landscape conservation and management. Applications to practical conservation include identifying problem individuals in human–wildlife conflicts, and evaluating the intrapopulation variation in efficacy of conservation strategies, such as wildlife crossings."																				
2020	"Couret, Jannelle; Moreira, Danilo C.; Bernier, Davin; Loberti, Aria Mia; Dotson, Ellen M.; Alvarez, Marco"	Delimiting cryptic morphological variation among human malaria vector species using convolutional neural networks	Images	CNN	"Classification, Regression"	PLOS Neglected Tropical Diseases	14	12	e0008904	10.1371/journal.pntd.0008904	https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0008904	"Deep learning is a powerful approach for distinguishing classes of images, and there is a growing interest in applying these methods to delimit species, particularly in the identification of mosquito vectors. Visual identification of mosquito species is the foundation of mosquito-borne disease surveillance and management, but can be hindered by cryptic morphological variation in mosquito vector species complexes such as the malaria-transmitting Anopheles gambiae complex. We sought to apply Convolutional Neural Networks (CNNs) to images of mosquitoes as a proof-of-concept to determine the feasibility of automatic classification of mosquito sex, genus, species, and strains using whole-body, 2D images of mosquitoes. We introduce a library of 1, 709 images of adult mosquitoes collected from 16 colonies of mosquito vector species and strains originating from five geographic regions, with 4 cryptic species not readily distinguishable morphologically even by trained medical entomologists. We present a methodology for image processing, data augmentation, and training and validation of a CNN. Our best CNN configuration achieved high prediction accuracies of 96.96% for species identification and 98.48% for sex. Our results demonstrate that CNNs can delimit species with cryptic morphological variation, 2 strains of a single species, and specimens from a single colony stored using two different methods. We present visualizations of the CNN feature space and predictions for interpretation of our results, and we further discuss applications of our findings for future applications in malaria mosquito surveillance."																				
2020	"de Solan, Thomas; Renoult, Julien Pierre; Geniez, Philippe; David, Patrice; Crochet, Pierre-André"	Looking for Mimicry in a Snake Assemblage Using Deep Learning	Images	CNN	Modeling	The American Naturalist	196	1	74-86	10.1086/708763	https://www.journals.uchicago.edu/doi/full/10.1086/708763	"Batesian mimicry is a canonical example of evolution by natural selection, popularized by highly colorful species resembling unrelated models with astonishing precision. However, Batesian mimicry could also occur in inconspicuous species and rely on subtle resemblance. Although potentially widespread, such instances have been rarely investigated, such that the real frequency of Batesian mimicry has remained largely unknown. To fill this gap, we developed a new approach using deep learning to quantify the visual resemblance between putative mimics and models from photographs. We applied this method to Western Palearctic snakes. Potential nonvenomous mimics were revealed by an excess of resemblance to sympatric venomous snakes compared with random expectations. We found that 8% of the nonvenomous species were potential mimics, although they resembled their models imperfectly. This study is the first to quantify the frequency of Batesian mimicry in a whole community of vertebrates, and it shows that even concealed species can act as potential models. Our approach should prove useful for detecting mimicry in other communities, and more generally it highlights the benefits of deep learning for quantitative studies of phenotypic resemblance."																				
2020	"Desai, Heta P; Parameshwaran, Anuja P; Sunderraman, Rajshekhar; Weeks, Michael"	Comparative Study Using Neural Networks for 16S Ribosomal Gene Classification	Molecular	"CNN, RNN"	Classification	Journal of Computational Biology	27	2	248-258	10.1089/cmb.2019.0436	https://www.liebertpub.com/doi/pdf/10.1089/cmb.2019.0436	"Bacterial 16S ribosomal gene was used to classify bacteria because it consists of both highly conservative region, as well as a hypervariable region, in its sequence. This hypervariable region serves as a discriminative factor to differentiate bacteria at taxonomic levels. In the past, many efforts have been made to correctly identify a bacterial species from environmental samples or human gut microbiome samples, yet this identiﬁcation and subsequent classiﬁcation task is challenging. For such bacterial taxonomic classiﬁcation, several studies in the past have been performed based on k-mer frequency matching, assembly-based clustering, supervised/unsupervised machine learning models, and a very few studies with deep learning architectures. In this article, we study and propose six different deep learning architectures involving recurrent neural networks (RNNs) and convolutional neural networks to classify bacteria at a family, genus, and species taxonomic level using *12,900 16S ribosomal DNA sequences. The best classiﬁcation accuracies achieved are 92%, 86%, and 70% at family, genus, and species taxonomic level, respectively, by variants of RNN."																				
2020	"Diehn, Sabrina; Zimmermann, Boris; Tafintseva, Valeria; Ba_cıo_lu, Murat; Kohler, Achim; Ohlson, Mikael; Fjellheim, Siri; Kneipp, Janina"	Discrimination of grass pollen of different species by FTIR spectroscopy of individual pollen grains	Other	DNN	Classification	Analytical and Bioanalytical Chemistry	412	24	6459-6474	10.1007/s00216-020-02628-2	https://doi.org/10.1007/s00216-020-02628-2	"Fourier-transform infrared (FTIR) spectroscopy enables the chemical characterization and identification of pollen samples, leading to a wide range of applications, such as paleoecology and allergology. This is of particular interest in the identification of grass (Poaceae) species since they have pollen grains of very similar morphology. Unfortunately, the correct identification of FTIR microspectroscopy spectra of single pollen grains is hindered by strong spectral contributions from Mie scattering. Embedding of pollen samples in paraffin helps to retrieve infrared spectra without scattering artifacts. In this study, pollen samples from 10 different populations of five grass species (Anthoxanthum odoratum, Bromus inermis, Hordeum bulbosum, Lolium perenne, and Poa alpina) were embedded in paraffin, and their single grain spectra were obtained by FTIR microspectroscopy. Spectra were subjected to different preprocessing in order to suppress paraffin influence on spectral classification. It is shown that decomposition by non-negative matrix factorization (NMF) and extended multiplicative signal correction (EMSC) that utilizes a paraffin constituent spectrum, respectively, leads to good success rates for the classification of spectra with respect to species by a partial least square discriminant analysis (PLS-DA) model in full cross-validation for several species. PLS-DA, artificial neural network, and random forest classifiers were applied on the EMSC-corrected spectra using an independent validation to assign spectra from unknown populations to the species. Variation within and between species, together with the differences in classification results, is in agreement with the systematics within the Poaceae family. The results illustrate the great potential of FTIR microspectroscopy for automated classification and identification of grass pollen, possibly together with other, complementary methods for single pollen chemical characterization."																				
2020	"Ditria, Ellen M.; Lopez-Marcano, Sebastian; Sievers, Michael; Jinks, Eric L.; Brown, Christopher J.; Connolly, Rod M."	Automating the analysis of fish abundance using object detection: optimizing animal ecology with deep learning	"Images, Video"	CNN	Regression	Frontiers in Marine Science	7			10.3389/fmars.2020.00429	https://www.frontiersin.org/article/10.3389/fmars.2020.00429	"Aquatic ecologists routinely count animals to provide critical information for conservation and management. Increased accessibility to underwater recording equipment such as action cameras and unmanned underwater devices has allowed footage to be captured efficiently and safely, without the logistical difficulties manual data collection often presents. It has, however, led to immense volumes of data being collected that require manual processing and thus significant time, labor, and money. The use of deep learning to automate image processing has substantial benefits but has rarely been adopted within the field of aquatic ecology. To test its efficacy and utility, we compared the accuracy and speed of deep learning techniques against human counterparts for quantifying fish abundance in underwater images and video footage. We collected footage of fish assemblages in seagrass meadows in Queensland, Australia. We produced three models using an object detection framework to detect the target species, an ecologically important fish, luderick (Girella tricuspidata). Our models were trained on three randomized 80:20 ratios of training:validation datasets from a total of 6,080 annotations. The computer accurately determined abundance from videos with high performance using unseen footage from the same estuary as the training data (F1 = 92.4%, mAP50 = 92.5%) and from novel footage collected from a different estuary (F1 = 92.3%, mAP50 = 93.4%). The computer’s performance in determining abundance was 7.1% better than human marine experts and 13.4% better than citizen scientists in single image test datasets, and 1.5 and 7.8% higher in video datasets, respectively. We show that deep learning can be a more accurate tool than humans at determining abundance and that results are consistent and transferable across survey locations. Deep learning methods provide a faster, cheaper, and more accurate alternative to manual data analysis methods currently used to monitor and assess animal abundance and have much to offer the field of aquatic ecology."																				
2020	"Espejo-Garcia, Borja; Mylonas, Nikos; Athanasakos, Loukas; Fountas, Spyros; Vasilakoglou, Ioannis"	Towards weeds identification assistance through transfer learning	Images	CNN	Classification	Computers and Electronics in Agriculture	171		105306	10.1016/j.compag.2020.105306	https://www.sciencedirect.com/science/article/pii/S0168169919319854	"Reducing the use of pesticides through selective spraying is an important component towards a more sustainable computer-assisted agriculture. Weed identification at early growth stage contributes to reduced herbicide rates. However, while computer vision alongside deep learning have overcome the performance of approaches that use hand-crafted features, there are still some open challenges in the development of a reliable automatic plant identification system. These type of systems have to take into account different sources of variability, such as growth stages and soil conditions, with the added constraint of the limited size of usual datasets. This study proposes a novel crop/weed identification system that relies on a combination of fine-tuning pre-trained convolutional networks (Xception, Inception-Resnet, VGNets, Mobilenet and Densenet) with the “traditional” machine learning classifiers (Support Vector Machines, XGBoost and Logistic Regression) trained with the previously deep extracted features. The aim of this approach was to avoid overfitting and to obtain a robust and consistent performance. To evaluate this approach, an open access dataset of two crop [tomato (Solanum lycopersicum L.) and cotton (Gossypium hirsutum L.)] and two weed species [black nightshade (Solanum nigrum L.) and velvetleaf (Abutilon theophrasti Medik.)] was generated. The pictures were taken by different production sites across Greece under natural variable light conditions from RGB cameras. The results revealed that a combination of fine-tuned Densenet and Support Vector Machine achieved a micro F1 score of 99.29% with a very low performance difference between train and test sets. Other evaluated approaches also obtained repeatedly more than 95% F1 score. Additionally, our results analysis provides some heuristics for designing transfer-learning based systems to avoid overfitting without decreasing performance."																				
2020	"Fekri-Ershad, Shervan"	Bark texture classification using improved local ternary patterns and multilayer neural network	Images	DNN	Classification	Expert Systems with Applications	158		113509	10.1016/j.eswa.2020.113509	https://www.sciencedirect.com/science/article/pii/S095741742030333X	"Tree identification is one of the areas that are regarded by researchers. It is done by human expert with high cost. Experts believe that tree bark has a high relation with species in comparison with other phenotype properties. Repeated textures in the bark is usually various with slight differences. So, lbp-like descriptors used in most recent works. But, most of them do not provide discriminative features. Also some texture descriptors are sensitive to noise and rotation. Local ternary pattern is one of the operators that are resistant to the noise with high discrimination. In most of descriptors, histogram of patterns is used to extract features. But, it is rotation sensitive with high computational complexity. In this paper, the main contribution is to propose a method for bark texture classification with high accuracy based on the improved local ternary patterns (ILTP). In the proposed ILTP, the ternary patterns are coded into two binary patterns, and then each one is classified into two uniform/non-uniform groups. The extracted patterns are labeled according to the degree of uniformity. Finally the occurrence probability of the labels is extracted as features. Also, a multilayer perceptron is designed with four theories in the number of hidden nodes. Experimental results on two benchmark datasets showed that our proposed approach provides higher classification accuracy than most well known methods. Noise-resistant and rotation invariant are other advantages of the presented method. The proposed bark texture classification, because of its high classification accuracy, can be applied in real applications and reduce the financial costs and human risks in the diagnosis of plant species."																				
2020	"Ferreira, André C.; Silva, Liliana R.; Renna, Francesco; Brandl, Hanja B.; Renoult, Julien P.; Farine, Damien R.; Covas, Rita; Doutrelant, Claire"	Deep learning-based methods for individual recognition in small birds	Images	CNN	"Classification, Regression"	Methods in Ecology and Evolution	11	9	1072-1085	10.1111/2041-210X.13436	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13436	"Individual identification is a crucial step to answer many questions in evolutionary biology and is mostly performed by marking animals with tags. Such methods are well-established, but often make data collection and analyses time-consuming, or limit the contexts in which data can be collected. Recent computational advances, specifically deep learning, can help overcome the limitations of collecting large-scale data across contexts. However, one of the bottlenecks preventing the application of deep learning for individual identification is the need to collect and identify hundreds to thousands of individually labelled pictures to train convolutional neural networks (CNNs). Here we describe procedures for automating the collection of training data, generating training datasets, and training CNNs to allow identification of individual birds. We apply our procedures to three small bird species, the sociable weaver Philetairus socius, the great tit Parus major and the zebra finch Taeniopygia guttata, representing both wild and captive contexts. We first show how the collection of individually labelled images can be automated, allowing the construction of training datasets consisting of hundreds of images per individual. Second, we describe how to train a CNN to uniquely re-identify each individual in new images. Third, we illustrate the general applicability of CNNs for studies in animal biology by showing that trained CNNs can re-identify individual birds in images collected in contexts that differ from the ones originally used to train the CNNs. Finally, we present a potential solution to solve the issues of new incoming individuals. Overall, our work demonstrates the feasibility of applying state-of-the-art deep learning tools for individual identification of birds, both in the laboratory and in the wild. These techniques are made possible by our approaches that allow efficient collection of training data. The ability to conduct individual recognition of birds without requiring external markers that can be visually identified by human observers represents a major advance over current methods."																				
2020	"Figueroa-Mata, Geovanni; Mata-Montero, Erick"	Using a Convolutional Siamese Network for Image-Based Plant Species Identification with Small Datasets	Images	CNN	Classification	Biomimetics	5	1	8	10.3390/biomimetics5010008	https://www.mdpi.com/2313-7673/5/1/8	"The application of deep learning techniques may prove difficult when datasets are small. Recently, techniques such as one-shot learning, few-shot learning, and Siamese networks have been proposed to address this problem. In this paper, we propose the use a convolutional Siamese network (CSN) that learns a similarity metric that discriminates between plant species based on images of leaves. Once the CSN has learned the similarity function, its discriminatory power is generalized to classify not just new pictures of the species used during training but also entirely new species for which only a few images are available. This is achieved by exposing the network to pairs of similar and dissimilar observations and minimizing the Euclidean distance between similar pairs while simultaneously maximizing it between dissimilar pairs. We conducted experiments to study two different scenarios. In the first one, the CSN was trained and validated with datasets that comprise 5, 10, 15, 20, 25, and 30 pictures per species, extracted from the well-known Flavia dataset. Then, the trained model was tested with another dataset composed of 320 images (10 images per species) also from Flavia. The obtained accuracy was compared with the results of feeding the same training, validation, and testing datasets to a convolutional neural network (CNN) in order to determine if there is a threshold value t for dataset size that defines the intervals for which either the CSN or the CNN has better accuracy. In the second studied scenario, the accuracy of both the CSN and the CNN—both trained and validated with the same datasets extracted from Flavia—were compared when tested on a set of images of leaves of 20 Costa Rican tree species that are not represented in Flavia."																				
2020	"Fuentes, Alvaro; Yoon, Sook; Park, Dong Sun"	Deep Learning-Based Phenotyping System With Glocal Description of Plant Anomalies and Symptoms	Images	"CNN, RNN"	Regression	Frontiers in Plant Science	10			10.3389/fpls.2019.01321	https://www.frontiersin.org/article/10.3389/fpls.2019.01321	"Recent advances in Deep Neural Networks have allowed the development of efficient and automated diagnosis systems for plant anomalies recognition. Although existing methods have shown promising results, they present several limitations to provide an appropriate characterization of the problem, especially in real-field scenarios. To address this limitation, we propose an approach that besides being able to efficiently detect and localize plant anomalies, allows to generate more detailed information about their symptoms and interactions with the scene, by combining visual object recognition and language generation. It uses an image as input and generates a diagnosis result that shows the location of anomalies and sentences describing the symptoms as output. Our framework is divided into two main parts: First, a detector obtains a set of region features that contain the anomalies using a Region-based Deep Neural Network. Second, a language generator takes the features of the detector as input and generates descriptive sentences with details of the symptoms using Long-Short Term Memory (LSTM). Our loss metric allows the system to be trained end-to-end from the object detector to the language generator. Finally, the system outputs a set of bounding boxes along with the sentences that describe their symptoms using glocal criteria into two different ways: a set of specific descriptions of the anomalies detected in the plant and an abstract description that provides general information about the scene. We demonstrate the efficiency of our approach in the challenging tomato diseases and pests recognition task. We further show that our approach achieves a mean Average Precision (mAP) of 92.5% in our newly created Tomato Plant Anomalies Description Dataset. Our objective evaluation allows users to understand the relationships between pathologies and their evolution throughout their stage of infection, location in the plant, symptoms, etc. Our work introduces a cost-efficient tool that provides farmers with a technology that facilitates proper handling of crops."																				
2020	"Fuentes, Alvaro; Yoon, Sook; Park, Jongbin; Park, Dong Sun"	Deep learning-based hierarchical cattle behavior recognition with spatio-temporal information	Video	CNN	Classification	Computers and Electronics in Agriculture	177		105627	10.1016/j.compag.2020.105627	https://linkinghub.elsevier.com/retrieve/pii/S0168169920307110	"Behavior is an important indicator for understanding the well-being of animals. This process has been frequently carried out by observing video records to detect changes with statistical analysis, or by using portable devices to monitor animal movements. However, regarding animal welfare, the use of such devices could affect the normal behavior of the animal, and present limitations in its applicability. This paper introduces an approach for hierarchical cattle behavior recognition with spatio-temporal information based on deep learning. Our research extends the idea of activity recognition in video and focuses specifically on cattle behavior. Our framework involves appearance features at frame-level and spatio-temporal information that incorporates more context-temporal features. The system can detect (class) and localize (bounding box) regions containing multiple cattle behaviors in the video frames. Additionally, we introduce our cattle behavior dataset that includes videos recorded with RGB cameras on different livestock farms during day and night environments. Experimental results show that our system can effectively recognize 15 different types of hierarchical activities divided into individual and group activities, and also part actions. Qualitative and quantitative evaluation evidence the performance of our framework as an effective method to monitor cattle behavior."																				
2020	"Gal, Asaf; Saragosti, Jonathan; Kronauer, Daniel JC"	"anTraX, a software package for high-throughput video tracking of color-tagged insects"	Video	CNN	Classification	eLife	9		e58145	10.7554/eLife.58145	https://elifesciences.org/articles/58145	"Recent years have seen a surge in methods to track and analyze animal behavior. Nevertheless, tracking individuals in closely interacting, group-living organisms remains a challenge. Here, we present anTraX, an algorithm and software package for high-throughput video tracking of color-tagged insects. anTraX combines neural network classification of animals with a novel approach for representing tracking data as a graph, enabling individual tracking even in cases where it is difficult to segment animals from one another, or where tags are obscured. The use of color tags, a well-established and robust method for marking individual insects in groups, relaxes requirements for image size and quality, and makes the software broadly applicable. anTraX is readily integrated into existing tools and methods for automated image analysis of behavior to further augment its output. anTraX can handle large-scale experiments with minimal human involvement, allowing researchers to simultaneously monitor many social groups over long time periods."																				
2020	"González-Rivero, Manuel; Beijbom, Oscar; Rodriguez-Ramirez, Alberto; Bryant, Dominic E. P.; Ganase, Anjani; Gonzalez-Marrero, Yeray; Herrera-Reveles, Ana; Kennedy, Emma V.; Kim, Catherine J. S.; Lopez-Marcano, Sebastian; Markey, Kathryn; Neal, Benjamin P.; Osborne, Kate; Reyes-Nivia, Catalina; Sampayo, Eugenia M.; Stolberg, Kristin; Taylor, Abbie; Vercelloni, Julie; Wyatt, Mathew; Hoegh-Guldberg, Ove"	Monitoring of Coral Reefs Using Artificial Intelligence: A Feasible and Cost-Effective Approach	Images	CNN	Classification	Remote Sensing	12	3	489	10.3390/rs12030489	https://www.mdpi.com/2072-4292/12/3/489	"Ecosystem monitoring is central to effective management, where rapid reporting is essential to provide timely advice. While digital imagery has greatly improved the speed of underwater data collection for monitoring benthic communities, image analysis remains a bottleneck in reporting observations. In recent years, a rapid evolution of artificial intelligence in image recognition has been evident in its broad applications in modern society, offering new opportunities for increasing the capabilities of coral reef monitoring. Here, we evaluated the performance of Deep Learning Convolutional Neural Networks for automated image analysis, using a global coral reef monitoring dataset. The study demonstrates the advantages of automated image analysis for coral reef monitoring in terms of error and repeatability of benthic abundance estimations, as well as cost and benefit. We found unbiased and high agreement between expert and automated observations (97%). Repeated surveys and comparisons against existing monitoring programs also show that automated estimation of benthic composition is equally robust in detecting change and ensuring the continuity of existing monitoring data. Using this automated approach, data analysis and reporting can be accelerated by at least 200x and at a fraction of the cost (1%). Combining commonly used underwater imagery in monitoring with automated image annotation can dramatically improve how we measure and monitor coral reefs worldwide, particularly in terms of allocating limited resources, rapid reporting and data integration within and across management areas."																				
2020	"Goodwin, Morten; Halvorsen, Kim Tallaksen; Jiao, Lei; Knausgård, Kristian Muri; Martin, Angela Helen; Moyano, Marta; Oomen, Rebekah A; Rasmussen, Jeppe Have; Sørdalen, Tonje Knutsen; Thorbjørnsen, Susanna Huneide"	"Unlocking the potential of deep learning for marine ecology: overview, applications, and outlook"	NA	NA	Review	ICES Journal of Marine Science	79	2	319-336	10.1093/icesjms/fsab255	https://academic.oup.com/icesjms/article/79/2/319/6507793	"The deep learning (DL) revolution is touching all scientific disciplines and corners of our lives as a means of harnessing the power of big data. Marine ecology is no exception. New methods provide analysis of data from sensors, cameras, and acoustic recorders, even in real time, in ways that are reproducible and rapid. Off-the-shelf algorithms find, count, and classify species from digital images or video and detect cryptic patterns in noisy data. These endeavours require collaboration across ecological and data science disciplines, which can be challenging to initiate. To promote the use of DL towards ecosystem-based management of the sea, this paper aims to bridge the gap between marine ecologists and computer scientists. We provide insight into popular DL approaches for ecological data analysis, focusing on supervised learning techniques with deep neural networks, and illustrate challenges and opportunities through established and emerging applications of DL to marine ecology. We present case studies on plankton, fish, marine mammals, pollution, and nutrient cycling that involve object detection, classification, tracking, and segmentation of visualized data. We conclude with a broad outlook of the field’s opportunities and challenges, including potential technological advances and issues with managing complex data sets."																				
2020	"Grandini, Margherita; Bagli, Enrico; Visani, Giorgio"	Metrics for multi-class classification: an overview	NA	NA	Review	arXiv			2008.05756	10.48550/arXiv.2008.05756	http://arxiv.org/abs/2008.05756	"Classification tasks in machine learning involving more than two classes are known by the name of ""multi-class classification"". Performance indicators are very useful when the aim is to evaluate and compare different classification models or machine learning techniques. Many metrics come in handy to test the ability of a multi-class classifier. Those metrics turn out to be useful at different stage of the development process, e.g. comparing the performance of two different models or analysing the behaviour of the same model by tuning different parameters. In this white paper we review a list of the most promising multi-class metrics, we highlight their advantages and disadvantages and show their possible usages during the development of a classification model."																				
2020	"Graving, Jacob M.; Couzin, Iain D."	VAE-SNE: a deep generative model for simultaneous dimensionality reduction and clustering	Other	VAE	Regression	bioRxiv			2020.07.17.207993	10.1101/2020.07.17.207993v1	https://www.biorxiv.org/content/10.1101/2020.07.17.207993v1	"Scientific datasets are growing rapidly in scale and complexity. Consequently, the task of understanding these data to answer scientific questions increasingly requires the use of compression algorithms that reduce dimensionality by combining correlated features and cluster similar observations to summarize large datasets. Here we introduce a method for both dimension reduction and clustering called VAE-SNE (variational autoencoder stochastic neighbor embedding). Our model combines elements from deep learning, probabilistic inference, and manifold learning to produce interpretable compressed representations while also readily scaling to tens-of-millions of observations. Unlike existing methods, VAE-SNE simultaneously compresses high-dimensional data and automatically learns a distribution of clusters within the data — without the need to manually select the number of clusters. This naturally creates a multi-scale representation, which makes it straightforward to generate coarse-grained descriptions for large subsets of related observations and select specific regions of interest for further analysis. VAE-SNE can also quickly and easily embed new samples, detect outliers, and can be optimized with small batches of data, which makes it possible to compress datasets that are otherwise too large to fit into memory. We evaluate VAE-SNE as a general purpose method for dimensionality reduction by applying it to multiple real-world datasets and by comparing its performance with existing methods for dimensionality reduction. We find that VAE-SNE produces high-quality compressed representations with results that are on par with existing nonlinear dimensionality reduction algorithms. As a practical example, we demonstrate how the cluster distribution learned by VAE-SNE can be used for unsupervised action recognition to detect and classify repeated motifs of stereotyped behavior in high-dimensional timeseries data. Finally, we also introduce variants of VAE-SNE for embedding data in polar (spherical) coordinates and for embedding image data from raw pixels. VAE-SNE is a robust, feature-rich, and scalable method with broad applicability to a range of datasets in the life sciences and beyond."																				
2020	"Guo, Qinghua; Jin, Shichao; Li, Min; Yang, Qiuli; Xu, Kexin; Ju, Yuanzhen; Zhang, Jing; Xuan, Jing; Liu, Jin; Su, Yanjun; Xu, Qiang; Liu, Yu"	"Application of deep learning in ecological resource research: Theories, methods, and challenges"	NA	NA	Review	Science China Earth Sciences	63	10	1457-1474	10.1007/s11430-019-9584-9	http://link.springer.com/10.1007/s11430-019-9584-9	"Ecological resources are an important material foundation for the survival, development, and self-realization of human beings. In-depth and comprehensive research and understanding of ecological resources are beneficial for the sustainable development of human society. Advances in observation technology have improved the ability to acquire long-term, cross-scale, massive, heterogeneous, and multi-source data. Ecological resource research is entering a new era driven by big data. Traditional statistical learning and machine learning algorithms have problems with saturation in dealing with big data. Deep learning is a method for automatically extracting complex high-dimensional nonlinear features, which is increasingly used for scientific and industrial data processing because of its ability to avoid saturation with big data. To promote the application of deep learning in the field of ecological resource research, here, we first introduce the relationship between deep learning theory and research on ecological resources, common tools, and datasets. Second, applications of deep learning in classification and recognition, detection and localization, semantic segmentation, instance segmentation, and graph neural network in typical spatial discrete data are presented through three cases: species classification, crop breeding, and vegetation mapping. Finally, challenges and opportunities for the application of deep learning in ecological resource research in the era of big data are summarized by considering the characteristics of ecological resource data and the development status of deep learning. It is anticipated that the cooperation and training of cross-disciplinary talents may promote the standardization and sharing of ecological resource data, improve the universality and interpretability of algorithms, and enrich applications with the development of hardware."																				
2020	"Guo, Songtao; Xu, Pengfei; Miao, Qiguang; Shao, Guofan; Chapman, Colin A.; Chen, Xiaojiang; He, Gang; Fang, Dingyi; Zhang, He; Sun, Yewen; Shi, Zhihui; Li, Baoguo"	Automatic Identification of Individual Primates with Deep Learning Techniques	Images	CNN	"Classification, Regression"	iScience	23	8	101412	10.1016/j.isci.2020.101412	https://www.sciencedirect.com/science/article/pii/S2589004220306027	"The difficulty of obtaining reliable individual identification of animals has limited researcher's ability to obtain quantitative data to address important ecological, behavioral, and conservation questions. Traditional marking methods placed animals at undue risk. Machine learning approaches for identifying species through analysis of animal images has been proved to be successful. But for many questions, there needs a tool to identify not only species but also individuals. Here, we introduce a system developed specifically for automated face detection and individual identification with deep learning methods using both videos and still-framed images that can be reliably used for multiple species. The system was trained and tested with a dataset containing 102,399 images of 1,040 individuals across 41 primate species whose individual identity was known and 6,562 images of 91 individuals across four carnivore species. For primates, the system correctly identified individuals 94.1% of the time and could process 31 facial images per second."																				
2020	"Gupta, G.; Saini, S."	DAVI: Deep learning-based tool for alignment and single nucleotide variant identification	Molecular	"CNN, RNN"	Classification	Machine Learning: Science and Technology	1	2	25013	10.1088/2632-2153/ab7e19	https://iopscience.iop.org/article/10.1088/2632-2153/ab7e19/meta	"Next-generation sequencing (NGS) technologies have provided affordable but errorful ways to generate raw genetic data. To extract variant information from billions of NGS reads is still a daunting task which involves various hand-crafted and parameterized statistical tools. Here we propose a deep neural networks (DNN) based alignment and single nucleotide variant (SNV) identifier tool known as DAVI: deep alignment and variant identification. DAVI consists of models for both global and local alignment and for variant calling. We have evaluated the performance of DAVI against existing state-of-the-art tool sets and found that its accuracy and performance is comparable to existing tools used for bench-marking. We further demonstrate that while existing tools are based on data generated from a specific sequencing technology, the models proposed in DAVI are generic and can be used across different NGS technologies as well as across different species. The use of DAVI will therefore help non-human sequencing projects to benefit from the wealth of human ground truth data. Moreover, this approach is a migration from expert-driven statistical models to generic, automated, self-learning models."																				
2020	"Han, Fangfang; Zhu, Junchao; Liu, Bin; Zhang, Baofeng; Xie, Fuhua"	Fish Shoals Behavior Detection Based on Convolutional Neural Network and Spatiotemporal Information	Images	CNN	Classification	IEEE Access	8		126907-126926	10.1109/ACCESS.2020.3008698	https://ieeexplore.ieee.org/document/9139232	"Behavior is the first visible change in an animal species after exposure to its own or environmental stressors and is a sensitive indicator. Fish are social animals, and the abnormality of group behavior is more indicative about a particular event than individual behavior, providing more effective informeqation about environmental or group social changes. The group behavior is not only reflected in the spatial distribution, but also reflected in the temporal behavior of the group and individual movement changes under the influence of pressure factors. This paper proposes a group behavior discrimination method based on convolutional neural network and spatiotemporal information fusion, which intends to make use of the prominent performance of convolutional neural network in image recognition and state classification, and imitating the attentional mechanism of ventral channel and dorsal channel when the human brain processes visual signals. Some pressure environments are made in laboratory, the behavior states of fish shoals are recorded, and the sample database of shoals' behavior state is established by combining the spatial information of shoals' spatial distribution with the time information reflected in the movement behavior. A simple convolutional neural network is constructed to quickly identify the behavior state of fish shoals. The effects of bath size and training epoch on network training speed and recognition accuracy are discussed, and the visualization of the intermediate data of the convolutional neural network is studied. Shown from the results of experiments of this paper, different behavior states of fish shoals can be recognized and classified effectively by using the simple convolutional neural network and spatiotemporal fusion images. What's more, from the visualization of network intermediate data, it is found that the convolutional neural network has a higher discrimination power to the image edge feature than the image gray-value feature."																				
2020	"Hansen, Oskar L. P.; Svenning, Jens_Christian; Olsen, Kent; Dupont, Steen; Garner, Beulah H.; Iosifidis, Alexandros; Price, Benjamin W.; Høye, Toke T."	Species_level image classification with convolutional neural network enables insect identification from habitus images	Images	CNN	Classification	Ecology and Evolution	10	2	737-747	10.1002/ece3.5921	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.5921	"Changes in insect biomass, abundance, and diversity are challenging to track at sufficient spatial, temporal, and taxonomic resolution. Camera traps can capture habitus images of ground-dwelling insects. However, currently sampling involves manually detecting and identifying specimens. Here, we test whether a convolutional neural network (CNN) can classify habitus images of ground beetles to species level, and estimate how correct classification relates to body size, number of species inside genera, and species identity. We created an image database of 65,841 museum specimens comprising 361 carabid beetle species from the British Isles and fine-tuned the parameters of a pretrained CNN from a training dataset. By summing up class confidence values within genus, tribe, and subfamily and setting a confidence threshold, we trade-off between classification accuracy, precision, and recall and taxonomic resolution. The CNN classified 51.9% of 19,164 test images correctly to species level and 74.9% to genus level. Average classification recall on species level was 50.7%. Applying a threshold of 0.5 increased the average classification recall to 74.6% at the expense of taxonomic resolution. Higher top value from the output layer and larger sized species were more often classified correctly, as were images of species in genera with few species. Fine-tuning enabled us to classify images with a high mean recall for the whole test dataset to species or higher taxonomic levels, however, with high variability. This indicates that some species are more difficult to identify because of properties such as their body size or the number of related species. Together, species-level image classification of arthropods from museum collections and ecological monitoring can substantially increase the amount of occurrence data that can feasibly be collected. These tools thus provide new opportunities in understanding and predicting ecological responses to environmental change"																				
2020	"Hatton-Jones, Kyle M.; Christie, Corey; Griffith, Tia A.; Smith, Amanda G.; Naghipour, Saba; Robertson, Kai; Russell, Jake S.; Peart, Jason N.; Headrick, John P.; Cox, Amanda J.; du Toit, Eugene F."	A YOLO based software for automated detection and analysis of rodent behaviour in the open field arena	Images	CNN	"Classification, Regression"	Computers in Biology and Medicine	134		104474	10.1016/j.compbiomed.2021.104474	https://www.sciencedirect.com/science/article/pii/S0010482521002687	"Rodent models are important in mechanistic studies of the physiological and pathophysiological determinants of behaviour. The Open Field Test (OFT) is one of the most commonly utilised tests to assess rodent behaviour in a novel open environment. The key variables assessed in an OFT are general locomotor activity and exploratory behaviours and can be assessed manually or by automated systems. Although several automated systems exist, they are often expensive, difficult to use, or limited in the type of video that can be analysed. Here we describe a machine-learning algorithm – dubbed Cosevare – that uses a trained YOLOv3 DNN to identify and track movement of mice in the open-field arena. We validated Cosevare's capacity to accurately track locomotive and exploratory behaviour in 10 videos, comparing outputs generated by Cosevare with analysis by 5 manual scorers. Behavioural differences between control mice and those with diet-induced obesity (DIO) were also documented. We found the YOLOv3 based tracker to be accurate at identifying and tracking the mice within the open-field arena and in instances with variable backgrounds. Additionally, kinematic and spatial-based analysis demonstrated highly consistent scoring of locomotion, centre square duration (CSD) and entries (CSE) between Cosevare and manual scorers. Automated analysis was also able to distinguish behavioural differences between healthy control and DIO mice. The study found that a YOLOv3 based tracker is able to easily track mouse behaviour in the open field arena and supports machine learning as a potential future alternative for the assessment of animal behaviour in a wide range of species in differing environments and behavioural tests."																				
2020	"He, Tuo; Lu, Yang; Jiao, Lichao; Zhang, Yonggang; Jiang, Xiaomei; Yin, Yafang"	Developing deep learning models to automate rosewood tree species identification for CITES designation and implementation	Images	CNN	Classification	Holzforschung	74	12	1123-1133	10.1515/hf-2020-0006	https://www.degruyter.com/document/doi/10.1515/hf-2020-0006/html?lang=en	"The implementation of Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES) to combat illegal logging and associated trade necessitates accurate and efficient field screening of wood species. In this study, a total of 10,237 images of 15 Dalbergia and 11 Pterocarpus species were collected from the transverse surfaces of 417 wood specimens. Three deep learning models were then constructed, trained, and tested with these images to discriminate between timber species. The optimal parameters of the deep learning model were analyzed, and the representative wood anatomical features that were activated by the deep learning models were visualized. The results demonstrated that the overall accuracies of the 26-class, 15-class, and 11-class models were 99.3, 93.7, and 88.4%, respectively. It is suggested that at least 100 high-quality images per species with minimum patch sizes of 1000 _ 1000 from more than 10 wood specimens were needed to train reliable and applicable deep learning models. The feature visualization indicated that the vessel groupings and axial parenchyma were the main wood anatomical features activated by the deep learning models. The combination of the state-of-the-art deep learning models, parameter configuration, and feature visualization provide a time- and cost-effective tool for the field screening of wood species to support effective CITES designation and implementation."																				
2020	"Hou, Jin; He, Yuxin; Yang, Hongbo; Connor, Thomas; Gao, Jie; Wang, Yujun; Zeng, Yichao; Zhang, Jindong; Huang, Jinyan; Zheng, Bochuan; Zhou, Shiqiang"	Identification of animal individuals using deep learning: A case study of giant panda	Images	CNN	Classification	Biological Conservation	242		108414	10.1016/j.biocon.2020.108414	https://www.sciencedirect.com/science/article/pii/S000632071931609X	"Giant panda (Ailuropoda melanoleuca) is an iconic species of conservation. However, long-term monitoring of wild giant pandas has been a challenge, largely due to the lack of appropriate method for the identification of target panda individuals. Although there are some traditional methods, such as distance-bamboo stem fragments methods, molecular biological method, and manual visual identification, they all have some limitations that can restrict their application. Therefore, it is urgent to explore a reliable and efficient approach to identify giant panda individuals. Here, we applied the deep learning technology and developed a novel face-identification model based on convolutional neural network to identify giant panda individuals. The model was able to identify 95% of giant panda individuals in the validation dataset. In all simulated field situations where the quality of photo data was degraded, the model still accurately identified more than 90% of panda individuals. The identification accuracy of our model is robust to brightness, small rotation, and cleanness of photos, although large rotation angle (>20°) of photos has significant influence on the identification accuracy of the model (P < 0.01). Our model can be applied in future studies of giant panda such as long-term monitoring, big data analysis for behavior and be adapted for individual identification of other wildlife species."																				
2020	"Hu, Jun; Zhou, Chengquan; Zhao, Dandan; Zhang, Linnan; Yang, Guijun; Chen, Wenxuan"	"A rapid, low-cost deep learning system to classify squid species and evaluate freshness based on digital images"	Images	CNN	Classification	Fisheries Research	221		105376	10.1016/j.fishres.2019.105376	https://www.sciencedirect.com/science/article/pii/S0165783619302310	"We developed and evaluated a rapid, low-cost system to classify squid in industrial production. This involved designing an easy-to-use handheld image-acquisition system combined with an automated, labor-saving, and efficient deep learning model (named “improved faster recurrent convolutional neural network”) to identify three squid species from the North Pacific Ocean. Three indicators, Accuracy, Intersection-over-Union, and Average Running Time, are used to evaluate the classification, and the average results for the test samples are 85.7%, 80.1%, and 0.144_s, respectively. The proposed network provides better squid classification compared with four other approaches. In addition, to ensure quality, the freshness of the selected squid is also evaluated using global threshold segmentation analysis. This proposed method is demonstrated to be a robust, noninvasive, and high-throughput system for squid classification and can also be expanded to other fine processing of aquatic products."																				
2020	"Huixian, Jiang"	The Analysis of Plants Image Recognition Based on Deep Learning and Artificial Neural Network	Images	DNN	Classification	IEEE Access	8		68828-68841	10.1109/ACCESS.2020.2986946	https://ieeexplore.ieee.org/document/9062591	"Classification and identification of plants are helpful for people to effectively understand and protect plants. The leaves of plants are the most important recognition organs. With the development of artificial intelligence and machine vision technology, plant leaf recognition technology based on image analysis is used to improve the knowledge of plant classification and protection. Deep learning is the abbreviation of deep neural network learning method and belongs to neural network structure. It can automatically learn features from big data and use artificial neural network based on back propagation algorithm to train and classify plant leaf samples. The main content of this paper is to extract plant leaf features and identify plant species based on image analysis. Firstly, plant leaf images are segmented by various methods, and then feature extraction algorithm is used to extract leaf shape and texture features from leaf sample images. Then the comprehensive characteristic information of plant leaves is formed according to the comprehensive characteristic information. In this paper, 50 plant leaf databases are tested and compared with KNN-based neighborhood classification, Kohonen network based on self-organizing feature mapping algorithm and SVM-based support vector machine. At the same time, the leaves of 7 different plants were compared and it was found that ginkgo leaves were easier to identify. For leaf images under complex background, good recognition effect has been achieved. Image samples of the test set are input into the learning model to obtain reconstruction errors. The class label of the test set can be obtained by reconstructing the deep learning model with the smallest error set. The results show that this method has the shortest recognition time and the highest correct recognition rate."																				
2020	"Huynh, Hiep Xuan; Truong, Bao Quoc; Nguyen Thanh, Kiet Tan; Truong, Dinh Quoc"	Plant Identification Using New Architecture Convolutional Neural Networks Combine with Replacing the Red of Color Channel Image by Vein Morphology Leaf	Images	CNN	Classification	Vietnam Journal of Computer Science	7	2	197-208	10.1142/S2196888820500116	https://www.worldscientific.com/doi/10.1142/S2196888820500116	"The determination of plant species from field observation requires substantial botanical expertise, which puts it beyond the reach of most nature enthusiasts. Traditional plant species identification is almost impossible for the general public and challenging even for professionals who deal with botanical problems daily such as conservationists, farmers, foresters, and landscape architects. Even for botanists themselves, species identification is often a difficult task. This paper proposes a model deep learning with a new architecture Convolutional Neural Network (CNN) for leaves classifier based on leaf pre-processing extract vein shape data replaced for the red channel of colors. This replacement improves the accuracy of the model significantly. This model experimented on collector leaves data set Flavia leaf data set and the Swedish leaf data set. The classification results indicate that the proposed CNN model is effective for leaf recognition with the best accuracy greater than 98.22%."																				
2020	"Itaki, Takuya; Taira, Yosuke; Kuwamori, Naoki; Saito, Hitoshi; Ikehara, Minoru; Hoshino, Tatsuhiko"	Innovative microfossil (radiolarian) analysis using a system for automated image collection and AI-based classification of species	Images	CNN	Classification	Scientific Reports	10	1	21136	10.1038/s41598-020-77812-6	https://www.nature.com/articles/s41598-020-77812-6	"Microfossils are a powerful tool in earth sciences, and they have been widely used for the determination of geological age and in paleoenvironmental studies. However, the identification of fossil species requires considerable time and labor by experts with extensive knowledge and experience. In this study, we successfully automated the acquisition of microfossil data using an artificial intelligence system that employs a computer-controlled microscope and deep learning methods. The system was used to calculate changes in the relative abundance (%) of Cycladophora davisiana, a siliceous microfossil species (Radiolaria) that is widely used as a stratigraphic tool in studies on Pleistocene sediments in the Southern Ocean. The estimates obtained using this system were consistent with the results obtained by a human expert (<_±_3.2%). In terms of efficiency, the developed system was capable of performing the classification tasks approximately three times faster than a human expert performing the same task."																				
2020	"Jalal, Ahsan; Salman, Ahmad; Mian, Ajmal; Shortis, Mark; Shafait, Faisal"	Fish detection and species classification in underwater environments using deep learning with temporal information	Video	CNN	"Classification, Regression"	Ecological Informatics	57		101088	10.1016/j.ecoinf.2020.101088	https://www.sciencedirect.com/science/article/pii/S1574954120300388	"It is important for marine scientists and conservationists to frequently estimate the relative abundance of fish species in their habitats and monitor changes in their populations. As opposed to laborious manual sampling, various automatic computer-based fish sampling solutions in underwater videos have been presented. However, an optimal solution for automatic fish detection and species classification does not exist. This is mainly because of the challenges present in underwater videos due to environmental variations in luminosity, fish camouflage, dynamic backgrounds, water murkiness, low resolution, shape deformations of swimming fish, and subtle variations between some fish species. To overcome these challenges, we propose a hybrid solution to combine optical flow and Gaussian mixture models with YOLO deep neural network, an unified approach to detect and classify fish in unconstrained underwater videos. YOLO based object detection system are originally employed to capture only the static and clearly visible fish instances. We eliminate this limitation of YOLO to enable it to detect freely moving fish, camouflaged in the background, using temporal information acquired via Gaussian mixture models and optical flow. We evaluated the proposed system on two underwater video datasets i.e., the LifeCLEF 2015 benchmark from the Fish4Knowledge repository and a dataset collected by The University of Western Australia (UWA). We achieve fish detection F-scores of 95.47% and 91.2%, while fish species classification accuracies of 91.64% and 79.8% on both datasets respectively. To our knowledge, these are the best reported results on these datasets, which show the effectiveness of our proposed approach."																				
2020	"Jamal, Salma; Khubaib, Mohd; Gangwar, Rishabh; Grover, Sonam; Grover, Abhinav; Hasnain, Seyed E."	Artificial Intelligence and Machine learning based prediction of resistant and susceptible mutations in Mycobacterium tuberculosis	Other	Unknown	Classification	Scientific Reports	10	1	5487	10.1038/s41598-020-62368-2	https://www.nature.com/articles/s41598-020-62368-2	"Tuberculosis (TB), an infectious disease caused by Mycobacterium tuberculosis (M.tb), causes highest number of deaths globally for any bacterial disease necessitating novel diagnosis and treatment strategies. High-throughput sequencing methods generate a large amount of data which could be exploited in determining multi-drug resistant (MDR-TB) associated mutations. The present work is a computational framework that uses artificial intelligence (AI) based machine learning (ML) approaches for predicting resistance in the genes rpoB, inhA, katG, pncA, gyrA and gyrB for the drugs rifampicin, isoniazid, pyrazinamide and fluoroquinolones. The single nucleotide variations were represented by several sequence and structural features that indicate the influence of mutations on the target protein coded by each gene. We used ML algorithms - naïve bayes, k nearest neighbor, support vector machine, and artificial neural network, to build the prediction models. The classification models had an average accuracy of 85% across all examined genes and were evaluated on an external unseen dataset to demonstrate their application. Further, molecular docking and molecular dynamics simulations were performed for wild type and predicted resistance causing mutant protein and anti-TB drug complexes to study their impact on the conformation of proteins to confirm the observed phenotype."																				
2020	"Joseph, Maxwell B."	Neural hierarchical models of ecological populations	Environmental	RNN	Regression	Ecology Letters	23	4	734-747	10.1111/ele.13462	https://onlinelibrary.wiley.com/doi/abs/10.1111/ele.13462	"Neural networks are increasingly being used in science to infer hidden dynamics of natural systems from noisy observations, a task typically handled by hierarchical models in ecology. This article describes a class of hierarchical models parameterised by neural networks – neural hierarchical models. The derivation of such models analogises the relationship between regression and neural networks. A case study is developed for a neural dynamic occupancy model of North American bird populations, trained on millions of detection/non-detection time series for hundreds of species, providing insights into colonisation and extinction at a continental scale. Flexible models are increasingly needed that scale to large data and represent ecological processes. Neural hierarchical models satisfy this need, providing a bridge between deep learning and ecological modelling that combines the function representation power of neural networks with the inferential capacity of hierarchical models."																				
2020	"Kattenborn, Teja; Eichel, Jana; Wiser, Susan; Burrows, Larry; Fassnacht, Fabian E.; Schmidtlein, Sebastian"	Convolutional Neural Networks accurately predict cover fractions of plant species and communities in Unmanned Aerial Vehicle imagery	Images	CNN	Classification	Remote Sensing in Ecology and Conservation	6	4	472-486	10.1002/rse2.146	https://onlinelibrary.wiley.com/doi/10.1002/rse2.146	"Unmanned Aerial Vehicles (UAV) greatly extended our possibilities to acquire high resolution remote sensing data for assessing the spatial distribution of species composition and vegetation characteristics. Yet, current pixel- or texture-based mapping approaches do not fully exploit the information content provided by the high spatial resolution. Here, to fully harness this spatial detail, we apply deep learning techniques, that is, Convolutional Neural Networks (CNNs), on regular tiles of UAV-orthoimagery (here 2–5 m) to identify the cover of target plant species and plant communities. The approach was tested with UAV-based orthomosaics and photogrammetric 3D information in three case studies, that is, (1) mapping tree species cover in primary forests, (2) mapping plant invasions by woody species into forests and open land and (3) mapping vegetation succession in a glacier foreland. All three case studies resulted in high predictive accuracies. The accuracy increased with increasing tile size (2–5 m) reflecting the increased spatial context captured by a tile. The inclusion of 3D information derived from the photogrammetric workflow did not significantly improve the models. We conclude that CNN are powerful in harnessing high resolution data acquired from UAV to map vegetation patterns. The study was based on low cost red, green, blue (RGB) sensors making the method accessible to a wide range of users. Combining UAV and CNN will provide tremendous opportunities for ecological applications"																				
2020	"Khodabandelou, Ghazaleh; Routhier, Etienne; Mozziconacci, Julien"	Genome annotation across species using deep convolutional neural networks	Molecular	CNN	Classification	PeerJ Computer Science	6		e278	10.7717/peerj-cs.278	https://peerj.com/articles/cs-278	"Application of deep neural network is a rapidly expanding field now reaching many disciplines including genomics. In particular, convolutional neural networks have been exploited for identifying the functional role of short genomic sequences. These approaches rely on gathering large sets of sequences with known functional role, extracting those sequences from whole-genome-annotations. These sets are then split into learning, test and validation sets in order to train the networks. While the obtained networks perform well on validation sets, they often perform poorly when applied on whole genomes in which the ratio of positive over negative examples can be very different than in the training set. We here address this issue by assessing the genome-wide performance of networks trained with sets exhibiting different ratios of positive to negative examples. As a case study, we use sequences encompassing gene starts from the RefGene database as positive examples and random genomic sequences as negative examples. We then demonstrate that models trained using data from one organism can be used to predict gene-start sites in a related species, when using training sets providing good genome-wide performance. This cross-species application of convolutional neural networks provides a new way to annotate any genome from existing high-quality annotations in a related reference species. It also provides a way to determine whether the sequence motifs recognised by chromatin-associated proteins in different species are conserved or not."																				
2020	"Kiskin, Ivan; Zilli, Davide; Li, Yunpeng; Sinka, Marianne; Willis, Kathy; Roberts, Stephen"	Bioacoustic detection with wavelet-conditioned convolutional neural networks	Sound	CNN	Classification	Neural Computing and Applications	32	4	915-927	10.1007/s00521-018-3626-7	https://link.springer.com/article/10.1007/s00521-018-3626-7	"Many real-world time series analysis problems are characterized by low signal-to-noise ratios and compounded by scarce data. Solutions to these types of problems often rely on handcrafted features extracted in the time or frequency domain. Recent high-profile advances in deep learning have improved performance across many application domains; however, they typically rely on large data sets that may not always be available. This paper presents an application of deep learning for acoustic event detection in a challenging, data-scarce, real-world problem. We show that convolutional neural networks (CNNs), operating on wavelet transformations of audio recordings, demonstrate superior performance over conventional classifiers that utilize handcrafted features. Our key result is that wavelet transformations offer a clear benefit over the more commonly used short-time Fourier transform. Furthermore, we show that features, handcrafted for a particular dataset, do not generalize well to other datasets. Conversely, CNNs trained on generic features are able to achieve comparable results across multiple datasets, along with outperforming human labellers. We present our results on the application of both detecting the presence of mosquitoes and the classification of bird species."																				
2020	"Kislov, Dmitry E.; Korznikov, Kirill A."	Automatic Windthrow Detection Using Very-High-Resolution Satellite Imagery and Deep Learning	Images	CNN	Classification	Remote Sensing	12	7	1145	10.3390/rs12071145	https://www.mdpi.com/2072-4292/12/7/1145	"Wind disturbances are significant phenomena in forest spatial structure and succession dynamics. They cause changes in biodiversity, impact on forest ecosystems at different spatial scales, and have a strong influence on economics and human beings. The reliable recognition and mapping of windthrow areas are of high importance from the perspective of forest management and nature conservation. Recent research in artificial intelligence and computer vision has demonstrated the incredible potential of neural networks in addressing image classification problems. The most efficient algorithms are based on artificial neural networks of nested and complex architecture (e.g., convolutional neural networks (CNNs)), which are usually referred to by a common term—deep learning. Deep learning provides powerful algorithms for the precise segmentation of remote sensing data. We developed an algorithm based on a U-Net-like CNN, which was trained to recognize windthrow areas in Kunashir Island, Russia. We used satellite imagery of very-high spatial resolution (0.5 m\/pixel) as source data. We performed a grid search among 216 parameter combinations defining different U-Net-like architectures. The best parameter combination allowed us to achieve an overall accuracy for recognition of windthrow sites of up to 94% for forested landscapes by coniferous and mixed coniferous forests. We found that the false-positive decisions of our algorithm correspond to either seashore logs, which may look similar to fallen tree trunks, or leafless forest stands. While the former can be rectified by applying a forest mask, the latter requires the usage of additional information, which is not always provided by satellite imagery."																				
2020	"Knyshov, Alexander; Hoang, Samantha; Weirauch, Christiane"	Pretrained Convolutional Neural Networks Perform Well in a Challenging Test Case: Identification of Plant Bugs (Hemiptera: Miridae) Using a Small Number of Training Images	Images	CNN	Classification	Insect Systematics and Diversity	5	2	3	10.1093/isd/ixab004	https://doi.org/10.1093/isd/ixab004	"Automated insect identification systems have been explored for more than two decades but have only recently started to take advantage of powerful and versatile convolutional neural networks (CNNs). While typical CNN applications still require large training image datasets with hundreds of images per taxon, pretrained CNNs recently have been shown to be highly accurate, while being trained on much smaller datasets. We here evaluate the performance of CNN-based machine learning approaches in identifying three curated species-level dorsal habitus datasets for Miridae, the plant bugs. Miridae are of economic importance, but species-level identifications are challenging and typically rely on information other than dorsal habitus (e.g., host plants, locality, genitalic structures). Each dataset contained 2–6 species and 126–246 images in total, with a mean of only 32 images per species for the most difficult dataset. We find that closely related species of plant bugs can be identified with 80–90% accuracy based on their dorsal habitus alone. The pretrained CNN performed 10–20% better than a taxon expert who had access to the same dorsal habitus images. We find that feature extraction protocols (selection and combination of blocks of CNN layers) impact identification accuracy much more than the classifying mechanism (support vector machine and deep neural network classifiers). While our network has much lower accuracy on photographs of live insects (62%), overall results confirm that a pretrained CNN can be straightforwardly adapted to collection-based images for a new taxonomic group and successfully extract relevant features to classify insect species."																				
2020	"Koumakis, Lefteris"	Deep learning models in genomics; are we there yet?	NA	NA	Review	Computational and Structural Biotechnology Journal	18		1466-1473	10.1016/j.csbj.2020.06.017	https://www.sciencedirect.com/science/article/pii/S2001037020303068	"With the evolution of biotechnology and the introduction of the high throughput sequencing, researchers have the ability to produce and analyze vast amounts of genomics data. Since genomics produce big data, most of the bioinformatics algorithms are based on machine learning methodologies, and lately deep learning, to identify patterns, make predictions and model the progression or treatment of a disease. Advances in deep learning created an unprecedented momentum in biomedical informatics and have given rise to new bioinformatics and computational biology research areas. It is evident that deep learning models can provide higher accuracies in specific tasks of genomics than the state of the art methodologies. Given the growing trend on the application of deep learning architectures in genomics research, in this mini review we outline the most prominent models, we highlight possible pitfalls and discuss future directions. We foresee deep learning accelerating changes in the area of genomics, especially for multi-scale and multimodal data analysis for precision medicine."																				
2020	"Le, Nguyen Quoc Khanh; Do, Duyen Thi; Hung, Truong Nguyen Khanh; Lam, Luu Ho Thanh; Huynh, Tuan-Tu; Nguyen, Ngan Thi Kim"	A Computational Framework Based on Ensemble Deep Neural Networks for Essential Genes Identification	Molecular	CNN	Classification	International Journal of Molecular Sciences	21	23	9070	10.3390/ijms21239070	https://www.mdpi.com/1422-0067/21/23/9070	"Essential genes contain key information of genomes that could be the key to a comprehensive understanding of life and evolution. Because of their importance, studies of essential genes have been considered a crucial problem in computational biology. Computational methods for identifying essential genes have become increasingly popular to reduce the cost and time-consumption of traditional experiments. A few models have addressed this problem, but performance is still not satisfactory because of high dimensional features and the use of traditional machine learning algorithms. Thus, there is a need to create a novel model to improve the predictive performance of this problem from DNA sequence features. This study took advantage of a natural language processing (NLP) model in learning biological sequences by treating them as natural language words. To learn the NLP features, a supervised learning model was consequentially employed by an ensemble deep neural network. Our proposed method could identify essential genes with sensitivity, specificity, accuracy, Matthews correlation coefficient (MCC), and area under the receiver operating characteristic curve (AUC) values of 60.2%, 84.6%, 76.3%, 0.449, and 0.814, respectively. The overall performance outperformed the single models without ensemble, as well as the state-of-the-art predictors on the same benchmark dataset. This indicated the effectiveness of the proposed method in determining essential genes, in particular, and other sequencing problems, in general."																				
2020	"Le, Van-Linh; Beurton-Aimar, Marie; Zemmari, Akka; Marie, Alexia; Parisey, Nicolas"	Automated landmarking for insects morphometric analysis using deep neural networks	Images	CNN	Regression	Ecological Informatics	60		101175	10.1016/j.ecoinf.2020.101175	https://www.sciencedirect.com/science/article/pii/S1574954120301254	"Landmarks are one of the important concepts in morphometry analysis. They are anatomical points that can be located consistently (e.g., corner of the eyes) and used to establish correspondence or divergence among morphologies of biological or non-biological specimens. Currently, the landmarks are mostly positioned manually by entomologists on numerical images. In this work, we propose a method to automatically predict the landmarks on entomological images based on Deep Learning methods, more specifically by using Convolutional Neural Network (CNN). We propose a CNN architecture, EB-Net, which is built in a modular way the concept of “Elementary Blocks”, each made up of usual layer types of CNN. After using a custom data augmentation procedure, the network has been trained and tested on a data set of different anatomical part of carabids (pronotum, head and elytra). In this numerical experiment, we have generated two strategies to evaluate the network and to improve the obtained results: training from scratch or applying a fine-tuning step. The predicted landmark coordinates have been compared to the coordinates of the manual landmarks provided by the biologists. The statistical analysis of the distances between predicted and manual coordinates has shown that our predictions can replace efficiently manual landmarking and allows to propose automatization of such operation."																				
2020	"Leuchtenberger, Alina F; Crotty, Stephen M; Drucks, Tamara; Schmidt, Heiko A; Burgstaller-Muehlbacher, Sebastian; von Haeseler, Arndt"	Distinguishing Felsenstein zone from Farris zone using neural networks	Molecular	DNN	Classification	Molecular Biology and Evolution	37	12	3632-3641	10.1093/molbev/msaa164	https://doi.org/10.1093/molbev/msaa164	"Maximum likelihood and maximum parsimony are two key methods for phylogenetic tree reconstruction. Under certain conditions, each of these two methods can perform more or less efficiently, resulting in unresolved or disputed phylogenies. We show that a neural network can distinguish between four-taxon alignments that were evolved under conditions susceptible to either long-branch attraction or long-branch repulsion. When likelihood and parsimony methods are discordant, the neural network can provide insight as to which tree reconstruction method is best suited to the alignment. When applied to the contentious case of Strepsiptera evolution, our method shows robust support for the current scientific view, that is, it places Strepsiptera with beetles, distant from flies."																				
2020	"Li, Jiangtao; Zhou, Huiling; Wang, Zhongming; Jia, Qingxuan"	Multi-scale detection of stored-grain insects for intelligent monitoring	Images	CNN	"Classification, Regression"	Computers and Electronics in Agriculture	168		105114	10.1016/j.compag.2019.105114	https://linkinghub.elsevier.com/retrieve/pii/S0168169919316977	"In order to implement intelligent monitoring for insects in grain warehouses, a Multi-Scale Insect Detector (MSI_Detector) was developed by applying deep convolutional neural networks. It solved the problem existing in common anchor-based insect detection methods whose performance decrease sharply as insects become smaller. We built a feature pyramid network to extract insect image features with different spatial resolutions and semantic information, and tiled anchors with reasonable scales on each pyramid level to handle different scales of insects well. Besides, we altered the classification and box regression subnets to residual structure in order to improve the detection performance, and proposed the recombined loss function to balance the weights of easy and hard samples during training for both insect classification and box regression tasks. Excellent results for the detection of adults of 10 species 6 genera of common stored-grain insects were achieved, the mean Average Precision reached 94.77%, which demonstrated the robustness to insect scales."																				
2020	"Li, Jinquan; Xie, Shanshan; Chen, Zhe; Liu, Hongwen; Kang, Jia; Fan, Zixuan; Li, Wenjie"	A Shallow Convolutional Neural Network for Apple Classification	Images	CNN	Classification	IEEE Access	8		111683-111692	10.1109/ACCESS.2020.3002882	https://ieeexplore.ieee.org/document/9118928	"In the automatic apple sorting task, it is necessary to automatically classify certain apple species. A shallow convolutional neural network (CNN) architecture is proposed for this purpose. After collecting a certain number of apple images and labelling them, training data is obtained through a series of data augmentation operations, and then training and parameter optimization are carried out through the Caffe framework. The feasibility of the method is verified by experiments which are divided into two cases. In the case of no occlusion, the classification accuracy of apple images reaches approximately 92% in our test set. Besides, block voting is used to aid the proposed method and a good result can be achieved in our test set in the case of part occlusion caused by branches and leaves, rotten spots, and other kinds of apples. The proposed shallow network is characterized by a small number of parameters and shows resistance to overfitting with a limited dataset. Such a network presents an alternative for classification related tasks in smart visual Internet of Things and brings attention to reducing the complexity of deep neural networks while maintaining their strength."																				
2020	"Li, Jiwei; Knapp, David E.; Fabina, Nicholas S.; Kennedy, Emma V.; Larsen, Kirk; Lyons, Mitchell B.; Murray, Nicholas J.; Phinn, Stuart R.; Roelfsema, Chris M.; Asner, Gregory P."	A global coral reef probability map generated using convolutional neural networks	Images	CNN	Regression	Coral Reefs	39	6	1805-1815	10.1007/s00338-020-02005-6	http://link.springer.com/10.1007/s00338-020-02005-6	"Coral reef research and management efforts can be improved when supported by reef maps providing local-scale details across global extents. However, such maps are difficult to generate due to the broad geographic range of coral reefs, the complexities of relating satellite imagery to geomorphic or ecological realities, and other challenges. However, reef extent maps are one of the most commonly used and most valuable data products from the perspective of reef scientists and managers. Here, we used convolutional neural networks to generate a globally consistent coral reef probability map—a probabilistic estimate of the geospatial extent of reef ecosystems—to facilitate scientific, conservation, and management efforts. We combined a global mosaic of high spatial resolution Planet Dove satellite imagery with regional Millennium Coral Reef Mapping Project reef extents to build training, validation, and application datasets. These datasets trained our reef extent prediction model, a neural network with a dense-unet architecture followed by a random forest classifier, which was used to produce a global coral reef probability map. Based on this probability map, we generated a global coral reef extent map from a 60% threshold of reef probability (reef: probability ≥ 60%, non-reef: probability < 60%). Our findings provide a proof-of-concept method for global reef extent estimates using a consistent and readily updateable methodology that leverages modern deep learning approaches to support downstream users. These maps are openly-available through the Allen Coral Atlas."																				
2020	"Li, Wang; Buitenwerf, Robert; Munk, Michael; Bøcher, Peder Klith; Svenning, Jens-Christian"	Deep-learning based high-resolution mapping shows woody vegetation densification in greater Maasai Mara ecosystem	"Images, Other"	DNN	Regression	Remote Sensing of Environment	247		111953	10.1016/j.rse.2020.111953	https://linkinghub.elsevier.com/retrieve/pii/S0034425720303230	"The Greater Maasai Mara Ecosystem (GMME) in Kenya is an iconic savanna ecosystem of high importance as natural and cultural heritage, notably by including the largest remaining seasonal migration of African ungulates and the semi-nomadic pastoralist Maasai culture. Comprehensive mapping of vegetation distribution and dynamics in GMME is important for understanding ecosystem changes across time and space since recent reports suggest dramatic declines in wildlife populations alongside troubling reports of grassland conversion to cropland and habitat fragmentation due to increasing small-holder fencing. Here, we present the first comprehensive vegetation map of GMME at high (10-m) spatial resolution. The map consists of nine key vegetation cover types (VCTs), which were derived in a two-step process integrating data from high-resolution WorldView-3 images (1.2-m) and Sentinel-2 images using a deep-learning workflow. We evaluate the role of anthropogenic, topographic, and climatic factors in affecting the fractional cover of the identified VCTs in 2017 and their MODIS-derived browning/greening rates in the preceding 17 years at 250-m resolution. Results show that most VCTs showed a preceding greening trend in the protected land. In contrast, the semi- and unprotected land showed a general preceding greening trend in the woody-dominated cover types, while they exhibited browning trends in grass-dominated cover types. These results suggest that woody vegetation densification may be happening across much of the GMME, alongside vegetation declines within the non-woody covers in the semi- and unprotected lands. Greening and potential woody densification in GMME is positively correlated with mean annual precipitation and negatively correlated with anthropogenic pressure. Increasing woody densification across the entire GMME in the future would replace high-quality grass cover and pose a risk to the maintenance of the region's rich savanna megafauna, thus pointing to a need for further investigation using alternative data sources. The increasing availability of high-resolution remote sensing and efficient approaches for vegetation mapping will play a crucial role in monitoring conservation effectiveness as well as ecosystem dynamics due to pressures such as climate change"																				
2020	"Li, Wang; Niu, Zheng; Shang, Rong; Qin, Yuchu; Wang, Li; Chen, Hanyue"	"High-resolution mapping of forest canopy height using machine learning by coupling ICESat-2 LiDAR with Sentinel-1, Sentinel-2 and Landsat-8 data"	"Images, Other"	DNN	Regression	International Journal of Applied Earth Observation and Geoinformation	92		102163	10.1016/j.jag.2020.102163	https://linkinghub.elsevier.com/retrieve/pii/S030324342030026X	"Forest canopy height is an important indicator of forest carbon storage, productivity, and biodiversity. The present study showed the first attempt to develop a machine-learning workflow to map the spatial pattern of the forest canopy height in a mountainous region in the northeast China by coupling the recently available canopy height (Hcanopy) footprint product from ICESat-2 with the Sentinel-1 and Sentinel-2 satellite data. The ICESat-2 Hcanopy was initially validated by the high-resolution canopy height from airborne LiDAR data at different spatial scales. Performance comparisons were conducted between two machine-learning models – deep learning (DL) model and random forest (RF) model, and between the Sentinel and Landsat-8 satellites. Results showed that the ICESat-2 Hcanopy showed the highest correlation with the airborne LiDAR canopy height at a spatial scale of 250_m with a Pearson’s correlation coefficient (R) of 0.82 and a mean bias of -1.46_m, providing important evidence on the reliability of the ICESat-2 vegetation height product from the case in China’s forest. Both DL and RF models obtained satisfactory accuracy on the upscaling of ICESat-2 Hcanopy assisted by Sentinel satellite co-variables with an R-value between the observed and predicted Hcanopy equalling 0.78 and 0.68, respectively. Compared to Sentinel satellites, Landsat-8 showed relatively weaker performance in Hcanopy prediction, suggesting that the addition of the backscattering coefficients from Sentinel-1 and the red-edge related variables from Sentinel-2 could positively contribute to the prediction of forest canopy height. To our knowledge, few studies have demonstrated large-scale vegetation height mapping in a resolution ≤ 250_m based on the newly available satellites (ICESat-2, Sentinel-1 and Sentinel-2) and DL regression model, particularly in the forest areas in China. Thus, the present work provided a timely and important supplementary to the applications of these new earth observation tools"																				
2020	"Li, Yanfen; Wang, Hanxiang; Dang, L. Minh; Sadeghi-Niaraki, Abolghasem; Moon, Hyeonjoon"	Crop pest recognition in natural scenes using convolutional neural networks	Images	CNN	Classification	Computers and Electronics in Agriculture	169		105174	10.1016/j.compag.2019.105174	https://www.sciencedirect.com/science/article/pii/S0168169919313638	"Crop diseases and insect pests are major agricultural problems worldwide, because the severity and extent of their occurrence causes significant crop losses. In addition, traditional crop pests recognition methods are limited, ineffective, and time-consuming due to the manual selection of the useful feature sets. This paper introduces a crop pest recognition method that accurately recognizes ten common species of crop pests by applying several deep convolutional neural networks (CNNs). The main contributions of this paper are (1) a manually collected and validated crop pest dataset is described and shared; (2) a fine-tuned GoogLeNet model is proposed to deal with the complicated backgrounds presented by farmland scenes, with pest classification results better than the original model; and (3) the fine-tuned GoogLeNet model obtains an improvement of 6.22% compared to the state-of-the-art method. As a result, the proposed model has the potential to be applied in real-world applications and further motivate research on crop disease identification."																				
2020	"Li, Zhenbo; Guo, Ruohao; Li, Meng; Chen, Yaru; Li, Guangyao"	A review of computer vision technologies for plant phenotyping	NA	NA	Review	Computers and Electronics in Agriculture	176		105672	10.1016/j.compag.2020.105672	https://www.sciencedirect.com/science/article/pii/S0168169920307511	"Plant phenotype plays an important role in genetics, botany, and agronomy, while the currently popular methods for phenotypic trait measurement have some limitations in aspects of cost, performance, and space-time coverage. With the rapid development of imaging technology, computing power, and algorithms, computer vision has thoroughly revolutionized the plant phenotyping and is now a major tool for phenotypic analysis. Based on the above reasons, researchers are devoted to developing image-based plant phenotyping methods as a complementary or even alternative to the manual measurement. However, the use of computer vision technology to analyze plant phenotypic traits can be affected by many factors such as research environment, imaging system, research object, feature extraction, model selection, and so on. Currently, there is no review paper to compare and analyze these methods thoroughly. Therefore, this review introduces the typical plant phenotyping methods based on computer vision in detail, with their principle, applicable range, results, and comparison. This paper extensively reviews 200+ papers of plant phenotyping in the light of its technical evolution, spanning over twenty years (from 2000 to 2020). A number of topics have been covered in this paper, including imaging technologies, plant datasets, and state-of-the-art phenotyping methods. In this review, we categorize the plant phenotyping into two main groups: plant organ phenotyping and whole-plant phenotyping. Furthermore, for each group, we analyze each research of these groups and discuss the limitations of the current approaches and future research directions."																				
2020	"Liang, Qiaoxing; Bible, Paul W; Liu, Yu; Zou, Bin; Wei, Lai"	DeepMicrobes: taxonomic classification for metagenomics with deep learning	Molecular	RNN	Classification	NAR Genomics and Bioinformatics	2	1	lqaa009	10.1093/nargab/lqaa009	https://academic.oup.com/nargab/article/2/1/lqaa009/5740226?login=false	"Large-scale metagenomic assemblies have uncovered thousands of new species greatly expanding the known diversity of microbiomes in specific habitats. To investigate the roles of these uncultured species in human health or the environment, researchers need to incorporate their genome assemblies into a reference database for taxonomic classification. However, this procedure is hindered by the lack of a well-curated taxonomic tree for newly discovered species, which is required by current metagenomics tools. Here we report DeepMicrobes, a deep learning-based computational framework for taxonomic classification that allows researchers to bypass this limitation. We show the advantage of DeepMicrobes over state-of-the-art tools in species and genus identification and comparable accuracy in abundance estimation. We trained DeepMicrobes on genomes reconstructed from gut microbiomes and discovered potential novel signatures in inflammatory bowel diseases. DeepMicrobes facilitates effective investigations into the uncharacterized roles of metagenomic species."																				
2020	"Lins, Elison Alfeu; Rodriguez, João Pedro Mazuco; Scoloski, Sandy Ismael; Pivato, Juliana; Lima, Marília Balotin; Fernandes, José Maurício Cunha; da Silva Pereira, Paulo Roberto Valle; Lau, Douglas; Rieder, Rafael"	A method for counting and classifying aphids using computer vision	Images	CNN	"Classification, Regression"	Computers and Electronics in Agriculture	169		105200	10.1016/j.compag.2019.105200	https://linkinghub.elsevier.com/retrieve/pii/S0168169919306039	"Aphids are insects that attack crops and cause damage directly, by consuming the sap of plants, and indirectly, by vectoring microorganisms that can cause diseases. Cereal crops are hosts for many aphid species, including Rhopalosiphum padi (an economically important aphid species). Recording and classifying aphids are necessary for evaluating and predicting crop damage. Thus, serving as a basis for decision making on the utilization of control measures. It can also be useful to evaluate plant resistance to aphids. Traditionally, the recording process is manual and depends on magnification and well-trained staff. The manual counting is also a time-consuming process and susceptible to errors. With this in mind, this paper presents a method and software to automate the counting and classification of Rhopalosiphum padi using image processing, computer vision, and machine learning methods. The text also presents a comparison of manually counts from experts and values obtained with the software, considering 40 samples. The results showed strong positive correlation in counting and classification ( = 0.92579) and measurement (r = 0.9799). Concluding, the software proved to be reliable and useful to aphid population monitoring studies"																				
2020	"Liu, Li; Ouyang, Wanli; Wang, Xiaogang; Fieguth, Paul; Chen, Jie; Liu, Xinwang; Pietikäinen, Matti"	Deep Learning for Generic Object Detection: A Survey	NA	NA	Review	International Journal of Computer Vision	128	2	261-318	10.1007/s11263-019-01247-4	https://doi.org/10.1007/s11263-019-01247-4	"Object detection, one of the most fundamental and challenging problems in computer vision, seeks to locate object instances from a large number of predefined categories in natural images. Deep learning techniques have emerged as a powerful strategy for learning feature representations directly from data and have led to remarkable breakthroughs in the field of generic object detection. Given this period of rapid evolution, the goal of this paper is to provide a comprehensive survey of the recent achievements in this field brought about by deep learning techniques. More than 300 research contributions are included in this survey, covering many aspects of generic object detection: detection frameworks, object feature representation, object proposal generation, context modeling, training strategies, and evaluation metrics. We finish the survey by identifying promising directions for future research."																				
2020	"Liu, Liu; Xie, Chengjun; Wang, Rujing; Yang, Po; Sudirman, Sud; Zhang, Jie; Li, Rui; Wang, Fangyuan"	Deep Learning based Automatic Multi-Class Wild Pest Monitoring Approach using Hybrid Global and Local Activated Features	Images	CNN	Classification	IEEE Transactions on Industrial Informatics			1-Jan	10.1109/TII.2020.2995208	https://ieeexplore.ieee.org/document/9095236/	"Specialized control of pests and diseases have been a high-priority issue for the agriculture industry in many countries. On account of automation and cost effectiveness, image analytic pest recognition systems are widely utilized in practical crops prevention applications. But due to powerless hand-crafted features, current image analytic approaches achieve low accuracy and poor robustness in practical large-scale multiclass pest detection and recognition. To tackle this problem, this article proposes a novel deep learning based automatic approach using hybrid and local activated features for pest monitoring. In the presented method, we exploit the global information from feature maps to build our global activated feature pyramid network to extract pests' highly discriminative features across various scales over both depth and position levels. It makes changes of depth or spatial sensitive features in pest images more visible during downsampling. Next, an improved pest localization module named local activated region proposal network is proposed to find the precise pest objects positions by augmenting contextualized and attentional information for feature completion and enhancement in local level. The approach is evaluated on our seven-year large-scale pest data-set containing 88.6 K images (16 types of pests) with 582.1 K manually labeled pest objects. The experimental results show that our solution performs over 75.03% mean average precision (mAP) in industrial circumstances, which outweighs two other state-of-the-art methods: Faster R-CNN with mAP up to 70% and feature pyramid network mAP up to 72%."																				
2020	"Liu, Xiaokang; Song, Haijun"	Automatic identification of fossils and abiotic grains during carbonate microfacies analysis using deep convolutional neural networks	Images	CNN	Classification	Sedimentary Geology	410		105790	10.1016/j.sedgeo.2020.105790	https://linkinghub.elsevier.com/retrieve/pii/S0037073820302050	"Petrographic analysis based on microfacies identification in thin sections is widely used in sedimentary environment interpretation and paleoecological reconstruction. Fossil recognition from microfacies is an essential procedure for petrographers to complete this task. Distinguishing the morphological and microstructural diversity of skeletal fragments requires extensive prior knowledge of fossil morphotypes in microfacies and long training sessions under the microscope. This requirement engenders certain challenges for sedimentologists and paleontologists, especially novices. However, a machine classifier can help address this challenge. In this study, we collected a microfacies image dataset comprising both public data from 1133 references and our own materials (including a total of 30,815 images of 22 fossil and abiotic grain groups). We employed a high-performance workstation to implement four classic deep convolutional neural networks, which have proven to be highly efficient in computer vision. Our framework uses a transfer learning technique, which reuses the pre-trained parameters that are trained on a larger ImageNet dataset as initialization for the network to achieve high accuracy with low computing costs. We obtained up to 95% of the top one and 99% of the top three test accuracies in the Inception ResNet v2 architecture. The machine classifier exhibited 0.99 precision on minerals such as dolomite and pyrite. Although it had some difficulty on samples having similar morphologies, such as bivalve, brachiopod, and ostracod, it nevertheless obtained 0.88 precision. Our machine learning framework demonstrates high accuracy with reproducibility and bias avoidance that is comparable to those of human classifiers. Its application can thus eliminate much of the tedious, manually intensive efforts by human experts conducting routine identification."																				
2020	"López-Cortés, Xaviera Alejandra; Matamala, Felipe; Maldonado, Carlos; Mora-Poblete, Freddy; Scapim, Carlos Alberto"	A Deep Learning Approach to Population Structure Inference in Inbred Lines of Maize	Molecular	VAE	Modeling	Frontiers in Genetics	11			10.3389/fgene.2020.543459	https://www.frontiersin.org/article/10.3389/fgene.2020.543459	"Analysis of population genetic variation and structure is a common practice for genome-wide studies, including association mapping, ecology, and evolution studies in several crop species. In this study, machine learning (ML) clustering methods, K-means (KM), and hierarchical clustering (HC), in combination with non-linear and linear dimensionality reduction techniques, deep autoencoder (DeepAE) and principal component analysis (PCA), were used to infer population structure and individual assignment of maize inbred lines, i.e., dent field corn (n = 97) and popcorn (n = 86). The results revealed that the HC method in combination with DeepAE-based data preprocessing (DeepAE-HC) was the most effective method to assign individuals to clusters (with 96% of correct individual assignments), whereas DeepAE-KM, PCA-HC, and PCA-KM were assigned correctly 92, 89, and 81% of the lines, respectively. These findings were consistent with both Silhouette Coefficient (SC) and Davies–Bouldin validation indexes. Notably, DeepAE-HC also had better accuracy than the Bayesian clustering method implemented in InStruct. The results of this study showed that deep learning (DL)-based dimensional reduction combined with ML clustering methods is a useful tool to determine genetically differentiated groups and to assign individuals into subpopulations in genome-wide studies without having to consider previous genetic assumptions."																				
2020	"Lopez-Vazquez, Vanesa; Lopez-Guede, Jose Manuel; Marini, Simone; Fanelli, Emanuela; Johnsen, Espen; Aguzzi, Jacopo"	Video Image Enhancement and Machine Learning Pipeline for Underwater Animal Detection and Classification at Cabled Observatories	Video	"DNN, CNN"	Classification	Sensors	20	3	726	10.3390/s20030726	https://www.mdpi.com/1424-8220/20/3/726	"An understanding of marine ecosystems and their biodiversity is relevant to sustainable use of the goods and services they offer. Since marine areas host complex ecosystems, it is important to develop spatially widespread monitoring networks capable of providing large amounts of multiparametric information, encompassing both biotic and abiotic variables, and describing the ecological dynamics of the observed species. In this context, imaging devices are valuable tools that complement other biological and oceanographic monitoring devices. Nevertheless, large amounts of images or movies cannot all be manually processed, and autonomous routines for recognizing the relevant content, classification, and tagging are urgently needed. In this work, we propose a pipeline for the analysis of visual data that integrates video/image annotation tools for defining, training, and validation of datasets with video/image enhancement and machine and deep learning approaches. Such a pipeline is required to achieve good performance in the recognition and classification tasks of mobile and sessile megafauna, in order to obtain integrated information on spatial distribution and temporal dynamics. A prototype implementation of the analysis pipeline is provided in the context of deep-sea videos taken by one of the fixed cameras at the LoVe Ocean Observatory network of Lofoten Islands (Norway) at 260 m depth, in the Barents Sea, which has shown good classification results on an independent test dataset with an accuracy value of 76.18% and an area under the curve (AUC) value of 87.59%."																				
2020	"Maekawa, Takuya; Ohara, Kazuya; Zhang, Yizhe; Fukutomi, Matasaburo; Matsumoto, Sakiko; Matsumura, Kentarou; Shidara, Hisashi; Yamazaki, Shuhei J.; Fujisawa, Ryusuke; Ide, Kaoru; Nagaya, Naohisa; Yamazaki, Koji; Koike, Shinsuke; Miyatake, Takahisa; Kimura, Koutarou D.; Ogawa, Hiroto; Takahashi, Susumu; Yoda, Ken"	Deep learning-assisted comparative analysis of animal trajectories with DeepHL	Temporal	CNN	Regression	Nature Communications	11	1	5316	10.1038/s41467-020-19105-0	http://www.nature.com/articles/s41467-020-19105-0	"A comparative analysis of animal behavior (e.g., male vs. female groups) has been widely used to elucidate behavior specific to one group since pre-Darwinian times. However, big data generated by new sensing technologies, e.g., GPS, makes it difficult for them to contrast group differences manually. This study introduces DeepHL, a deep learning-assisted platform for the comparative analysis of animal movement data, i.e., trajectories. This software uses a deep neural network based on an attention mechanism to automatically detect segments in trajectories that are characteristic of one group. It then highlights these segments in visualized trajectories, enabling biologists to focus on these segments, and helps them reveal the underlying meaning of the highlighted segments to facilitate formulating new hypotheses. We tested the platform on a variety of trajectories of worms, insects, mice, bears, and seabirds across a scale from millimeters to hundreds of kilometers, revealing new movement features of these animals."																				
2020	"Maglietta, Rosalia; renò, Vito; Caccioppoli, Rocco; Seller, Emanuele; Bellomo, Stefano; Santacesaria, Francesca Cornelia; Colella, Roberto; Cipriano, Giulia; Stella, Ettore; Hartman, Karin; Fanizza, Carmelo; Dimauro, Giovanni; Carlucci, Roberto"	Convolutional Neural Networks for Risso’s Dolphins Identification	Images	CNN	Classification	IEEE Access	8		80195-80206	10.1109/ACCESS.2020.2990427	https://ieeexplore.ieee.org/document/9078758	"Photo-identification is one of the best practices to estimate the abundance of cetaceans and, as such, it can help to obtain the biological information necessary to decision-making and actions to preserve the marine environment and its biodiversity. The Risso's dolphin is one of the least-known cetacean species on a global scale, and the distinctive scars on its dorsal fin proved to be extremely useful to photo-identify single individuals. The main novelty of this paper is the development of a new method based on deep learning, called Neural Network Pool (NNPool), and specifically devoted to the photo-identification of Risso's dolphins. This new method also includes the unique function of recognizing unknown vs known dolphins in large datasets with no interaction by the user. Moreover, the new version of DolFin catalogue, collecting Risso's dolphins data and photos acquired between 2013-2018 in the Northern Ionian Sea (Central-eastern Mediterranean Sea), is presented and used here to carry out the experiments. Results have been validated using a further data set, containing new images of Risso's dolphins from the Northern Ionian Sea and the Azores, acquired in 2019. The performance of the NNPool appears satisfying and increases proportionally to the number of images available, thus highlighting the importance of building large-scale data set for the application at hand."																				
2020	"Måløy, Håkon"	EchoBERT: A Transformer-Based Approach for Behavior Detection in Echograms	Sound	Other	Classification	IEEE Access	8		218372-218385	10.1109/ACCESS.2020.3042337	https://ieeexplore.ieee.org/document/9281296	"Monitoring fish welfare has become increasingly important for salmon farmers. Current approaches require manual labor and physical inspection or interpretation of video. Echo sounders make real-time monitoring of the entire fish population over time possible. However, current approaches for automatic interpretation of echograms mainly focus on species classification and therefore fail to appropriately encode the spatiotemporal properties contained within the data. Other approaches are primarily aimed at the feeding process and require a human-in-the-loop. Transformer-based approaches have been shown to better handle long sequences than Long Short-Term Memory networks in recent Natural Language Processing research. We therefore introduce EchoBERT - Echo Bidirectional Encoder Representation Transformer, a transformer-based approach for behavior detection in farmed Atlantic salmon (Salmo salar, Salmonidae), using the spatiotemporal properties contained in echograms. The model interprets the spatiotemporal dynamics of echograms through attention mechanisms to classify fish behavior. We compare EchoBERT to a traditional sequence modeling approach on the task of detecting behavior indicative of pancreas disease in a six-fold cross-validation study using data from 6 distinct farming cages. We show that EchoBERT shows a strong correlation between model predictions and true labels, indicated by a Matthew's Correlation Coefficient score of 0.694 ± 0.178 using an ensemble approach, compared to 0.626 ± 0.084 for traditional sequence models. We also find that EchoBERT is capable of detecting disease indicators over a month prior to detection using standard procedures. Our results show that EchoBERT has high potential for automatic behavior detection through unintrusive methods suitable for applications in aquaculture. The source code is available at: https://gitlab.com/hakonma/echobert."																				
2020	"Marchant, Ross; Tetard, Martin; Pratiwi, Adnya; Adebayo, Michael; de Garidel-Thoron, Thibault"	Automated analysis of foraminifera fossil records by image classification using a convolutional neural network	Images	CNN	Classification	Journal of Micropalaeontology	39	2	183-202	10.5194/jm-39-183-2020	https://jm.copernicus.org/articles/39/183/2020/	"Manual identification of foraminiferal morphospecies or morphotypes under stereo microscopes is time consuming for micropalaeontologists and not possible for nonspecialists. Therefore, a long-term goal has been to automate this process to improve its efficiency and repeatability. Recent advances in computation hardware have seen deep convolutional neural networks emerge as the state-of-the-art technique for image-based automated classification. Here, we describe a method for classifying large foraminifera image sets using convolutional neural networks. Construction of the classifier is demonstrated on the publicly available Endless Forams image set with a best accuracy of approximately 90&thinsp;%. A complete automatic analysis is performed for benthic species dated to the last deglacial period for a sediment core from the north-eastern Pacific and for planktonic species dated from the present until 180&thinsp;000 years ago in a core from the western Pacific warm pool. The relative abundances from automatic counting based on more than 500&thinsp;000 images compare favourably with manual counting, showing the same signal dynamics. Our workflow opens the way to automated palaeoceanographic reconstruction based on computer image analysis and is freely available for use."																				
2020	"Marre, Guilhem; De Almeida Braga, Cedric; Ienco, Dino; Luque, Sandra; Holon, Florian; Deter, Julie"	Deep convolutional neural networks to monitor coralligenous reefs: Operationalizing biodiversity and ecological assessment	Images	CNN	Classification	Ecological Informatics	59		101110	10.1016/j.ecoinf.2020.101110	https://www.sciencedirect.com/science/article/pii/S1574954120300601	"Monitoring the ecological status of natural habitats is crucial to the conservation process, as it enables the implementation of efficient conservation policies. Nowadays, it is increasingly possible to automate species identification, given the availability of very large image databases and state-of-the-art computational power which makes the training of automated machine learning-based classification models an increasingly viable tool for monitoring marine habitats. Coralligenous reefs are an underwater habitat of particular importance, found in the Mediterranean. This habitat is of a similar biocomplexity to coral reefs. They have been monitored in French waters since 2010 using manually annotated photo quadrats (RECOR monitoring network). Based on the large database of annotations accumulated therein, we have trained convolutional neural networks to automatically recognise coralligenous species using the data gathered from photo quadrats. Previous studies conducted on similar habitats performed well, but were only able to consider a limited number of classes, resulting in a very coarse description of these often-complex habitats. We therefore designed a custom network based on off-the-shelf architectures which is able to discriminate between 61 classes with 72.59% accuracy. Our results showed that confusion errors were for the most part taxonomically coherent, showing accuracy performances of 84.47% when the task was simplified to 15 major categories, thereby outperforming the human accuracy previously recorded in a similar study. In light of this, we built a semi-automated tool to reject unsure results and reduce error risk, for when a higher level of accuracy is required. Finally, we used our model to assess the biodiversity and ecological status of coralligenous reefs with the Coralligenous Assemblage Index (CAI) and the Shannon Index. Our results showed that whilst the prediction of the CAI was only moderately accurate (pearson correlation between observed and predicted CAI = 0.61), the prediction of Shannon Index was more accurate (pearson correlation = 0.74). In conclusion, it will be argued that the approach outlined by this study offers a cost and time-effective tool for the analysis of coralligenous assemblages which is suitable for integration into a large-scale monitoring network of this habitat."																				
2020	"Marsot, Mathieu; Mei, Jiangqiang; Shan, Xiaocai; Ye, Liyong; Feng, Peng; Yan, Xuejun; Li, Chenfan; Zhao, Yifan"	An adaptive pig face recognition approach using Convolutional Neural Networks	Images	CNN	Classification	Computers and Electronics in Agriculture	173		105386	10.1016/j.compag.2020.105386	https://www.sciencedirect.com/science/article/pii/S0168169920300673	"The evolution of agriculture towards intensive farming leads to an increasing demand for animal identification associated with high traceability, driven by the need for quality control and welfare management in agricultural animals. Automatic identification of individual animals is an important step to achieve individualised care in terms of disease detection and control, and improvement of the food quality. For example, as feeding patterns can differ amongst pigs in the same pen, even in homogenous groups, automatic registration shows the most potential when applied to an individual pig. In the EU for instance, this capability is required for certification purposes. Although the RFID technology has been gradually developed and widely applied for this task, chip implanting might still be time-consuming and costly for current practical applications. In this paper, a novel framework composed of computer vision algorithms, machine learning and deep learning techniques is proposed to offer a relatively low-cost and scalable solution of pig recognition. Firstly, pig faces and eyes are detected automatically by two Haar feature-based cascade classifiers and one shallow convolutional neural network to extra high-quality images. Secondly, face recognition is performed by employing a deep convolutional neural network. Additionally, class activation maps generated by grad-CAM and saliency maps are utilised to visually understand how the discriminating parameters have been learned by the neural network. By applying the proposed approach on 10 randomly selected pigs filmed in farm condition, the proposed method demonstrates the superior performance against the state-of-art method with an accuracy of 83% over 320 testing images. The outcome of this study will facilitate the real-application of AI-based animal identification in swine production."																				
2020	"Mathis, Mackenzie Weygandt; Mathis, Alexander"	Deep learning tools for the measurement of animal behavior in neuroscience	NA	NA	Review	Current Opinion in Neurobiology	60		11-Jan	10.1016/j.conb.2019.10.008	https://linkinghub.elsevier.com/retrieve/pii/S0959438819301151	"Recent advances in computer vision have made accurate, fast and robust measurement of animal behavior a reality. In the past years powerful tools specifically designed to aid the measurement of behavior have come to fruition. Here we discuss how capturing the postures of animals — pose estimation - has been rapidly advancing with new deep learning methods. While challenges still remain, we envision that the fast-paced development of new deep learning tools will rapidly change the landscape of realizable real-world neuroscience."																				
2020	"McClure, Eva C.; Sievers, Michael; Brown, Christopher J.; Buelow, Christina A.; Ditria, Ellen M.; Hayes, Matthew A.; Pearson, Ryan M.; Tulloch, Vivitskaia J.D.; Unsworth, Richard K.F.; Connolly, Rod M."	Artificial Intelligence Meets Citizen Science to Supercharge Ecological Monitoring	NA	NA	Review	Patterns	1	7	100109	10.1016/j.patter.2020.100109	https://linkinghub.elsevier.com/retrieve/pii/S2666389920301434	"The Bigger Picture:Citizen science and artificial intelligence (AI) are often used in isolation for ecological monitoring, but their integration likely has emergent benefits for management and scientific inquiry. We explore the complementarity of citizen science and AI for ecological monitoring, highlighting key opportunities and challenges. We show that strategic integration of citizen science and AI can improve outcomes for conservation activities. For example, coupling the public engagement benefits of citizen science with the advanced analytical capabilities of AI can increase multi-stakeholder accord on issues of public and scientific interest. Furthermore, both techniques speed up data collection and processing compared with conventional scientific techniques, suggesting that their integration can fast-track monitoring and conservation actions. We present key project attributes that will assist project managers in prioritizing the resources needed to implement citizen science, AI, or preferably both. Summary: The development and uptake of citizen science and artificial intelligence (AI) techniques for ecological monitoring is increasing rapidly. Citizen science and AI allow scientists to create and process larger volumes of data than possible with conventional methods. However, managers of large ecological monitoring projects have little guidance on whether citizen science, AI, or both, best suit their resource capacity and objectives. To highlight the benefits of integrating the two techniques and guide future implementation by managers, we explore the opportunities, challenges, and complementarities of using citizen science and AI for ecological monitoring. We identify project attributes to consider when implementing these techniques and suggest that financial resources, engagement, participant training, technical expertise, and subject charisma and identification are important project considerations. Ultimately, we highlight that integration can supercharge outcomes for ecological monitoring, enhancing cost-efficiency, accuracy, and multi-sector engagement."																				
2020	"Meisner, Jonas; Albrechtsen, Anders"	Haplotype and Population Structure Inference using Neural Networks in Whole-Genome Sequencing Data	Molecular	VAE	Classification	bioRxiv				10.1101/2020.12.28.424587	http://biorxiv.org/lookup/doi/10.1101/2020.12.28.424587	"Accurate inference of population structure is important in many studies of population genetics. In this paper we present, HaploNet, a novel method for performing dimensionality reduction and clustering in genetic data. The method is based on local clustering of phased haplotypes using neural networks from whole-genome sequencing or genotype data. By utilizing a Gaussian mixture prior in a variational autoencoder framework, we are able to learn a low-dimensional latent space in which we cluster haplotypes along the genome in a highly scalable manner. We demonstrate that we can use haplotype clusters in the latent space to infer global population structure utilizing haplotype information by exploiting the generative properties of our framework. Based on fitted neural networks and its latent haplotype clusters, we can perform principal component analysis and estimate the ancestry proportions based on a maximum likelihood framework. Using sequencing data from closely related human populations, we demonstrate that our approach is better at distinguishing closely related populations than standard admixture and principal component analysis software. We further show that HaploNet is fast and highly scalable by applying it to genotype array data of the UK Biobank."																				
2020	"Memmolo, Pasquale; Carcagnì, Pierluigi; Bianco, Vittorio; Merola, Francesco; Goncalves da Silva Junior, Andouglas; Garcia Goncalves, Luis Marcos; Ferraro, Pietro; Distante, Cosimo"	Learning Diatoms Classification from a Dry Test Slide by Holographic Microscopy	Images	CNN	Classification	Sensors	20	21	6353	10.3390/s20216353	https://www.mdpi.com/1424-8220/20/21/6353	"Diatoms are among the dominant phytoplankters in marine and freshwater habitats, and important biomarkers of water quality, making their identification and classification one of the current challenges for environmental monitoring. To date, taxonomy of the species populating a water column is still conducted by marine biologists on the basis of their own experience. On the other hand, deep learning is recognized as the elective technique for solving image classification problems. However, a large amount of training data is usually needed, thus requiring the synthetic enlargement of the dataset through data augmentation. In the case of microalgae, the large variety of species that populate the marine environments makes it arduous to perform an exhaustive training that considers all the possible classes. However, commercial test slides containing one diatom element per class fixed in between two glasses are available on the market. These are usually prepared by expert diatomists for taxonomy purposes, thus constituting libraries of the populations that can be found in oceans. Here we show that such test slides are very useful for training accurate deep Convolutional Neural Networks (CNNs). We demonstrate the successful classification of diatoms based on a proper CNNs ensemble and a fully augmented dataset, i.e., creation starting from one single image per class available from a commercial glass slide containing 50 fixed species in a dry setting. This approach avoids the time-consuming steps of water sampling and labeling by skilled marine biologists. To accomplish this goal, we exploit the holographic imaging modality, which permits the accessing of a quantitative phase-contrast maps and a posteriori flexible refocusing due to its intrinsic 3D imaging capability. The network model is then validated by using holographic recordings of live diatoms imaged in water samples i.e., in their natural wet environmental condition."																				
2020	"Menad, Hanane; Ben-naoum, Farah; Amine, Abdelmalek"	A Hybrid Grey Wolves Optimizer and Convolutional Neural Network for Pollen Grain Recognition	Images	CNN	Classification	International Journal of Swarm Intelligence Research (IJSIR)	11	3	49-71	10.4018/IJSIR.2020070104	https://www.igi-global.com/gateway/article/255709	"Melissopalynology, or pollen analysis of honey, is one of the areas that benefited greatly from image processing and analysis techniques, where melissopalynology is the science that studies the pollen contained in honey, using a microscopic examination. Nowadays, developing an automatic classification system for pollen identification presents a challenge. This article presents a metaheuristic for image segmentation to detect pollen grains in images. It is a swarm intelligence technique inspired from grey wolf hunting behavior in nature, centered around respecting the hierarchy of a pack. It was tested on a set of microscopic images of pollen grains. To evaluate pollen detection, we represented the detected pollen grains using two methods, grey-level based representations where we kept grey value of each pixel, and a binary mask-based technique, where a pixel could have only two values (1 or 0). Then, we used a convolutional neural network (CNN) technique for image classification to predict the specie of each pollen. The proposed system was tested on a set of microscopic images of pollen grains. The obtained performance measures of the system proved that the system is very successful."																				
2020	"Miele, Vincent; Dussert, Gaspard; Cucchi, Thomas; Renaud, Sabrina"	Deep learning for species identification of modern and fossil rodent molars	Images	CNN	Classification	bioRxiv				10.1101/2020.08.20.259176	http://biorxiv.org/lookup/doi/10.1101/2020.08.20.259176	"Reliable identification of species is a key step to assess biodiversity. In fossil and archaeological contexts, genetic identifications remain often difficult or even impossible and morphological criteria are the only window on past biodiversity. Methods of numerical taxonomy based on geometric morphometric provide reliable identifications at the specific and even intraspecific levels, but they remain relatively time consuming and require expertise on the group under study. Here, we explore an alternative based on computer vision and machine learning. The identification of three rodent species based on pictures of their molar tooth row constituted the case study. We focused on the first upper molar in order to transfer the model elaborated on modern, genetically identified specimens to isolated fossil teeth. A pipeline based on deep neural network automatically cropped the first molar from the pictures, and returned a prediction regarding species identification. The deep-learning approach performed equally good as geometric morphometrics and, provided an extensive reference dataset including fossil teeth, it was able to successfully identify teeth from an archaeological deposit that was not included in the training dataset. This is a proof-of-concept that such methods could allow fast and reliable identification of extensive amounts of fossil remains, often left unstudied in archaeological deposits for lack of time and expertise. Deep-learning methods may thus allow new insights on the biodiversity dynamics across the last 10.000 years, including the role of humans in extinction or recent evolution."																				
2020	"Milo_evi_, Djuradj; Milosavljevi_, Aleksandar; Predi_, Bratislav; Medeiros, Andrew S.; Savi_-Zdravkovi_, Dimitrija; Stojkovi_ Piperac, Milica; Kosti_, Tijana; Spasi_, Filip; Leese, Florian"	Application of deep learning in aquatic bioassessment: Towards automated identification of non-biting midges	Images	CNN	"Classification, Regression"	Science of The Total Environment	711		135160	10.1016/j.scitotenv.2019.135160	https://www.sciencedirect.com/science/article/pii/S0048969719351526	"Morphological species identification is often a difficult, expensive, and time-consuming process which hinders the ability for reliable biomonitoring of aquatic ecosystems. An alternative approach is to automate the whole process, accelerating the identification process. Here, we demonstrate an automatic machine-based identification approach for non-biting midges (Diptera: Chironomidae) using Convolutional Neural Networks (CNNs) as a means of increasing taxonomic resolution of biomonitoring data at a minimal cost. Chironomidae were used to build the automatic identifier, as a family of insects that are abundant and ecologically important, yet difficult and time-consuming to accurately identify. The approach was tested with 10 morphologically very similar species from the same genus or subfamilies, comprising 1846 specimens from the South Morava river basin, Serbia. Three CNN models were built utilizing either species, genus, or subfamily data. After training the artificial neural network, images that the network had not seen during the training phase achieved an accuracy of 99.5% for species-level identification, while at the genus and subfamily level all images were correctly assigned (100% accuracy). Gradient-weighted Class Activation Mapping (Grad-CAM) visualized the mentum, ventromental plates, mandibles, submentum, and postoccipital margin to be morphologically important features for CNN classification. Thus, the CNN approach was a highly accurate solution for chironomid identification of aquatic macroinvertebrates opening a new avenue for implementation of artificial intelligence and deep learning methodology in the biomonitoring world. This approach also provides a means to overcome the gap in bioassessment for developing countries where widespread use techniques for routine monitoring are currently limited."																				
2020	"Miyoshi, Gabriela Takahashi; Arruda, Mauro dos Santos; Osco, Lucas Prado; Marcato Junior, José; Gonçalves, Diogo Nunes; Imai, Nilton Nobuhiro; Tommaselli, Antonio Maria Garcia; Honkavaara, Eija; Gonçalves, Wesley Nunes"	A Novel Deep Learning Method to Identify Single Tree Species in UAV-Based Hyperspectral Images	Other	CNN	Classification	Remote Sensing	12	8	1294	10.3390/rs12081294	https://www.mdpi.com/2072-4292/12/8/1294	"Deep neural networks are currently the focus of many remote sensing approaches related to forest management. Although they return satisfactory results in most tasks, some challenges related to hyperspectral data remain, like the curse of data dimensionality. In forested areas, another common problem is the highly-dense distribution of trees. In this paper, we propose a novel deep learning approach for hyperspectral imagery to identify single-tree species in highly-dense areas. We evaluated images with 25 spectral bands ranging from 506 to 820 nm taken over a semideciduous forest of the Brazilian Atlantic biome. We included in our network’s architecture a band combination selection phase. This phase learns from multiple combinations between bands which contributed the most for the tree identification task. This is followed by a feature map extraction and a multi-stage model refinement of the confidence map to produce accurate results of a highly-dense target. Our method returned an f-measure, precision and recall values of 0.959, 0.973, and 0.945, respectively. The results were superior when compared with a principal component analysis (PCA) approach. Compared to other learning methods, ours estimate a combination of hyperspectral bands that most contribute to the mentioned task within the network’s architecture. With this, the proposed method achieved state-of-the-art performance for detecting and geolocating individual tree-species in UAV-based hyperspectral images in a complex forest."																				
2020	"Motta, Daniel; Santos, Alex Álisson Bandeira; Machado, Bruna Aparecida Souza; Ribeiro-Filho, Otavio Gonçalvez Vicente; Camargo, Luis Octavio Arriaga; Valdenegro-Toro, Matias Alejandro; Kirchner, Frank; Badaró, Roberto"	Optimization of convolutional neural network hyperparameters for automatic classification of adult mosquitoes	Images	CNN	Classification	PLOS ONE	15	7	e0234959	10.1371/journal.pone.0234959	https://dx.plos.org/10.1371/journal.pone.0234959	"The economic and social impacts due to diseases transmitted by mosquitoes in the latest years have been significant. Currently, no specific treatment or commercial vaccine exists for the control and prevention of arboviruses, thereby making entomological characterization fundamental in combating diseases such as dengue, chikungunya, and Zika. The morphological identification of mosquitos includes a visual exam of the samples. It is time consuming and requires adequately trained professionals. Accordingly, the development of a new automated method for realizing mosquito-perception and -classification is becoming increasingly essential. Therefore, in this study, a computational model based on a convolutional neural network (CNN) was developed to extract features from the images of mosquitoes and then classify the species Aedes aegypti, Aedes albopictus, and Culex quinquefasciatus. In addition, the model was trained to detect the mosquitoes of the genus Aedes. To train CNNs to perform the automatic morphological classification of mosquitoes, a dataset, which included 7,561 images of the target mosquitoes and 1,187 images of other insects, was acquired. Various neural networks, such as Xception and DenseNet, were used for developing the automatic-classification model based on images. A structured optimization process of random search and grid search was developed to select the hyperparameters set and increase the accuracy of the model. In addition, strategies to eliminate overfitting were implemented to increase the generalization of the model. The optimized model, during the test phase, obtained the balanced accuracy (BA) of 93.5% in classifying the target mosquitoes and other insects and the BA of 97.3% in detecting the mosquitoes of the genus Aedes in comparison to Culex. The results provide fundamental information for performing the automatic morphological classification of mosquito species. Using a CNN-embedded entomological tool is a valuable and accessible resource for health workers and non-taxonomists for identifying insects that can transmit infectious diseases."																				
2020	"Musher, Lukas J.; Galante, Peter J.; Thom, Gregory; Huntley, Jerry W.; Blair, Mary E."	Shifting ecosystem connectivity during the Pleistocene drove diversification and gene-flow in a species complex of Neotropical birds (Tityridae: Pachyramphus)	Molecular	DNN	Modeling	Journal of Biogeography	47	8	1714-1726	10.1111/jbi.13862	https://onlinelibrary.wiley.com/doi/abs/10.1111/jbi.13862	"Aim We aim to test the biogeographic drivers of diversification and gene-flow at the Isthmus of Panama using a species complex of suboscine birds as a case study. We specifically evaluate whether diversification in these birds is better explained by continuous parapatry or a Refuge Model of periodic isolation and gene-flow due glacial cycling. Location The Isthmus of Panama (Neotropics). Taxon Pachyramphus aglaiae and Pachyramphus homochrous (Aves: Tityridae). Methods We develop an approach to distinguish among the two biogeographic hypotheses—parapatric ecological speciation versus climatically mediated speciation—by making explicit predictions for demographic history, niche evolution and change in geographic connectivity over time. We sequenced genome-wide markers (ultraconserved elements) to estimate the evolutionary and demographic history of this group. We applied both phylogenomic network analyses and demographic modelling using a supervised machine learning approach. These genetic analyses were combined with a novel distribution modelling method that estimates the probability of interspecies contact as a function of climatic conditions through time. Results We found that both spatial and genetic analyses revealed concordant results. All speciation events occurred during the Pleistocene and were characterized by non-continuous gene-flow, supporting a scenario of climate-mediated diversification. Spatial connectivity was highest at present, consistent with our best demographic model of secondary contact. Main conclusions This study exemplifies a mechanism by which speciation, dispersal and introgression unfold in an important region for Neotropical diversification—the Isthmus of Panama—where periods of both isolation and introgression probably drive diversification. Overall, our results are consistent with the Refuge Model of biotic diversification, but suggest that introgression may be a crucial yet underappreciated component of this classic paradigm."																				
2020	"Mustafa, M. S.; Husin, Z.; Tan, W. K.; Mavi, M. F.; Farook, R. S. M."	Development of automated hybrid intelligent system for herbs plant classification and early herbs plant disease detection	Images	Other	Classification	Neural Computing and Applications	32	15	11419-11441	10.1007/s00521-019-04634-7	https://doi.org/10.1007/s00521-019-04634-7	"Plants such as herbs are widely used in the medical and cosmetic industry. Recognizing a species and detecting an early disease of a plant are quite challenging and difficult to implement as an automated device. The manual identification process is a lengthy process and requires a prior understanding about the plant itself, such as shape, odour, and texture. Thus, this research aimed to realize the computerized method to recognize the species and detect early disease of the herbs by referring to these characteristics. This research has been developed a system for recognizing the species and detecting the early disease of the herbs using computer vision and electronic nose, which focus on odour, shape, colour and texture extraction of herb leaves, together with a hybrid intelligent system that are involved fuzzy inference system, naïve Bayes (NB), probabilistic neural network (PNN) and support vector machine (SVM) classifier. These techniques were used to perform a convenient and effective herb species recognition and early disease detection on ten different herb species samples. The species recognition accuracy rate among ten different species using computer vision and electronic nose is archived 97% and 96%, respectively, in SVM, 98% and 98%, respectively, in PNN and both 94% in NB. In the early disease detection, the detection rate among ten different herb’s species using computer vision and electronic nose are 98% and 97%, respectively, in SVM, both 98% in PNN, 95% and 94%, respectively, in NB. Integrated three machine learning approaches have successfully achieved almost 99% for recognition and detection rate."																				
2020	"Natesan, Sowmya; Armenakis, Costas; Vepakomma, Udayalakshmi"	Individual tree species identification using Dense Convolutional Network (DenseNet) on multitemporal RGB images from UAV	Images	CNN	Classification	Journal of Unmanned Vehicle Systems	8	4	310-333	10.1139/juvs-2020-0014	https://cdnsciencepub.com/doi/full/10.1139/juvs-2020-0014	"Tree species identification at the individual tree level is crucial for forest operations and management, yet its automated mapping remains challenging. Emerging technology, such as the high-resolution imagery from unmanned aerial vehicles (UAV) that is now becoming part of every forester’s surveillance kit, can potentially provide a solution to better characterize the tree canopy. To address this need, we have developed an approach based on a deep Convolutional Neural Network (CNN) to classify forest tree species at the individual tree-level that uses high-resolution RGB images acquired from a consumer-grade camera mounted on a UAV platform. This work explores the ability of the Dense Convolutional Network (DenseNet) to classify commonly available economic coniferous tree species in eastern Canada. The network was trained using multitemporal images captured under varying acquisition parameters to include seasonal, temporal, illumination, and angular variability. Validation of this model using distinct images over a mixed-wood forest in Ontario, Canada, showed over 84% classification accuracy in distinguishing five predominant species of coniferous trees. The model remains highly robust even when using images taken during different seasons and times, and with varying illumination and angles."																				
2020	"Niemi, Juha; Tanttu, Juha T."	Deep learning–based automatic bird identification system for offshore wind farms	Video	CNN	Classification	Wind Energy	23	6	1394-1407	10.1002/we.2492	https://onlinelibrary.wiley.com/doi/abs/10.1002/we.2492	"Practical deterrent methods are needed to prevent collisions between birds and wind turbine blades for offshore wind farms. It is improbable that a single deterrent method would work for all bird species in a given area. An automatic bird identification system is required in order to develop bird species–level deterrent methods. This system is the first and necessary part of the entirety that is eventually able to automatically monitor bird movements, identify bird species, and launch deterrent measures. A prototype system has been built on Finnish west coast. In the proposed system, a separate radar system detects birds and provides WGS84 coordinates to a steering system of a camera. The steering system consists of a motorized video head and our software to control it. The steering system tracks flying birds in order to capture series of images by a digital single-lens reflex camera. Classification is based on these images, and it is implemented by convolutional neural network trained with a deep learning algorithm. We applied to the images our data augmentation method in which images are rotated and converted into different color temperatures. The results indicate that the proposed system has good performance to identify bird species in the test area. Aiming accuracy for the video head was 88.91 %. Image classification performance as true positive rate was 0.8688."																				
2020	"Okwori, Michael; Eslami, Ali"	Investigating the Impact of Gene Cofunctionality in Predicting Gene Mutations of E. coli	Other	DNN	Regression	IEEE Access	8		167397-167410	10.1109/ACCESS.2020.3023662	https://ieeexplore.ieee.org/document/9195469	"Machine learning algorithms (MLAs) have recently been applied to predict gene mutations of Escherichia coli (E. coli) under different exposure conditions, with room for improvement in performance. In a bid to improve performance, we hypothesize that incorporating the interactions between genes will help MLAs make better predictions. To investigate this, we integrated protein-coding gene cofunctional networks into a mutation dataset of E. coli exposed to different conditions. Also, we proposed a feature-selection algorithm based on gene cofunctional networks to pick the most relevant exposure conditions. Then, we used the extended dataset to train a support vector classifier, an artificial neural network, and an ensemble of both MLAs. Separate models were trained for each of the protein-coding genes. Validation results showed that our approach improved both the area under the receiver operating characteristic (ROC) curve (AUC) and the area under the precision-recall curve (AUPRC). A peak increase of 8.20% in AUPRC was observed. A similar analysis on selected genes, with ten or more mutation points for each gene, also showed improvement in the general performance of the MLAs. Out-of-sample testing on adaptive laboratory evolution experiments curated from the literature provided further evidence of an enhanced mutation-prediction performance, where a maximum 8.74% boost in the AUC was observed. Finally, we highlighted the genes with the most improved and most degraded predictions due to the additional information of the cofunctional genes. This work suggests that the functional relationship between genes may play a role in gene mutation and illustrates how the relationships might help to improve mutation prediction."																				
2020	"Oliveira, E. A.; Perez, M. F.; Bertollo, L. A. C.; Gestich, C. C.; Ráb, P.; Ezaz, T.; Souza, F. H. S.; Viana, P.; Feldberg, E.; Oliveira, E. H. C.; Cioffi, M. B."	Historical demography and climate driven distributional changes in a widespread Neotropical freshwater species with high economic importance	Molecular	CNN	Classification	Ecography	43	9	1291-1304	10.1111/ecog.04874	https://onlinelibrary.wiley.com/doi/10.1111/ecog.04874	"The Neotropical region exhibits the greatest worldwide diversity and the diversification history of several clades is related to the puzzling geomorphologic and climatic history of this region. The freshwater Amazon ecoregion contains the main hydrographic basins of the Neotropical region that are highly dendritic and ecologically diverse. It contains a rich and endemic fish fauna, including one of its most iconic and economically important representatives, the bony-tongue Arapaima gigas (Teleostei, Osteoglossiformes). Here, we evaluated the projected distribution of the genus in different historical periods (Present, Last Glacial Maximum, Last Interglacial Maximum and Near Future) and interpreted these results in light of the genomic diversity and modeled historical demography. For that, we combined species distribution models, population genetic analysis using SNPs and deep learning model selection. We analyzed a representative sample of the genus from the two basins where it naturally occurs, four localities in the Amazon (Am) and three in the Tocantins-Araguaia (To-Ar) basin, as well as individuals from three fish farms. We inferred a potentially smaller distribution in the glacial period, with a possible refuge in central Am. Our genetic data agrees with this result, suggesting a higher level of genetic diversity in the Am basin, compared to that observed in To-Ar. Our deep learning model comparison indicated that the To-Ar basin was colonized by the population from the Am basin. Considering a global warming scenario in the near future, A. gigas could reach an even larger range, especially if anthropogenic related dispersal occurs, potentially invading new areas and impacting their communities"																				
2020	"Olschofsky, Konstantin; Köhl, Michael"	Rapid field identification of cites timber species by deep learning	Images	CNN	Classification	"Trees, Forests and People"	2		100016	10.1016/j.tfp.2020.100016	https://www.sciencedirect.com/science/article/pii/S2666719320300169	"Enforcement of the ban on trade in protected tree species is often hampered by insufficient knowledge of species identification by the authorities responsible for control. We present a new method based on a deep learning approach that facilitates the separation of protected and non protected tree species. The classification system used here is based on the image classification model Inception-v3, a so-called transfer learning tool provided by Google. Inceptionv3 uses a convolutional neural network (CNN) for feature extraction and classification and has been pre-trained with 1.2 million images. Input and bottleneck layers of the pre-trained CNN are used to generate new CNNs to which images are passed and classified. As an example of a protected tree species, we have chosen Cedrella odorata, which we compare with 13 other tropical tree species. In a first step, the data set of C. odorata and five other unprotected tree species was partitioned into five groups using a bootstrap algorithm. Then the images of each group were passed to an image classification system and used to generate five CNNs independently. Each CNN assigns image data to the two classes of protected tree species, i.e. C. odorata, or unprotected tree species. The five CNNs were first verified with images of the same six tree species that were used for training. For this purpose, images were taken that were not used for CNN training. 98 percent of the image scans were correctly classified into the two classes of protected and non-protected species. In a second verification step, additional tree species not used for training were presented to the image classification system. Here the correct allocation was reduced to 87 percent. Both the tree species and the CNNs used influence the accuracy of the correct class assignment. Against the background that only a few samples were used to train the CNNs, the accuracy achieved is convincing and shows the potential of simple applicable pre trained deep learning for the operational field inspection of timber loads as a first step to enforce legal timber trade regulations."																				
2020	"Orozco-Arias, Simon; Piña, Johan S.; Tabares-Soto, Reinel; Castillo-Ossa, Luis F.; Guyot, Romain; Isaza, Gustavo"	Measuring Performance Metrics of Machine Learning Algorithms for Detecting and Classifying Transposable Elements	"Molecular, Other"	DNN	Classification	Processes	8	6	638	10.3390/pr8060638	https://www.mdpi.com/2227-9717/8/6/638	"Because of the promising results obtained by machine learning (ML) approaches in several fields, every day is more common, the utilization of ML to solve problems in bioinformatics. In genomics, a current issue is to detect and classify transposable elements (TEs) because of the tedious tasks involved in bioinformatics methods. Thus, ML was recently evaluated for TE datasets, demonstrating better results than bioinformatics applications. A crucial step for ML approaches is the selection of metrics that measure the realistic performance of algorithms. Each metric has specific characteristics and measures properties that may be different from the predicted results. Although the most commonly used way to compare measures is by using empirical analysis, a non-result-based methodology has been proposed, called measure invariance properties. These properties are calculated on the basis of whether a given measure changes its value under certain modifications in the confusion matrix, giving comparative parameters independent of the datasets. Measure invariance properties make metrics more or less informative, particularly on unbalanced, monomodal, or multimodal negative class datasets and for real or simulated datasets. Although several studies applied ML to detect and classify TEs, there are no works evaluating performance metrics in TE tasks. Here, we analyzed 26 different metrics utilized in binary, multiclass, and hierarchical classifications, through bibliographic sources, and their invariance properties. Then, we corroborated our findings utilizing freely available TE datasets and commonly used ML algorithms. Based on our analysis, the most suitable metrics for TE tasks must be stable, even using highly unbalanced datasets, multimodal negative class, and training datasets with errors or outliers. Based on these parameters, we conclude that the F1-score and the area under the precision-recall curve are the most informative metrics since they are calculated based on other metrics, providing insight into the development of an ML application."																				
2020	"Ott, Tankred; Palm, Christoph; Vogt, Robert; Oberprieler, Christoph"	GinJinn: An object_detection pipeline for automated feature extraction from herbarium specimens	Images	CNN	Classification	Applications in Plant Sciences	8	6		10.1002/aps3.11351	https://onlinelibrary.wiley.com/doi/abs/10.1002/aps3.11351	"Premise: The generation of morphological data in evolutionary, taxonomic, and ecological studies of plants using herbarium material has traditionally been a labor-intensive task. Recent progress in machine learning using deep artificial neural networks (deep learning) for image classification and object detection has facilitated the establishment of a pipeline for the automatic recognition and extraction of relevant structures in images of herbarium specimens. Methods and Results: We implemented an extendable pipeline based on state-of-the-art deep-learning object-detection methods to collect leaf images from herbarium specimens of two species of the genus Leucanthemum. Using 183 specimens as the training data set, our pipeline extracted one or more intact leaves in 95% of the 61 test images. Conclusions: We establish GinJinn as a deep-learning object-detection tool for the automatic recognition and extraction of individual leaves or other structures from herbarium specimens. Our pipeline offers greater flexibility and a lower entrance barrier than previous image-processing approaches based on hand-crafted features."																				
2020	"Pan, B. Jack; Vernet, Maria; Manck, Lauren; Forsch, Kiefer; Ekern, Lindsey; Mascioni, Martina; Barbeau, Katherine A.; Almandoz, Gastón O.; Orona, Alexander J."	Environmental drivers of phytoplankton taxonomic composition in an Antarctic fjord	Environmental	DNN	Regression	Progress in Oceanography	183		102295	10.1016/j.pocean.2020.102295	https://www.sciencedirect.com/science/article/pii/S0079661120300343	"The impact of ice-ocean interaction on the Southern Ocean is expected to intensify in the future. However, its influence on phytoplankton community composition remains an open question. The Antarctic Peninsula fjords offer an ideal system to understand the effect of ice-ocean forcing on phytoplankton community, providing an extreme in the spatial gradient from the glacio-marine boundary to the Western Antarctic Peninsula (WAP) continental shelf. During two cruises conducted in December 2015 and April 2016 in Andvord Bay, we found that glacial meltwater input altered surface salinity, promoting shallow mixed layers, and enriched surface waters in dissolved iron and nitrate. The three major groups of phytoplankton fueled by glacial input were: cryptophytes, diatoms, and a group of unidentified small flagellates. Prasinophytes and dinoflagellates were also present, in lower concentrations. In December, cryptophytes dominated the phytoplankton community and were correlated with relatively warmer temperatures in the surface layer; in addition, contrary to our hypothesis, no diatom bloom was observed in the fjord in spite of dissolved iron concentration >1 nM. By April, after the growth season, the overall phytoplankton abundance had decreased by an order of magnitude. Phytoplankton, in particular diatoms, were then limited by daytime length despite abundant macro-nutrient and iron concentrations. Mixed flagellates emerged as the dominant group during April due to the decline of other major taxa. Deep-learning algorithms for predicting the abundance of each major phytoplankton group captured the effects of these environmental factors on the phytoplankton community. Our results show that the fjord has relatively high phytoplankton biomass combined with high macro- and trace nutrient concentrations when compared to the broader WAP region. Based on this study, we confirm that flagellates can be the dominant taxon in Antarctic nearshore waters and we propose that iron concentration alone is insufficient to predict diatom growth. Furthermore, marine terminating glaciers in the WAP can enrich surface waters with nitrate even if the main fjord circulation is not driven by glacier meltwater discharge."																				
2020	"Pant, Gaurav; Yadav, D. P.; Gaur, Ashish"	ResNeXt convolution neural network topology-based deep learning model for identification and classification of Pediastrum	Images	CNN	Classification	Algal Research	48		101932	10.1016/j.algal.2020.101932	https://www.sciencedirect.com/science/article/pii/S221192642030312X	"For identification of different Pediastrum species in a sample, the determination of microscopic feature and colony morphology are the preliminary steps before sending them to the higher genomic and proteomic level. Great efforts with high expertise are required for the time-consuming manual process. In the present study, the first time an effort has been done to address the problem for identification and classification of Pediastrum species with the help of convolutional neural networks (CNNs). The modified ResNeXt CNN (Convolution Neural Network) model is used for training and validation of the data set consisting of 42,000 algal images. Modified ResNeXt CNN topology differentiates cells based on the formation of coenobia, cell arrangement and feature and particularly the sculptures on the outer sporopollenin cell-wall layers. An experimental result of 98.45% classification accuracy and F1-score more than 0.98 demonstrates the effectiveness of the proposed method. In the future, such time and cost-effective facilities can be used as promising sources for phycological studies."																				
2020	"Park, Junyoung; Kim, Dong In; Choi, Byoungjo; Kang, Woochul; Kwon, Hyung Wook"	Classification and Morphological Analysis of Vector Mosquitoes using Deep Convolutional Neural Networks	Images	CNN	"Classification, Regression"	Scientific Reports	10	1	1012	10.1038/s41598-020-57875-1	https://www.nature.com/articles/s41598-020-57875-1	"Image-based automatic classification of vector mosquitoes has been investigated for decades for its practical applications such as early detection of potential mosquitoes-borne diseases. However, the classification accuracy of previous approaches has never been close to human experts’ and often images of mosquitoes with certain postures and body parts, such as flatbed wings, are required to achieve good classification performance. Deep convolutional neural networks (DCNNs) are state-of-the-art approach to extracting visual features and classifying objects, and, hence, there exists great interest in applying DCNNs for the classification of vector mosquitoes from easy-to-acquire images. In this study, we investigated the capability of state-of-the-art deep learning models in classifying mosquito species having high inter-species similarity and intra-species variations. Since no off-the-shelf dataset was available capturing the variability of typical field-captured mosquitoes, we constructed a dataset with about 3,600 images of 8 mosquito species with various postures and deformation conditions. To further address data scarcity problems, we investigated the feasibility of transferring general features learned from generic dataset to the mosquito classification. Our result demonstrated that more than 97% classification accuracy can be achieved by fine-tuning general features if proper data augmentation techniques are applied together. Further, we analyzed how this high classification accuracy can be achieved by visualizing discriminative regions used by deep learning models. Our results showed that deep learning models exploit morphological features similar to those used by human experts."																				
2020	"Pathan, Refat Khan; Biswas, Munmun; Khandaker, Mayeen Uddin"	Time series prediction of COVID-19 by mutation rate analysis using recurrent neural network-based LSTM model	Molecular	RNN	Regression	"Chaos, Solitons & Fractals"	138		110018	10.1016/j.chaos.2020.110018	https://www.sciencedirect.com/science/article/pii/S0960077920304161	"SARS-CoV-2, a novel coronavirus mostly known as COVID-19 has created a global pandemic. The world is now immobilized by this infectious RNA virus. As of June 15, already more than 7.9 million people have been infected and 432k people died. This RNA virus has the ability to do the mutation in the human body. Accurate determination of mutation rates is essential to comprehend the evolution of this virus and to determine the risk of emergent infectious disease. This study explores the mutation rate of the whole genomic sequence gathered from the patient's dataset of different countries. The collected dataset is processed to determine the nucleotide mutation and codon mutation separately. Furthermore, based on the size of the dataset, the determined mutation rate is categorized for four different regions: China, Australia, the United States, and the rest of the World. It has been found that a huge amount of Thymine (T) and Adenine (A) are mutated to other nucleotides for all regions, but codons are not frequently mutating like nucleotides. A recurrent neural network-based Long Short Term Memory (LSTM) model has been applied to predict the future mutation rate of this virus. The LSTM model gives Root Mean Square Error (RMSE) of 0.06 in testing and 0.04 in training, which is an optimized value. Using this train and testing process, the nucleotide mutation rate of 400th patient in future time has been predicted. About 0.1% increment in mutation rate is found for mutating of nucleotides from T to C and G, C to G and G to T. While a decrement of 0.1% is seen for mutating of T to A, and A to C. It is found that this model can be used to predict day basis mutation rates if more patient data is available in updated time."																				
2020	"Pearson, Katelin D; Nelson, Gil; Aronson, Myla F J; Bonnet, Pierre; Brenskelle, Laura; Davis, Charles C; Denny, Ellen G; Ellwood, Elizabeth R; Goëau, Hervé; Heberling, J Mason; Joly, Alexis; Lorieul, Titouan; Mazer, Susan J; Meineke, Emily K; Stucky, Brian J; Sweeney, Patrick; White, Alexander E; Soltis, Pamela S"	Machine Learning Using Digitized Herbarium Specimens to Advance Phenological Research	NA	NA	Review	BioScience	70	7	610-620	10.1093/biosci/biaa044	https://academic.oup.com/bioscience/article/70/7/610/5825721	"Machine learning (ML) has great potential to drive scientific discovery by harvesting data from images of herbarium specimens—preserved plant material curated in natural history collections—but ML techniques have only recently been applied to this rich resource. ML has particularly strong prospects for the study of plant phenological events such as growth and reproduction. As a major indicator of climate change, driver of ecological processes, and critical determinant of plant fitness, plant phenology is an important frontier for the application of ML techniques for science and society. In the present article, we describe a generalized, modular ML workflow for extracting phenological data from images of herbarium specimens, and we discuss the advantages, limitations, and potential future improvements of this workflow. Strategic research and investment in specimen-based ML methods, along with the aggregation of herbarium specimen data, may give rise to a better understanding of life on Earth."																				
2020	"Pereda-Solís, Martin E.; García-Fernández, Francisco; Sierra-Franco, Daniel; Martínez-Guerrero, José H.; Ruvalcaba-Ortega, Irene; Hennegan-Strasser, Erin"	DIFERENCIACIÓN DEL SEXO DEL GORRIÓN DE BAIRD (Centronyx bairdii) POR MEDIO DE REDES NEURONALES ARTIFICIALES Y DATOS MORFOMÉTRICOS	Other	DNN	Classification	Agrociencia	54	3	353-365	10.47163/agrociencia.v54i3.1911	https://agrociencia-colpos.mx/index.php/agrociencia/article/view/1911	"Estimates indicate that 148 species of birds in North America face a high or severe threat, because their populations are decreasing. The Baird sparrow (Centronyx bairdii) is one of the species with population decline, it presents monomorphic plumage and sex cannot be determined at plain sight. Sex determination in birds allows understanding their social behavior and proportion regarding population dynamics. Artificial neural networks are used as a classification method which has been used in various fields, such as plant and seed classification, and species differentiation of timber species. In the scope of ornithology, it has been scarcely used. Therefore, the objective of this study was to develop an artificial neural network to differentiate the sex of sparrows of the species Centronyx bairdii, with zoometric data obtained in the field. The hypothesis was that artificial neural networks can predict the sex of the birds of the species Centronyx bairdii. The neural network built from the data of weight, wing chord, tail length, culmen, width of the beak and depth of the beak of 111 birds, allowed differentiating the sex of the species with a degree of certainty of 92.3%."																				
2020	"Pereira, Talmo D.; Tabris, Nathaniel; Li, Junyu; Ravindranath, Shruthi; Papadoyannis, Eleni S.; Wang, Z. Yan; Turner, David M.; McKenzie-Smith, Grace; Kocher, Sarah D.; Falkner, Annegret L.; Shaevitz, Joshua W.; Murthy, Mala"	SLEAP: Multi-animal pose tracking	Video	CNN	Classification	bioRxiv				10.1101/2020.08.31.276246	http://biorxiv.org/lookup/doi/10.1101/2020.08.31.276246	"The desire to understand how the brain generates and patterns behavior has driven rapid methodological innovation to quantify and model natural animal behavior. This has led to important advances in deep learning-based markerless pose estimation that have been enabled in part by the success of deep learning for computer vision applications. Here we present SLEAP (Social LEAP Estimates Animal Poses), a framework for multi-animal pose tracking via deep learning. This system is capable of simultaneously tracking any number of animals during social interactions and across a variety of experimental conditions. SLEAP implements several complementary approaches for dealing with the problems inherent in moving from single-to multi-animal pose tracking, including configurable neural network architectures, inference techniques, and tracking algorithms, enabling easy specialization and tuning for particular experimental conditions or performance requirements. We report results on multiple datasets of socially interacting animals (flies, bees, and mice) and describe how dataset-specific properties can be leveraged to determine the best configuration of SLEAP models. Using a high accuracy model (&lt;2.8 px error on 95% of points), we were able to track two animals from full size 1024 _ 1024 pixel frames at up to 320 FPS. The SLEAP framework comes with a sophisticated graphical user interface, multi-platform support, Colab-based GPU-free training and inference, and complete tutorials available, in addition to the datasets, at sleap.ai ."																				
2020	"Peteinatos, Gerassimos G.; Reichel, Philipp; Karouta, Jeremy; Andújar, Dionisio; Gerhards, Roland"	"Weed Identification in Maize, Sunflower, and Potatoes with the Aid of Convolutional Neural Networks"	Images	CNN	Classification	Remote Sensing	12	24	4185	10.3390/rs12244185	https://www.mdpi.com/2072-4292/12/24/4185	"The increasing public concern about food security and the stricter rules applied worldwide concerning herbicide use in the agri-food chain, reduce consumer acceptance of chemical plant protection. Site-Specific Weed Management can be achieved by applying a treatment only on the weed patches. Crop plants and weeds identification is a necessary component for various aspects of precision farming in order to perform on the spot herbicide spraying or robotic weeding and precision mechanical weed control. During the last years, a lot of different methods have been proposed, yet more improvements need to be made on this problem, concerning speed, robustness, and accuracy of the algorithms and the recognition systems. Digital cameras and Artificial Neural Networks (ANNs) have been rapidly developed in the past few years, providing new methods and tools also in agriculture and weed management. In the current work, images gathered by an RGB camera of Zea mays, Helianthus annuus, Solanum tuberosum, Alopecurus myosuroides, Amaranthus retroflexus, Avena fatua, Chenopodium album, Lamium purpureum, Matricaria chamomila, Setaria spp., Solanum nigrum and Stellaria media were provided to train Convolutional Neural Networks (CNNs). Three different CNNs, namely VGG16, ResNet–50, and Xception, were adapted and trained on a pool of 93,000 images. The training images consisted of images with plant material with only one species per image. A Top-1 accuracy between 77% and 98% was obtained in plant detection and weed species discrimination, on the testing of the images."																				
2020	"Pires De Lima, Rafael; Welch, Katie F.; Barrick, James E.; Marfurt, Kurt J.; Burkhalter, Roger; Cassel, Murphy; Soreghan, Gerilyn S."	Convolutional neural networks as an aid to biostratigraphy and micropaleontology: A test on Late Paleozoic microfossils	Images	CNN	Classification	PALAIOS	35	9	391-402	10.2110/palo.2019.102	https://pubs.geoscienceworld.org/sepm/palaios/article/35/9/391/591723/CONVOLUTIONAL-NEURAL-NETWORKS-AS-AN-AID-TO	"Accurate taxonomic classification of microfossils in thin-sections is an important biostratigraphic procedure. As paleontological expertise is typically restricted to specific taxonomic groups and experts are not present in all institutions, geoscience researchers often suffer from lack of quick access to critical taxonomic knowledge for biostratigraphic analyses. Moreover, diminishing emphasis on education and training in systematics poses a major challenge for the future of biostratigraphy, and on associated endeavors reliant on systematics. Here we present a machine learning approach to classify and organize fusulinids—microscopic index fossils for the late Paleozoic. The technique we employ has the potential to use such important taxonomic knowledge in models that can be applied to recognize and categorize fossil specimens. Our results demonstrate that, given adequate images and training, convolutional neural network models can correctly identify fusulinids with high levels of accuracy. Continued efforts in digitization of biological and paleontological collections at numerous museums and adoption of machine learning by paleontologists can enable the development of highly accurate and easy-to-use classification tools and, thus, facilitate biostratigraphic analyses by non-experts as well as allow for cross-validation of disparate collections around the world. Automation of classification work would also enable expert paleontologists and others to focus efforts on exploration of more complex interpretations and concepts."																				
2020	"Pryer, Kathleen M.; Tomasi, Carlo; Wang, Xiaohan; Meineke, Emily K.; Windham, Michael D."	Using computer vision on herbarium specimen images to discriminate among closely related horsetails Equisetum	Images	CNN	Classification	Applications in Plant Sciences	8	6		10.1002/aps3.11372	https://onlinelibrary.wiley.com/doi/abs/10.1002/aps3.11372	"Premise: Equisetum is a distinctive vascular plant genus with 15 extant species worldwide. Species identification is complicated by morphological plasticity and frequent hybridization events, leading to a disproportionately high number of misidentified specimens. These may be correctly identified by applying appropriate computer vision tools. Methods: We hypothesize that aerial stem nodes can provide enough information to distinguish among Equisetum hyemale, E. laevigatum, and E. _ferrissii, the latter being a hybrid between the other two. An object detector was trained to find nodes on a given image and to distinguish E. hyemale nodes from those of E. laevigatum. A classifier then took statistics from the detection results and classified the given image into one of the three taxa. Both detector and classifier were trained and tested on expert manually annotated images. Results: In our exploratory test set of 30 images, our detector/classifier combination identified all 10 E. laevigatum images correctly, as well as nine out of 10 E. hyemale images, and eight out of 10 E. _ferrissii images, for a 90% classification accuracy. Discussion: Our results support the notion that computer vision may help with the identification of herbarium specimens once enough manual annotations become available."																				
2020	"Qian, Wanqiang; Huang, Yiqi; Liu, Qi; Fan, Wei; Sun, Zhongyu; Dong, Hui; Wan, Fanghao; Qiao, Xi"	UAV and a deep convolutional neural network for monitoring invasive alien plants in the wild	Images	CNN	Classification	Computers and Electronics in Agriculture	174		105519	10.1016/j.compag.2020.105519	https://www.sciencedirect.com/science/article/pii/S0168169920302921	"Invasive alien plants (IAPs) are considered to be among the greatest global threats to biodiversity and ecosystems. Timely and effective monitoring is important for their prevention and control. However, monitoring remains mainly dependent on satellite remote sensing and manual inspection, which has a high cost and rather low accuracy and efficiency. We considered that this problem could be solved using unmanned aerial vehicle (UAV) intelligent monitoring. Accurate and rapid identification of IAPs in the wild is the core of intelligent monitoring. We intended to acquire colour images of the monitoring area in a field environment using an UAV and proposing a novel IAPsNet based on a deep convolutional neural network (CNN) to identify the IAPs appearing in the images. 6400 samples were one by one manually divided into seven IAP categories and one background category as training set. IAPsNet incorporated AlexNet local response normalization (LRN), GoogLeNet inception models, and continuous VGG convolution. Through training and testing, the IAPsNet performance for 893 testing samples was rather satisfactory, reaching an accuracy of 93.39% within a time of 1.8846_s and the average recall, average precision and average F1-score can reach 93.3%, 93.74% and 93.52% respectively. Moreover, in quantitative and qualitative comparative analysis, IAPsNet not only has high accuracy, high recall, high precision, high F1-score and efficiency but also has a high anti-interference capacity against blur, environment and multi-scales. Additionally, IAPsNet was applied to 4 different real wild conditions, proving that it is able to adapt to different scenes and simultaneously identify multiple species; it has potential to be used in the wild. High-quality distributional data of invasive plants are provided for subsequent ecological analysis. The data will help management authorities to implement the necessary steps in an identified area to develop a comprehensive strategy for IAP control."																				
2020	"Quenu, Mathieu; Trewick, Steven A; Brescia, Fabrice; Morgan-Richards, Mary"	"Geometric morphometrics and machine learning challenge currently accepted species limits of the land snail Placostylus (Pulmonata: Bothriembryontidae) on the Isle of Pines, New Caledonia"	Other	DNN	Classification	Journal of Molluscan Studies	86	1	35-41	10.1093/mollus/eyz031	https://academic.oup.com/mollus/article/86/1/35/5722382	"Size and shape variations of shells can be used to identify natural phenotypic clusters and thus delimit snail species. Here, we apply both supervised and unsupervised machine learning algorithms to a geometric morphometric dataset to investigate size and shape variations of the shells of the endemic land snail Placostylus from New Caledonia. We sampled eight populations of Placostylus from the Isle of Pines, where two species of this genus reportedly coexist. We used neural network analysis as a supervised learning algorithm and Gaussian mixture models as an unsupervised learning algorithm. Using a training dataset of individuals assigned to species using nuclear markers, we found that supervised learning algorithms could not unambiguously classify all individuals of our expanded dataset using shell size and shape. Unsupervised learning showed that the optimal division of our data consisted of three phenotypic clusters. Two of these clusters correspond to the established species Placostylus fibratus and P. porphyrostomus, while the third cluster was intermediate in both shape and size. Most of the individuals that were not clearly classified using supervised learning were classified to this intermediate phenotype by unsupervised learning, and most of these individuals came from previously unsampled populations. These results may indicate the presence of persistent putative-hybrid populations of Placostylus in the Isle of Pines."																				
2020	"Raman, Srinivasan; Maskeli_nas, Rytis; Dama_evi_ius, Robertas"	Markerless Dog Pose Recognition in the Wild Using ResNet Deep Learning Model	Video	CNN	Classification	Computers	11	1	2	10.3390/computers11010002	https://www.mdpi.com/2073-431X/11/1/2	"The analysis and perception of behavior has usually been a crucial task for researchers. The goal of this paper is to address the problem of recognition of animal poses, which has numerous applications in zoology, ecology, biology, and entertainment. We propose a methodology to recognize dog poses. The methodology includes the extraction of frames for labeling from videos and deep convolutional neural network (CNN) training for pose recognition. We employ a semi-supervised deep learning model of reinforcement. During training, we used a combination of restricted labeled data and a large amount of unlabeled data. Sequential CNN is also used for feature localization and to find the canine’s motions and posture for spatio-temporal analysis. To detect the canine’s features, we employ image frames to locate the annotations and estimate the dog posture. As a result of this process, we avoid starting from scratch with the feature model and reduce the need for a large dataset. We present the results of experiments on a dataset of more than 5000 images of dogs in different poses. We demonstrated the effectiveness of the proposed methodology for images of canine animals in various poses and behavior. The methodology implemented as a mobile app that can be used for animal tracking."																				
2020	"Raphael, Alina; Dubinsky, Zvy; Iluz, David; Netanyahu, Nathan S."	Neural Network Recognition of Marine Benthos and Corals	NA	NA	Review	Diversity	12	1	29	10.3390/d12010029	https://www.mdpi.com/1424-2818/12/1/29	"We present thorough this review the developments in the field, point out their current limitations, and outline its timelines and unique potential. In order to do so we introduce the methods used in each of the advances in the application of deep learning (DL) to coral research that took place between the years: 2016–2018. DL has unique capability of streamlining the description, analysis, and monitoring of coral reefs, saving time, and obtaining higher reliability and accuracy compared with error-prone human performance. Coral reefs are the most diverse and complex of marine ecosystems, undergoing a severe decline worldwide resulting from the adverse synergistic influences of global climate change, ocean acidification, and seawater warming, exacerbated by anthropogenic eutrophication and pollution. DL is an extension of some of the concepts originating from machine learning that join several multilayered neural networks. Machine learning refers to algorithms that automatically detect patterns in data. In the case of corals these data are underwater photographic images. Based on “learned” patterns, such programs can recognize new images. The novelty of DL is in the use of state-of-art computerized image analyses technologies, and its fully automated methodology of dealing with large data sets of images. Automated Image recognition refers to technologies that identify and detect objects or attributes in a digital video or image automatically. Image recognition classifies data into selected categories out of many. We show that Neural Network methods are already reliable in distinguishing corals from other benthos and non-coral organisms. Automated recognition of live coral cover is a powerful indicator of reef response to slow and transient changes in the environment. Improving automated recognition of coral species, DL methods already recognize decline of coral diversity due to natural and anthropogenic stressors. Diversity indicators can document the effectiveness of reef bioremediation initiatives. We explored the current applications of deep learning for corals and benthic image classification by discussing the most recent studies conducted by researchers. We review the developments in the field, point out their current limitations, and outline their timelines and unique potential. We also discussed a few future research directions in the fields of deep learning. Future needs are the age detection of single species, in order to track trends in their population recruitment, decline, and recovery. Fine resolution, at the polyp level, is still to be developed, in order to allow separation of species with similar macroscopic features. That refinement of DL will allow such comparisons and their analyses. We conclude that the usefulness of future, more refined automatic identification will allow reef comparison, and tracking long term changes in species diversity. The hitherto unused addition of intraspecific coral color parameters, will add the inclusion of physiological coral responses to environmental conditions and change thereof. The core aim of this review was to underscore the strength and reliability of the DL approach for documenting coral reef features based on an evaluation of the currently available published uses of this method. We expect that this review will encourage researchers from computer vision and marine societies to collaborate on similar long-term joint ventures."																				
2020	"Rast, Wanja; Kimmig, Sophia Elisabeth; Giese, Lisa; Berger, Anne"	Machine learning goes wild: Using data from captive individuals to infer wildlife behaviours	Other	DNN	Classification	PLOS ONE	15	5	e0227317	10.1371/journal.pone.0227317	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0227317	"1. Remotely tracking distinct behaviours of animals using acceleration data and machine learning has been carried out successfully in several species in captive settings. In order to study the ecology of animals in natural habitats, such behaviour classification models need to be transferred to wild individuals. However, at present, the development of those models usually requires direct observation of the target animals. 2. The goal of this study was to infer the behaviour of wild, free-roaming animals from acceleration data by training behaviour classification models on captive individuals, without the necessity to observe their wild conspecifics. We further sought to develop methods to validate the credibility of the resulting behaviour extrapolations. 3. We trained two machine learning algorithms proposed by the literature, Random Forest (RF) and Support Vector Machine (SVM), on data from captive red foxes (Vulpes vulpes) and later applied them to data from wild foxes. We also tested a new advance for behaviour classification, by applying a moving window to an Artificial Neural Network (ANN). Finally, we investigated four strategies to validate our classification output. 4. While all three machine learning algorithms performed well under training conditions (Kappa values: RF (0.82), SVM (0.78), ANN (0.85)), the established methods, RF and SVM, failed in classifying distinct behaviours when transferred from captive to wild foxes. Behaviour classification with the ANN and a moving window, in contrast, inferred distinct behaviours and showed consistent results for most individuals. 5. Our approach is a substantial improvement over the methods previously proposed in the literature as it generated plausible results for wild fox behaviour. We were able to infer the behaviour of wild animals that have never been observed in the wild and to further illustrate the credibility of the output. This framework is not restricted to foxes but can be applied to infer the behaviour of many other species and thus empowers new advances in behavioural ecology."																				
2020	"Ratnayake, Malika Nisal; Dyer, Adrian G.; Dorin, Alan"	Tracking individual honeybees among wildflower clusters with computer vision-facilitated pollinator monitoring	Video	CNN	"Classification, Regression"	PLOS ONE	16	2	e0239504	10.1371/journal.pone.0239504	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0239504	"Monitoring animals in their natural habitat is essential for advancement of animal behavioural studies, especially in pollination studies. Non-invasive techniques are preferred for these purposes as they reduce opportunities for research apparatus to interfere with behaviour. One potentially valuable approach is image-based tracking. However, the complexity of tracking unmarked wild animals using video is challenging in uncontrolled outdoor environments. Out-of-the-box algorithms currently present several problems in this context that can compromise accuracy, especially in cases of occlusion in a 3D environment. To address the issue, we present a novel hybrid detection and tracking algorithm to monitor unmarked insects outdoors. Our software can detect an insect, identify when a tracked insect becomes occluded from view and when it re-emerges, determine when an insect exits the camera field of view, and our software assembles a series of insect locations into a coherent trajectory. The insect detecting component of the software uses background subtraction and deep learning-based detection together to accurately and efficiently locate the insect among a cluster of wildflowers. We applied our method to track honeybees foraging outdoors using a new dataset that includes complex background detail, wind-blown foliage, and insects moving into and out of occlusion beneath leaves and among three-dimensional plant structures. We evaluated our software against human observations and previous techniques. It tracked honeybees at a rate of 86.6% on our dataset, 43% higher than the computationally more expensive, standalone deep learning model YOLOv2. We illustrate the value of our approach to quantify fine-scale foraging of honeybees. The ability to track unmarked insect pollinators in this way will help researchers better understand pollination ecology. The increased efficiency of our hybrid approach paves the way for the application of deep learning-based techniques to animal tracking in real-time using low-powered devices suitable for continuous monitoring."																				
2020	"Ravoor, Prashanth C.; T.s.b., Sudarshan"	Deep Learning Methods for Multi-Species Animal Re-identification and Tracking – a Survey	Images	CNN	Classification	Computer Science Review	38		100289	10.1016/j.cosrev.2020.100289	https://www.sciencedirect.com/science/article/pii/S1574013720303890	"Technology has an important part to play in wildlife and ecosystem conservation, and can vastly reduce time and effort spent in the associated tasks. Deep learning methods for computer vision in particular show good performance on a variety of tasks; animal detection and classification using deep learning networks are widely used to assist ecological studies. A related challenge is tracking animal movement over multiple cameras. For effective animal movement tracking, it is necessary to distinguish between individuals of the same species to correctly identify an individual moving between two cameras. Such problems could potentially be solved through animal re-identification methods. In this paper, the applicability of existing animal re-identification techniques for fully automated individual animal tracking in a cross-camera setup is explored. Recent developments in animal re-identification in the context of open-set recognition of individuals, and the extension of these systems to multiple species is examined. Some of the best performing human re-identification and object tracking systems are also reviewed in view of extending ideas within them to individual animal tracking. The survey concludes by presenting common trends in re-identification methods, lists a few challenges in the domain and recommends possible solutions."																				
2020	"Reiman, Derek; Metwally, Ahmed A.; Sun, Jun; Dai, Yang"	PopPhy-CNN: A Phylogenetic Tree Embedded Architecture for Convolutional Neural Networks to Predict Host Phenotype From Metagenomic Data	Other	CNN	Classification	IEEE Journal of Biomedical and Health Informatics	24	10	2993-3001	10.1109/JBHI.2020.2993761	https://ieeexplore.ieee.org/document/9091025	"Accurate prediction of the host phenotype from a metagenomic sample and identification of the associated microbial markers are important in understanding potential host-microbiome interactions related to disease initiation and progression. We introduce PopPhy-CNN, a novel convolutional neural network (CNN) learning framework that effectively exploits phylogenetic structure in microbial taxa for host phenotype prediction. Our approach takes an input format of a 2D matrix representing the phylogenetic tree populated with the relative abundance of microbial taxa in a metagenomic sample. This conversion empowers CNNs to explore the spatial relationship of the taxonomic annotations on the tree and their quantitative characteristics in metagenomic data. We show the competitiveness of our model compared to other available methods using nine metagenomic datasets of moderate size for binary classification. With synthetic and biological datasets, we show the superior and robust performance of our model for multi-class classification. Furthermore, we design a novel scheme for feature extraction from the learned CNN models and demonstrate improved performance when the extracted features. PopPhy-CNN is a practical deep learning framework for the prediction of host phenotype with the ability of facilitating the retrieval of predictive microbial taxa."																				
2020	"Renò, Vito; Losapio, Gianvito; Forenza, Flavio; Politi, Tiziano; Stella, Ettore; Fanizza, Carmelo; Hartman, Karin; Carlucci, Roberto; Dimauro, Giovanni; Maglietta, Rosalia"	Combined Color Semantics and Deep Learning for the Automatic Detection of Dolphin Dorsal Fins	Images	CNN	Classification	Electronics	9	5	758	10.3390/electronics9050758	https://www.mdpi.com/2079-9292/9/5/758	"Photo-identification is a widely used non-invasive technique in biological studies for understanding if a specimen has been seen multiple times only relying on specific unique visual characteristics. This information is essential to infer knowledge about the spatial distribution, site fidelity, abundance or habitat use of a species. Today there is a large demand for algorithms that can help domain experts in the analysis of large image datasets. For this reason, it is straightforward that the problem of identify and crop the relevant portion of an image is not negligible in any photo-identification pipeline. This paper approaches the problem of automatically cropping cetaceans images with a hybrid technique based on domain analysis and deep learning. Domain knowledge is applied for proposing relevant regions with the aim of highlighting the dorsal fins, then a binary classification of fin vs. no-fin is performed by a convolutional neural network. Results obtained on real images demonstrate the feasibility of the proposed approach in the automated process of large datasets of Risso’s dolphins photos, enabling its use on more complex large scale studies. Moreover, the results of this study suggest to extend this methodology to biological investigations of different species."																				
2020	"Romero, Ingrid C.; Kong, Shu; Fowlkes, Charless C.; Jaramillo, Carlos; Urban, Michael A.; Oboh-Ikuenobe, Francisca; D’Apolito, Carlos; Punyasena, Surangi W."	Improving the taxonomy of fossil pollen using convolutional neural networks and superresolution microscopy	Images	CNN	Classification	Proceedings of the National Academy of Sciences	117	45	28496-28505	10.1073/pnas.2007324117	https://www.pnas.org/doi/10.1073/pnas.2007324117	"Significance   We demonstrate that combining optical superresolution imaging with deep learning classification methods increases the speed and accuracy of assessing the biological affinities of fossil pollen taxa. We show that it is possible to taxonomically separate pollen grains that appear morphologically similar under standard light microscopy based on nanoscale variation in pollen shape, texture, and wall structure. Using a single pollen morphospecies, Striatopollis catatumbus  , we show that nanoscale morphological variation within the fossil taxon coincides with paleobiogeographic distributions. This new approach improves the taxonomic resolution of fossil pollen identifications and greatly enhances the use of pollen data in ecological and evolutionary research."																				
2020	"Ruff, Zachary J.; Lesmeister, Damon B.; Duchac, Leila S.; Padmaraju, Bharath K.; Sullivan, Christopher M."	Automated identification of avian vocalizations with deep convolutional neural networks	Sound	CNN	Classification	Remote Sensing in Ecology and Conservation	6	1	79-92	10.1002/rse2.125	https://onlinelibrary.wiley.com/doi/abs/10.1002/rse2.125	"Passive acoustic monitoring is an emerging approach to wildlife monitoring that leverages recent improvements in automated recording units and other technologies. A central challenge of this approach is the task of locating and identifying target species vocalizations in large volumes of audio data. To address this issue, we developed an efficient data processing pipeline using a deep convolutional neural network (CNN) to automate the detection of owl vocalizations in spectrograms generated from unprocessed field recordings. While the project was initially focused on spotted and barred owls, we also trained the network to recognize northern saw-whet owl, great horned owl, northern pygmy-owl, and western screech-owl. Although classification performance varies across species, initial results are promising. Recall, or the proportion of calls in the dataset that are detected and correctly identified, ranged from 63.1% for barred owl to 91.5% for spotted owl based on raw network output. Precision, the rate of true positives among apparent detections, ranged from 0.4% for spotted owl to 77.1% for northern saw-whet owl based on raw output. In limited tests, the CNN performed as well as or better than human technicians at detecting owl calls. Our model output is suitable for developing species encounter histories for occupancy models and other analyses. We believe our approach is sufficiently general to support long-term, large-scale monitoring of a broad range of species beyond our target species list, including birds, mammals, and others."																				
2020	"Salido, Jesús; Sánchez, Carlos; Ruiz-Santaquiteria, Jesús; Cristóbal, Gabriel; Blanco, Saul; Bueno, Gloria"	A Low-Cost Automated Digital Microscopy Platform for Automatic Identification of Diatoms	Images	CNN	"Classification, Regression"	Applied Sciences	10	17	6033	10.3390/app10176033	https://www.mdpi.com/2076-3417/10/17/6033	"Currently, microalgae (i.e., diatoms) constitute a generally accepted bioindicator of water quality and therefore provide an index of the status of biological ecosystems. Diatom detection for specimen counting and sample classification are two difficult time-consuming tasks for the few existing expert diatomists. To mitigate this challenge, in this work, we propose a fully operative low-cost automated microscope, integrating algorithms for: (1) stage and focus control, (2) image acquisition (slide scanning, stitching, contrast enhancement), and (3) diatom detection and a prospective specimen classification (among 80 taxa). Deep learning algorithms have been applied to overcome the difficult selection of image descriptors imposed by classical machine learning strategies. With respect to the mentioned strategies, the best results were obtained by deep neural networks with a maximum precision of 86% (with the YOLO network) for detection and 99.51% for classification, among 80 different species (with the AlexNet network). All the developed operational modules are integrated and controlled by the user from the developed graphical user interface running in the main controller. With the developed operative platform, it is noteworthy that this work provides a quite useful toolbox for phycologists in their daily challenging tasks to identify and classify diatoms."																				
2020	"Salman, Ahmad; Siddiqui, Shoaib Ahmad; Shafait, Faisal; Mian, Ajmal; Shortis, Mark R; Khurshid, Khawar; Ulges, Adrian; Schwanecke, Ulrich"	Automatic fish detection in underwater videos by a deep neural network-based hybrid motion learning system	Video	CNN	Regression	ICES Journal of Marine Science	77	4	1295-1307	10.1093/icesjms/fsz025	https://academic.oup.com/icesjms/article/77/4/1295/5366225?login=false	"It is interesting to develop effective fish sampling techniques using underwater videos and image processing to automatically estimate and consequently monitor the fish biomass and assemblage in water bodies. Such approaches should be robust against substantial variations in scenes due to poor luminosity, orientation of fish, seabed structures, movement of aquatic plants in the background and image diversity in the shape and texture among fish of different species. Keeping this challenge in mind, we propose a unified approach to detect freely moving fish in unconstrained underwater environments using a Region-Based Convolutional Neural Network, a state-of-the-art machine learning technique used to solve generic object detection and localization problems. To train the neural network, we employ a novel approach to utilize motion information of fish in videos via background subtraction and optical flow, and subsequently combine the outcomes with the raw image to generate fish-dependent candidate regions. We use two benchmark datasets extracted from a large Fish4Knowledge underwater video repository, Complex Scenes dataset and the LifeCLEF 2015 fish dataset to validate the effectiveness of our hybrid approach. We achieve a detection accuracy (F-Score) of 87.44% and 80.02% respectively on these datasets, which advocate the utilization of our approach for fish detection task."																				
2020	"Sanchez, Théophile; Cury, Jean; Charpiat, Guillaume; Jay, Flora"	"Deep learning for population size history inference: Design, comparison and combination with approximate Bayesian computation"	Molecular	CNN	Regression	Molecular Ecology Resources			1755-0998.13224	10.1111/1755-0998.13224	https://onlinelibrary.wiley.com/doi/abs/10.1111/1755-0998.13224	"For the past decades, simulation-based likelihood-free inference methods have enabled researchers to address numerous population genetics problems. As the richness and amount of simulated and real genetic data keep increasing, the field has a strong opportunity to tackle tasks that current methods hardly solve. However, high data dimensionality forces most methods to summarize large genomic data sets into a relatively small number of handcrafted features (summary statistics). Here, we propose an alternative to summary statistics, based on the automatic extraction of relevant information using deep learning techniques. Specifically, we design artificial neural networks (ANNs) that take as input single nucleotide polymorphic sites (SNPs) found in individuals sampled from a single population and infer the past effective population size history. First, we provide guidelines to construct artificial neural networks that comply with the intrinsic properties of SNP data such as invariance to permutation of haplotypes, long scale interactions between SNPs and variable genomic length. Thanks to a Bayesian hyperparameter optimization procedure, we evaluate the performance of multiple networks and compare them to well-established methods like Approximate Bayesian Computation (ABC). Even without the expert knowledge of summary statistics, our approach compares fairly well to an ABC approach based on handcrafted features. Furthermore, we show that combining deep learning and ABC can improve performance while taking advantage of both frameworks. Finally, we apply our approach to reconstruct the effective population size history of cattle breed populations"																				
2020	"Sanga, S. L.; Machuve, D.; Jomanga, K."	Mobile-based Deep Learning Models for Banana Disease Detection	Images	CNN	Classification	"Engineering, Technology & Applied Science Research"	10	3	5674-5677	10.48084/etasr.3452	https://etasr.com/index.php/ETASR/article/view/3452	"In Tanzania, smallholder farmers contribute significantly to banana production and Kagera, Mbeya, and Arusha are among the leading regions. However, pests and diseases are a threat to food security. Early detection of banana diseases is important to identify the diseases before too much damage is done on the plants. In this paper, a tool for early detection of banana diseases by using a deep learning approach is proposed. Five deep learning architectures, namely Vgg16, Resnet18, Resnet50, Resnet152 and InceptionV3 were used to develop models for banana disease detection, achieving all high accuracies, varying from 95.41% for InceptionV3 to 99.2% for Resnet152. InceptionV3 was selected for mobile deployment because it demands much less memory. The developed tool was capable of detecting diseases with a confidence of 99% of the captured leaves from the real environment. This tool will help smallholder farmers conduct early detection of banana diseases and improve their productivity."																				
2020	"Satoto, Budi Dwi; Utoyo, Imam; Rulaningtyas, Riries; Khoendori, Eko Budi"	An improvement of Gram-negative bacteria identification using convolutional neural network with fine tuning	Images	CNN	Classification	TELKOMNIKA (Telecommunication Computing Electronics and Control)	18	3	1397	10.12928/telkomnika.v18i3.14890	http://journal.uad.ac.id/index.php/TELKOMNIKA/article/view/14890	"This paper proposes an image processing approach to identify Gram-negative bacteria. Gram-negative bacteria are one of the bacteria that cause lung lobe damage-bacterial samples obtained through smears of the patient's sputum. The first step bacterium should pass the pathogen test process. After that, it bred using Mc Conkey's media. The problem faced is that the process of identifying bacterial objects is still done manually under a fluorescence microscope. The contributions offered from this research are focused on observing bacterial morphology for the operation of selecting shape features. The proposed method is a convolutional neural network with fine-tuning. In the stages of the process, a convolutional neural network of the VGG-16 architecture used dropout, data augmentation, and fine-tuning stages. The main goal of the current research was to determine the method selection is to get a high degree of accuracy. This research uses a total sample of 2520 images from 2 different classes. The amount of data used at each stage of training, testing, and validation is 840 images with dimensions of 256x256 pixels, a resolution of 96 points per inch, and a depth of 24 bits. The accuracy of the results obtained at the training stage is 99.20%."																				
2020	"Schneider, Stefan; Greenberg, Saul; Taylor, Graham W.; Kremer, Stefan C."	Three critical factors affecting automated image species recognition performance for camera traps	Images	CNN	Classification	Ecology and Evolution	10	7	3503-3517	10.1002/ece3.6147	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.6147	"Ecological camera traps are increasingly used by wildlife biologists to unobtrusively monitor an ecosystems animal population. However, manual inspection of the images produced is expensive, laborious, and time-consuming. The success of deep learning systems using camera trap images has been previously explored in preliminary stages. These studies, however, are lacking in their practicality. They are primarily focused on extremely large datasets, often millions of images, and there is little to no focus on performance when tasked with species identification in new locations not seen during training. Our goal was to test the capabilities of deep learning systems trained on camera trap images using modestly sized training data, compare performance when considering unseen background locations, and quantify the gradient of lower bound performance to provide a guideline of data requirements in correspondence to performance expectations. We use a dataset provided by Parks Canada containing 47,279 images collected from 36 unique geographic locations across multiple environments. Images represent 55 animal species and human activity with high-class imbalance. We trained, tested, and compared the capabilities of six deep learning computer vision networks using transfer learning and image augmentation: DenseNet201, Inception-ResNet-V3, InceptionV3, NASNetMobile, MobileNetV2, and Xception. We compare overall performance on “trained” locations where DenseNet201 performed best with 95.6% top-1 accuracy showing promise for deep learning methods for smaller scale research efforts. Using trained locations, classifications with <500 images had low and highly variable recall of 0.750 ± 0.329, while classifications with over 1,000 images had a high and stable recall of 0.971 ± 0.0137. Models tasked with classifying species from untrained locations were less accurate, with DenseNet201 performing best with 68.7% top-1 accuracy. Finally, we provide an open repository where ecologists can insert their image data to train and test custom species detection models for their desired ecological domain."																				
2020	"Sethi, Sarab S.; Jones, Nick S.; Fulcher, Ben D.; Picinali, Lorenzo; Clink, Dena Jane; Klinck, Holger; Orme, C. David L.; Wrege, Peter H.; Ewers, Robert M."	Characterizing soundscapes across diverse ecosystems using a universal acoustic feature set	Sound	CNN	Modeling	Proceedings of the National Academy of Sciences	117	29	17049-17055	10.1073/pnas.2004702117	https://www.pnas.org/doi/10.1073/pnas.2004702117	"Significance  Human pressures are causing natural ecosystems to change at an unprecedented rate. Understanding these changes is important (e.g., to inform policy decisions), but we are hampered by the slow, labor-intensive nature of traditional ecological surveys. In this study, we show that automated analysis of the sounds of an ecosystem—its soundscape—enables rapid and scalable ecological monitoring. We used a neural network to calculate fingerprints of soundscapes from a variety of ecosystems. From these acoustic fingerprints we could accurately predict habitat quality and biodiversity across multiple scales and automatically identify anomalous sounds such as gunshots and chainsaws. Crucially, our approach generalized well across ecosystems, offering promise as a backbone technology for global monitoring efforts."																				
2020	"Sevillano, Víctor; Holt, Katherine; Aznarte, José L."	Precise automatic classification of 46 different pollen types with convolutional neural networks	Images	CNN	Classification	PLOS ONE	15	6	e0229751	10.1371/journal.pone.0229751	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0229751	"In palynology, the visual classification of pollen grains from different species is a hard task which is usually tackled by human operators using microscopes. Many industries, including medical and pharmaceutical, rely on the accuracy of this manual classification process, which is reported to be around 67%. In this paper, we propose a new method to automatically classify pollen grains using deep learning techniques that improve the correct classification rates in images not previously seen by the models. Our proposal manages to properly classify up to 98% of the examples from a dataset with 46 different classes of pollen grains, produced by the Classifynder classification system. This is an unprecedented result which surpasses all previous attempts both in accuracy and number and difficulty of taxa under consideration, which include types previously considered as indistinguishable."																				
2020	"Shepley, Andrew; Falzon, Greg; Meek, Paul; Kwan, Paul"	Location Invariant Animal Recognition Using Mixed Source Datasets and Deep Learning	Images	CNN	Classification	bioRxiv				10.1101/2020.05.13.094896	http://biorxiv.org/lookup/doi/10.1101/2020.05.13.094896	"A time-consuming challenge faced by camera trap practitioners all over the world is the extraction of meaningful data from images to inform ecological management. The primary methods of image processing used by practitioners includes manual analysis and citizen science. An increasingly popular alternative is automated image classification software. However, most automated solutions are not sufficiently robust to be deployed on a large scale. Key challenges include limited access to images for each species and lack of location invariance when transferring models between sites. This prevents optimal use of ecological data and results in significant expenditure of time and resources to annotate and retrain deep learning models. In this study, we aimed to (a) assess the value of publicly available non-iconic FlickR images in the training of deep learning models for camera trap object detection, (b) develop an out-of-the-box location invariant automated camera trap image processing solution for ecologist using deep transfer learning and (c) explore the use of small subsets of camera trap images in optimisation of a FlickR trained deep learning model for high precision ecological object detection. We collected and annotated a dataset of images of “pigs” ( Sus scrofa and Phacochoerus africanus) from the consumer image sharing website FlickR. These images were used to achieve transfer learning using a RetinaNet model in the task of object detection. We compared the performance of this model to the performance of models trained on combinations of camera trap images obtained from five different projects, each characterised by 5 different geographical regions. Furthermore, we explored optimisation of the FlickR model via infusion of small subsets of camera trap images to increase robustness in difficult images. In most cases, the mean Average Precision (mAP) of the FlickR trained model when tested on out of sample camera trap sites (67.21-91.92%) was significantly higher than the mAP achieved by models trained on only one geographical location (4.42-90.8%) and rivalled the mAP of models trained on mixed camera trap datasets (68.96-92.75%). The infusion of camera trap images into the FlickR training further improved AP by 5.10-22.32% to 83.60-97.02%. Ecology researchers can use FlickR images in the training of automated deep learning solutions for camera trap image processing to significantly reduce time and resource expenditure by allowing the development of location invariant, highly robust out-of-the-box solutions. This would allow AI technologies to be deployed on a large scale in ecological applications."																				
2020	"Shiu, Yu; Palmer, K. J.; Roch, Marie A.; Fleishman, Erica; Liu, Xiaobai; Nosal, Eva-Marie; Helble, Tyler; Cholewiak, Danielle; Gillespie, Douglas; Klinck, Holger"	Deep neural networks for automated detection of marine mammal species	Sound	"CNN, RNN"	Classification	Scientific Reports	10	1	607	10.1038/s41598-020-57549-y	https://www.nature.com/articles/s41598-020-57549-y	"Deep neural networks have advanced the field of detection and classification and allowed for effective identification of signals in challenging data sets. Numerous time-critical conservation needs may benefit from these methods. We developed and empirically studied a variety of deep neural networks to detect the vocalizations of endangered North Atlantic right whales (Eubalaena glacialis). We compared the performance of these deep architectures to that of traditional detection algorithms for the primary vocalization produced by this species, the upcall. We show that deep-learning architectures are capable of producing false-positive rates that are orders of magnitude lower than alternative algorithms while substantially increasing the ability to detect calls. We demonstrate that a deep neural network trained with recordings from a single geographic region recorded over a span of days is capable of generalizing well to data from multiple years and across the species’ range, and that the low false positives make the output of the algorithm amenable to quality control for verification. The deep neural networks we developed are relatively easy to implement with existing software, and may provide new insights applicable to the conservation of endangered species."																				
2020	"Siekiera, Julia; Kramer, Stefan"	Deep Unsupervised Identification of Selected SNPs between Adapted Populations on Pool-seq Data	Molecular	CNN	Classification	"arXiv:2101.00004 [cs, q-bio]"				10.48550/arXiv.2101.00004	http://arxiv.org/abs/2101.00004	"The exploration of selected single nucleotide polymorphisms (SNPs) to identify genetic diversity between different sequencing population pools (Pool-seq) is a fundamental task in genetic research. As underlying sequence reads and their alignment are error-prone and univariate statistical solutions only take individual positions of the genome into account, the identification of selected SNPs remains a challenging process. Deep learning models like convolutional neural networks (CNNs) are able to consider large input areas in their decisions. We suggest an unsupervised pipeline to be independent of a rarely known ground truth. We train a supervised discriminator CNN to distinguish alignments from different populations and utilize the model for unsupervised SNP calling by applying explainable artificial intelligence methods. Our proposed multivariate method is based on two main assumptions: We assume (i) that instances having a high predictive certainty of being distinguishable are likely to contain genetic variants, and (ii) that selected SNPs are located at regions with input features having the highest influence on the model's decision process. We directly compare our method with statistical results on two different Pool-seq datasets and show that our solution is able to extend statistical results"																				
2020	"Sil, Sanchita; Mukherjee, Ria; Kumbhar, Dipak; Reghu, Dhanya; Shrungar, Divya; Kumar, Nallaperumal Shunmuga; Singh, Upendra Kumar; Umapathy, Siva"	Raman spectroscopy and artificial intelligence open up accurate detection of pathogens from DNA-based sub-species level classification	Other	CNN	Classification	Journal of Raman Spectroscopy	52	12	2648-2659	10.1002/jrs.6115	https://onlinelibrary.wiley.com/doi/abs/10.1002/jrs.6115	"Genomic deoxyribounucleic acid (DNA) extracted from Brucella and Bacillus genera including Bacillus anthracis was investigated for the first time using Raman spectroscopy coupled with deep learning technique. Since DNA sequence is unique and independent of growth phases of bacteria, Raman spectroscopy can be a potential molecular diagnostic tool to identify different pathogens. Additionally, pure cellular components such as DNA provide pure Raman spectra and are not corrupted by spectral features from other cell components which is usually the case in whole organism detection. In this work, 15 DNA samples (two from Brucella genus and 13 from Bacillus genus) were studied. Raman signatures revealed unique features for Brucella and Bacillus genus bacteria. We propose an artificial intelligence (AI) based method, convolutional neural network (CNN) to discriminate all 15 DNA samples. The results reveal that Bacillus anthracis has distinct Raman DNA signatures compared to Bacillus cereus and Bacillus thuringiensis and could be discriminated from the latter two using principal component analysis (PCA), hierarchical cluster analysis (HCA), principal component-linear discriminant analysis (PC-LDA). In addition to these multivariate analysis techniques, we show that using convolutional neural network (CNN) architecture all 15 DNA samples could be discriminated with 100% accuracy."																				
2020	"Sulc, Milan; Picek, Lukas; Matas, Jiri; Jeppesen, Thomas S.; Heilmann-Clausen, Jacob"	Fungi Recognition: A Practical Use Case	Images	CNN	Classification	2020 IEEE Winter Conference on Applications of Computer Vision (WACV)			2305-2313	10.1109/WACV45572.2020.9093624	https://ieeexplore.ieee.org/document/9093624/	"The paper presents a system for visual recognition of 1394 fungi species based on deep convolutional neural networks and its deployment in a citizen-science project. The system allows users to automatically identify observed specimens, while providing valuable data to biologists and computer vision researchers. The underlying classification method scored first in the FGVCx Fungi Classification Kaggle competition organized in connection with the Fine-Grained Visual Categorization (FGVC) workshop at CVPR 2018. We describe our winning submission and evaluate all technicalities that increased the recognition scores, and discuss the issues related to deployment of the system via the web- and mobile- interfaces"																				
2020	"Sumruayphol, Suchada; Siribat, Praphaiphat; Dujardin, Jean-Pierre; Dujardin, Sébastien; Komalamisra, Chalit; Thaenkham, Urusa"	"Fasciola gigantica, F. hepatica and Fasciola intermediate forms: geometric morphometrics and an artificial neural network to help morphological identification"	"Images, Other"	DNN	Classification	PeerJ	8		e8597	10.7717/peerj.8597	https://peerj.com/articles/8597	"Background Fasciola hepatica and F. gigantica cause fascioliasis in both humans and livestock. Some adult specimens of Fasciola sp. referred to as “intermediate forms” based on their genetic traits, are also frequently reported. Simple morphological criteria are unreliable for their specific identification. In previous studies, promising phenotypic identification scores were obtained using morphometrics based on linear measurements (distances, angles, curves) between anatomical features. Such an approach is commonly termed “traditional” morphometrics, as opposed to “modern” morphometrics, which is based on the coordinates of anatomical points. Methods Here, we explored the possible improvements that modern methods of morphometrics, including landmark-based and outline-based approaches, could bring to solving the problem of the non-molecular identification of these parasites. F. gigantica and Fasciola intermediate forms suitable for morphometric characterization were selected from Thai strains following their molecular identification. Specimens of F. hepatica were obtained from the Liverpool School of Tropical Medicine (UK). Using these three taxa, we tested the taxonomic signal embedded in traditional linear measurements versus the coordinates of anatomical points (landmark- and outline-based approaches). Various statistical techniques of validated reclassification were used, based on either the shortest Mahalanobis distance, the maximum likelihood, or the artificial neural network method. Results Our results revealed that both traditional and modern morphometric approaches can help in the morphological identification of Fasciola sp. We showed that the accuracy of the traditional approach could be improved by selecting a subset of characters among the most contributive ones. The influence of size on discrimination by shape was much more important in traditional than in modern analyses. In our study, the modern approach provided different results according to the type of data: satisfactory when using pseudolandmarks (outlines), less satisfactory when using landmarks. The different reclassification methods provided approximately similar scores, with a special mention to the neural network, which allowed improvements in accuracy by combining data from both morphometric approaches. Conclusion We conclude that morphometrics, whether traditional or modern, represent a valuable tool to assist in Fasciola species recognition. The general level of accuracy is comparable among the various methods, but their demands on skills and time differ. Based on the outline method, our study could provide the first description of the shape differences between species, highlighting the more globular contours of the intermediate forms."																				
2020	"Sundaram, Divya Meena; Loganathan, Agilandeeswari"	A new supervised clustering framework using multi discriminative parts and expectation-maximization approach for a fine-grained animal breed classification (SC-MPEM)	Images	CNN	Classification	Neural Processing Letters	52	1	727–766	10.1007/s11063-020-10246-3	https://doi.org/10.1007/s11063-020-10246-3	"Fine-grained image classification is active research in the field of computer vision. Specifically, animal breed classification is an arduous task due to the challenges in camera traps images like occlusion, camouflage, poor illumination, pose variation, etc. In this paper, we propose a fine-grained animal breed classification model using supervised clustering based on Multi Part-Convolutional Neural Network (MP-CNN) and Expectation–Maximization (EM) clustering. The proposed model follows a straightforward pipeline that combines the deep feature extraction using the CNN pre-trained on ImageNet and classifies unsupervised data using EM clustering. Further, we also propose a multi discriminative part selection and detection for the precise classification of animal breeds without using bounding box and annotations on both training and testing phases. The model is tested on several benchmark datasets for animals, including the largest camera trap Snapshot Serengeti dataset and has achieved a cumulative accuracy of 98.4%. The results from the proposed model strengthen the belief that supervised training of deep CNN on a large and versatile dataset, extracts better features than most of the traditional approaches, even for the unsupervised tasks."																				
2020	"Tabak, Michael A.; Norouzzadeh, Mohammad S.; Wolfson, David W.; Newton, Erica J.; Boughton, Raoul K.; Ivan, Jacob S.; Odell, Eric A.; Newkirk, Eric S.; Conrey, Reesa Y.; Stenglein, Jennifer; Iannarilli, Fabiola; Erb, John; Brook, Ryan K.; Davis, Amy J.; Lewis, Jesse; Walsh, Daniel P.; Beasley, James C.; VerCauteren, Kurt C.; Clune, Jeff; Miller, Ryan S."	Improving the accessibility and transferability of machine learning algorithms for identification of animals in camera trap images: MLWIC2	Images	CNN	Classification	Ecology and Evolution	10	19	10374-10383	10.1002/ece3.6692	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.6692	"Motion-activated wildlife cameras (or “camera traps”) are frequently used to remotely and noninvasively observe animals. The vast number of images collected from camera trap projects has prompted some biologists to employ machine learning algorithms to automatically recognize species in these images, or at least filter-out images that do not contain animals. These approaches are often limited by model transferability, as a model trained to recognize species from one location might not work as well for the same species in different locations. Furthermore, these methods often require advanced computational skills, making them inaccessible to many biologists. We used 3 million camera trap images from 18 studies in 10 states across the United States of America to train two deep neural networks, one that recognizes 58 species, the “species model,” and one that determines if an image is empty or if it contains an animal, the “empty-animal model.” Our species model and empty-animal model had accuracies of 96.8% and 97.3%, respectively. Furthermore, the models performed well on some out-of-sample datasets, as the species model had 91% accuracy on species from Canada (accuracy range 36%–91% across all out-of-sample datasets) and the empty-animal model achieved an accuracy of 91%–94% on out-of-sample datasets from different continents. Our software addresses some of the limitations of using machine learning to classify images from camera traps. By including many species from several locations, our species model is potentially applicable to many camera trap studies in North America. We also found that our empty-animal model can facilitate removal of images without animals globally. We provide the trained models in an R package (MLWIC2: Machine Learning for Wildlife Image Classification in R), which contains Shiny Applications that allow scientists with minimal programming experience to use trained models and train new models in six neural network architectures with varying depths."																				
2020	"Tang, Hui; Wang, Bin; Chen, Xin"	Deep learning techniques for automatic butterfly segmentation in ecological images	Images	"CNN, VAE"	Classification	Computers and Electronics in Agriculture	178		105739	10.1016/j.compag.2020.105739	https://www.sciencedirect.com/science/article/pii/S0168169920313491	"Automatic identification of butterfly species has attracted more and more attention due to the increasing demand for the accuracy and timeliness of butterfly species identification. Since the butterfly images we captured are usually ecological images, which not only have butterflies but also contain many irrelevant objects, such as leaves, flowers and other complex backgrounds. Therefore, segmenting butterflies from their ecological images is an issue that needs to be addressed prior to the tasks of identification and the segmentation quality directly affects the identification effect. However, the huge differences in butterflies, and the complexity of the natural environment make it very challenging to accurately segment butterflies from ecological images. Deep learning based methods are more promising for butterfly ecological image segmentation than traditional methods because they have powerful feature learning and representation ability. However, butterfly segmentation is still challenging when complex background interference occurs in images. To address this issue, we propose a dilated encoder network to capture more high-level features and get high-resolution output, which is both lightweight and accurate for automatic butterfly ecological image segmentation. In addition, we adopt the dice coefficient loss function to better balance the butterfly and non-butterfly regions. Experimental results on the public Leeds Butterfly dataset demonstrate that our method outperforms the state-of-the-art deep learning based image segmentation approaches."																				
2020	"Terry, J. Christopher D.; Roy, Helen E.; August, Tom A."	Thinking like a naturalist: Enhancing computer vision of citizen science images by harnessing contextual data	Images	CNN	Classification	Methods in Ecology and Evolution	11	2	303-315	10.1111/2041-210X.13335	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13335	"The accurate identification of species in images submitted by citizen scientists is currently a bottleneck for many data uses. Machine learning tools offer the potential to provide rapid, objective and scalable species identification for the benefit of many aspects of ecological science. Currently, most approaches only make use of image pixel data for classification. However, an experienced naturalist would also use a wide variety of contextual information such as the location and date of recording. Here, we examine the automated identification of ladybird (Coccinellidae) records from the British Isles submitted to the UK Ladybird Survey, a volunteer-led mass participation recording scheme. Each image is associated with metadata; a date, location and recorder ID, which can be cross-referenced with other data sources to determine local weather at the time of recording, habitat types and the experience of the observer. We built multi-input neural network models that synthesize metadata and images to identify records to species level. We show that machine learning models can effectively harness contextual information to improve the interpretation of images. Against an image-only baseline of 48.2%, we observe a 9.1 percentage-point improvement in top-1 accuracy with a multi-input model compared to only a 3.6% increase when using an ensemble of image and metadata models. This suggests that contextual data are being used to interpret an image, beyond just providing a prior expectation. We show that our neural network models appear to be utilizing similar pieces of evidence as human naturalists to make identifications. Metadata is a key tool for human naturalists. We show it can also be harnessed by computer vision systems. Contextualization offers considerable extra information, particularly for challenging species, even within small and relatively homogeneous areas such as the British Isles. Although complex relationships between disparate sources of information can be profitably interpreted by simple neural network architectures, there is likely considerable room for further progress. Contextualizing images has the potential to lead to a step change in the accuracy of automated identification tools, with considerable benefits for large-scale verification of submitted records."																				
2020	"Thompson, Peter; Brink, Willie"	Image identification of Protea species with attributes and subgenus scaling	Images	CNN	Classification	2020 IEEE Winter Conference on Applications of Computer Vision (WACV)			2094-2102	10.1109/WACV45572.2020.9093641	https://ieeexplore.ieee.org/document/9093641/	"The flowering plant genus Protea is a dominant representative for the biodiversity of the Cape Floristic Region in South Africa, and from a conservation point of view important to monitor. The recent surge in popularity of crowd-sourced wildlife monitoring platforms presents both challenges and opportunities for automatic image based species identification. We consider the problem of identifying the Protea species in a given image with additional (but optional) attributes linked to the observation, such as location and date. We collect training and test data from a crowd-sourced platform, and find that the Protea identification problem is exacerbated by considerable inter-class similarity, data scarcity, class imbalance, as well as large variations in image quality, composition and background. Our proposed solution consists of three parts. The first part incorporates a variant of multi-region attention into a pretrained convolutional neural network, to focus on the flower-head in the image. The second part performs coarser-grained classification on subgenera (superclasses) and then rescales the output of the first part. The third part conditions a probabilistic model on the additional attributes associated with the observation. We perform an ablation study on the proposed model and its constituents, and find that all three components together outperform our baselines and all other variants quite significantly."																				
2020	"Tiwari, Shamik"	A Comparative Study of Deep Learning Models With Handcraft Features and Non-Handcraft Features for Automatic Plant Species Identification	"Images, Other"	"DNN, CNN"	Classification	International Journal of Agricultural and Environmental Information Systems (IJAEIS)	11	2	44-57	10.4018/IJAEIS.2020040104	https://www.igi-global.com/gateway/article/249691	"The classification of plants is one of the most important aims for botanists since plants have a significant part in the natural life cycle. In this work, a leaf-based automatic plant classification framework is investigated. The aim is to compare two different deep learning approaches named Deep Ne..."																				
2020	"Torrisi, Mirko; Pollastri, Gianluca; Le, Quan"	Deep learning methods in protein structure prediction	NA	NA	Review	Computational and Structural Biotechnology Journal	18		1301-1310	10.1016/j.csbj.2019.12.011	https://www.sciencedirect.com/science/article/pii/S2001037019304441	"Protein Structure Prediction is a central topic in Structural Bioinformatics. Since the ’60s statistical methods, followed by increasingly complex Machine Learning and recently Deep Learning methods, have been employed to predict protein structural information at various levels of detail. In this review, we briefly introduce the problem of protein structure prediction and essential elements of Deep Learning (such as Convolutional Neural Networks, Recurrent Neural Networks and basic feed-forward Neural Networks they are founded on), after which we discuss the evolution of predictive methods for one-dimensional and two-dimensional Protein Structure Annotations, from the simple statistical methods of the early days, to the computationally intensive highly-sophisticated Deep Learning algorithms of the last decade. In the process, we review the growth of the databases these algorithms are based on, and how this has impacted our ability to leverage knowledge about evolution and co-evolution to achieve improved predictions. We conclude this review outlining the current role of Deep Learning techniques within the wider pipelines to predict protein structures and trying to anticipate what challenges and opportunities may arise next."																				
2020	"Troumbis, Ioannis A.; Tsekouras, George E.; Tsimikas, John; Kalloniatis, Christos; Haralambopoulos, Dias"	A Chebyshev polynomial feedforward neural network trained by differential evolution and its application in environmental case studies	Environmental	Other	Regression	Environmental Modelling & Software	126		104663	10.1016/j.envsoft.2020.104663	https://www.sciencedirect.com/science/article/pii/S1364815218309538	"This paper introduces a polynomial feedforward neural network based on Chebyshev polynomials able to effectively model non-linear and highly complex environmental data. The data sets were cautiously selected from the fields of biology, ecology, climate, and environmental management, and economics as to represent a scientifically meaningful and consistent corpus of disparate domains of intensive focus and interest in current ecological/environmental research, covering issues related to body growth/age, biomass production, energy efficiency/consumption, and ecology/geographic extension. The proposed network uses a number of layers to estimate the output in terms of a weighted sum of truncated Chebyshev series expansions applied to linear combinations of the input variables, and it is trained by the differential evolution algorithm. Its performance was compared to three neural networks. First, a polynomial feedforward network that uses Hermite polynomials as activation function in the hidden nodes; second, a radial basis function neural network; third, a Takagi-Sugeno-Kang neuro-fuzzy network. All the above networks were trained by evolutionary optimization algorithms. The comparison was carried out by standard criteria such as the root mean square error and the mean absolute error. Moreover, a non-parametric Kruskal-Wallis statistical test used to compare the median values of the root mean square errors between methods. The main experimental outcomes are: (a) the network's efficiency improves for higher polynomial orders, (b) the statistical analysis suggests that the proposed network appears to be very competitive to the other three networks."																				
2020	"van Dam, Elsbeth A.; Noldus, Lucas P.J.J.; van Gerven, Marcel A.J."	Deep learning improves automated rodent behavior recognition within a specific experimental setup	Video	CNN	Classification	Journal of Neuroscience Methods	332		108536	10.1016/j.jneumeth.2019.108536	https://linkinghub.elsevier.com/retrieve/pii/S0165027019303930	"Automated observation and analysis of rodent behavior is important to facilitate research progress in neuroscience and pharmacology. Available automated systems lack adaptivity and can benefit from advances in AI. In this work we compare a state-of-the-art conventional rat behavior recognition (RBR) system to an advanced deep learning method and evaluate its performance within and across experimental setups. We show that using a multi-fiber network (MF-Net) in conjunction with data augmentation strategies within-setup dataset performance improves over the conventional RBR system. Two new methods for video augmentation were used: video cutout and dynamic illumination change. However, we also show that improvements do not transfer to videos in different experimental setups, for which we discuss possible causes and cures."																				
2020	"Verly Lopes, Dercilio Junior; Burgreen, Greg W.; Entsminger, Edward D."	North American Hardwoods Identification Using Machine-Learning	Images	CNN	Classification	Forests	11	3	298	10.3390/f11030298	https://www.mdpi.com/1999-4907/11/3/298	"This technical note determines the feasibility of using an InceptionV4_ResNetV2 convolutional neural network (CNN) to correctly identify hardwood species from macroscopic images. The method is composed of a commodity smartphone fitted with a 14_ macro lens for photography. The end-grains of ten different North American hardwood species were photographed to create a dataset of 1869 images. The stratified 5-fold cross-validation machine-learning method was used, in which the number of testing samples varied from 341 to 342. Data augmentation was performed on-the-fly for each training set by rotating, zooming, and flipping images. It was found that the CNN could correctly identify hardwood species based on macroscopic images of its end-grain with an adjusted accuracy of 92.60%. With the current growing of machine-learning field, this model can then be readily deployed in a mobile application for field wood identification."																				
2020	"Vilasini, M.; Ramamoorthy, P."	CNN Approaches for Classification of Indian Leaf Species Using Smartphones	Images	"DNN, CNN"	Classification	"Computers, Materials & Continua"				10.32604/cmc.2020.08857	https://www.techscience.com/cmc/v62n3/38365	"Leaf species identification leads to multitude of societal applications. There is enormous research in the lines of plant identification using pattern recognition. With the help of robust algorithms for leaf identification, rural medicine has the potential to reappear as like the previous decades. This paper discusses CNN based approaches for Indian leaf species identification from white background using smartphones. Variations of CNN models over the features like traditional shape, texture, color and venation apart from the other miniature features of uniformity of edge patterns, leaf tip, margin and other statistical features are explored for efficient leaf classification."																				
2020	"Villon, Sébastien; Mouillot, David; Chaumont, Marc; Subsol, Gérard; Claverie, Thomas; Villéger, Sébastien"	A new method to control error rates in automated species identification with deep learning algorithms	Video	CNN	Classification	Scientific Reports	10	1	10972	10.1038/s41598-020-67573-7	http://www.nature.com/articles/s41598-020-67573-7	"Processing data from surveys using photos or videos remains a major bottleneck in ecology. Deep Learning Algorithms (DLAs) have been increasingly used to automatically identify organisms on images. However, despite recent advances, it remains difficult to control the error rate of such methods. Here, we proposed a new framework to control the error rate of DLAs. More precisely, for each species, a confidence threshold was automatically computed using a training dataset independent from the one used to train the DLAs. These species-specific thresholds were then used to post-process the outputs of the DLAs, assigning classification scores to each class for a given image including a new class called “unsure”. We applied this framework to a study case identifying 20 fish species from 13,232 underwater images on coral reefs. The overall rate of species misclassification decreased from 22% with the raw DLAs to 2.98% after post-processing using the thresholds defined to minimize the risk of misclassification. This new framework has the potential to unclog the bottleneck of information extraction from massive digital data while ensuring a high level of accuracy in biodiversity assessment."																				
2020	"Wagner, Fabien H.; Dalagnol, Ricardo; Tagle Casapia, Ximena; Streher, Annia S.; Phillips, Oliver L.; Gloor, Emanuel; Aragão, Luiz E. O. C."	Regional Mapping and Spatial Distribution Analysis of Canopy Palms in an Amazon Forest Using Deep Learning and VHR Images	Other	CNN	Modeling	Remote Sensing	12	14	2225	10.3390/rs12142225	https://www.mdpi.com/2072-4292/12/14/2225	"Mapping plant species at the regional scale to provide information for ecologists and forest managers is a challenge for the remote sensing community. Here, we use a deep learning algorithm called U-net and very high-resolution multispectral images (0.5 m) from GeoEye satellite to identify, segment and map canopy palms over _3000 km 2 of Amazonian forest. The map was used to analyse the spatial distribution of canopy palm trees and its relation to human disturbance and edaphic conditions. The overall accuracy of the map was 95.5% and the F1-score was 0.7. Canopy palm trees covered 6.4% of the forest canopy and were distributed in more than two million patches that can represent one or more individuals. The density of canopy palms is affected by human disturbance. The post-disturbance density in secondary forests seems to be related to the type of disturbance, being higher in abandoned pasture areas and lower in forests that have been cut once and abandoned. Additionally, analysis of palm trees’ distribution shows that their abundance is controlled naturally by local soil water content, avoiding both flooded and waterlogged areas near rivers and dry areas on the top of the hills. They show two preferential habitats, in the low elevation above the large rivers, and in the slope directly below the hill tops. Overall, their distribution over the region indicates a relatively pristine landscape, albeit within a forest that is critically endangered because of its location between two deforestation fronts and because of illegal cutting. New tree species distribution data, such as the map of all adult canopy palms produced in this work, are urgently needed to support Amazon species inventory and to understand their distribution and diversity."																				
2020	"Wang, Hongda; Ceylan Koydemir, Hatice; Qiu, Yunzhe; Bai, Bijie; Zhang, Yibo; Jin, Yiyin; Tok, Sabiha; Yilmaz, Enis Cagatay; Gumustekin, Esin; Rivenson, Yair; Ozcan, Aydogan"	Early detection and classification of live bacteria using time-lapse coherent imaging and deep learning	Images	CNN	Classification	Light: Science & Applications	9	1	118	10.1038/s41377-020-00358-9	https://www.nature.com/articles/s41377-020-00358-9	"Early identification of pathogenic bacteria in food, water, and bodily fluids is very important and yet challenging, owing to sample complexities and large sample volumes that need to be rapidly screened. Existing screening methods based on plate counting or molecular analysis present various tradeoffs with regard to the detection time, accuracy/sensitivity, cost, and sample preparation complexity. Here, we present a computational live bacteria detection system that periodically captures coherent microscopy images of bacterial growth inside a 60-mm-diameter agar plate and analyses these time-lapsed holograms using deep neural networks for the rapid detection of bacterial growth and the classification of the corresponding species. The performance of our system was demonstrated by the rapid detection of Escherichia coli and total coliform bacteria (i.e., Klebsiella aerogenes and Klebsiella pneumoniae subsp. pneumoniae) in water samples, shortening the detection time by >12_h compared to the Environmental Protection Agency (EPA)-approved methods. Using the preincubation of samples in growth media, our system achieved a limit of detection (LOD) of ~1 colony forming unit (CFU)/L in ≤9_h of total test time. This platform is highly cost-effective (~$0.6/test) and has high-throughput with a scanning speed of 24_cm2/min over the entire plate surface, making it highly suitable for integration with the existing methods currently used for bacteria detection on agar plates. Powered by deep learning, this automated and cost-effective live bacteria detection platform can be transformative for a wide range of applications in microbiology by significantly reducing the detection time and automating the identification of colonies without labelling or the need for an expert."																				
2020	"Wang, Kaidi; Chen, Lei; Ma, Xiangyun; Ma, Lina; Chou, Keng C.; Cao, Yankai; Khan, Izhar U. H.; Gölz, Greta; Lu, Xiaonan"	Arcobacter Identification and Species Determination Using Raman Spectroscopy Combined with Neural Networks	Other	CNN	Classification	Applied and Environmental Microbiology	86	20	e00924-20	10.1128/AEM.00924-20	https://journals.asm.org/doi/10.1128/AEM.00924-20	"Rapid identification of bacterial pathogens is critical for developing an early warning system and performing epidemiological investigation. Arcobacter  is an emerging foodborne pathogen and has become more important in recent decades. The incidence of Arcobacter  species in the agro-ecosystem is probably underestimated mainly due to the limitation in the available detection and characterization techniques. Raman spectroscopy combined with machine learning can accurately identify Arcobacter  at the species level in a rapid and reliable manner, providing a promising tool for epidemiological surveillance of this microbe in the agri-food chain. The knowledge elicited from this study has the potential to be used for routine bacterial screening and diagnostics by the government, food industry, and clinics."																				
2020	"Wang, Xiaoying"	A Neural Network Algorithm Based Assessment for Marine Ecological Environment	Environmental	DNN	Regression	Journal of Coastal Research	107	sp1	145-148	10.2112/JCR-SI107-037.1	https://bioone.org/journals/journal-of-coastal-research/volume-107/issue-sp1/JCR-SI107-037.1/A-Neural-Network-Algorithm-Based-Assessment-for-Marine-Ecological-Environment/10.2112/JCR-SI107-037.1.full	"Wang, X.-Y., 2020. A neural network algorithm based assessment for marine ecological environment. In: Qiu, Y.; Zhu, H., and Fang, X. (eds.), Current Advancements in Marine and Coastal Research for Technological and Sociological Applications. Journal of Coastal Research, Special Issue No. 107, pp. 145-148. Coconut Creek (Florida), ISSN 0749-0208.With the deepening of ocean development and utilization, marine ecology and marine environment have also been greatly influenced by human activities. Because the traditional comprehensive assessment method or theory of marine ecological environment is difficult to reveal and reflect the complex relationship between the influencing factors of marine ecological conditions, this paper adopts a more objective and practical comprehensive assessment method of marine ecological environment based on neural network algorithm. This paper first studies the method of marine ecological environment comprehensive assessment based on neural network algorithm, then analyzes the comparison between neural network model and other methods, and finally verifies the application effect of the model based on neural network algorithm in marine ecological environment comprehensive assessment."																				
2020	"Wang, Xudong; Lian, Long; Miao, Zhongqi; Liu, Ziwei; Yu, Stella X."	Long-tailed Recognition by Routing Diverse Distribution-Aware Experts	Images	CNN	Classification	arXiv				10.48550/arxiv.2010.01809	http://arxiv.org/abs/2010.01809	"Natural data are often long-tail distributed over semantic classes. Existing recognition methods tackle this imbalanced classification by placing more emphasis on the tail data, through class re-balancing/re-weighting or ensembling over different data groups, resulting in increased tail accuracies but reduced head accuracies. We take a dynamic view of the training data and provide a principled model bias and variance analysis as the training data fluctuates: Existing long-tail classifiers invariably increase the model variance and the head-tail model bias gap remains large, due to more and larger confusion with hard negatives for the tail. We propose a new long-tailed classifier called RoutIng Diverse Experts (RIDE). It reduces the model variance with multiple experts, reduces the model bias with a distribution-aware diversity loss, reduces the computational cost with a dynamic expert routing module. RIDE outperforms the state-of-the-art by 5% to 7% on CIFAR100-LT, ImageNet-LT and iNaturalist 2018 benchmarks. It is also a universal framework that is applicable to various backbone networks, long-tailed algorithms, and training mechanisms for consistent performance gains. Our code is available at: https://github.com/frank-xwang/RIDE-LongTailRecognition."																				
2020	"Wang, Xueting; Cheng, Jun; Wang, Lei"	A reinforcement learning-based predator-prey model	Images	CNN	Modeling	Ecological Complexity	42		100815	10.1016/j.ecocom.2020.100815	https://linkinghub.elsevier.com/retrieve/pii/S1476945X1930039X	"Classic population models can often predict the dynamics of biological populations in nature. However, the adaptation process and learning mechanism of species are rarely considered in the study of population dynamics, due to the complex interaction of species, seasonal variation, spatial distribution or other factors. We use reinforcement learning algorithms to improve the existing individual-based ecosystem simulation algorithms, which allows species to spontaneously adjust their strategies according to a short period of experience and then feed back to improve their abilities to make action decisions. Our results show that the reinforcement learning of predators is beneficial to the stability of the ecosystem, and predators can learn to spontaneously form hunting patterns that surround their prey. The learning of prey makes the ecosystem oscillate and meanwhile leads to a higher risk of extinction for predators. When individuals are more likely to die, these herbivores rely on reproductive behavior to maintain their populations; when individuals live longer, herbivores spend more time eating to maintain their own survival. The co-reinforcement learning of predators and prey helps predators to find a more suitable way to survive with their prey, that is, the number of predators is more stable and larger than when only predator or only prey learns."																				
2020	"Wang, Yaqing; Yao, Quanming; Kwok, James T.; Ni, Lionel M."	Generalizing from a few examples: a survey on few-shot learning	NA	NA	Review	ACM Computing Surveys	53	3	63:1–63:34	10.1145/3386252	https://doi.org/10.1145/3386252	"Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this article, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimizer is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications, and theories, are also proposed to provide insights for future research. 1"																				
2020	"Westerman, Erica L; Bowman, Sarah E J; Davidson, Bradley; Davis, Marcus C; Larson, Eric R; Sanford, Christopher P J"	Deploying Big Data to Crack the Genotype to Phenotype Code	NA	NA	Review	Integrative and Comparative Biology	60	2	385-396	10.1093/icb/icaa055	https://academic.oup.com/icb/article/60/2/385/5850862	"Synopsis  Mechanistically connecting genotypes to phenotypes is a longstanding and central mission of biology. Deciphering these connections will unite questions and datasets across all scales from molecules to ecosystems. Although high-throughput sequencing has provided a rich platform on which to launch this effort, tools for deciphering mechanisms further along the genome to phenome pipeline remain limited. Machine learning approaches and other emerging computational tools hold the promise of augmenting human efforts to overcome these obstacles. This vision paper is the result of a Reintegrating Biology Workshop, bringing together the perspectives of integrative and comparative biologists to survey challenges and opportunities in cracking the genotype to phenotype code and thereby generating predictive frameworks across biological scales. Key recommendations include promoting the development of minimum “best practices” for the experimental design and collection of data; fostering sustained and long-term data repositories; promoting programs that recruit, train, and retain a diversity of talent; and providing funding to effectively support these highly cross-disciplinary efforts. We follow this discussion by highlighting a few specific transformative research opportunities that will be advanced by these efforts."																				
2020	"White, Alexander E.; Dikow, Rebecca B.; Baugh, Makinnon; Jenkins, Abigail; Frandsen, Paul B."	Generating segmentation masks of herbarium specimens and a data set for training segmentation models using deep learning	Images	CNN	Classification	Applications in Plant Sciences	8	6		10.1002/aps3.11352	https://onlinelibrary.wiley.com/doi/abs/10.1002/aps3.11352	"Premise: Digitized images of herbarium specimens are highly diverse with many potential sources of visual noise and bias. The systematic removal of noise and minimization of bias must be achieved in order to generate biological insights based on the plants rather than the digitization and mounting practices involved. Here, we develop a workflow and data set of high-resolution image masks to segment plant tissues in herbarium specimen images and remove background pixels using deep learning. Methods and Results: We generated 400 curated, high-resolution masks of ferns using a combination of automatic and manual tools for image manipulation. We used those images to train a U-Net-style deep learning model for image segmentation, achieving a final Sørensen–Dice coefficient of 0.96. The resulting model can automatically, efficiently, and accurately segment massive data sets of digitized herbarium specimens, particularly for ferns. Conclusions: The application of deep learning in herbarium sciences requires transparent and systematic protocols for generating training data so that these labor-intensive resources can be generalized to other deep learning applications. Segmentation ground-truth masks are hard-won data, and we share these data and the model openly in the hopes of furthering model training and transfer learning opportunities for broader herbarium applications."																				
2020	"Wróbel, Anna; Gygax, Gregory; Schmid, Andi; Ott, Thomas"	Going for 2D or 3D? Investigating Various Machine Learning Approaches for Peach Variety Identification	Images	CNN	Classification	Artificial Neural Networks in Pattern Recognition	12294		257-265	10.1007/978-3-030-58309-5_21	http://link.springer.com/10.1007/978-3-030-58309-5_21	"Machine learning-based pattern recognition methods are about to revolutionize the farming sector. For breeding and cultivation purposes, the identification of plant varieties is a particularly important problem that involves specific challenges for the different crop species. In this contribution, we consider the problem of peach variety identification for which alternatives to DNA-based analysis are being sought. While a traditional procedure would suggest using manually designed shape descriptors as the basis for classification, the technical developments of the last decade have opened up possibilities for fully automated approaches, either based on 3D scanning technology or by employing deep learning methods for 2D image classification. In our feasibility study, we investigate the potential of various machine learning approaches with a focus on the comparison of methods based on 2D images and 3D scans. We provide and discuss first results, paving the way for future use of the methods in the field."																				
2020	"Xu, Weitao; Zhang, Xiang; Yao, Lina; Xue, Wanli; Wei, Bo"	A multi-view CNN-based acoustic classification system for automatic animal species identification	Sound	CNN	Classification	Ad Hoc Networks	102		102115	10.1016/j.adhoc.2020.102115	https://www.sciencedirect.com/science/article/pii/S1570870519308923	"Automatic identification of animal species by their vocalization is an important and challenging task. Although many kinds of audio monitoring system have been proposed in the literature, they suffer from several disadvantages such as non-trivial feature selection, accuracy degradation because of environmental noise or intensive local computation. In this paper, we propose a deep learning based acoustic classification framework for Wireless Acoustic Sensor Network (WASN). The proposed framework is based on cloud architecture which relaxes the computational burden on the wireless sensor node. To improve the recognition accuracy, we design a multi-view Convolution Neural Network (CNN) to extract the short-, middle-, and long-term dependencies in parallel. The evaluation on two real datasets shows that the proposed architecture can achieve high accuracy and outperforms traditional classification systems significantly when the environmental noise dominate the audio signal (low SNR). Moreover, we implement and deploy the proposed system on a testbed and analyse the system performance in real-world environments. Both simulation and real-world evaluation demonstrate the accuracy and robustness of the proposed acoustic classification system in distinguishing species of animals."																				
2020	"Yan, Haidong; Bombarely, Aureliano; Li, Song"	DeepTE: a computational method for de novo classification of transposons with convolutional neural network	Molecular	CNN	Classification	Bioinformatics	36	15	4269-4275	10.1093/bioinformatics/btaa519	https://academic.oup.com/bioinformatics/article/36/15/4269/5838183?login=false	"Transposable elements (TEs) classification is an essential step to decode their roles in genome evolution. With a large number of genomes from non-model species becoming available, accurate and efficient TE classification has emerged as a new challenge in genomic sequence analysis.We developed a novel tool, DeepTE, which classifies unknown TEs using convolutional neural networks (CNNs). DeepTE transferred sequences into input vectors based on k-mer counts. A tree structured classification process was used where eight models were trained to classify TEs into super families and orders. DeepTE also detected domains inside TEs to correct false classification. An additional model was trained to distinguish between non-TEs and TEs in plants. Given unclassified TEs of different species, DeepTE can classify TEs into seven orders, which include 15, 24 and 16 super families in plants, metazoans and fungi, respectively. In several benchmarking tests, DeepTE outperformed other existing tools for TE classification. In conclusion, DeepTE successfully leverages CNN for TE classification, and can be used to precisely classify TEs in newly sequenced eukaryotic genomes.DeepTE is accessible at https://github.com/LiLabAtVT/DeepTE.Supplementary data are available at Bioinformatics online."																				
2020	"Yang, Ling; Liu, Yeqi; Yu, Huihui; Fang, Xiaomin; Song, Lihua; Li, Daoliang; Chen, Yingyi"	Computer Vision Models in Intelligent Aquaculture with Emphasis on Fish Detection and Behavior Analysis: A Review	NA	NA	Review	Archives of Computational Methods in Engineering				10.1007/s11831-020-09486-2	http://link.springer.com/10.1007/s11831-020-09486-2	"Intelligence technologies play an important role in increasing product quality and production efficiency in digital aquaculture. Automatic fish detection will contribute to achieving intelligent production and scientific management in precision farming. Due to the availability and ubiquity of modern information technology, such as the internet of things, big data, and camera devices, computer vision techniques, as an essential branch of artificial intelligence, have emerged as a powerful tool for achieving automatic fish detection. At present, it has been widely used in fish species identification, counting, and behavior analysis. Nevertheless, computer vision modeling used for fish detection is riddled with many challenges, such as varies in illumination, low contrast, high noise, fish deformation, frequent occlusion, and dynamic background. Hence, this paper provides a comprehensive review of the computer vision model for fish detection under unique application scenarios. Firstly, the image acquisition system based on 2D and 3D is discussed. Further, many fish detection techniques are categorized as appearance-based, motion-based, and deep learning. In addition, applications of fish detection and public open-source datasets are also presented in the literature. Finally, the prominent findings and the directions of future research are addressed toward the advancement in the aquaculture field throughout the discussion and conclusion section"																				
2020	"Yang, Sang-Yun; Kwon, Ohkyung; Park, Yonggun; Chung, Hyunwoo; Kim, Hyunbin; Park, Se-Yeong; Choi, In-Gyu; Yeo, Hwanmyeong"	Application of neural networks for classifying softwood species using near infrared spectroscopy	Other	CNN	Classification	Journal of Near Infrared Spectroscopy	28	6-May	298-307	10.1177/0967033520939320	https://doi.org/10.1177/0967033520939320	"Lumber species identification is an important issue for the wood industry. In this study, three types of neural networks (artificial neural network (ANN), deep neural network (DNN), and convolutional neural network (CNN)) were employed for classifying softwood lumber species using NIR spectroscopy. The results show that CNN, which is based on deep learning, was more stable than the other neural networks. In particular, the stability of the training process was remarkably improved in CNN models. During the training procedure, the validation accuracy of the CNN model was 99.3% for the raw spectra, 99.9% for the standard normal variate (SNV) spectra and 100.0% for the Savitzky-Golay second derivative spectra. Interestingly, there was little difference in the validation accuracies among the CNN models depending on mathematical preprocessing. The results showed that CNN is sufficiently adequate to classify the softwood lumber species."																				
2020	"Ye, Sijing; Lu, Shuhan; Bai, Xuesong; Gu, Jinfeng"	ResNet-Locust-BN Network-Based Automatic Identification of East Asian Migratory Locust Species and Instars from RGB Images	Images	CNN	Classification	Insects	11	8	458	10.3390/insects11080458	https://www.mdpi.com/2075-4450/11/8/458	"Locusts are agricultural pests found in many parts of the world. Developing efficient and accurate locust information acquisition techniques helps in understanding the relation between locust distribution density and structural changes in locust communities. It also helps in understanding the hydrothermal and vegetation growth conditions that affect locusts in their habitats in various parts of the world as well as in providing rapid and accurate warnings on locust plague outbreak. This study is a preliminary attempt to explore whether the batch normalization-based convolutional neural network (CNN) model can be applied used to perform automatic classification of East Asian migratory locust (AM locust), Oxya chinensis (rice locusts), and cotton locusts. In this paper, we present a way of applying the CNN technique to identify species and instars of locusts using the proposed ResNet-Locust-BN model. This model is based on the ResNet architecture and involves introduction of a BatchNorm function before each convolution layer to improve the network’s stability, convergence speed, and classification accuracy. Subsequently, locust image data collected in the field were used as input to train the model. By performing comparison experiments of the activation function, initial learning rate, and batch size, we selected ReLU as the preferred activation function. The initial learning rate and batch size were set to 0.1 and 32, respectively. Experiments performed to evaluate the accuracy of the proposed ResNet-Locust-BN model show that the model can effectively distinguish AM locust from rice locusts (93.60% accuracy) and cotton locusts (97.80% accuracy). The model also performed well in identifying the growth status information of AM locusts (third-instar (77.20% accuracy), fifth-instar (88.40% accuracy), and adult (93.80% accuracy)) with an overall accuracy of 90.16%. This is higher than the accuracy scores obtained by using other typical models: AlexNet (73.68%), GoogLeNet (69.12%), ResNet 18 (67.60%), ResNet 50 (80.84%), and VggNet (81.70%). Further, the model has good robustness and fast convergence rate."																				
2020	"Zhang, Ce; Atkinson, Peter M.; George, Charles; Wen, Zhaofei; Diazgranados, Mauricio; Gerard, France"	Identifying and mapping individual plants in a highly diverse high-elevation ecosystem using UAV imagery and deep learning	Images	CNN	"Classification, Regression"	ISPRS Journal of Photogrammetry and Remote Sensing	169		280-291	10.1016/j.isprsjprs.2020.09.025	https://www.sciencedirect.com/science/article/pii/S0924271620302720	"The identification and counting of plant individuals is essential for environmental monitoring. UAV based imagery offer ultra-fine spatial resolution and flexibility in data acquisition, and so provide a great opportunity to enhance current plant and in-situ field surveying. However, accurate mapping of individual plants from UAV imagery remains challenging, given the great variation in the sizes and geometries of individual plants and in their distribution. This is true even for deep learning based semantic segmentation and classification methods. In this research, a novel Scale Sequence Residual U-Net (SS Res U-Net) deep learning method was proposed, which integrates a set of Residual U-Nets with a sequence of input scales that can be derived automatically. The SS Res U-Net classifies individual plants by continuously increasing the patch scale, with features learned at small scales passing gradually to larger scales, thus, achieving multi-scale information fusion while retaining fine spatial details of interest. The SS Res U-Net was tested to identify and map frailejones (all plant species of the subtribe Espeletiinae), the dominant plants in one of the world’s most biodiverse high-elevation ecosystems (i.e. the páramos) from UAV imagery. Results demonstrate that the SS Res U-Net has the ability to self-adapt to variation in objects, and consistently achieved the highest classification accuracy (91.67% on average) compared with four state-of-the-art benchmark approaches. In addition, SS Res U-Net produced the best performances in terms of both robustness to training sample size reduction and computational efficiency compared with the benchmarks. Thus, SS Res U-Net shows great promise for solving remotely sensed semantic segmentation and classification tasks, and more general machine intelligence. The prospective implementation of this method to identify and map frailejones in the páramos will benefit immensely the monitoring of their populations for conservation assessments and management, among many other applications."																				
2020	"Zhang, Shanwen; Huang, Wenzhun; Huang, Yu-an; Zhang, Chuanlei"	Plant species recognition methods using leaf image: Overview	NA	NA	Review	Neurocomputing	408		246-272	10.1016/j.neucom.2019.09.113	https://www.sciencedirect.com/science/article/pii/S0925231220304902	"Plant plays an important role in agricultural, industrial, medicine, environmental and ecological protection. Recently, with global warming, biodiversity loss, rapid urban development and environmental damage, people have been seriously destroying the natural environments, which results in that a large number of plant species constantly dying and even dying out every year. It is essential to protect plant species. The first step of protecting plants is to recognize them and understand what they are and where they come from. But there are a large number of plant species that have been named on Earth, and many are still unknown yet, it is difficult to identifiy each species. To handle such huge information, develop a quick and efficient classification method has become a significant research. Plant species can be recognized by its leaf, flower, skin, fruit and seed, etc. Relatively speaking, using leaf to recognize plant species is very simple and convenient, and many leaf based plant species recognition methods have been proposed. In this paper, we mainly summarize the existing leaf based plant species identification methods, including plant leaf characteristic, public databases, feature extraction based methods, subspace learning based methods, sparse representation based methods, and deep learning based methods. The aim is to emphasize the importance of plant species identification, train people to know about plant species, and provide guidance and comprehensive study for the beginners in this field, in turn, to treasure and protect plant species."																				
2020	"Zhao, Yafeng; Gao, Xuan; Hu, Junfeng; Chen, Zhen; Zhao, Yafeng; Gao, Xuan; Hu, Junfeng; Chen, Zhen"	Tree species identification based on the fusion of bark and leaves	Images	CNN	Classification	Mathematical Biosciences and Engineering	17	4	4018-4033	10.3934/mbe.2020222	http://www.aimspress.com/article/doi/10.3934/mbe.2020222	"For trees, leaves are often used for identification, but the shape of leaves changes greatly, bark will be another identifying feature. However, it is difficult to recognize by a single organ when there are intra class differences and inter class similarities between leaves or bark. So we fuse features of leaf and bark. Firstly, we collected 17 species of leaves and bark of trees through field shooting and web crawling. Then propose a method of combining convolution neural network (CNN) with cascade fusion, additive fusion algorithm, bilinear fusion and score level fusion. Finally, the features extracted from the leaves and bark are fused in the ReLu layer and Fully connected layer. The method was compared with single organ recognition, Support Vector Machines (SVM), and existing fusion methods, results show that the two organ fusion method proposed are better than the other recognition methods, and recognition accuracy is 87.86%. For similar trees, when it is impossible to accurately determine its species by a single organ, the fusion of two organs can effectively improve this situation."																				
2020	"Zieli_ski, Bartosz; Sroka-Oleksiak, Agnieszka; Rymarczyk, Dawid; Piekarczyk, Adam; Brzychczy-W_och, Monika"	Deep learning approach to describe and classify fungi microscopic images	Images	CNN	"Classification, Modeling"	PLOS ONE	15	6	e0234806	10.1371/journal.pone.0234806	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0234806	"Preliminary diagnosis of fungal infections can rely on microscopic examination. However, in many cases, it does not allow unambiguous identification of the species due to their visual similarity. Therefore, it is usually necessary to use additional biochemical tests. That involves additional costs and extends the identification process up to 10 days. Such a delay in the implementation of targeted therapy may be grave in consequence as the mortality rate for immunosuppressed patients is high. In this paper, we apply a machine learning approach based on deep neural networks and bag-of-words to classify microscopic images of various fungi species. Our approach makes the last stage of biochemical identification redundant, shortening the identification process by 2-3 days, and reducing the cost of the diagnosis."																				
2021	"Abdelghani, Bassam A.; Banitaan, Shadi; Maleki, Mina; Mazen, Amna"	Kissing Bugs Identification Using Convolutional Neural Network	Images	CNN	Classification	IEEE Access	9		140539-140548	10.1109/ACCESS.2021.3119587	https://ieeexplore.ieee.org/document/9568939	"Chagas disease is one of the most important parasitic diseases transmitted to animals and people by insect vectors. According to the World Health Organization, around seven million people were infected with Trypanosoma cruzi (also known as kissing bug) that causes Chagas disease. As kissing bugs belong to different families with different danger levels, accurate classifications of kissing bugs species would help the public authorities create a controlled surveillance system. Clinical methods for detecting kissing bugs are expensive, time-consuming, and need a high level of expertise. To overcome these limitations, computational methods can be used. In this paper, a fully automated deep learning model using a convolutional neural network (CNN) with a fine-tuned transfer learning model is proposed to identify kissing versus non-kissing bugs and classify the type of kissing bug species. The accuracy of 99.45% for the classifications of kissing vs. non-kissing bugs and 96% for the classifications of different kissing bugs species is achieved. Finally, a web application is developed based on the proposed model to help the community collecting and identifying kissing bugs species."																				
2021	"Abellán, Natalia; Jiménez-García, Blanca; Aznarte, José; Baquedano, Enrique; Domínguez-Rodrigo, Manuel"	Deep learning classification of tooth scores made by different carnivores: achieving high accuracy when comparing African carnivore taxa and testing the hominin shift in the balance of power	Images	CNN	Classification	Archaeological and Anthropological Sciences	13	2	31	10.1007/s12520-021-01273-9	https://link.springer.com/article/10.1007/s12520-021-01273-9	"The balance of power (that is the dominance on the predation arena between carnivore competitors and hominins) remains controversial. One reflection of this is the carnivore modification of hominin bones. During human evolution, hominins were first prey and then predators of other animals, including carnivores. Modifications reported on some hominin bones could result from primary predators feeding on them or post-depositional modifications by scavengers. Determining carnivore agency would be crucial to interpret such information. Here, a series of computer vision models based on convolutional neural networks is presented, comparing five different types of carnivores jointly and then pairwise. It is shown how such models contain different heuristics regarding specific carnivore taxa, which regarding tooth marks made by lions and spotted hyenas can be accurately classified by as much as 92% of the testing set. The present study also shows the potential of transfer knowledge in building accurate classification of images and for taphonomic interpretation. The application to tooth marking on a 500 ka hominin femoral shaft indicates that by that time, carnivore modifications of human remains may have resulted from post-depositional scavenging rather than by predation."																				
2021	"Abeywardhana, D. L.; Dangalle, C. D.; Nugaliyadde, Anupiya; Mallawarachchi, Yashas"	Deep learning approach to classify Tiger beetles of Sri Lanka	Images	CNN	Classification	Ecological Informatics	62		101286	10.1016/j.ecoinf.2021.101286	https://www.sciencedirect.com/science/article/pii/S1574954121000777	"Deep learning has shown to achieve dramatic results in image classification tasks. However, deep learning models require large amounts of data to train. Most of the real-world datasets, generally insect classification data does not have large number of training dataset. These images have a large amount of noise and various differences. The paper proposes a novel architectural model which removes the background noise and classify the Tiger beetles. Here object location is identified using contours by converting the original coloured image to white on black background. Then the remaining background is eliminated using grabcut algorithm. Later the extracted images are classified using a modified SqueezeNet transfer learning model to identify the tiger beetle class up to genus level. Transfer learning models with fewer trainable parameters performed well than the total number of parameters in the original model. When evaluating results it was identified that by freezing uppermost layers of SqueezeNet model better accuracy can be gained while freezing lowermost layers will reduce the validation accuracy. The proposed model achieved more than 90% for the test set in 40 epochs using 701,481 trainable parameters by freezing the top 19 layers of the original model. Improving the pre-processing to localize insect has improved the accuracy."																				
2021	"Allen, Ann N.; Harvey, Matt; Harrell, Lauren; Jansen, Aren; Merkens, Karlina P.; Wall, Carrie C.; Cattiau, Julie; Oleson, Erin M."	"A Convolutional Neural Network for Automated Detection of Humpback Whale Song in a Diverse, Long-Term Passive Acoustic Dataset"	Sound	CNN	Classification	Frontiers in Marine Science	8			10.3389/fmars.2021.607321	https://www.frontiersin.org/article/10.3389/fmars.2021.607321	"Passive acoustic monitoring is a well-established tool for researching the occurrence, movements, and ecology of a wide variety of marine mammal species. Advances in hardware and data collection have exponentially increased the volumes of passive acoustic data collected, such that discoveries are now limited by the time required to analyze rather than collect the data. In order to address this limitation, we trained a deep convolutional neural network (CNN) to identify humpback whale song in over 187,000 h of acoustic data collected at 13 different monitoring sites in the North Pacific over a 14-year period. The model successfully detected 75 s audio segments containing humpback song with an average precision of 0.97 and average area under the receiver operating characteristic curve (AUC-ROC) of 0.992. The model output was used to analyze spatial and temporal patterns of humpback song, corroborating known seasonal patterns in the Hawaiian and Mariana Islands, including occurrence at remote monitoring sites beyond well-studied aggregations, as well as novel discovery of humpback whale song at Kingman Reef, at 5_ North latitude. This study demonstrates the ability of a CNN trained on a small dataset to generalize well to a highly variable signal type across a diverse range of recording and noise conditions. We demonstrate the utility of active learning approaches for creating high-quality models in specialized domains where annotations are rare. These results validate the feasibility of applying deep learning models to identify highly variable signals across broad spatial and temporal scales, enabling new discoveries through combining large datasets with cutting edge tools."																				
2021	"Allken, Vaneeda; Rosen, Shale; Handegard, Nils Olav; Malde, Ketil"	A real-world dataset and data simulation algorithm for automated fish species identification	Images	CNN	Classification	Geoscience Data Journal	8	2	199-209	10.1002/gdj3.114	https://onlinelibrary.wiley.com/doi/abs/10.1002/gdj3.114	"Developing high-performing machine learning algorithms requires large amounts of annotated data. Manual annotation of data is labour-intensive, and the cost and effort needed are an important obstacle to the development and deployment of automated analysis. In a previous work, we have shown that deep learning classifiers can successfully be trained on synthetic images and annotations. Here, we provide a curated set of fish image data and backgrounds, the necessary software tools to generate synthetic images and annotations, and annotated real datasets to test classifier performance. The dataset is constructed from images collected using the Deep Vision system during two surveys from 2017 and 2018 that targeted economically important pelagic species in the Northeast Atlantic Ocean. We annotated a total of 1,879 images, randomly selected across trawl stations from both surveys, comprising 482 images of blue whiting, 456 images of Atlantic herring, 341 images of Atlantic mackerel, 335 images of mesopelagic fishes and 265 images containing a mixture of the four categories."																				
2021	"Allken, Vaneeda; Rosen, Shale; Handegard, Nils Olav; Malde, Ketil"	A deep learning-based method to identify and count pelagic and mesopelagic fishes from trawl camera images	Images	CNN	"Classification, Regression"	ICES Journal of Marine Science	78	10	3780-3792	10.1093/icesjms/fsab227	https://doi.org/10.1093/icesjms/fsab227	"Fish counts and species information can be obtained from images taken within trawls, which enables trawl surveys to operate without extracting fish from their habitat, yields distribution data at fine scale for better interpretation of acoustic results, and can detect fish that are not retained in the catch due to mesh selection. To automate the process of image-based fish detection and identification, we trained a deep learning algorithm (RetinaNet) on images collected from the trawl-mounted Deep Vision camera system. In this study, we focused on the detection of blue whiting, Atlantic herring, Atlantic mackerel, and mesopelagic fishes from images collected in the Norwegian sea. To address the need for large amounts of annotated data to train these models, we used a combination of real and synthetic images, and obtained a mean average precision of 0.845 on a test set of 918 images. Regression models were used to compare predicted fish counts, which were derived from RetinaNet classification of fish in the individual image frames, with catch data collected at 20 trawl stations. We have automatically detected and counted fish from individual images, related these counts to the trawl catches, and discussed how to use this in regular trawl surveys."																				
2021	"Allred, Brady W.; Bestelmeyer, Brandon T.; Boyd, Chad S.; Brown, Christopher; Davies, Kirk W.; Duniway, Michael C.; Ellsworth, Lisa M.; Erickson, Tyler A.; Fuhlendorf, Samuel D.; Griffiths, Timothy V.; Jansen, Vincent; Jones, Matthew O.; Karl, Jason; Knight, Anna; Maestas, Jeremy D.; Maynard, Jonathan J.; McCord, Sarah E.; Naugle, David E.; Starns, Heath D.; Twidwell, Dirac; Uden, Daniel R."	Improving Landsat predictions of rangeland fractional cover with multitask learning and uncertainty	Images	CNN	"Classification, Regression"	Methods in Ecology and Evolution	12	5	841-849	10.1111/2041-210X.13564	https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13564	"Operational satellite remote sensing products are transforming rangeland management and science. Advancements in computation, data storage and processing have removed barriers that previously blocked or hindered the development and use of remote sensing products. When combined with local data and knowledge, remote sensing products can inform decision-making at multiple scales. We used temporal convolutional networks to produce a fractional cover product that spans western United States rangelands. We trained the model with 52,012 on-the-ground vegetation plots to simultaneously predict fractional cover for annual forbs and grasses, perennial forbs and grasses, shrubs, trees, litter and bare ground. To assist interpretation and to provide a measure of prediction confidence, we also produced spatiotemporal-explicit, pixel-level estimates of uncertainty. We evaluated the model with 5,780 on-the-ground vegetation plots removed from the training data. Model evaluation averaged 6.3% mean absolute error and 9.6% root mean squared error. Evaluation with additional datasets that were not part of the training dataset, and that varied in geographic range, method of collection, scope and size, revealed similar metrics. Model performance increased across all functional groups compared to the previously produced fractional product. The advancements achieved with the new rangeland fractional cover product expand the management toolbox with improved predictions of fractional cover and pixel-level uncertainty. The new product is available on the Rangeland Analysis Platform (https://rangelands.app/), an interactive web application that tracks rangeland vegetation through time. This product is intended to be used alongside local on-the-ground data, expert knowledge, land use history, scientific literature and other sources of information when making interpretations. When being used to inform decision-making, remotely sensed products should be evaluated and utilized according to the context of the decision and not be used in isolation."																				
2021	"Ardakani, Ilya; Hashimoto, Koichi; Yoda, Ken"	Context-based semantical vector representations for animal trajectories	Other	DNN	Regression	Advanced Robotics	33	4-Mar	118-133	10.1080/01691864.2019.1573704	https://www.tandfonline.com/doi/abs/10.1080/01691864.2019.1573704	"Behaviour could be expressed as a set of specific movement patterns in time. An animal's movement or trajectory could characterise its behaviours and provide information about its internal states. Recent advances in GPS-based sensor technologies led to drastic increase in volume of the data collected from animals' movements which enables researchers to analyse and model their behaviours using data-driven methods. However, having compact, discriminative, semantical and independent numerical representations of trajectories as features, is essential for employing the most of available off-the-shelf machine learning and deep learning techniques. Inspired by language processing, the approach presented in this study utilizes Skip-gram model to create contextual vector embeddings or representations of key-points in animal trajectories to be used as input features. Here, a key-point is defined as a location which represents a trajectory segment. It is assumed that these key-points encapsulate contextual information which is attributed to a certain behaviour or specific group of animals with similar behavioural features. So, the vector embeddings could be interpreted as contextual semantical representations of trajectory key-points independent of their spatial coordinates. With these representations, it would be possible to predict likelihood of preceding or subsequent key-points given a context or an internal state, or vice versa. To test this hypothesis, an experiment was conducted on birds' trajectories logged from a seabird species, Streaked Shearwater (Calonectris leucomelas). In this experiment, vector representations of the key-points in birds' trajectories were constructed and optimized using candidate sampling. The experimental results showcased the utility of these vector embeddings in both exploration of Streaked Shearwater trajectory data and improvement of gender-based trajectory classification. In summary, the proposed method provided a novel approach for numerical representation of animal trajectories and, it was illustrated to be semantically more explanatory for analysis as well as being more informative as features for modelling of animal movement data."																				
2021	"Arfianti, Tri; Costello, Mark John"	The distribution of benthic amphipod crustaceans in Indonesian seas	Images	CNN	Classification	PeerJ	9		e12054	10.7717/peerj.12054	https://peerj.com/articles/12054	"Amphipod crustaceans are an essential component of tropical marine biodiversity. However, their distribution and biogeography have not been analysed in one of the world’s largest tropical countries nested in the Coral Triangle, Indonesia. We collected and identified amphipod crustaceans from eight sites in Indonesian waters and combined the results with data from 32 additional sites in the literature. We analysed the geographic distribution of 147 benthic amphipod crustaceans using cluster analysis and the ‘Bioregions Infomaps’ neural network method of biogeographic discrimination. We found five groups of benthic amphipod crustaceans which show relationships with sampling methods, depth, and substrata. Neural network biogeographic analysis indicated there was only one biogeographic region that matched with the global amphipod regions and marine biogeographic realms defined for all marine taxa. There was no support for Wallaces or other lines being marine biogeographic boundaries in the region. Species richness was lower than expected considering the region is within the Coral Triangle. We hypothesise that this low richness might be due to the intense fish predation which may have limited amphipod diversification. The results indicated that habitat rather than biogeography determines amphipod distribution in Indonesia. Therefore, future research needs to sample more habitats, and consider habitat in conservation planning."																				
2021	"Arroyo, Jan Carlo T."	Coleoptera Classification Using Convolutional Neural Network and Transfer Learning	Images	CNN	Classification	International Journal of Engineering Trends and Technology - IJETT				10.14445/22315381/IJETT-V69I5P201	https://ijettjournal.org/archive/ijett-v69i5p201	Coleoptera Classification Using Convolutional Neural Network and Transfer Learning																				
2021	"Assaf, Rida; Xia, Fangfang; Stevens, Rick"	Identifying genomic islands with deep neural networks	Molecular	CNN	Classification	BMC Genomics	22	3	281	10.1186/s12864-021-07575-5	https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-021-07575-5	"Horizontal gene transfer is the main source of adaptability for bacteria, through which genes are obtained from different sources including bacteria, archaea, viruses, and eukaryotes. This process promotes the rapid spread of genetic information across lineages, typically in the form of clusters of genes referred to as genomic islands (GIs). Different types of GIs exist, and are often classified by the content of their cargo genes or their means of integration and mobility. While various computational methods have been devised to detect different types of GIs, no single method is capable of detecting all types."																				
2021	"Auslander, Noam; Gussow, Ayal B.; Koonin, Eugene V."	Incorporating machine learning into established bioinformatics frameworks	NA	NA	Review	International Journal of Molecular Sciences	22	6	2903	10.3390/ijms22062903	https://www.mdpi.com/1422-0067/22/6/2903	"The exponential growth of biomedical data in recent years has urged the application of numerous machine learning techniques to address emerging problems in biology and clinical research. By enabling the automatic feature extraction, selection, and generation of predictive models, these methods can be used to efficiently study complex biological systems. Machine learning techniques are frequently integrated with bioinformatic methods, as well as curated databases and biological networks, to enhance training and validation, identify the best interpretable features, and enable feature and model investigation. Here, we review recently developed methods that incorporate machine learning within the same framework with techniques from molecular evolution, protein structure analysis, systems biology, and disease genomics. We outline the challenges posed for machine learning, and, in particular, deep learning in biomedicine, and suggest unique opportunities for machine learning techniques integrated with established bioinformatics approaches to overcome some of these challenges."																				
2021	"Badirli, Sarkhan; Picard, Christine J.; Mohler, George; Akata, Zeynep; Dundar, Murat"	Classifying the Unknown: Identification of Insects by Deep Open-set Bayesian Learning	"Images, Molecular"	CNN	"Classification, Regression"	bioRxiv			2021.09.15.460492	10.1101/2021.09.15.460492	https://www.biorxiv.org/content/10.1101/2021.09.15.460492v1	"Insects represent a large majority of biodiversity on Earth, yet only 20% of the estimated 5.5 million insect species are currently described (1). While describing new species typically requires specific taxonomic expertise to identify morphological characters that distinguish it from other potential species, DNA-based methods have aided in providing additional evidence of separate species (2). Machine learning (ML) is emerging as a potential new approach in identifying new species, given that this analysis may be more sensitive to subtle differences humans may not process. Existing ML algorithms are limited by image repositories that do not include undescribed species. We developed a Bayesian deep learning method for the open-set classification of species. The proposed approach forms a Bayesian hierarchy of species around corresponding genera and uses deep embeddings of images and barcodes together to identify insects at the lowest level of abstraction possible. To demonstrate proof of concept, we used a database of 32,848 insect instances from 1,040 described species split into training and test data. The test data included 243 species not present in the training data. Our results demonstrate that using DNA sequences and images together, insect instances of described species can be classified with 96.66% accuracy while achieving accuracy of 81.39% in identifying genera of insect instances of undescribed species. The proposed deep open-set Bayesian model demonstrates a powerful new approach that can be used for the gargantuan task of identifying new insect species."																				
2021	"Bao, Francielli; Bambil, Deborah"	"Applicability of computer vision in seed identification: deep learning, random forest, and support vector machine classification algorithms"	Other	Unknown	Classification	Acta Botanica Brasilica	35		17-21	10.1590/0102-33062020abb0361	http://www.scielo.br/j/abb/a/3nMMRrK3hX5CZGZM88xYxZp/?lang=en	"The use of computer image analysis can assist the extraction of morphological information from seeds, potentially serving as a resource for solving taxonomic problems that require extensive training by specialists whose primary method of examination is visual identification. We propose to test the ability of deep learning, SVM and random forest algorithms to classify seeds from twelve species of aquatic plants as an alternative to traditional classification methods. A total of 150 seeds of the species were collected. The attributes of colour, shape, and texture were analysed through the machine learning algorithms of deep learning, random forest, and support vector machine (SVM). Computer vision proved to be efficient at classifying species using all three algorithms, with an accuracy rate for SVM of 97.91 %, random forest 97.08 % and deep learning 92.5 %. We believe that the method performed well in our experiment and improved seed classification accuracy. As a result, the algorithms SVM and random forest were found to be enough at aquatic plant seed recognition."																				
2021	"Bao, Yuwei; Wadden, Jack; Erb-Downward, John R.; Ranjan, Piyush; Zhou, Weichen; McDonald, Torrin L.; Mills, Ryan E.; Boyle, Alan P.; Dickson, Robert P.; Blaauw, David; Welch, Joshua D."	"SquiggleNet: real-time, direct classification of nanopore signals"	Molecular	CNN	Classification	Genome Biology	22	1	298	10.1186/s13059-021-02511-y	https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02511-y	"We present SquiggleNet, the first deep-learning model that can classify nanopore reads directly from their electrical signals. SquiggleNet operates faster than DNA passes through the pore, allowing real-time classification and read ejection. Using 1 s of sequencing data, the classifier achieves significantly higher accuracy than base calling followed by sequence alignment. Our approach is also faster and requires an order of magnitude less memory than alignment-based approaches. SquiggleNet distinguished human from bacterial DNA with over 90% accuracy, generalized to unseen bacterial species in a human respiratory meta genome sample, and accurately classified sequences containing human long interspersed repeat elements."																				
2021	"Baquero, Diana P.; Gazi, Anastasia D.; Sachse, Martin; Liu, Junfeng; Schmitt, Christine; Moya-Nilges, Maryse; Schouten, Stefan; Prangishvili, David; Krupovic, Mart"	A filamentous archaeal virus is enveloped inside the cell and released through pyramidal portals	Other	CNN	Classification	Proceedings of the National Academy of Sciences	118	32	e2105540118	10.1073/pnas.2105540118	https://www.pnas.org/doi/10.1073/pnas.2105540118	"Significance  Egress of most eukaryotic enveloped viruses, including such human pathogens as HIV-1, Ebola, and coronaviruses, occurs via budding through cellular membranes, a process concomitant with virion assembly. Archaea are also infected by enveloped viruses, but how their virions are assembled and released from the cells remained largely unknown. We show that virions of Sulfolobus islandicus filamentous virus (SIFV) are assembled and enveloped in the cell cytoplasm. Instead of budding, SIFV induces the formation of pyramidal structures, which penetrate the cell envelope and serve as portals for virion release. Comparison of the infection cycles of evolutionarily related enveloped and nonenveloped filamentous archaeal viruses suggests that the primary role of the lipothrixvirus membrane is to protect the genome against extreme environmental conditions."																				
2021	"Barburiceanu, Stefania; Meza, Serban; Orza, Bogdan; Malutan, Raul; Terebes, Romulus"	Convolutional Neural Networks for Texture Feature Extraction. Applications to Leaf Disease Classification in Precision Agriculture	Images	CNN	Classification	IEEE Access	9		160085-160103	10.1109/ACCESS.2021.3131002	https://ieeexplore.ieee.org/document/9627678	"This paper studies the use of deep-learning models (AlexNet, VggNet, ResNet) pre-trained on object categories (ImageNet) in applied texture classification problems such as plant disease detection tasks. Research related to precision agriculture is of high relevance due to its potential economic impact on agricultural productivity and quality. Within this context, we propose a deep learning-based feature extraction method for the identification of plant species and the classification of plant leaf diseases. We focus on results relevant to real-time processing scenarios that can be easily transferred to manned/unmanned agricultural smart machinery (e.g. tractors, drones, robots, IoT smart sensor networks, etc.) by reconsidering the common processing pipeline. In our approach, texture features are extracted from different layers of pre-trained Convolutional Neural Network models and are later applied to a machine-learning classifier. For the experimental evaluation, we used publicly available datasets consisting of RGB textured images and datasets containing images of healthy and non-healthy plant leaves of different species. We compared our method to feature vectors derived from traditional handcrafted feature extraction descriptors computed for the same images and end-to-end deep-learning approaches. The proposed method proves to be significantly more efficient in terms of processing times and discriminative power, being able to surpass traditional and end-to-end CNN-based methods and provide a solution also to the problem of the reduced datasets available for precision agriculture."																				
2021	"Barsanti, Laura; Birindelli, Lorenzo; Gualtieri, Paolo"	Water monitoring by means of digital microscopy identification and classification of microalgae	NA	NA	Review	Environmental Science: Processes & Impacts	23	10	1443-1457	10.1039/D1EM00258A	https://pubs.rsc.org/en/content/articlelanding/2021/em/d1em00258a	"This review reports state-of-the-art methods for automated microalgae classification aimed at monitoring water ecosystem conditions by means of digital microscopy, its current state and indications of future directions the field is expected to take."																				
2021	"Battey, C J; Coffing, Gabrielle C; Kern, Andrew D"	Visualizing population structure with variational autoencoders	Molecular	VAE	Modeling	G3 Genes|Genomes|Genetics	11	1	jkaa036	10.1093/g3journal/jkaa036	https://academic.oup.com/g3journal/article/doi/10.1093/g3journal/jkaa036/6105578	"Dimensionality reduction is a common tool for visualization and inference of population structure from genotypes, but popular methods either return too many dimensions for easy plotting (PCA) or fail to preserve global geometry (t-SNE and UMAP). Here we explore the utility of variational autoencoders (VAEs)—generative machine learning models in which a pair of neural networks seek to first compress and then recreate the input data—for visualizing population genetic variation. VAEs incorporate nonlinear relationships, allow users to define the dimensionality of the latent space, and in our tests preserve global geometry better than t-SNE and UMAP. Our implementation, which we call popvae, is available as a command-line python program at github.com\/kr-colab\/popvae. The approach yields latent embeddings that capture subtle aspects of population structure in humans and Anopheles mosquitoes, and can generate artificial genotypes characteristic of a given sample or population."																				
2021	"Beery, Sara; Cole, Elijah; Parker, Joseph; Perona, Pietro; Winner, Kevin"	Species distribution modeling for machine learning practitioners: a review	NA	NA	Review	arXiv				10.48550/arXiv.2107.10400	http://arxiv.org/abs/2107.10400	"Conservation science depends on an accurate understanding of what's happening in a given ecosystem. How many species live there? What is the makeup of the population? How is that changing over time? Species Distribution Modeling (SDM) seeks to predict the spatial (and sometimes temporal) patterns of species occurrence, i.e. where a species is likely to be found. The last few years have seen a surge of interest in applying powerful machine learning tools to challenging problems in ecology. Despite its considerable importance, SDM has received relatively little attention from the computer science community. Our goal in this work is to provide computer scientists with the necessary background to read the SDM literature and develop ecologically useful ML-based SDM algorithms. In particular, we introduce key SDM concepts and terminology, review standard models, discuss data availability, and highlight technical challenges and pitfalls."																				
2021	"Bellin, Nicolò; Calzolari, Mattia; Callegari, Emanuele; Bonilauri, Paolo; Grisendi, Annalisa; Dottori, Michele; Rossi, Valeria"	Geometric morphometrics and machine learning as tools for the identification of sibling mosquito species of the Maculipennis complex (Anopheles)	Other	DNN	Classification	"Infection, Genetics and Evolution"	95		105034	10.1016/j.meegid.2021.105034	https://www.sciencedirect.com/science/article/pii/S1567134821003324	"Geometric morphometrics allows researchers to use the specific software to quantify and to visualize morphological differences between taxa from insect wings. Our objective was to assess wing geometry to distinguish four Anopheles sibling species of the Maculipennis complex, An. maculipennis s. s., An. daciae sp. inq., An. atroparvus and An. melanoon, found in Northern Italy. We combined the geometric morphometric approach with different machine learning alghorithms: support vector machine (SVM), random forest (RF), artificial neural network (ANN) and an ensemble model (EN). Centroid size was smaller in An. atroparvus than in An. maculipennis s. s. and An. daciae sp. inq. Principal component analysis (PCA) explained only 33% of the total variance and appeared not very useful to discriminate among species, and in particular between An. maculipennis s. s. and An. daciae sp. inq. The performance of four different machine learning alghorithms using procrustes coordinates of wing shape as predictors was evaluated. All models showed ROC-AUC and PRC-AUC values that were higher than the random classifier but the SVM algorithm maximized the most metrics on the test set. The SVM algorithm with radial basis function allowed the correct classification of 83% of An. maculipennis s. s. and 79% of An. daciae sp. inq. ROC-AUC analysis showed that three landmarks, 11, 16 and 15, were the most important procrustes coordinates in mean wing shape comparison between An. maculipennis s. s. and An. daciae sp. inq. The pattern in the three-dimensional space of the most important procrustes coordinates showed a clearer differentiation between the two species than the PCA. Our study demonstrated that machine learning algorithms could be a useful tool combined with the wing geometric morphometric approach."																				
2021	"Bisen, Dhananjay"	Deep convolutional neural network based plant species recognition through features of leaf	Images	CNN	Classification	Multimedia Tools and Applications	80	4	6443-6456	10.1007/s11042-020-10038-w	http://link.springer.com/10.1007/s11042-020-10038-w	"In present scenario, the research under image processing has been rapidly transformed from machine learning to deep learning. The deep learning algorithms are usually applied in the various areas like images to be classified or identified more accurately. One of the application areas of deep learning is the plant identification through its leaf which helps to recognize plant species. Botanists consume most of time in identifying plant species by manually scrutinizing and finding its features. This paper proposes an automated plant identification system, for identifying the plants species through their leaf. This task is accomplished using deep convolutional neural network to achieve higher accuracy. Image pre-processing, feature extraction and recognition are three main identification steps which are taken under consideration. Proposed CNN classifier learns the features of plants such as classification of leafs by using hidden layers like convolutional layer, max pooling layer, dropout layers and fully connected layers. The model acquires a knowledge related to features of Swedish leaf dataset in which 15 tree classes are available, that helps to predict the correct category of unknown plant with accuracy of 97% and minimum losses. Result is slightly better than the previous work that analyzes 93.75% of accuracy."																				
2021	"Bjerge, Kim; Mann, Hjalte M. R.; Høye, Toke Thomas"	Real-time insect tracking and monitoring with computer vision and deep learning	Video	CNN	Regression	Remote Sensing in Ecology and Conservation	n/a	n/a		10.1002/rse2.245	https://onlinelibrary.wiley.com/doi/abs/10.1002/rse2.245	"Insects are declining in abundance and diversity, but their population trends remain uncertain as insects are difficult to monitor. Manual methods require substantial time investment in trapping and subsequent species identification. Camera trapping can alleviate some of the manual fieldwork, but the large quantities of image data are challenging to analyse. By embedding the image analyses into the recording process using computer vision techniques, it is possible to focus efforts on the most ecologically relevant image data. Here, we present an intelligent camera system, capable of detecting, tracking, and identifying individual insects in situ. We constructed the system from commercial off-the-shelf components and used deep learning open source software to perform species detection and classification. We present the Insect Classification and Tracking algorithm (ICT) that performs real-time classification and tracking at 0.33 frames per second. The system can upload summary data on the identity and movement track of insects to a server via the internet on a daily basis. We tested our system during the summer 2020 and detected 2994 insect tracks across 98 days. We achieved an average precision of 89% for correctly classified insect tracks of eight different species. This result was based on 504 manually verified tracks observed in videos during 10 days with varying insect activities. Using the track data, we could estimate the mean residence time for individual flower visiting insects within the field of view of the camera, and we were able to show a substantial variation in residence time among insect taxa. For honeybees, which were most abundant, residence time also varied through the season in relation to the plant species in bloom. Our proposed automated system showed promising results in non-destructive and real-time monitoring of insects and provides novel information about phenology, abundance, foraging behaviour, and movement ecology of flower visiting insects."																				
2021	"Bjerge, Kim; Nielsen, Jakob Bonde; Sepstrup, Martin Videbæk; Helsing-Nielsen, Flemming; Høye, Toke Thomas"	An automated light trap to monitor moths (Lepidoptera) using computer vision-based tracking and deep learning	Images	CNN	Classification	Sensors	21	2	343	10.3390/s21020343	https://www.mdpi.com/1424-8220/21/2/343	"Insect monitoring methods are typically very time-consuming and involve substantial investment in species identification following manual trapping in the field. Insect traps are often only serviced weekly, resulting in low temporal resolution of the monitoring data, which hampers the ecological interpretation. This paper presents a portable computer vision system capable of attracting and detecting live insects. More specifically, the paper proposes detection and classification of species by recording images of live individuals attracted to a light trap. An Automated Moth Trap (AMT) with multiple light sources and a camera was designed to attract and monitor live insects during twilight and night hours. A computer vision algorithm referred to as Moth Classification and Counting (MCC), based on deep learning analysis of the captured images, tracked and counted the number of insects and identified moth species. Observations over 48 nights resulted in the capture of more than 250,000 images with an average of 5675 images per night. A customized convolutional neural network was trained on 2000 labeled images of live moths represented by eight different classes, achieving a high validation F1-score of 0.93. The algorithm measured an average classification and tracking F1-score of 0.71 and a tracking detection rate of 0.79. Overall, the proposed computer vision system and algorithm showed promising results as a low-cost solution for non-destructive and automatic monitoring of moths."																				
2021	"Blischak, Paul D.; Barker, Michael S.; Gutenkunst, Ryan N."	Chromosome-scale inference of hybrid speciation and admixture with convolutional neural networks	Images	CNN	Modeling	Molecular Ecology Resources	21	8	2676-2688	10.1111/1755-0998.13355	https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13355	"Inferring the frequency and mode of hybridization among closely related organisms is an important step for understanding the process of speciation and can help to uncover reticulated patterns of phylogeny more generally. Phylogenomic methods to test for the presence of hybridization come in many varieties and typically operate by leveraging expected patterns of genealogical discordance in the absence of hybridization. An important assumption made by these tests is that the data (genes or SNPs) are independent given the species tree. However, when the data are closely linked, it is especially important to consider their nonindependence. Recently, deep learning techniques such as convolutional neural networks (CNNs) have been used to perform population genetic inferences with linked SNPs coded as binary images. Here, we use CNNs for selecting among candidate hybridization scenarios using the tree topology (((P1, P2), P3), Out) and a matrix of pairwise nucleotide divergence (dXY) calculated in windows across the genome. Using coalescent simulations to train and independently test a neural network showed that our method, HyDe-CNN, was able to accurately perform model selection for hybridization scenarios across a wide breath of parameter space. We then used HyDe-CNN to test models of admixture in Heliconius butterflies, as well as comparing it to phylogeny-based introgression statistics. Given the flexibility of our approach, the dropping cost of long-read sequencing and the continued improvement of CNN architectures, we anticipate that inferences of hybridization using deep learning methods like ours will help researchers to better understand patterns of admixture in their study organisms"																				
2021	"Borges Oliveira, Dario Augusto; Ribeiro Pereira, Luiz Gustavo; Bresolin, Tiago; Pontes Ferreira, Rafael Ehrich; Reboucas Dorea, Joao Ricardo"	A review of deep learning algorithms for computer vision systems in livestock	NA	NA	Review	Livestock Science	253		104700	10.1016/j.livsci.2021.104700	https://www.sciencedirect.com/science/article/pii/S1871141321003085	"In livestock operations, systematically monitoring animal body weight, biometric body measurements, animal behavior, feed bunk, and other difficult-to-measure phenotypes is manually unfeasible due to labor, costs, and animal stress. Applications of computer vision are growing in importance in livestock systems due to their ability to generate real-time, non-invasive, and accurate animal-level information. However, the development of a computer vision system requires sophisticated statistical and computational approaches for efficient data management and appropriate data mining, as it involves massive datasets. This article aims to provide an overview of how deep learning has been implemented in computer vision systems used in livestock, and how such implementation can be an effective tool to predict animal phenotypes and to accelerate the development of predictive modeling for precise management decisions. First, we reviewed the most recent milestones achieved with computer vision systems and the respective deep learning algorithms implemented in Animal Science studies. Then, we reviewed the published research studies in Animal Science which used deep learning algorithms as the primary analytical strategy for image classification, object detection, object segmentation, and feature extraction. The great number of reviewed articles published in the last few years demonstrates the high interest and rapid development of deep learning algorithms in computer vision systems across livestock species. Deep learning algorithms for computer vision systems, such as Mask R-CNN, Faster R-CNN, YOLO (v3 and v4), DeepLab v3, U-Net and others have been used in Animal Science research studies. Additionally, network architectures such as ResNet, Inception, Xception, and VGG16 have been implemented in several studies across livestock species. The great performance of these deep learning algorithms suggests an improved predictive ability in livestock applications and a faster inference. However, only a few articles fully described the deep learning algorithms and their implementation. Thus, information regarding hyperparameter tuning, pre-trained weights, deep learning backbone, and hierarchical data structure were missing. We summarized peer-reviewed articles by computer vision tasks (image classification, object detection, and object segmentation), deep learning algorithms, animal species, and phenotypes including animal identification and behavior, feed intake, animal body weight, and many others. Understanding the principles of computer vision and the algorithms used for each application is crucial to develop efficient systems in livestock operations. Such development will potentially have a major impact on the livestock industry by predicting real-time and accurate phenotypes, which could be used in the future to improve farm management decisions, breeding programs through high-throughput phenotyping, and optimized data-driven interventions."																				
2021	"Burbrink, Frank T; Bernstein, Justin M; Kuhn, Arianna; Gehara, Marcelo; Ruane, Sara"	Ecological divergence and the history of gene flow in the Nearctic milksnakes (Lampropeltis triangulum complex)	Molecular	DNN	Classification	Systematic Biology			syab093	10.1093/sysbio/syab093	https://academic.oup.com/sysbio/advance-article-abstract/doi/10.1093/sysbio/syab093/6433690	"Many phylogeographic studies on species with large ranges have found genetic–geographic structure associated with changes in habitat and physical barriers preventing or reducing gene flow. These interactions with geographic space, contemporary and historical climate, and biogeographic barriers have complex effects on contemporary population genetic structure and processes of speciation. While allopatric speciation at biogeographic barriers is considered the primary mechanism for generating species, more recently it has been shown that parapatric modes of divergence may be equally or even more common. With genomic data and better modeling capabilities, we can more clearly define causes of speciation in relation to biogeography and migration between lineages, the location of hybrid zones with respect to the ecology of parental lineages, and differential introgression of genes between taxa. Here, we examine the origins of three Nearctic milksnakes (Lampropeltis elapsoides, Lampropeltis triangulum and Lampropeltis gentilis) using genome-scale data to better understand species diversification. Results from artificial neural networks show that a mix of a strong biogeographic barrier, environmental changes, and physical space has affected genetic structure in these taxa. These results underscore conspicuous environmental changes that occur as the sister taxa L. triangulum and L. gentilis diverged near the Great Plains into the forested regions of the Eastern Nearctic. This area has been recognized as a region for turnover for many vertebrate species, but as we show here the contemporary boundary does not isolate these sister species. These two species likely formed in the mid-Pleistocene and have remained partially reproductively isolated over much of this time, showing differential introgression of loci. We also demonstrate that when L. triangulum and L. gentilis are each in contact with the much older L. elapsoides, some limited gene flow has occurred. Given the strong agreement between nuclear and mtDNA genomes, along with estimates of ecological niche, we suggest that all three lineages should continue to be recognized as unique species. Furthermore, this work emphasizes the importance of considering complex modes of divergence and differential allelic introgression over a complex landscape when testing mechanisms of speciation. [Cline; delimitation; Eastern Nearctic; Great Plains; hybrids; introgression; speciation.]"																				
2021	"Burbrink, Frank T.; Gehara, Marcelo; McKelvy, Alexander D.; Myers, Edward A."	Resolving spatial complexities of hybridization in the context of the gray zone of speciation in North American ratsnakes (Pantherophis obsoletus complex)	"Environmental, Molecular"	DNN	"Classification, Regression"	Evolution	75	2	260-277	10.1111/evo.14141	https://onlinelibrary.wiley.com/doi/abs/10.1111/evo.14141	"Inferring the history of divergence between species in a framework that permits the presence of gene flow has been crucial for characterizing the “gray zone” of speciation, which is the period of time where lineages have diverged but have not yet achieved strict reproductive isolation. However, estimates of both divergence times and rates of gene flow often ignore spatial information, for example when considering the location and width of hybrid zones with respect to changes in the environment between lineages. Using population genomic data from the North American ratsnake complex (Pantherophis obsoletus), we connected phylogeographic estimates of lineage structure, migration, historical demography, and timing of divergence with hybrid zone dynamics. We examined the spatial context of diversification by linking migration and timing of divergence to the location and widths of hybrid zones. Artificial neural network approaches were applied to understand how landscape features and past climate have influenced population genetic structure among these lineages. We found that rates of migration between lineages were associated with the overall width of hybrid zones. Timing of divergence was not related to migration rate or hybrid zone width across species pairs but may be related to the number of alleles weakly introgressing through hybrid zones. This research underscores how incomplete reproductive isolation can be better understood by considering differential allelic introgression and the effects of historical and contemporary landscape features on the formation of lineages as well as overall genomic estimates of migration rates through time."																				
2021	"Burger, Klara Elisabeth; Pfaffelhuber, Peter; Baumdicker, Franz"	Neural networks for self-adjusting mutation rate estimation when the recombination rate is unknown	Molecular	DNN	Regression	bioRxiv				10.1101/2021.09.02.457550	http://biorxiv.org/lookup/doi/10.1101/2021.09.02.457550	"Estimating the mutation rate, or equivalently effective population size, is a common task in population genetics. If recombination is low or high, the optimal linear estimation methods, namely Fu’s and Watterson’s estimator, are known and well understood. For intermediate recombination rates, the calculation of optimal estimators is more involved. As an alternative to model-based estimation, neural networks and other machine learning tools could help to develop good estimators in these involved scenarios. However, if no benchmark is available it is difficult to assess how well suited these tools are for different applications in population genetics. Here we investigate feedforward neural networks for the estimation of the mutation rate and compare their performance with the frequently used optimal estimators introduced by Fu and Watterson. We find that neural networks can reproduce the optimal estimators if provided with the appropriate features and training sets. Remarkably, only one hidden layer is necessary to obtain a single estimator that performs almost as well as the optimal estimators for both, low and high recombination rates and provides a superior estimation method for intermediate recombination rates at the same time."																				
2021	"Cai, Jiarui; Wang, Yizhou; Hwang, Jenq-Neng"	ACE: Ally Complementary Experts for Solving Long-Tailed Recognition in One-Shot	Images	CNN	Classification	arXiv				10.48550/arXiv.2108.02385	http://arxiv.org/abs/2108.02385	"One-stage long-tailed recognition methods improve the overall performance in a ""seesaw"" manner, i.e., either sacrifice the head's accuracy for better tail classification or elevate the head's accuracy even higher but ignore the tail. Existing algorithms bypass such trade-off by a multi-stage training process: pre-training on imbalanced set and fine-tuning on balanced set. Though achieving promising performance, not only are they sensitive to the generalizability of the pre-trained model, but also not easily integrated into other computer vision tasks like detection and segmentation, where pre-training of classifiers solely is not applicable. In this paper, we propose a one-stage long-tailed recognition scheme, ally complementary experts (ACE), where the expert is the most knowledgeable specialist in a sub-set that dominates its training, and is complementary to other experts in the less-seen categories without being disturbed by what it has never seen. We design a distribution-adaptive optimizer to adjust the learning pace of each expert to avoid over-fitting. Without special bells and whistles, the vanilla ACE outperforms the current one-stage SOTA method by 3-10% on CIFAR10-LT, CIFAR100-LT, ImageNet-LT and iNaturalist datasets. It is also shown to be the first one to break the ""seesaw"" trade-off by improving the accuracy of the majority and minority categories simultaneously in only one stage. Code and trained models are at https://github.com/jrcai/ACE."																				
2021	"Capinha, César; Ceia-Hasse, Ana; Kramer, Andrew M.; Meijer, Christiaan"	Deep learning for supervised classification of temporal data in ecology	Temporal	"CNN, Other"	"Regression, Modeling"	Ecological Informatics	61		e101252	10.1016/j.ecoinf.2021.101252	https://linkinghub.elsevier.com/retrieve/pii/S1574954121000431	"Temporal data is ubiquitous in ecology and ecologists often face the challenge of accurately differentiating these data into predefined classes, such as biological entities or ecological states. The usual approach consists of transforming the time series into user-defined features and then using these features as predictors in conventional statistical or machine learning models. Here we suggest the use of deep learning models as an alternative to this approach. Recent deep learning techniques can perform the classification directly from the time series, elimi_ nating subjective and resource-consuming data transformation steps, and potentially improving classification results. We describe some of the deep learning architectures relevant for time series classification and show how these architectures and their hyper-parameters can be tested and used for the classification problems at hand. We illustrate the approach using three case studies from distinct ecological subdisciplines: i) insect species identi_ fication from wingbeat spectrograms; ii) species distribution modelling from climate time series and iii) the classification of phenological phases from continuous meteorological data. The deep learning approach delivered ecologically sensible and accurate classifications demonstrating its potential for wide applicability across sub_ fields of ecology."																				
2021	"Carbonell-Rivera, Juan Pedro; Torralba, Jesús; Estornell, Javier; Ruiz, Luis Ángel; Crespo-Peremarch, Pablo"	Classification of Mediterranean Shrub Species from UAV Point Clouds	Images	DNN	Classification	Remote Sensing	14	1	199	10.3390/rs14010199	https://www.mdpi.com/2072-4292/14/1/199	"Modelling fire behaviour in forest fires is based on meteorological, topographical, and vegetation data, including species’ type. To accurately parameterise these models, an inventory of the area of analysis with the maximum spatial and temporal resolution is required. This study investigated the use of UAV-based digital aerial photogrammetry (UAV-DAP) point clouds to classify tree and shrub species in Mediterranean forests, and this information is key for the correct generation of wildfire models. In July 2020, two test sites located in the Natural Park of Sierra Calderona (eastern Spain) were analysed, registering 1036 vegetation individuals as reference data, corresponding to 11 shrub and one tree species. Meanwhile, photogrammetric flights were carried out over the test sites, using a UAV DJI Inspire 2 equipped with a Micasense RedEdge multispectral camera. Geometrical, spectral, and neighbour-based features were obtained from the resulting point cloud generated. Using these features, points belonging to tree and shrub species were classified using several machine learning methods, i.e., Decision Trees, Extra Trees, Gradient Boosting, Random Forest, and MultiLayer Perceptron. The best results were obtained using Gradient Boosting, with a mean cross-validation accuracy of 81.7% and 91.5% for test sites 1 and 2, respectively. Once the best classifier was selected, classified points were clustered based on their geometry and tested with evaluation data, and overall accuracies of 81.9% and 96.4% were obtained for test sites 1 and 2, respectively. Results showed that the use of UAV-DAP allows the classification of Mediterranean tree and shrub species. This technique opens a wide range of possibilities, including the identification of species as a first step for further extraction of structure and fuel variables as input for wildfire behaviour models."																				
2021	"Cheeseman, Ted; Southerland, Ken; Park, Jinmo; Olio, Marilia; Flynn, Kiirsten; Calambokidis, John; Jones, Lindsey; Garrigue, Claire; Frisch Jordán, Astrid; Howard, Addison; Reade, Walter; Neilson, Janet; Gabriele, Christine; Clapham, Phil"	"Advanced image recognition: a fully automated, high-accuracy photo-identification matching system for humpback whales"	Images	CNN	Classification	Mammalian Biology				10.1007/s42991-021-00180-9	https://link.springer.com/article/10.1007/s42991-021-00180-9	"We describe the development and application of a new convolutional neural network-based photo-identification algorithm for individual humpback whales (Megaptera novaeangliae). The method uses a Densely Connected Convolutional Network (DenseNet) to extract special keypoints of an image of the ventral surface of the fluke and then a separate DenseNet trained to look for features within these keypoints. The extracted features are then compared against those of the reference set of previously known humpback whales for similarity. This offers the potential to successfully automate recognition of individuals in large photographic datasets such as in ocean basin-wide marine mammal studies. The algorithm requires minimal image pre-processing and is capable of accurate, rapid matching of fair to high-quality humpback fluke photographs. In real world testing compared to manual image matching, the algorithm reduces image management time by at least 98% and reduces error rates of missing potential matches from approximately 6–9% to 1–3%. The success of this new system permits automated comparisons to be made for the first time across photo-identification datasets with tens to hundreds of thousands of individually identified encounters, with profound implications for long-term and large population studies of the species."																				
2021	"Chen, Chen; Zhu, Weixing; Norton, Tomas"	Behaviour recognition of pigs and cattle: Journey from computer vision to deep learning	NA	NA	Review	Computers and Electronics in Agriculture	187		106255	10.1016/j.compag.2021.106255	https://www.sciencedirect.com/science/article/pii/S0168169921002726	"The increasing demand for sustainable livestock products also demands new considerations in animal breeding. Breeding programs are now seeking to integrate animal behavioural phenotypes, as these relate to the productivity, health and welfare of the animals and thereby can influence yield and economic benefits in the industry. Traditional manual observation of pig behaviour is time-consuming, laborious, subjective, and difficult to achieve in continuous and large-scale operations. It is not surprising that computer vision technology with the advantages of being objective, non-invasive and continuous has been widely researched for its use in the recognition of livestock behaviours over recent years. Nevertheless, in studies of livestock behaviour recognition, computer vision technology faces some challenges, e.g., complex scenes, variable illumination, occlusion, touching and overlapping between livestock, which has limited the fast translation of technology to industry. On the other hand, deep learning technology has proven to solve these difficulties to a certain extent and is being adopted to recognise livestock behaviours. This paper mainly evaluates the recent developments in computer vision methods for recognition of these behaviours in pigs and cattle. The focus on these species is made possible by the number of studies exist quantifying behaviours that are of importance for their health, welfare and productivity such as aggression, drinking, feeding, lameness, mounting, posture, tail-biting and nursing. This review paper especially analyses the development of image segmentation, identification and behaviour recognition using tradition computer vision and more recent deep learning methods, and evaluates the evolution of key research in the field. We elaborate the research trend of livestock behaviour recognition from four aspects, i.e., development of robust livestock identification algorithms, recognition of livestock behaviours for different growth stages, further quantification of the results of behaviour recognition, and building evaluation system of growth status, health and welfare."																				
2021	"Chen, Jian-Wen; Lin, Wan-Ju; Cheng, Hui-Jun; Hung, Che-Lun; Lin, Chun-Yuan; Chen, Shu-Pei"	A Smartphone-Based Application for Scale Pest Detection Using Multiple-Object Detection Methods	Images	CNN	"Classification, Regression"	Electronics	10	4	372	10.3390/electronics10040372	https://www.mdpi.com/2079-9292/10/4/372	"Taiwan’s economy mainly relies on the export of agricultural products. If even the suspicion of a pest is found in the crop products after they are exported, not only are the agricultural products returned but the whole batch of crops is destroyed, resulting in extreme crop losses. The species of mealybugs, Coccidae, and Diaspididae, which are the primary pests of the scale insect in Taiwan, can not only lead to serious damage to the plants but also severely affect agricultural production. Hence, to recognize the scale pests is an important task in Taiwan’s agricultural field. In this study, we propose an AI-based pest detection system for solving the specific issue of detection of scale pests based on pictures. Deep-learning-based object detection models, such as faster region-based convolutional networks (Faster R-CNNs), single-shot multibox detectors (SSDs), and You Only Look Once v4 (YOLO v4), are employed to detect and localize scale pests in the picture. The experimental results show that YOLO v4 achieved the highest classification accuracy among the algorithms, with 100% in mealybugs, 89% in Coccidae, and 97% in Diaspididae. Meanwhile, the computational performance of YOLO v4 has indicated that it is suitable for real-time application. Moreover, the inference results of the YOLO v4 model further help the end user. A mobile application using the trained scale pest recognition model has been developed to facilitate pest identification in farms, which is helpful in applying appropriate pesticides to reduce crop losses."																				
2021	"Chen, Qianjun; Ding, Yongchang; Liu, Chang; Liu, Jie; He, Tingting"	Research on Spider Sex Recognition From Images Based on Deep Learning	Images	CNN	Classification	IEEE Access	9		120985-120995	10.1109/ACCESS.2021.3109120	https://ieeexplore.ieee.org/document/9525395	"The rapid and accurate identification of spider sex is the first step in spider image recognition. The traditional artificial method used to identify the sex of mature spiders is mainly based on their genital structures (male palps or female epigynum) and highly dependent on the professional background of the identifiers. This article uses computer-based deep learning and transfer learning to identify the sex of spider, explores the design and application of convolutional neural networks in deep learning for spider sex recognition from images, and establishes a neural network model that displays excellent performance in experiments. In addition to optimizing the network model, we select appropriate hyperparameters to improve the accuracy of recognition and reduce the influence of human factors in the identification process. Through a comparison of multiple sets of experiments based on existing sample data collected in the laboratory, we find that the transfer learning method based on Xception can obtain better prediction accuracy than ResNet-152. After data augmentation, the optimization of a combined activation function and the fine-tuning of frozen layers, the prediction accuracy reaches 98.02%, and for an actual measurement of independent samples, the recognition accuracy reaches 92.38%. Therefore, the proposed method can basically replace manual identification and provide a reference for the artificial intelligence-based identification of spider species. Additionally, the model results indicate that male and female dimorphism may exist beyond the non-genital characteristics of spiders."																				
2021	"Chen, Serena H.; Londoño-Larrea, Pablo; McGough, Andrew Stephen; Bible, Amber N.; Gunaratne, Chathika; Araujo-Granda, Pablo A.; Morrell-Falvey, Jennifer L.; Bhowmik, Debsindhu; Fuentes-Cabrera, Miguel"	Application of Machine Learning Techniques to an Agent-Based Model of Pantoea	Other	DNN	Regression	Frontiers in Microbiology	12			10.3389/fmicb.2021.726409	https://www.frontiersin.org/article/10.3389/fmicb.2021.726409	"Agent-based modeling (ABM) is a powerful simulation technique which describes a complex dynamic system based on its interacting constituent entities. While the flexibility of ABM enables broad application, the complexity of real-world models demands intensive computing resources and computational time; however, a metamodel may be constructed to gain insight at less computational expense. Here, we developed a model in NetLogo to describe the growth of a microbial population consisting of Pantoea. We applied 13 parameters that defined the model and actively changed seven of the parameters to modulate the evolution of the population curve in response to these changes. We efficiently performed more than 3,000 simulations using a Python wrapper, NL4Py. Upon evaluation of the correlation between the active parameters and outputs by random forest regression, we found that the parameters which define the depth of medium and glucose concentration affect the population curves significantly. Subsequently, we constructed a metamodel, a dense neural network, to predict the simulation outputs from the active parameters and found that it achieves high prediction accuracy, reaching an R2 coefficient of determination value up to 0.92. Our approach of using a combination of ABM with random forest regression and neural network reduces the number of required ABM simulations. The simplified and refined metamodels may provide insights into the complex dynamic system before their transition to more sophisticated models that run on high-performance computing systems. The ultimate goal is to build a bridge between simulation and experiment, allowing model validation by comparing the simulated data to experimental data in microbiology."																				
2021	"Chen, Zhiting; Liu, Hongyan; Xu, Chongyang; Wu, Xiuchen; Liang, Boyi; Cao, Jing; Chen, Deliang"	Modeling vegetation greenness and its climate sensitivity with deep-learning technology	Other	RNN	Regression	Ecology and Evolution	11	12	7335-7345	10.1002/ece3.7564	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.7564	"Climate sensitivity of vegetation has long been explored using statistical or process-based models. However, great uncertainties still remain due to the methodologies’ deficiency in capturing the complex interactions between climate and vegetation. Here, we developed global gridded climate–vegetation models based on long short-term memory (LSTM) network, which is a powerful deep-learning algorithm for long-time series modeling, to achieve accurate vegetation monitoring and investigate the complex relationship between climate and vegetation. We selected the normalized difference vegetation index (NDVI) that represents vegetation greenness as model outputs. The climate data (monthly temperature and precipitation) were used as inputs. We trained the networks with data from 1982 to 2003, and the data from 2004 to 2015 were used to validate the models. Error analysis and sensitivity analysis were performed to assess the model errors and investigate the sensitivity of global vegetation to climate change. Results show that models based on deep learning are very effective in simulating and predicting the vegetation greenness dynamics. For models training, the root mean square error (RMSE) is <0.01. Model validation also assure the accuracy of our models. Furthermore, sensitivity analysis of models revealed a spatial pattern of global vegetation to climate, which provides us a new way to investigate the climate sensitivity of vegetation. Our study suggests that it is a good way to integrate deep-learning method to monitor the vegetation change under global change. In the future, we can explore more complex climatic and ecological systems with deep learning and coupling with certain physical process to better understand the nature."																				
2021	"Christin, Sylvain; Hervet, Éric; Lecomte, Nicolas"	Going further with model verification and deep learning	NA	NA	Review	Methods in Ecology and Evolution	12	1	130-134	10.1111/2041-210X.13494	https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13494	"In our recent review paper aiming to introduce deep learning to ecologists, we presented a workflow describing the steps required to create a deep learning model. This figure did not present some of the following steps of model use such as model verification. By ensuring model adequacy, model verification is an important step after model creation in order to answer ecological questions. Adding model verification to a deep learning model development workflow can raise some new issues such as detecting the difference among the multiple datasets or what to do when model verification fails. In the spirit of our previous review, we identify some questions users trying to verify their deep learning model can have and try to find, for each, a solution to help them navigate the steps of deep learning model testing. We provide an additional cheat sheet to quickly help answer common questions regarding using model verification and deep learning. We hope these resources help stimulate further synthesis and coherence in the use of deep learning models in ecology"																				
2021	"Chung, Yi; Chou, Chih-Ang; Li, Chih-Yang"	Central Attention and a Dual Path Convolutional Neural Network in Real-World Tree Species Recognition	Images	CNN	Classification	International Journal of Environmental Research and Public Health	18	3	961	10.3390/ijerph18030961	https://www.mdpi.com/1660-4601/18/3/961	"Identifying plants is not only the job of professionals, but also useful or essential for the plant lover and the general public. Although deep learning approaches for plant recognition are promising, driven by the success of convolutional neural networks (CNN), their performances are still far from the requirements of an in-field scenario. First, we propose a central attention concept that helps focus on the target instead of backgrounds in the image for tree species recognition. It could prevent model training from confused vision by establishing a dual path CNN deep learning framework, in which the central attention model combined with the CNN model based on InceptionV3 were employed to automatically extract the features. These two models were then learned together with a shared classification layer. Experimental results assessed the effectiveness of our proposed approach which outperformed each uni-path alone, and existing methods in the whole plant recognition system. Additionally, we created our own tree image database where each photo contained a wealth of information on the entire tree instead of an individual plant organ. Lastly, we developed a prototype system of an online\/offline available tree species identification working on a consumer mobile platform that can identify the tree species not only by image recognition, but also detection and classification in real-time remotely."																				
2021	"Connolly, Rod M.; Fairclough, David V.; Jinks, Eric L.; Ditria, Ellen M.; Jackson, Gary; Lopez-Marcano, Sebastian; Olds, Andrew D.; Jinks, Kristin I."	Improved accuracy for automated counting of a fish in baited underwater videos for stock assessment	Images	CNN	Regression	Frontiers in Marine Science	8			10.3389/fmars.2021.658135	https://www.frontiersin.org/article/10.3389/fmars.2021.658135	"The ongoing need to sustainably manage fishery resources can benefit from fishery-independent monitoring of fish stocks. Camera systems, particularly baited remote underwater video system (BRUVS), are a widely used and repeatable method for monitoring relative abundance, required for building stock assessment models. The potential for BRUVS-based monitoring is restricted, however, by the substantial costs of manual data extraction from videos. Computer vision, in particular deep learning (DL) models, are increasingly being used to automatically detect and count fish at low abundances in videos. One of the advantages of BRUVS is that bait attractants help to reliably detect species in relatively short deployments (e.g., 1 h). The high abundances of fish attracted to BRUVS, however, make computer vision more difficult, because fish often obscure other fish. We build upon existing DL methods for identifying and counting a target fisheries species across a wide range of fish abundances. Using BRUVS imagery targeting a recovering fishery species, Australasian snapper ( Chrysophrys auratus ), we tested combinations of three further mathematical steps likely to generate accurate, efficient automation: (1) varying confidence thresholds (CTs), (2) on\/off use of sequential non-maximum suppression (Seq-NMS), and (3) statistical correction equations. Output from the DL model was more accurate at low abundances of snapper than at higher abundances (&amp;gt;15 fish per frame) where the model over-predicted counts by as much as 50%. The procedure providing the most accurate counts across all fish abundances, with counts either correct or within 1–2 of manual counts ( R 2 = 88%), used Seq-NMS, a 45% CT, and a cubic polynomial corrective equation. The optimised modelling provides an automated procedure offering an effective and efficient method for accurately identifying and counting snapper in the BRUV footage on which it was tested. Additional evaluation will be required to test and refine the procedure so that automated counts of snapper are accurate in the survey region over time, and to determine the applicability to other regions within the distributional range of this species. For monitoring stocks of fishery species more generally, the specific equations will differ but the procedure demonstrated here could help to increase the usefulness of BRUVS."																				
2021	"Conway, Alexander M.; Durbach, Ian N.; McInnes, Alistair; Harris, Robert N."	Frame-by-frame annotation of video recordings using deep neural networks	Video	"CNN, RNN"	Classification	Ecosphere	12	3	e03384	10.1002/ecs2.3384	https://onlinelibrary.wiley.com/doi/abs/10.1002/ecs2.3384	"Video data are widely collected in ecological studies, but manual annotation is a challenging and time-consuming task, and has become a bottleneck for scientific research. Classification models based on convolutional neural networks (CNNs) have proved successful in annotating images, but few applications have extended these to video classification. We demonstrate an approach that combines a standard CNN summarizing each video frame with a recurrent neural network (RNN) that models the temporal component of video. The approach is illustrated using two datasets: one collected by static video cameras detecting seal activity inside coastal salmon nets and another collected by animal-borne cameras deployed on African penguins, used to classify behavior. The combined RNN-CNN led to a relative improvement in test set classification accuracy over an image-only model of 25% for penguins (80% to 85%), and substantially improved classification precision or recall for four of six behavior classes (12–17%). Image-only and video models classified seal activity with very similar accuracy (88 and 89%), and no seal visits were missed entirely by either model. Temporal patterns related to movement provide valuable information about animal behavior, and classifiers benefit from including these explicitly. We recommend the inclusion of temporal information whenever manual inspection suggests that movement is predictive of class membership."																				
2021	"Curry, Ryan; Trotter, Cameron; McGough, A. Stephen"	Application of deep learning to camera trap data for ecologists in planning / engineering – Can captivity imagery train a model which generalises to the wild?	Images	CNN	Classification	2021 IEEE International Conference on Big Data (Big Data)			4011-4020	10.1109/BigData52589.2021.9671661	https://ieeexplore.ieee.org/document/9671661	"Understanding the abundance of a species is the first step towards understanding both its long-term sustainability and the impact that we may be having upon it. Ecologists use camera traps to remotely survey for the presence of specific animal species. Previous studies have shown that deep learning models can be trained to automatically detect and classify animals within camera trap imagery with high levels of confidence. However, the ability to train these models is reliant upon having enough high-quality training data. What happens when the animal is rare or the data sets are non-existent? This research proposes an approach of using images of rare animals in captivity (we focus on the Scottish wildcat) to generate the training dataset. We explore the challenges associated with generalising a model trained on captivity data when applied to data collected in the wild. The research is contextualised by the needs of ecologists in planning / engineering. Following precedents from other research, this project establishes an ensemble system of object detection, image segmentation and image classification models which are then tested using different image manipulation and class structuring techniques to encourage model generalisation. The research concludes, in the context of Scottish wildcat, that models trained on captivity imagery cannot be generalised to wild camera trap imagery using existing techniques. However, final model performances based on a two-class model (Wildcat vs Not Wildcat) achieved an overall accuracy score of 81.6% and Wildcat accuracy score of 54.8% on a test set in which only 1% of images contained a wildcat. This suggests using captivity images is feasible with further research. This is the first research which attempts to generate a training set based on captivity data and the first to explore the development of such models in the context of ecologists in planning / engineering."																				
2021	"de Lutio, Riccardo; She, Yihang; D’Aronco, Stefano; Russo, Stefania; Brun, Philipp; Wegner, Jan D.; Schindler, Konrad"	Digital taxonomist: Identifying plant species in community scientists’ photographs	"Images, Environmental"	CNN	Classification	ISPRS Journal of Photogrammetry and Remote Sensing	182		112-121	10.1016/j.isprsjprs.2021.10.002	https://www.sciencedirect.com/science/article/pii/S0924271621002641	"Automatic identification of plant specimens from amateur photographs could improve species range maps, thus supporting ecosystems research as well as conservation efforts. However, classifying plant specimens based on image data alone is challenging: some species exhibit large variations in visual appearance, while at the same time different species are often visually similar; additionally, species observations follow a highly imbalanced, long-tailed distribution due to differences in abundance as well as observer biases. On the other hand, most species observations are accompanied by side information about the spatial, temporal and ecological context. Moreover, biological species are not an unordered list of classes but embedded in a hierarchical taxonomic structure. We propose a multimodal deep learning model that takes into account these additional cues in a unified framework. Our Digital Taxonomist is able to identify plant species in photographs better than a classifier trained on the image content alone, the performance gained is over 6 percent points in terms of accuracy."																				
2021	"Delplanque, Alexandre; Foucher, Samuel; Lejeune, Philippe; Linchant, Julie; Théau, Jérôme"	Multispecies detection and identification of African mammals in aerial imagery using convolutional neural networks	Images	CNN	Classification	Remote Sensing in Ecology and Conservation	n/a	n/a		10.1002/rse2.234	https://onlinelibrary.wiley.com/doi/abs/10.1002/rse2.234	"Survey and monitoring of wildlife populations are among the key elements in nature conservation. The use of unmanned aerial vehicles and light aircrafts as aerial image acquisition systems is growing, as they are cheaper alternatives to traditional census methods. However, the manual localization and identification of species within imagery can be time-consuming and complex. Object detection algorithms, based on convolutional neural networks (CNNs), have shown a good capacity for animal detection. Nevertheless, most of the work has focused on binary detection cases (animal vs. background). The main objective of this study is to compare three recent detection algorithms to detect and identify African mammal species based on high-resolution aerial images. We evaluated the performance of three multi-class CNN algorithms: Faster-RCNN, Libra-RCNN and RetinaNet. Six species were targeted: topis (Damaliscus lunatus jimela), buffalos (Syncerus caffer), elephants (Loxodonta africana), kobs (Kobus kob), warthogs (Phacochoerus africanus) and waterbucks (Kobus ellipsiprymnus). The best model was then applied to a case study using an independent dataset. The best model was the Libra-RCNN, with the best mean average precision (0.80 ± 0.02), the lowest degree of interspecies confusion (3.5 ± 1.4%) and the lowest false positive per true positive ratio (1.7 ± 0.2) on the test set. This model was able to detect and correctly identify 73% of all individuals (1115), find 43 individuals of species other than those targeted and detect 84 missed individuals on our independent UAV dataset, with an average processing speed of 12 s/image. This model showed better detection performance than previous studies dealing with similar habitats. It was able to differentiate six animal species in nadir aerial images. Although limitations were observed with warthog identification and individual detection in herds, this model can save time and can perform precise surveys in open savanna."																				
2021	"Deneu, Benjamin; Servajean, Maximilien; Bonnet, Pierre; Botella, Christophe; Munoz, François; Joly, Alexis"	Convolutional neural networks improve species distribution modelling by capturing the spatial structure of the environment	Environmental	CNN	Modeling	PLOS Computational Biology	17	4	e1008856	10.1371/journal.pcbi.1008856	https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008856	"Convolutional Neural Networks (CNNs) are statistical models suited for learning complex visual patterns. In the context of Species Distribution Models (SDM) and in line with predictions of landscape ecology and island biogeography, CNN could grasp how local landscape structure affects prediction of species occurrence in SDMs. The prediction can thus reflect the signatures of entangled ecological processes. Although previous machine-learning based SDMs can learn complex influences of environmental predictors, they cannot acknowledge the influence of environmental structure in local landscapes (hence denoted “punctual models”). In this study, we applied CNNs to a large dataset of plant occurrences in France (GBIF), on a large taxonomical scale, to predict ranked relative probability of species (by joint learning) to any geographical position. We examined the way local environmental landscapes improve prediction by performing alternative CNN models deprived of information on landscape heterogeneity and structure (“ablation experiments”). We found that the landscape structure around location crucially contributed to improve predictive performance of CNN-SDMs. CNN models can classify the predicted distributions of many species, as other joint modelling approaches, but they further prove efficient in identifying the influence of local environmental landscapes. CNN can then represent signatures of spatially structured environmental drivers. The prediction gain is noticeable for rare species, which open promising perspectives for biodiversity monitoring and conservation strategies. Therefore, the approach is of both theoretical and practical interest. We discuss the way to test hypotheses on the patterns learnt by CNN, which should be essential for further interpretation of the ecological processes at play."																				
2021	"Deng, Zhiyu; Zhang, Jinming; Li, Junya; Zhang, Xiujun"	Application of Deep Learning in Plant–Microbiota Association Analysis	NA	NA	Review	Frontiers in Genetics	12			10.3389/fgene.2021.697090	https://www.frontiersin.org/article/10.3389/fgene.2021.697090	"Unraveling the association between microbiome and plant phenotype can illustrate the effect of microbiome on host and then guide the agriculture management. Adequate identification of species and appropriate choice of models are two challenges in microbiome data analysis. Computational models of microbiome data could help in association analysis between the microbiome and plant host. The deep learning methods have been widely used to learn the microbiome data due to their powerful strength of handling the complex, sparse, noisy, and high-dimensional data. Here, we review the analytic strategies in the microbiome data analysis and describe the applications of deep learning models for plant–microbiome correlation studies. We also introduce the application cases of different models in plant–microbiome correlation analysis and discuss how to adapt the models on the critical steps in data processing. From the aspect of data processing manner, model structure, and operating principle, most deep learning models are suitable for the plant microbiome data analysis. The ability of feature representation and pattern recognition is the advantage of deep learning methods in modeling and interpretation for association analysis. Based on published computational experiments, the convolutional neural network and graph neural networks could be recommended for plant microbiome analysis."																				
2021	"Dias, Fábio Felix; Ponti, Moacir Antonelli; Minghim, Rosane"	A classification and quantification approach to generate features in soundscape ecology using neural networks	Sound	CNN	"Classification, Regression"	Neural Computing and Applications	34	3	1923-1937	10.1007/s00521-021-06501-w	https://link.springer.com/article/10.1007/s00521-021-06501-w	"In soundscape ecology analysis, the use of acoustic features is well established and offers important baselines to ecological analyses. However, in many cases, the problem is difficult due to high-class overlap in terms of time-frequency characteristics, as well as the presence of noise. Deep neural networks have become state-of-the-art for feature learning in many multi-class applications, but they often present issues such as over-fitting or achieve unbalanced performances for different classes, which can hamper the deployment of such models in realistic scenarios. In the context of counting the number of classes in observations, the quantification task is attracting attention and was shown to be effective in other applications. This paper investigates the use of quantification combined with classification loss in order to train a convolutional neural network to classify species of birds and anurans. Results indicate quantification has advantages over both acoustic features alone and the use of regular classification networks, in particular in terms of generalization and class recall making it a suitable choice for segregation tasks related to soundscape ecology. Moreover, we show that a more compact network can outperform a deeper one for fine-grained scenarios of birds and anurans species."																				
2021	"Dong, Jian-E; Zhang, Ji; Zuo, Zhi-Tian; Wang, Yuan-Zhong"	Deep learning for species identification of bolete mushrooms with two-dimensional correlation spectral (2DCOS) images	Other	CNN	Classification	Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy	249		119211	10.1016/j.saa.2020.119211	https://www.sciencedirect.com/science/article/pii/S1386142520311902	"Bolete is well-known and widely consumed mushroom in the world. However, its medicinal properties and nutritional are completely different from one species to another. Therefore, the consumers need a fast and effective detection method to discriminate their species. A new method using directly digital images of two-dimensional correlation spectroscopy (2DCOS) for the species discrimination with deep learning is proposed in this paper. In our study, a total of 2054 fruiting bodies of 21 wild-grown bolete species were collected in 52 regions from 2011 to 2014. Firstly, we intercepted 1750–400 cm_1 fingerprint regions of each species from their mid-infrared (MIR) spectra, and converted them to 2DCOS spectra with matlab2017b. At the same time, we developed a specific method for the calculation of the 2DCOS spectra. Secondly, we established a deep residual convolutional neural network (Resnet) with 1848 (90%) 2DCOS spectral images. Therein, the discrimination of the bolete species using directly 2DCOS spectral images instead of data matric from the spectra was first to be reported. The results displayed that the respective identification accuracy of these samples was 100% in the training set and 99.76% in the test set. Then, 203 samples were accurately discriminated in 206 (10%) samples of external validation set. Thirdly, we employed t-SNE method to visualize and evaluate the spectral dataset. The result indicated that most samples can be clustered according to different species. Finally, a smartphone applications (APP) was developed based on the established 2DCOS spectral images strategy, which can make the discrimination of bolete mushrooms more easily in practice. In conclusion, deep learning method by using directly 2DCOS spectral image was considered to be an innovative and feasible way for the species discrimination of bolete mushrooms. Moreover, this method may be generalized to other edible mushrooms, food, herb and agricultural products in the further research."																				
2021	"Dourado-Filho, Luciano Araújo; Calumby, Rodrigo Tripodi"	An experimental assessment of deep convolutional features for plant species recognition	Images	CNN	Classification	Ecological Informatics	65		101411	10.1016/j.ecoinf.2021.101411	https://www.sciencedirect.com/science/article/pii/S1574954121002028	"The evolution of the Deep Convolutional Neural Networks (DCNN) has progressively increased their ability to transfer the weights learned with large generic datasets to tasks with smaller collections or more specific data. However, the adjustment of these networks for different domains usually demand a fine-tuning step for which data may not be abundant enough. That is the case of plant species recognition task, which also suffers from class imbalance. Moreover, there is still a large variety of classification effectiveness with the models trained with the features extracted with different networks. All these factors create a complex assessment scenario and demand costly experimental validation procedures. Hence, in the context of plant species recognition, this work performs a comparative study of multiple pre-trained DCNNs to extract deep features from images of multi-organ plant observations. Beyond it, Softmax and six variations of the Support Vector Machine (SVM) classifier were used for the assessment of the suitability of the evaluated DCNNs. The experimental validation demonstrates great effectiveness variances of different DCNNs for feature extraction and the importance of such an experimental assessment for classification accuracy maximization. Beyond it, our results also show that exploiting deep feature extraction and an SVM-based classification outperformed a traditional setting based on neural classifiers. In fact, considering a hyperparameter optimization, the top performing SVM configuration allowed 82% of Micro-F1 in contrast to 76% of the second best (Softmax). The experiments also highlight such behavior with an effectiveness evaluation which specially accounts for dataset imbalance, a usual scenario in plant species recognition."																				
2021	"Dufourq, Emmanuel; Durbach, Ian; Hansford, James P.; Hoepfner, Amanda; Ma, Heidi; Bryant, Jessica V.; Stender, Christina S.; Li, Wenyong; Liu, Zhiwei; Chen, Qing; Zhou, Zhaoli; Turvey, Samuel T."	Automated detection of Hainan gibbon calls for passive acoustic monitoring	Sound	CNN	Classification	Remote Sensing in Ecology and Conservation	7	3	475-487	10.1002/rse2.201	https://onlinelibrary.wiley.com/doi/10.1002/rse2.201	"Extracting species calls from passive acoustic recordings is a common preliminary step to ecological analysis. For many species, particularly those occupying noisy, acoustically variable habitats, the call extraction process continues to be largely manual, a time-consuming and increasingly unsustainable process. Deep neural networks have been shown to offer excellent performance across a range of acoustic classiﬁcation applications, but are relatively underused in ecology. We describe the steps involved in developing an automated classiﬁer for a passive acoustic monitoring project, using the identiﬁcation of calls of the Hainan gibbon Nomascus hainanus, one of the world’s rarest mammal species, as a case study. This includes preprocessing—selecting a temporal resolution, windowing and annotation; data augmentation; processing—choosing and ﬁtting appropriate neural network models; and post-processing—linking model predictions to replace, or more likely facilitate, manual labelling. Our best model converted acoustic recordings into spectrogram images on the mel frequency scale, using these to train a convolutional neural network. Model predictions were highly accurate, with per-second false positive and false negative rates of 1.5% and 22.3%. Nearly all false negatives were at the fringes of calls, adjacent to segments where the call was correctly identiﬁed, so that very few calls were missed altogether. A post-processing step identifying intervals of repeated calling reduced an 8-h recording to, on average, 22 min for manual processing, and did not miss any calling bouts over 72 h of test recordings. Gibbon calling bouts were detected regularly in multi-month recordings from all selected survey points within Bawangling National Nature Reserve, Hainan. We demonstrate that passive acoustic monitoring incorporating an automated classiﬁer represents an effective tool for remote detection of one of the world’s rarest and most threatened species. Our study highlights the viability of using neural networks to automate or greatly assist the manual labelling of data collected by passive acoustic monitoring projects. We emphasize that model development and implementation be informed and guided by ecological objectives, and increase accessibility of these tools with a series of notebooks that allow users to build and deploy their own acoustic classiﬁers."																				
2021	"Duggan, Matthew T.; Groleau, Melissa F.; Shealy, Ethan P.; Self, Lillian S.; Utter, Taylor E.; Waller, Matthew M.; Hall, Bryan C.; Stone, Chris G.; Anderson, Layne L.; Mousseau, Timothy A."	An approach to rapid processing of camera trap images with minimal human input	Images	CNN	Classification	Ecology and Evolution	11	17	12051-12063	10.1002/ece3.7970	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.7970	"Camera traps have become an extensively utilized tool in ecological research, but the manual processing of images created by a network of camera traps rapidly becomes an overwhelming task, even for small camera trap studies. We used transfer learning to create convolutional neural network (CNN) models for identification and classification. By utilizing a small dataset with an average of 275 labeled images per species class, the model was able to distinguish between species and remove false triggers. We trained the model to detect 17 object classes with individual species identification, reaching an accuracy up to 92% and an average F1 score of 85%. Previous studies have suggested the need for thousands of images of each object class to reach results comparable to those achieved by human observers; however, we show that such accuracy can be achieved with fewer images. With transfer learning and an ongoing camera trap study, a deep learning model can be successfully created by a small camera trap study. A generalizable model produced from an unbalanced class set can be utilized to extract trap events that can later be confirmed by human processors."																				
2021	"Dujon, Antoine M.; Ierodiaconou, Daniel; Geeson, Johanna J.; Arnould, John P. Y.; Allan, Blake M.; Katselidis, Kostas A.; Schofield, Gail"	"Machine learning to detect marine animals in UAV imagery: effect of morphology, spacing, behaviour and habitat"	Images	CNN	Classification	Remote Sensing in Ecology and Conservation	7	3	341-354	10.1002/rse2.205	https://onlinelibrary.wiley.com/doi/abs/10.1002/rse2.205	"Machine learning algorithms are being increasingly used to process large volumes of wildlife imagery data from unmanned aerial vehicles (UAVs); however, suitable algorithms to monitor multiple species are required to enhance efficiency. Here, we developed a machine learning algorithm using a low-cost computer. We trained a convolutional neural network and tested its performance in: (1) distinguishing focal organisms of three marine taxa (Australian fur seals, loggerhead sea turtles and Australasian gannets; body size ranges: 0.8–2.5 m, 0.6–1.0 m, and 0.8–0.9 m, respectively); and (2) simultaneously delineating the fine-scale movement trajectories of multiple sea turtles at a fish cleaning station. For all species, the algorithm performed best at detecting individuals of similar body length, displaying consistent behaviour or occupying uniform habitat (proportion of individuals detected, or recall of 0.94, 0.79 and 0.75 for gannets, seals and turtles, respectively). For gannets, performance was impacted by spacing (huddling pairs with offspring) and behaviour (resting vs. flying shapes, overall precision: 0.74). For seals, accuracy was impacted by morphology (sexual dimorphism and pups), spacing (huddling and creches) and habitat complexity (seal sized boulders) (overall precision: 0.27). For sea turtles, performance was impacted by habitat complexity, position in water column, spacing, behaviour (interacting individuals) and turbidity (overall precision: 0.24); body size variation had no impact. For sea turtle trajectories, locations were estimated with a relative positioning error of <50 cm. In conclusion, we demonstrate that, while the same machine learning algorithm can be used to survey multiple species, no single algorithm captures all components optimally within a given site. We recommend that, rather than attempting to fully automate detection of UAV imagery data, semi-automation is implemented (i.e. part automated and part manual, as commonly practised for photo-identification). Approaches to enhance the efficiency of manual detection are required in parallel to the development of effective implementation of machine learning algorithms."																				
2021	"Edwards, Thomas; Jones, Christopher B.; Corcoran, Padraig"	Identifying wildlife observations on twitter	Other	Other	Classification	Ecological Informatics	67		101500	10.1016/j.ecoinf.2021.101500	https://www.sciencedirect.com/science/article/pii/S1574954121002910	"Despite the potential of social media for environmental monitoring, concerns remain about the quality and reliability of the information automatically extracted. Notably there are many observations of wildlife on Twitter, but their automated detection is a challenge due to the frequent use of wildlife related words in messages that have no connection with wildlife observation. We investigate whether and what type of supervised machine learning methods can be used to create a fully automated text classification model to identify genuine wildlife observations on Twitter, irrespective of species type or whether Tweets are geo-tagged. We perform experiments with various techniques for building feature vectors that serve as input to the classifiers, and consider how they affect classification performance. We compare three classification approaches and perform an analysis of the types of features that are indicative for genuine wildlife observations on Twitter. In particular, we compare some classical machine learning algorithms, widely used in ecology studies, with state-of-the-art neural network models. Results showed that the neural network-based model Bidirectional Encoder Representations from Transformers (BERT) outperformed the classical methods. Notably this was the case for a relatively small training corpus, consisting of less than 3000 instances. This reflects that fact that the BERT classifier uses a transfer learning approach that benefits from prior learning on a very much larger collection of generic text. BERT performed particularly well even for Tweets that employed specialised language relating to wildlife observations. The analysis of possible indicative features for wildlife Tweets revealed interesting trends in the usage of hashtags that are unrelated to official citizen science campaigns. The findings from this study facilitate more accurate identification of wildlife-related data on social media which can in turn be used for enriching citizen science data collections."																				
2021	"Engel, Anael; Reuben, Yaela; Kolesnikov, Irina; Churilov, Dmitri; Nathan, Ran; Genin, Amatzia"	In situ three-dimensional video tracking of tagged individuals within site-attached social groups of coral-reef fish	Video	CNN	Regression	Limnology and Oceanography: Methods	19	9	579-588	10.1002/lom3.10444	https://onlinelibrary.wiley.com/doi/abs/10.1002/lom3.10444	"Tracking the movement of all individual group members in their natural environment remains a challenging task. Using advances in computer vision and Deep Learning, we developed and tested a semi-automated in situ tracking system to reconstruct simultaneous three-dimensional trajectories of marked individuals in social groups of a coral-reef fish. Our system has a temporal resolution of 10s of milliseconds, allowing for multiple 30-min tracking sessions that have been repeated over weeks to months. We present the technique and illustrate its application for Dascyllus marginatus, a planktivorous damselfish that lives in social groups associated with branching corals. Our technique identified all individuals 85–100% of the time, with a mean spatial error of 1.3 cm. It provides a cost-effective semi-automated tool for in situ research on movements and foraging of individuals within small site-attached groups of animals in their natural environment."																				
2021	"Eryigit, Recep; Tugrul, Bulent"	Performance of Various Deep-Learning Networks in the Seed Classification Problem	Images	CNN	Classification	Symmetry	13	10	1892	10.3390/sym13101892	https://www.mdpi.com/2073-8994/13/10/1892	We report the results of an in-depth study of 15 variants of five different Convolutional Neural Network (CNN) architectures for the classification of seeds of seven different grass species that possess symmetry properties. The performance metrics of the nets are investigated in relation to the computational load and the number of parameters. The results indicate that the relation between the accuracy performance and operation count or number of parameters is linear in the same family of nets but that there is no relation between the two when comparing different CNN architectures. Using default pre-trained weights of the CNNs was found to increase the classification accuracy by ≈3% compared with training from scratch. The best performing CNN was found to be DenseNet201 with a 99.42% test accuracy for the highest resolution image set.																				
2021	"Fabija_ska, Anna; Danek, Ma_gorzata; Barniak, Joanna"	Wood species automatic identification from wood core images with a residual convolutional neural network	Images	CNN	Classification	Computers and Electronics in Agriculture	181		105941	10.1016/j.compag.2020.105941	https://www.sciencedirect.com/science/article/pii/S016816992033146X	"This paper tackles the problem of automatic tree species identification from scanned images of wood cores. A convolutional neural network with residual connections is proposed to perform this task. The model is applied to consecutive image patches following the sliding window strategy to recognize a patch central pixel’s membership. It then decides about the resulting tree species via a majority voting. The model’s performance was assessed concerning a dataset of 312 wood core images representing 14 European tree species, including both conifer and angiosperm (ring-porous and diffuse-porous) wood. Two tasks were considered, including wood patch classification and wood core classification. In these tasks, the proposed model correctly recognized species of almost 93% the wood image patches and 98.7% of wood core images. It also outperformed the state-of-the-art convolutional neural network-based competitor by 9% and 3%, respectively. The influence of the model’s parameters and training set-up on its performance is analyzed in the manuscript to ensure the highest recognition rates of wood species. The source code of the proposed method is released together with the corresponding image dataset to facilitate the reproduction of results."																				
2021	"Fan, Li; Xu, Chunpeng; Jarzembowski, Edmund A.; Cui, Xiaohui"	Quantifying plant mimesis in fossil insects using deep learning	Images	CNN	Regression	Historical Biology	0	0	10-Jan	10.1080/08912963.2021.1952199	https://www.tandfonline.com/doi/abs/10.1080/08912963.2021.1952199	"As an important combination of behaviour and pattern in animals to resemble benign objects, biolog ical mimesis can effectively avoid the detection of their prey and predators. It at least dates back to the Permian in fossil records. The recognition of mimesis within fossil, however, might be subjective and lack quantitative analysis being only based on few fossils with limited information. To compensate for this omission, we propose a new method using a Siamese network to measure the dissimilarity between hypothetical mimics and their models from images. It generates dissimilarity values between paired images of organisms by extracting feature vectors and calculating Euclidean distances. Additionally, the idea of ‘transfer learning’ is adopted to fine-tune the Siamese network, to overcome the limitations of available fossil image pairs. We use the processed Totally-Looks-Like, a large similar image data set, to pretrain the Siamese network and fine-tune it with a collected mimetic-image data set. Based on our results, we propose two recommended image dissimilarity thresholds for judging the mimicry of extant insects (0–0.4556) and fossil insects (0–0.4717). Deep learning algorithms are used to quantify the mimicry of fossil insects in this study, providing novel insights into exploring the early evolution of mimicry."																				
2021	"Fang, Zhencheng; Zhou, Hongwei"	VirionFinder: Identification of Complete and Partial Prokaryote Virus Virion Protein From Virome Data Using the Sequence and Biochemical Properties of Amino Acids	Molecular	CNN	Classification	Frontiers in Microbiology	12			10.3389/fmicb.2021.615711	https://www.frontiersin.org/article/10.3389/fmicb.2021.615711	"Viruses are some of the most abundant biological entities on Earth, and prokaryote virus are the dominant members of the viral community. Because of the diversity of prokaryote virus, functional annotation cannot be performed on a large number of genes from newly discovered prokaryote virus by searching the current database; therefore, the development of an alignment-free algorithm for functional annotation of prokaryote virus proteins is important to understand the viral community. The identification of prokaryote virus virion proteins (PVVPs) is a critical step for many viral analyses, such as species classification, phylogenetic analysis and the exploration of how prokaryote virus interact with their hosts. Although a series of PVVP prediction tools have been developed, the performance of these tools is still not satisfactory. Moreover, viral metagenomic data contains fragmented sequences, leading to the existence of some incomplete genes. Therefore, a tool that can identify partial PVVPs is also needed. In this work, we present a novel algorithm, called VirionFinder, to identify the complete and partial PVVPs from non-prokaryote virus virion proteins (non-PVVPs). VirionFinder uses the sequence and biochemical properties of 20 amino acids as the mathematical model to encode the protein sequences and uses a deep learning technique to identify whether a given protein is a PVVP. Compared with the state-of-the-art tools using artificial benchmark datasets, the results show that under the same specificity (Sp), the sensitivity (Sn) of VirionFinder is approximately 10–34% much higher than the Sn of these tools on both complete and partial proteins. When evaluating related tools using real virome data, the recognition rate of PVVP-like sequences of VirionFinder is also much higher than that of the other tools. We expect that VirionFinder will be a powerful tool for identifying novel virion proteins from both complete prokaryote virus genomes and viral metagenomic data. VirionFinder is freely available at https://github.com/zhenchengfang/VirionFinder."																				
2021	"Fennell, John G.; Talas, Laszlo; Baddeley, Roland J.; Cuthill, Innes C.; Scott-Samuel, Nicholas E."	The Camouflage Machine: Optimizing protective coloration using deep learning with genetic algorithms	Other	DNN	Regression	Evolution	75	3	614-624	10.1111/evo.14162	https://onlinelibrary.wiley.com/doi/abs/10.1111/evo.14162	"Evolutionary biologists frequently wish to measure the fitness of alternative phenotypes using behavioral experiments. However, many phenotypes are complex. One example is coloration: camouflage aims to make detection harder, while conspicuous signals (e.g., for warning or mate attraction) require the opposite. Identifying the hardest and easiest to find patterns is essential for understanding the evolutionary forces that shape protective coloration, but the parameter space of potential patterns (colored visual textures) is vast, limiting previous empirical studies to a narrow range of phenotypes. Here, we demonstrate how deep learning combined with genetic algorithms can be used to augment behavioral experiments, identifying both the best camouflage and the most conspicuous signal(s) from an arbitrarily vast array of patterns. To show the generality of our approach, we do so for both trichromatic (e.g., human) and dichromatic (e.g., typical mammalian) visual systems, in two different habitats. The patterns identified were validated using human participants; those identified as the best for camouflage were significantly harder to find than a tried-and-tested military design, while those identified as most conspicuous were significantly easier to find than other patterns. More generally, our method, dubbed the “Camouflage Machine,” will be a useful tool for identifying the optimal phenotype in high dimensional state spaces."																				
2021	"Fonseca, Emanuel M.; Colli, Guarino R.; Werneck, Fernanda P.; Carstens, Bryan C."	Phylogeographic model selection using convolutional neural networks	Molecular	CNN	Classification	Molecular Ecology Resources	21	8	2661-2675	10.1111/1755-0998.13427	https://onlinelibrary.wiley.com/doi/abs/10.1111/1755-0998.13427	"The discipline of phylogeography has evolved rapidly in terms of the analytical toolkit used to analyse large genomic data sets. Despite substantial advances, analytical tools that could potentially address the challenges posed by increased model complexity have not been fully explored. For example, deep learning techniques are underutilized for phylogeographic model selection. In non-model organisms, the lack of information about their ecology and evolution can lead to uncertainty about which demographic models are appropriate. Here, we assess the utility of convolutional neural networks (CNNs) for assessing demographic models in South American lizards in the genus Norops. Three demographic scenarios (constant, expansion, and bottleneck) were considered for each of four inferred population-level lineages, and we found that the overall model accuracy was higher than 98% for all lineages. We then evaluated a set of 26 models that accounted for evolutionary relationships, gene flow, and changes in effective population size among the four lineages, identifying a single model with an estimated overall accuracy of 87% when using CNNs. The inferred demography of the lizard system suggests that gene flow between non-sister populations and changes in effective population sizes through time, probably in response to Pleistocene climatic oscillations, have shaped genetic diversity in this system. Approximate Bayesian computation (ABC) was applied to provide a comparison to the performance of CNNs. ABC was unable to identify a single model among the larger set of 26 models in the subsequent analysis. Our results demonstrate that CNNs can be easily and usefully incorporated into the phylogeographer's toolkit."																				
2021	"Fontaine, Laurent; Khomich, Maryia; Andersen, Tom; Hessen, Dag O.; Rasconi, Serena; Davey, Marie L.; Eiler, Alexander"	Multiple thresholds and trajectories of microbial biodiversity predicted across browning gradients by neural networks and decision tree learning	Other	DNN	Regression	ISME Communications	1	1	37	10.1038/s43705-021-00038-8	https://www.nature.com/articles/s43705-021-00038-8	"Ecological association studies often assume monotonicity such as between biodiversity and environmental properties although there is growing evidence that nonmonotonic relations dominate in nature. Here, we apply machine-learning algorithms to reveal the nonmonotonic association between microbial diversity and an anthropogenic-induced large-scale change, the browning of freshwaters, along a longitudinal gradient covering 70 boreal lakes in Scandinavia. Measures of bacterial richness and evenness (alpha-diversity) showed nonmonotonic trends in relation to environmental gradients, peaking at intermediate levels of browning. Depending on the statistical methods, variables indicative for browning could explain 5% of the variance in bacterial community composition (beta-diversity) when applying standard methods assuming monotonic relations and up to 45% with machine-learning methods taking non-monotonicity into account. This non-monotonicity observed at the community level was explained by the complex interchangeable nature of individual taxa responses as shown by a high degree of nonmonotonic responses of individual bacterial sequence variants to browning. Furthermore, the nonmonotonic models provide the position of thresholds and predict alternative bacterial diversity trajectories in boreal freshwater as a result of ongoing climate and land-use changes, which in turn will affect entire ecosystem metabolism and likely greenhouse gas production."																				
2021	"Galanty, Agnieszka; Danel, Tomasz; W_grzyn, Micha_; Podolak, Irma; Podolak, Igor"	Deep convolutional neural network for preliminary in-field classification of lichen species	Images	CNN	Classification	Biosystems Engineering	204		15-25	10.1016/j.biosystemseng.2021.01.004	https://www.sciencedirect.com/science/article/pii/S1537511021000052	"Lichens are unique organisms, valued for their pharmacological activity, but also well known as bioindicators of environmental pollution, key determinants for some natural ecological habitats, or just popular elements of decoration. High morphological similarity between lichen species makes their recognition complicated, especially under in-field conditions. Thus, there is a need for a quick and easy method that can help with the preliminary classification of selected lichen species. This paper presents a tool that can facilitate the recognition of Cladonia lichen species, based on a deep convolutional neural network, a model which has nowadays reached a classification level often comparable to humans. The network was trained and tested on twelve Cladonia species using a total of 1164 images, downloaded from various websites. The trained model achieved 60.94% accuracy, which is satisfactory for this novel, but still preliminary, automated classification of lichen species."																				
2021	"Gerovichev, Alexander; Sadeh, Achiad; Winter, Vlad; Bar-Massada, Avi; Keasar, Tamar; Keasar, Chen"	High Throughput Data Acquisition and Deep Learning for Insect Ecoinformatics	Images	CNN	Regression	Frontiers in Ecology and Evolution	9			10.3389/fevo.2021.600931/full	https://www.frontiersin.org/article/10.3389/fevo.2021.600931	"Ecology documents and interprets the abundance and distribution of organisms. Ecoinformatics addresses this challenge by analyzing databases of observational data. Ecoinformatics of insects has high scientific and applied importance, as insects are abundant, speciose, and involved in many ecosystem functions. They also crucially impact human well-being, and human activities dramatically affect insect demography and phenology. Hazards, such as pollinator declines, outbreaks of agricultural pests and the spread insect-borne diseases, raise an urgent need to develop ecoinformatics strategies for their study. Yet, insect databases are mostly focused on a small number of pest species, as data acquisition is labor-intensive and requires taxonomical expertise. Thus, despite decades of research, we have only a qualitative notion regarding fundamental questions of insect ecology, and only limited knowledge about the spatio-temporal distribution of insects. We describe a novel high throughput cost-effective approach for monitoring flying insects as an enabling step toward “big data” entomology. The proposed approach combines “high tech” deep learning with “low tech” sticky traps that sample flying insects in diverse locations. As a proof of concept we considered three recent insect invaders of Israel’s forest ecosystem: two hemipteran pests of eucalypts and a parasitoid wasp that attacks one of them. We developed software, based on deep learning, to identify the three species in images of sticky traps from Eucalyptus forests. These image processing tasks are quite difficult as the insects are small (<5 mm) and stick to the traps in random poses. The resulting deep learning model discriminated the three focal organisms from one another, as well as from other elements such as leaves and other insects, with high precision. We used the model to compare the abundances of these species among six sites, and validated the results by manually counting insects on the traps. Having demonstrated the power of the proposed approach, we started a more ambitious study that monitors these insects at larger spatial and temporal scales. We aim at building an ecoinformatics repository for trap images and generating data-driven models of the populations’ dynamics and morphological traits."																				
2021	"Gower, Graham; Picazo, Pablo Iáñez; Fumagalli, Matteo; Racimo, Fernando"	Detecting adaptive introgression in human evolution using convolutional neural networks	Molecular	CNN	Classification	eLife	10		e64669	10.7554/eLife.64669	https://doi.org/10.7554/eLife.64669	"Studies in a variety of species have shown evidence for positively selected variants introduced into a population via introgression from another, distantly related population—a process known as adaptive introgression. However, there are few explicit frameworks for jointly modelling introgression and positive selection, in order to detect these variants using genomic sequence data. Here, we develop an approach based on convolutional neural networks (CNNs). CNNs do not require the specification of an analytical model of allele frequency dynamics and have outperformed alternative methods for classification and parameter estimation tasks in various areas of population genetics. Thus, they are potentially well suited to the identification of adaptive introgression. Using simulations, we trained CNNs on genotype matrices derived from genomes sampled from the donor population, the recipient population and a related non-introgressed population, in order to distinguish regions of the genome evolving under adaptive introgression from those evolving neutrally or experiencing selective sweeps. Our CNN architecture exhibits 95% accuracy on simulated data, even when the genomes are unphased, and accuracy decreases only moderately in the presence of heterosis. As a proof of concept, we applied our trained CNNs to human genomic datasets—both phased and unphased—to detect candidates for adaptive introgression that shaped our evolutionary history."																				
2021	"Guglielmo, Garcia Fernandez; Martignac, François; Nevoux, Marie; Beaulaton, Laurent; Corpetti, Thomas"	A deep neural network for multi-species fish detection using multiple acoustic cameras	Sound	CNN	"Classification, Regression"	arXiv				10.48550/arXiv.2109.10664	http://arxiv.org/abs/2109.10664	"Underwater acoustic cameras are high potential devices for many applications in ecology, notably for fisheries management and monitoring. However how to extract such data into high value information without a time-consuming entire dataset reading by an operator is still a challenge. Moreover the analysis of acoustic imaging, due to its low signal-to-noise ratio, is a perfect training ground for experimenting with new approaches, especially concerning Deep Learning techniques. We present hereby a novel approach that takes advantage of both CNN (Convolutional Neural Network) and classical CV (Computer Vision) techniques, able to detect a generic class ''fish'' in acoustic video streams. The pipeline pre-treats the acoustic images to extract 2 features, in order to localise the signals and improve the detection performances. To ensure the performances from an ecological point of view, we propose also a two-step validation, one to validate the results of the trainings and one to test the method on a real-world scenario. The YOLOv3-based model was trained with data of fish from multiple species recorded by the two common acoustic cameras, DIDSON and ARIS, including species of high ecological interest, as Atlantic salmon or European eels. The model we developed provides satisfying results detecting almost 80% of fish and minimizing the false positive rate, however the model is much less efficient for eel detections on ARIS videos. The first CNN pipeline for fish monitoring exploiting video data from two models of acoustic cameras satisfies most of the required features. Many challenges are still present, such as the automation of fish species identification through a multiclass model. 1 However the results point a new solution for dealing with complex data, such as sonar data, which can also be reapplied in other cases where the signal-to-noise ratio is a challenge."																				
2021	"Guirado, Emilio; Blanco-Sacristán, Javier; Rodríguez-Caballero, Emilio; Tabik, Siham; Alcaraz-Segura, Domingo; Martínez-Valderrama, Jaime; Cabello, Javier"	Mask R-CNN and OBIA Fusion Improves the Segmentation of Scattered Vegetation in Very High-Resolution Optical Sensors	Images	CNN	Classification	Sensors	21	1	320	10.3390/s21010320	https://www.mdpi.com/1424-8220/21/1/320	"Vegetation generally appears scattered in drylands. Its structure, composition and spatial patterns are key controls of biotic interactions, water, and nutrient cycles. Applying segmentation methods to very high-resolution images for monitoring changes in vegetation cover can provide relevant information for dryland conservation ecology. For this reason, improving segmentation methods and understanding the effect of spatial resolution on segmentation results is key to improve dryland vegetation monitoring. We explored and analyzed the accuracy of Object-Based Image Analysis (OBIA) and Mask Region-based Convolutional Neural Networks (Mask R-CNN) and the fusion of both methods in the segmentation of scattered vegetation in a dryland ecosystem. As a case study, we mapped Ziziphus lotus, the dominant shrub of a habitat of conservation priority in one of the driest areas of Europe. Our results show for the first time that the fusion of the results from OBIA and Mask R-CNN increases the accuracy of the segmentation of scattered shrubs up to 25% compared to both methods separately. Hence, by fusing OBIA and Mask R-CNNs on very high-resolution images, the improved segmentation accuracy of vegetation mapping would lead to more precise and sensitive monitoring of changes in biodiversity and ecosystem services in drylands."																				
2021	"Guo, Qian; Li, Mo; Wang, Chunhui; Guo, Jinyuan; Jiang, Xiaoqing; Tan, Jie; Wu, Shufang; Wang, Peihong; Xiao, Tingting; Zhou, Man; Fang, Zhencheng; Xiao, Yonghong; Zhu, Huaiqiu"	Predicting hosts based on early SARS-CoV-2 samples and analyzing the 2020 pandemic	Molecular	CNN	Classification	Scientific Reports	11	1	17422	10.1038/s41598-021-96903-6	https://www.nature.com/articles/s41598-021-96903-6	"The SARS-CoV-2 pandemic has raised concerns in the identification of the hosts of the virus since the early stages of the outbreak. To address this problem, we proposed a deep learning method, DeepHoF, based on extracting viral genomic features automatically, to predict the host likelihood scores on five host types, including plant, germ, invertebrate, non-human vertebrate and human, for novel viruses. DeepHoF made up for the lack of an accurate tool, reaching a satisfactory AUC of 0.975 in the five-classification, and could make a reliable prediction for the novel viruses without close neighbors in phylogeny. Additionally, to fill the gap in the efficient inference of host species for SARS-CoV-2 using existing tools, we conducted a deep analysis on the host likelihood profile calculated by DeepHoF. Using the isolates sequenced in the earliest stage of the COVID-19 pandemic, we inferred that minks, bats, dogs and cats were potential hosts of SARS-CoV-2, while minks might be one of the most noteworthy hosts. Several genes of SARS-CoV-2 demonstrated their significance in determining the host range. Furthermore, a large-scale genome analysis, based on DeepHoF’s computation for the later pandemic in 2020, disclosed the uniformity of host range among SARS-CoV-2 samples and the strong association of SARS-CoV-2 between humans and minks."																				
2021	"Hadjisolomou, Ekaterini; Stefanidis, Konstantinos; Herodotou, Herodotos; Michaelides, Michalis; Papatheodorou, George; Papastergiadou, Eva"	Modelling Freshwater Eutrophication with Limited Limnological Data Using Artificial Neural Networks	Environmental	DNN	Regression	Water	13	11	1590	10.3390/w13111590	https://www.mdpi.com/2073-4441/13/11/1590	"Artificial Neural Networks (ANNs) have wide applications in aquatic ecology and specifically in modelling water quality and biotic responses to environmental predictors. However, data scarcity is a common problem that raises the need to optimize modelling approaches to overcome data limitations. With this paper, we investigate the optimal k-fold cross validation in building an ANN using a small water-quality data set. The ANN was created to model the chlorophyll-a levels of a shallow eutrophic lake (Mikri Prespa) located in N. Greece. The typical water quality parameters serving as the ANN’s inputs are pH, dissolved oxygen, water temperature, phosphorus, nitrogen, electric conductivity, and Secchi disk depth. The available data set was small, containing only 89 data samples. For that reason, k-fold cross validation was used for training the ANN. To find the optimal k value for the k-fold cross validation, several values of k were tested (ranging from 3 to 30). Additionally, the leave-one-out (LOO) cross validation, which is an extreme case of the k-fold cross validation, was also applied. The ANN’s performance indices showed a clear trend to be improved as the k number was increased, while the best results were calculated for the LOO cross validation as expected. The computational times were calculated for each k value, where it was found the computational time is relatively low when applying the more expensive LOO cross validation; therefore, the LOO is recommended. Finally, a sensitivity analysis was examined using the ANN to investigate the interactions of the input parameters with the Chlorophyll-a, and hence examining the potential use of the ANN as a water management tool for nutrient control."																				
2021	"Hahn-Klimroth, Max; Kapetanopoulos, Tobias; Gübert, Jennifer; Dierkes, Paul Wilhelm"	Deep learning-based pose estimation for African ungulates in zoos	Video	CNN	Classification	Ecology and Evolution	11	11	6015-6032	10.1002/ece3.7367	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.7367	"The description and analysis of animal behavior over long periods of time is one of the most important challenges in ecology. However, most of these studies are limited due to the time and cost required by human observers. The collection of data via video recordings allows observation periods to be extended. However, their evaluation by human observers is very time-consuming. Progress in automated evaluation, using suitable deep learning methods, seems to be a forward-looking approach to analyze even large amounts of video data in an adequate time frame. In this study, we present a multistep convolutional neural network system for detecting three typical stances of African ungulates in zoo enclosures which works with high accuracy. An important aspect of our approach is the introduction of model averaging and postprocessing rules to make the system robust to outliers. Our trained system achieves an in-domain classification accuracy of >0.92, which is improved to >0.96 by a postprocessing step. In addition, the whole system performs even well in an out-of-domain classification task with two unknown types, achieving an average accuracy of 0.93. We provide our system at https://github.com/Klimroth/Video-Action-Classifier-for-African-Ungulates-in-Zoos/tree/main/mrcnn_based so that interested users can train their own models to classify images and conduct behavioral studies of wildlife. The use of a multistep convolutional neural network for fast and accurate classification of wildlife behavior facilitates the evaluation of large amounts of image data in ecological studies and reduces the effort of manual analysis of images to a high degree. Our system also shows that postprocessing rules are a suitable way to make species-specific adjustments and substantially increase the accuracy of the description of single behavioral phases (number, duration). The results in the out-of-domain classification strongly suggest that our system is robust and achieves a high degree of accuracy even for new species, so that other settings (e.g., field studies) can be considered."																				
2021	"Han, Ying; Chang, Qiuyue; Ding, Shuaimin; Gao, Meijing; Zhang, Bozhi; Li, Shiyu"	Research on multiple jellyfish classification and detection based on deep learning	Images	CNN	"Classification, Regression"	Multimedia Tools and Applications				10.1007/s11042-021-11307-y	https://doi.org/10.1007/s11042-021-11307-y	"In recent years, there have been frequent jellyfish outbreaks in many offshore areas worldwide, which have severely affected marine fishery production, coastal tourism, coastal industrial cooling water systems, and marine ecology. Achieving the monitoring of jellyfish plays a vital role in solving the problems mentioned above. However, the research on jellyfish is still in the primary stage. Jellyfish detection technology based on deep learning is gradually being applied to jellyfish detection due to its high efficiency and accuracy, but it is not systematic enough and can identify few jellyfish species. So this paper studies a jellyfish detection algorithm based on deep learning. Based on convolution neural network theory and digital image processing technology, 10 species of jellyfish and fish are detected. Because the quality of underwater images affects the detection accuracy, to further improve the accuracy of the detection algorithm, this paper studies the underwater image processing algorithm. Experimental results show that the image quality is better after applying the three algorithms of dark channel prior algorithm, quadratic combining gray world and perfect reflection algorithm, and contrast-limited adaptive histogram equalization algorithm, which is more conducive to detection. Then, deep learning theory is applied to classify jellyfish. By comparing the AlexNet and GoogLeNet backbone networks’ classification results, the accuracy of the jellyfish classification task based on the GoogLeNet backbone network is 96.21%, which is better than AlexNet. Finally, the Faster R-CNN algorithm is used to detect jellyfish, and its detection performance is analyzed based on the two backbone networks mentioned above. The results show that the Faster R-CNN algorithm based on GoogLeNet has a higher detection accuracy in the jellyfish detection task, with an average detection accuracy of 74.96%. In addition, we set up a new jellyfish data set, which includes 25,344 images. The images were divided into 11 species, including 10 species of jellyfish and one fish species. The paper’s research lays a theoretical and technical foundation for the subsequent construction of a real-time monitoring system for underwater jellyfish optical imaging, plays an important role in the development of jellyfish monitoring technology, and provides valuable information for marine biologists."																				
2021	"Hassan, Sk Mahmudul; Maji, Arnab Kumar; Jasi_ski, Micha_; Leonowicz, Zbigniew; Jasi_ska, El_bieta"	Identification of Plant-Leaf Diseases Using CNN and Transfer-Learning Approach	Images	CNN	Classification	Electronics	10	12	1388	10.3390/electronics10121388	https://www.mdpi.com/2079-9292/10/12/1388	"The timely identification and early prevention of crop diseases are essential for improving production. In this paper, deep convolutional-neural-network (CNN) models are implemented to identify and diagnose diseases in plants from their leaves, since CNNs have achieved impressive results in the field of machine vision. Standard CNN models require a large number of parameters and higher computation cost. In this paper, we replaced standard convolution with depth=separable convolution, which reduces the parameter number and computation cost. The implemented models were trained with an open dataset consisting of 14 different plant species, and 38 different categorical disease classes and healthy plant leaves. To evaluate the performance of the models, different parameters such as batch size, dropout, and different numbers of epochs were incorporated. The implemented models achieved a disease-classification accuracy rates of 98.42%, 99.11%, 97.02%, and 99.56% using InceptionV3, InceptionResNetV2, MobileNetV2, and EfficientNetB0, respectively, which were greater than that of traditional handcrafted-feature-based approaches. In comparison with other deep-learning models, the implemented model achieved better performance in terms of accuracy and it required less training time. Moreover, the MobileNetV2 architecture is compatible with mobile devices using the optimized parameter. The accuracy results in the identification of diseases showed that the deep CNN model is promising and can greatly impact the efficient identification of the diseases, and may have potential in the detection of diseases in real-time agricultural systems."																				
2021	"Hayes, Madeline C; Gray, Patrick C; Harris, Guillermo; Sedgwick, Wade C; Crawford, Vivon D; Chazal, Natalie; Crofts, Sarah; Johnston, David W"	Drones and deep learning produce accurate and efficient monitoring of large-scale seabird colonies	Images	CNN	Classification	Ornithological Applications	123	3	duab022	10.1093/ornithapp/duab022	https://academic.oup.com/condor/article/doi/10.1093/ornithapp/duab022/6281065	"Population monitoring of colonial seabirds is often complicated by the large size of colonies, remote locations, and close inter- and intra-species aggregation. While drones have been successfully used to monitor large inaccessible colonies, the vast amount of imagery collected introduces a data analysis bottleneck. Convolutional neural networks (CNN) are evolving as a prominent means for object detection and can be applied to drone imagery for population monitoring. In this study, we explored the use of these technologies to increase capabilities for seabird monitoring by using CNNs to detect and enumerate Black-browed Albatrosses (Thalassarche melanophris) and Southern Rockhopper Penguins (Eudyptes c. chrysocome) at one of their largest breeding colonies, the Falkland (Malvinas) Islands. Our results showed that these techniques have great potential for seabird monitoring at significant and spatially complex colonies, producing accuracies of correctly detecting and counting birds at 97.66% (Black-browed Albatrosses) and 87.16% (Southern Rockhopper Penguins), with 90% of automated counts being within 5% of manual counts from imagery. The results of this study indicate CNN methods are a viable population assessment tool, providing opportunities to reduce manual labor, cost, and human error."																				
2021	"He, Yichen; Cooney, Christopher R.; Varley, Zoë K.; Nouri, Lara O.; Moody, Christopher J. A.; Jardine, Michael D.; Maddock, Steve; Thomas, Gavin H."	Segmenting biological specimens from photos to understand the evolution of UV plumage in passerine birds	Images	CNN	Classification	bioRxiv			2021.07.22.453339	10.1101/2021.07.22.453339v4	https://www.biorxiv.org/content/10.1101/2021.07.22.453339v4	"Ultraviolet (UV) colouration is thought to be an important signalling mechanism in many bird species, yet broad insights regarding the prevalence of UV plumage colouration and the factors promoting its evolution are currently lacking. Here, we develop a novel image segmentation pipeline based on deep learning that considerably outperforms classical (i.e. non-deep learning) segmentation methods, and use this to extract accurate information on whole-body plumage colouration from photographs of >24,000 museum specimens covering >4,500 species of passerine birds. Our results demonstrate that UV reflectance, particularly as a component of other colours, is widespread across the passerine radiation but is strongly phylogenetically conserved. We also find clear evidence in support of the role of light environment in promoting the evolution of UV plumage colouration, and a weak trend towards higher UV plumage reflectance among bird species with ultraviolet rather than violet-sensitive visual systems. Overall, our study provides important broad-scale insight into an enigmatic component of avian colouration, as well as demonstrating that deep learning has considerable promise for allowing new data to be bought to bear on long-standing questions in ecology and evolution."																				
2021	"Heidary-Sharifabad, Ahmad; Zarchi, Mohsen Sardari; Emadi, Sima; Zarei, Gholamreza"	Efficient Deep Learning Models for Categorizing Chenopodiaceae in the Wild	Images	CNN	Classification	International Journal of Pattern Recognition and Artificial Intelligence	35	10	2152015	10.1142/S0218001421520157	https://www.worldscientific.com/doi/10.1142/S0218001421520157	"The Chenopodiaceae species are ecologically and financially important, and play a significant role in biodiversity around the world. Biodiversity protection is critical for the survival and sustainability of each ecosystem and since plant species recognition in their natural habitats is the first process in plant diversity protection, an automatic species classification in the wild would greatly help the species analysis and consequently biodiversity protection on earth. Computer vision approaches can be used for automatic species analysis. Modern computer vision approaches are based on deep learning techniques. A standard dataset is essential in order to perform a deep learning algorithm. Hence, the main goal of this research is to provide a standard dataset of Chenopodiaceae images. This dataset is called ACHENY and contains 27030 images of 30 Chenopodiaceae species in their natural habitats. The other goal of this study is to investigate the applicability of ACHENY dataset by using deep learning models. Therefore, two novel deep learning models based on ACHENY dataset are introduced: First, a lightweight deep model which is trained from scratch and is designed innovatively to be agile and fast. Second, a model based on the EfficientNet-B1 architecture, which is pre-trained on ImageNet and is fine-tuned on ACHENY. The experimental results show that the two proposed models can do Chenopodiaceae fine-grained species recognition with promising accuracy. To evaluate our models, their performance was compared with the well-known VGG-16 model after fine-tuning it on ACHENY. Both VGG-16 and our first model achieved about 80% accuracy while the size of VGG-16 is about 16 _ _ larger than the first model. Our second model has an accuracy of about 90% and outperforms the other models where its number of parameters is 5 _ _ than the first model but it is still about one-third of the VGG-16 parameters."																				
2021	"Hejase, Hussein A.; Mo, Ziyi; Campagna, Leonardo; Siepel, Adam"	SIA: Selection nference using the ancestral recombination graph	Molecular	RNN	Regression	bioRxiv				10.1101/2021.06.22.449427	http://biorxiv.org/lookup/doi/10.1101/2021.06.22.449427	"Detecting signals of selection from genomic data is a central problem in population genetics. Coupling the rich information in the ancestral recombination graph (ARG) with a powerful and scalable deep learning framework, we developed a novel method to detect and quantify positive selection: S election I nference using the A ncestral recombination graph (SIA). Built on a Long Short-Term Memory (LSTM) architecture, a particular type of a Recurrent Neural Network (RNN), SIA can be trained to explicitly infer a full range of selection coefficients, as well as the allele frequency trajectory and time of selection onset. We benchmarked SIA extensively on simulations under a European human demographic model, and found that it performs as well or better as some of the best available methods, including state-of-the-art machine-learning and ARG-based methods. In addition, we used SIA to estimate selection coefficients at several loci associated with human phenotypes of interest. SIA detected novel signals of selection particular to the European (CEU) population at the MC1R and ABCC11 loci. In addition, it recapitulated signals of selection at the LCT locus and several pigmentation-related genes. Finally, we reanalyzed polymorphism data of a collection of recently radiated southern capuchino seedeater taxa in the genus Sporophila to quantify the strength of selection and improved the power of our previous methods to detect partial soft sweeps. Overall, SIA uses deep learning to leverage the ARG and thereby provides new insight into how selective sweeps shape genomic diversity."																				
2021	"Hirn, J.; García, J. E.; Montesinos-Navarro, A.; Sanchez-Martín, R.; Sanz, V.; Verdú, M."	A Deep Generative Artificial Intelligence system to decipher species coexistence patterns	Other	VAE-GAN	"Regression, Modeling"	Methods in Ecology and Evolution				10.1111/2041-210X.13827	https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13827	"1. Deciphering coexistence patterns is a current challenge to understanding diversity maintenance, especially in rich communities where the complexity of these patterns is magnified through indirect interactions that prevent their approximation with classical experimental approaches. 2. We explore cutting-edge Machine Learning techniques called Generative Artificial Intelligence (GenAI) to decipher species coexistence patterns in vegetation patches, training generative adversarial networks (GAN) and variational AutoEncoders (VAE) that are then used to unravel some of the mechanisms behind community assemblage. 3. The GAN accurately reproduces the species composition of real patches as well as the affinity of plant species to different soil types, and the VAE also reaches a high level of accuracy, above 99%. Using the artificially generated patches, we found that high order interactions tend to suppress the positive effects of low order interactions. Finally, by reconstructing successional trajectories we could identify the pioneer species with larger potential to generate a high diversity of distinct patches in terms of species composition. 4. Understanding the complexity of species coexistence patterns in diverse ecological communities requires new approaches beyond heuristic rules. Generative Artificial Intelligence can be a powerful tool to this end as it allows to overcome the inherent dimensionality of this challenge."																				
2021	"Hoekendijk, Jeroen P. A.; Kellenberger, Benjamin; Aarts, Geert; Brasseur, Sophie; Poiesz, Suzanne S. H.; Tuia, Devis"	Counting using deep learning regression gives value to ecological surveys	Images	CNN	Regression	Scientific Reports	11	1	23209	10.1038/s41598-021-02387-9	https://www.nature.com/articles/s41598-021-02387-9	"Many ecological studies rely on count data and involve manual counting of objects of interest, which is time-consuming and especially disadvantageous when time in the field or lab is limited. However, an increasing number of works uses digital imagery, which opens opportunities to automatise counting tasks. In this study, we use machine learning to automate counting objects of interest without the need to label individual objects. By leveraging already existing image-level annotations, this approach can also give value to historical data that were collected and annotated over longer time series (typical for many ecological studies), without the aim of deep learning applications. We demonstrate deep learning regression on two fundamentally different counting tasks: (i) daily growth rings from microscopic images of fish otolith (i.e., hearing stone) and (ii) hauled out seals from highly variable aerial imagery. In the otolith images, our deep learning-based regressor yields an RMSE of 3.40 day-rings and an $$R^2$$ R 2 of 0.92. Initial performance in the seal images is lower ( RMSE of 23.46 seals and $$R^2$$ R 2 of 0.72), which can be attributed to a lack of images with a high number of seals in the initial training set, compared to the test set. We then show how to improve performance substantially ( RMSE of 19.03 seals and $$R^2$$ R 2 of 0.77) by carefully selecting and relabelling just 100 additional training images based on initial model prediction discrepancy. The regression-based approach used here returns accurate counts ( $$R^2$$ R 2 of 0.92 and 0.77 for the rings and seals, respectively), directly usable in ecological research."																				
2021	"Homan, Dewald; du Preez, Johan A."	Automated feature-specific tree species identification from natural images using deep semi-supervised learning	Images	CNN	Classification	Ecological Informatics	66		101475	10.1016/j.ecoinf.2021.101475	https://www.sciencedirect.com/science/article/pii/S1574954121002661	"Prior work on plant species classification predominantly focuses on building models from isolated plant attributes. Hence, there is a need for tools that can assist in species identification in the natural world. We present a novel and robust two-fold approach capable of identifying trees in a real-world natural setting. Additionally, we leverage unlabelled data through deep semi-supervised learning and demonstrate superior performance to supervised learning. Our single-GPU implementation for feature recognition uses minimal annotated data and achieves accuracies of 93.96% and 93.11% for leaves and bark, respectively. Further, we extract feature-specific datasets of 50 species by employing this technique. Finally, our semi-supervised species classification method attains 94.04% top-5 accuracy for leaves and 83.04% top-5 accuracy for bark."																				
2021	"Høye, Toke T.; Ärje, Johanna; Bjerge, Kim; Hansen, Oskar L. P.; Iosifidis, Alexandros; Leese, Florian; Mann, Hjalte M. R.; Meissner, Kristian; Melvad, Claus; Raitoharju, Jenni"	Deep learning and computer vision will transform entomology	NA	NA	Review	Proceedings of the National Academy of Sciences	118	2	e2002545117	10.1073/pnas.2002545117	http://www.pnas.org/lookup/doi/10.1073/pnas.2002545117	"Most animal species on Earth are insects, and recent reports suggest that their abundance is in drastic decline. Although these reports come from a wide range of insect taxa and regions, the evidence to assess the extent of the phenomenon is sparse. Insect populations are challenging to study, and most monitoring methods are labor intensive and inefficient. Advances in computer vision and deep learning provide potential new solutions to this global challenge. Cameras and other sensors can effectively, continuously, and noninvasively perform entomological observations throughout diurnal and seasonal cycles. The physical appearance of specimens can also be captured by automated imaging in the laboratory. When trained on these data, deep learning models can provide estimates of insect abundance, biomass, and diversity. Further, deep learning models can quantify variation in phenotypic traits, behavior, and interactions. Here, we connect recent developments in deep learning and computer vision to the urgent demand for more cost-efficient monitoring of insects and other invertebrates. We present examples of sensor-based monitoring of insects. We show how deep learning tools can be applied to exceptionally large datasets to derive ecological information and discuss the challenges that lie ahead for the implementation of such solutions in entomology. We identify four focal areas, which will facilitate this transformation: 1) validation of image-based taxonomic identification; 2) generation of sufficient training data; 3) development of public, curated reference databases; and 4) solutions to integrate deep learning and molecular tools."																				
2021	"Huang, Jia-Hsin; Liu, Yu-Ting; Ni, Hung Chih; Chen, Bo-Ye; Huang, Shih-Ying; Tsai, Huai-Kuang; Li, Hou-Feng"	Termite Pest Identification Method Based on Deep Convolution Neural Networks	Images	CNN	Classification	Journal of Economic Entomology	114	6	2452-2459	10.1093/jee/toab162	https://doi.org/10.1093/jee/toab162	"Several species of drywood termites, subterranean termites, and fungus-growing termites cause extensive economic losses annually worldwide. Because no universal method is available for controlling all termites, correct species identification is crucial for termite management. Despite deep neural network technologies’ promising performance in pest recognition, a method for automatic termite recognition remains lacking. To develop an automated deep learning classifier for termite image recognition suitable for mobile applications, we used smartphones to acquire 18,000 original images each of four termite pest species: Kalotermitidae: Cryptotermes domesticus (Haviland); Rhinotermitidae: Coptotermes formosanus Shiraki and Reticulitermes flaviceps (Oshima); and Termitidae: Odontotermes formosanus (Shiraki). Each original image included multiple individuals, and we applied five image segmentation techniques for capturing individual termites. We used 24,000 individual-termite images (4 species _ 2 castes _ 3 groups _ 1,000 images) for model development and testing. We implemented a termite classification system by using a deep learning–based model, MobileNetV2. Our models achieved high accuracy scores of 0.947, 0.946, and 0.929 for identifying soldiers, workers, and both castes, respectively, which is not significantly different from human expert performance. We further applied image augmentation techniques, including geometrical transformations and intensity transformations, to individual-termite images. The results revealed that the same classification accuracy can be achieved by using 1,000 augmented images derived from only 200 individual-termite images, thus facilitating further model development on the basis of many fewer original images. Our image-based identification system can enable the selection of termite control tools for pest management professionals or homeowners."																				
2021	"Hussein, Burhan Rashid; Malik, Owais Ahmed; Ong, Wee-Hong; Slik, Johan Willem Frederik"	Automated Extraction of Phenotypic Leaf Traits of Individual Intact Herbarium Leaves from Herbarium Specimen Images Using Deep Learning Based Semantic Segmentation	Images	CNN	"Classification, Regression"	Sensors	21	13	4549	10.3390/s21134549	https://www.mdpi.com/1424-8220/21/13/4549	"With the increase in the digitization efforts of herbarium collections worldwide, dataset repositories such as iDigBio and GBIF now have hundreds of thousands of herbarium sheet images ready for exploration. Although this serves as a new source of plant leaves data, herbarium datasets have an inherent challenge to deal with the sheets containing other non-plant objects such as color charts, barcodes, and labels. Even for the plant part itself, a combination of different overlapping, damaged, and intact individual leaves exist together with other plant organs such as stems and fruits, which increases the complexity of leaf trait extraction and analysis. Focusing on segmentation and trait extraction on individual intact herbarium leaves, this study proposes a pipeline consisting of deep learning semantic segmentation model (DeepLabv3+), connected component analysis, and a single-leaf classifier trained on binary images to automate the extraction of an intact individual leaf with phenotypic traits. The proposed method achieved a higher F1-score for both the in-house dataset (96%) and on a publicly available herbarium dataset (93%) compared to object detection-based approaches including Faster R-CNN and YOLOv5. Furthermore, using the proposed approach, the phenotypic measurements extracted from the segmented individual leaves were closer to the ground truth measurements, which suggests the importance of the segmentation process in handling background noise. Compared to the object detection-based approaches, the proposed method showed a promising direction toward an autonomous tool for the extraction of individual leaves together with their trait data directly from herbarium specimen images."																				
2021	"Hussein, Burhan Rashid; Malik, Owais Ahmed; Ong, Wee-Hong; Slik, Johan Willem Frederik"	Reconstruction of damaged herbarium leaves using deep learning techniques for improving classification accuracy	Images	"CNN, GAN"	"Classification, Modeling"	Ecological Informatics	61		101243	10.1016/j.ecoinf.2021.101243	https://linkinghub.elsevier.com/retrieve/pii/S1574954121000340	"Leaf is one of the most commonly used organs for species identification. The traditional identification process involves a manual analysis of individual dried or fresh leaf's features by the botanists. Recent advancements in computer vision techniques have assisted in automating the plants families/species identification process based on the digital images of leaves. However, most of the existing studies have focused on using datasets for fresh and intact leaves. A huge amount of data for preserved plants in the form of digitized herbaria specimens have not been effectively utilized for the task of automated identification because of the presence of damaged leaves in specimens. In this study, deep learning techniques have been proposed as a tool for reconstructing the damaged herbarium leaves in order to maximize the usefulness of the digitized specimens for automated plant identification task by increasing the number of individual samples of leaves. The reconstruction results of two different families of convolution neural networks (CNNs) have been compared for data from ten different plant families namely Anacardiaceae, Annonaceae, Dipterocarpaceae, Ebenaceae, Euphorbiaceae, Malvaceae, Phyllanthaceae, Polygalaceae, Rubiaceae and Sapotaceae. The performance of automated identification task was improved by more than 20% using the reconstructed leaves images as compared to using the original data (i.e. images of specimens with damaged leaves). This work evidently suggests that deep learning techniques can be utilized for reconstruction of damaged leaves even on a challenging herbarium leaves dataset."																				
2021	"Hwang, Sung-Wook; Sugiyama, Junji"	Computer vision-based wood identification and its expansion and contribution potentials in wood science: A review	NA	NA	Review	Plant Methods	17	1	47	10.1186/s13007-021-00746-1	https://doi.org/10.1186/s13007-021-00746-1	"The remarkable developments in computer vision and machine learning have changed the methodologies of many scientific disciplines. They have also created a new research field in wood science called computer vision-based wood identification, which is making steady progress towards the goal of building automated wood identification systems to meet the needs of the wood industry and market. Nevertheless, computer vision-based wood identification is still only a small area in wood science and is still unfamiliar to many wood anatomists. To familiarize wood scientists with the artificial intelligence-assisted wood anatomy and engineering methods, we have reviewed the published mainstream studies that used or developed machine learning procedures. This review could help researchers understand computer vision and machine learning techniques for wood identification and choose appropriate techniques or strategies for their study objectives in wood science."																				
2021	"Iqbal, Muhammad Ather; Wang, Zhijie; Ali, Zain Anwar; Riaz, Shazia"	Automatic Fish Species Classification Using Deep Convolutional Neural Networks	Images	CNN	Classification	Wireless Personal Communications	116	2	1043-1053	10.1007/s11277-019-06634-1	https://link.springer.com/article/10.1007/s11277-019-06634-1	"In this paper, we presented an automated system for identification and classification of fish species. It helps the marine biologists to have greater understanding of the fish species and their habitats. The proposed model is based on deep convolutional neural networks. It uses a reduced version of AlexNet model comprises of four convolutional layers and two fully connected layers. A comparison is presented against the other deep learning models such as AlexNet and VGGNet. The four parameters are considered that is number of convolutional layers and number of fully-connected layers, number of iterations to achieve 100% accuracy on training data, batch size and dropout layer. The results show that the proposed and modified AlexNet model with less number of layers has achieved the testing accuracy of 90.48% while the original AlexNet model achieved 86.65% over the untrained benchmark fish dataset. The inclusion of dropout layer has enhanced the overall performance of our proposed model. It contain less training images, less memory and it is also less computational complex."																				
2021	"Isildak, Ulas; Stella, Alessandro; Fumagalli, Matteo"	Distinguishing between recent balancing selection and incomplete sweep using deep neural networks	Molecular	CNN	Classification	Molecular Ecology Resources	21	8	2706-2718	10.1111/1755-0998.13379	https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13379	"Balancing selection is an important adaptive mechanism underpinning a wide range of phenotypes. Despite its relevance, the detection of recent balancing selection from genomic data is challenging as its signatures are qualitatively similar to those left by ongoing positive selection. In this study, we developed and implemented two deep neural networks and tested their performance to predict loci under recent selection, either due to balancing selection or incomplete sweep, from population genomic data. Specifically, we generated forward-_in-_time simulations to train and test an artificial neural network (ANN) and a convolutional neural network (CNN). ANN received as input multiple summary statistics calculated on the locus of interest, while CNN was applied directly on the matrix of haplotypes. We found that both architectures have high accuracy to identify loci under recent selection. CNN generally outperformed ANN to distinguish between signals of balancing selection and incomplete sweep and was less affected by incorrect training data. We deployed both trained networks on neutral genomic regions in European populations and demonstrated a lower false-_ positive rate for CNN than ANN. We finally deployed CNN within the MEFV gene region and identified several common variants predicted to be under incomplete sweep in a European population. Notably, two of these variants are functional changes and could modulate susceptibility to familial Mediterranean fever, possibly as a consequence of past adaptation to pathogens. In conclusion, deep neural networks were able to characterize signals of selection on intermediate frequency variants, an analysis currently inaccessible by commonly used strategies."																				
2021	"Jeantet, Lorène; Vigon, Vincent; Geiger, Sébastien; Chevallier, Damien"	Fully Convolutional Neural Network: A solution to infer animal behaviours from multi-sensor data	Other	"CNN, Other"	Classification	Ecological Modelling	450		109555	10.1016/j.ecolmodel.2021.109555	https://www.sciencedirect.com/science/article/pii/S0304380021001253	"Animal-attached accelerometers have been widely used to monitor species that are difficult to observe, alongside the use of machine learning to identify behaviours from the obtained sequences. Artificial neural networks are powerful supervised learning algorithms that are based on deep learning and have been poorly exploited in movement ecology. Recently, the availability of sophisticated algorithmic architectures via open source libraries facilitates their use. In this study, we adapt a fully convolutional neural network that was originally developed for biomedical 3D image segmentation: the V-net. We test it on a labelled dataset collected from animal-borne video recorders combined with multi-sensors (accelerometers, gyroscopes and depth recorders) deployed on free-ranging immature green turtles (Chelonia mydas). The proposed model, fitted for 1D data, is able to predict six behavioural categories for green turtles with an AUC score of 88%. It shows a high ability to detect rare behaviours with low discriminative signals such as Feeding and Scratching. With a precision down to one centisecond, the V-net circumvents the segmentation process. We also show that the gyroscope is more informative than the accelerometer in identifying sea turtle behaviours and that the V-net is not able to discriminate Feeding from the raw data of accelerometer alone. However, human expertise can help to correct it with precise and adapted pre-processing. Thus, diverted from its initial purpose and tested on sea turtle, the V-net is a very efficient method of behavioural identification that should be easily generalized to a wide range of species. It could lead to considerable progress in remote accelerometric monitoring and help to understand the ecology of the species that are difficult to observe. Furthermore, as the model is light, there is also a huge potential to implement a trained V-net in satellite-relay data tag to remotely predict the expressed behaviours almost instantly."																				
2021	"Jiang, Yueyu; Balaban, Metin; Zhu, Qiyun; Mirarab, Siavash"	DEPP: Deep Learning Enables Extending Species Trees using Single Genes	Molecular	CNN	Modeling	bioRxiv				10.1101/2021.01.22.427808	http://biorxiv.org/lookup/doi/10.1101/2021.01.22.427808	"Placing new sequences onto reference phylogenies is increasingly used for analyzing environmental samples, especially microbiomes. However, existing placement methods have a fundamental limitation: they assume that query sequences have evolved using specific models directly on the reference phylogeny. Thus, they can place single-gene data (e.g., 16S rRNA amplicons) onto their own gene tree. This practice is a proxy for a more ambitious goal: extending a (genome-wide) species tree given data from individual genes. No algorithm currently addresses this challenging problem. Here, we introduce Deep-learning Enabled Phylogenetic Placement (DEPP), an algorithm that learns to extend species trees using single genes without pre-specified models. We show that DEPP updates the multi-locus microbial tree-of-life with single genes with high accuracy. We further demonstrate that DEPP can achieve the long-standing goal of combining 16S and metagenomic data onto a single tree, enabling community structure analyses that were previously impossible and producing robust patterns."																				
2021	"Jin, Lina; Yu, Jiong; Yuan, Xiaoqian; Du, Xusheng"	Fish Classification Using DNA Barcode Sequences through Deep Learning Method	Molecular	VAE	Modeling	Symmetry	13	9	1599	10.3390/sym13091599	https://www.mdpi.com/2073-8994/13/9/1599	"Fish is one of the most extensive distributed organisms in the world. Fish taxonomy is an important component of biodiversity and the basis of fishery resources management. The DNA barcode based on a short sequence fragment is a valuable molecular tool for fish classification. However, the high dimensionality of DNA barcode sequences and the limitation of the number of fish species make it difficult to reasonably analyze the DNA sequences and correctly classify fish from different families. In this paper, we propose a novel deep learning method that fuses Elastic Net-Stacked Autoencoder (EN-SAE) with Kernel Density Estimation (KDE), named ESK model. In stage one, the ESK preprocesses original data from DNA barcode sequences. In stage two, EN-SAE is used to learn the deep features and obtain the outgroup score of each fish. In stage three, KDE is used to select a threshold based on the outgroup scores and classify fish from different families. The effectiveness and superiority of ESK have been validated by experiments on three datasets, with the accuracy, recall, F1-Score reaching 97.57%, 97.43%, and 98.96% on average. Those findings confirm that ESK can accurately classify fish from different families based on DNA barcode sequences."																				
2021	"Jung, Minah; Song, Jong Seob; Hong, Seongmin; Kim, SunWoo; Go, Sangjin; Lim, Yong Pyo; Park, Juhan; Park, Sung Goo; Kim, Yong-Min"	Deep Learning Algorithms Correctly Classify Brassica rapa Varieties Using Digital Images	Images	CNN	Classification	Frontiers in Plant Science	12			10.3389/fpls.2021.738685	https://www.frontiersin.org/article/10.3389/fpls.2021.738685	"Efficient and accurate methods of analysis are needed for the huge amount of biological data that have accumulated in various research fields, including genomics, phenomics, and genetics. Artificial intelligence (AI)-based analysis is one promising method to manipulate biological data. To this end, various algorithms have been developed and applied in fields such as disease diagnosis, species classification, and object prediction. In the field of phenomics, classification of accessions and variants is important for basic science and industrial applications. To construct AI-based classification models, three types of phenotypic image data were generated from 156 Brassica rapa core collections, and classification analyses were carried out using four different convolutional neural network architectures. The results of lateral view data showed higher accuracy compared with top view data. Furthermore, the relatively low accuracy of ResNet50 architecture suggested that definition and estimation of similarity index of phenotypic data were required before the selection of deep learning architectures."																				
2021	"Justen, Lennart; Carlsmith, Duncan; Paskewitz, Susan M.; Bartholomay, Lyric C.; Bron, Gebbiena M."	Identification of public submitted tick images: A neural network approach	Images	CNN	Classification	PLOS ONE	16	12	e0260622	10.1371/journal.pone.0260622	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0260622	"Ticks and tick-borne diseases represent a growing public health threat in North America and Europe. The number of ticks, their geographical distribution, and the incidence of tick-borne diseases, like Lyme disease, are all on the rise. Accurate, real-time tick-image identification through a smartphone app or similar platform could help mitigate this threat by informing users of the risks associated with encountered ticks and by providing researchers and public health agencies with additional data on tick activity and geographic range. Here we outline the requirements for such a system, present a model that meets those requirements, and discuss remaining challenges and frontiers in automated tick identification. We compiled a user-generated dataset of more than 12,000 images of the three most common tick species found on humans in the U.S.: Amblyomma americanum, Dermacentor variabilis, and Ixodes scapularis. We used image augmentation to further increase the size of our dataset to more than 90,000 images. Here we report the development and validation of a convolutional neural network which we call “TickIDNet,” that scores an 87.8% identification accuracy across all three species, outperforming the accuracy of identifications done by a member of the general public or healthcare professionals. However, the model fails to match the performance of experts with formal entomological training. We find that image quality, particularly the size of the tick in the image (measured in pixels), plays a significant role in the network’s ability to correctly identify an image: images where the tick is small are less likely to be correctly identified because of the small object detection problem in deep learning. TickIDNet’s performance can be increased by using confidence thresholds to introduce an “unsure” class and building image submission pipelines that encourage better quality photos. Our findings suggest that deep learning represents a promising frontier for tick identification that should be further explored and deployed as part of the toolkit for addressing the public health consequences of tick-borne diseases."																				
2021	"Kahl, Stefan; Wood, Connor M.; Eibl, Maximilian; Klinck, Holger"	BirdNET: A deep learning solution for avian diversity monitoring	Sound	CNN	Classification	Ecological Informatics	61			10.1016/j.ecoinf.2021.101236	https://linkinghub.elsevier.com/retrieve/pii/S1574954121000273	"Variation in avian diversity in space and time is commonly used as a metric to assess environmental changes. Conventionally, such data were collected by expert observers, but passively collected acoustic data is rapidly emerging as an alternative survey technique. However, efficiently extracting accurate species richness data from large audio datasets has proven challenging. Recent advances in deep artificial neural networks (DNNs) have transformed the field of machine learning, frequently outperforming traditional signal processing techniques in the domain of acoustic event detection and classification. We developed a DNN, called BirdNET, capable of identifying 984 North American and European bird species by sound. Our task-specific model architecture was derived from the family of residual networks (ResNets), consisted of 157 layers with more than 27 million parameters, and was trained using extensive data pre-processing, augmentation, and mixup. We tested the model against three independent datasets: (a) 22,960 single-species recordings; (b) 286 h of fully annotated soundscape data collected by an array of autonomous recording units in a design analogous to what researchers might use to measure avian diversity in a field setting; and (c) 33,670 h of soundscape data from a single high-quality omnidirectional microphone deployed near four eBird hotspots frequented by expert birders. We found that domain-specific data augmentation is key to build models that are robust against high ambient noise levels and can cope with overlapping vocalizations. Task-specific model designs and training regimes for audio event recognition perform on-par with very complex architectures used in other domains (e.g., object detection in images). We also found that high temporal resolution of input spectrograms (short FFT window length) improves the classification performance for bird sounds. In summary, BirdNET achieved a mean average precision of 0.791 for single-species recordings, a F0.5 score of 0.414 for annotated soundscapes, and an average correlation of 0.251 with hotspot observation across 121 species and 4 years of audio data. By enabling the efficient extraction of the vocalizations of many hundreds of bird species from potentially vast amounts of audio data, BirdNET and similar tools have the potential to add tremendous value to existing and future passively collected audio datasets and may transform the field of avian ecology and conservation"																				
2021	"Kakehi, Shigeho; Sekiuchi, Takayuki; Ito, Hiroshi; Ueno, Soichiro; Takeuchi, Yutaka; Suzuki, Kousuke; Togawa, Mai"	Identification and counting of Pacific oyster Crassostrea gigas larvae by object detection using deep learning	Images	CNN	"Classification, Regression"	Aquacultural Engineering	95		102197	10.1016/j.aquaeng.2021.102197	https://www.sciencedirect.com/science/article/pii/S0144860921000534	"Natural seedling collection is widely used in the culture of various bivalve species. For successful natural seedling collection, collectors must be installed when larvae appear in the water column at a stage immediately before attachment. Aquaculture farmers generally identify target larvae by morphological features through microscopic examination in a time- and labor-expensive exercise, which also requires a level of expertise to ensure accurate larval identification. We develop a deep-learning-based object-detection technique that ultimately might reduce the time and effort required to accurately identify and count Pacific oyster larvae, render their identification more consistent, and negate the need for expertise. Images of plankton net samples collected in Matsushima and Sendai bays, Japan, were taken using a new photographic device with a CMOS image sensor. Images of oyster larvae identified by an expert were used to create a library of labeled images to train a deep-learning model, which proved to be 82.4% accurate in precision, 90.8% in recall, and 86.4% in F-measure. A further method for estimating larval shell height from the rectangular shape of oyster larval images is also developed. The standardized mean difference in shell height between measurements and estimates is 3.3%. This deep-learning model has the potential to significantly reduce the time and effort required to identify oyster larvae in plankton samples, and thereby costs of this exercise."																				
2021	"Karlicki, Micha_; Antonowicz, Stanis_aw; Karnkowska, Anna"	Tiara: deep learning-based classification system for eukaryotic sequences	Molecular	DNN	Classification	Bioinformatics	38	2	344-350	10.1093/bioinformatics/btab672	https://academic.oup.com/bioinformatics/article/38/2/344/6375939	"With a large number of metagenomic datasets becoming available, eukaryotic metagenomics emerged as a new challenge. The proper classification of eukaryotic nuclear and organellar genomes is an essential step toward a better understanding of eukaryotic diversity.We developed Tiara, a deep-learning-based approach for the identification of eukaryotic sequences in the metagenomic datasets. Its two-step classification process enables the classification of nuclear and organellar eukaryotic fractions and subsequently divides organellar sequences into plastidial and mitochondrial. Using the test dataset, we have shown that Tiara performed similarly to EukRep for prokaryotes classification and outperformed it for eukaryotes classification with lower calculation time. In the tests on the real data, Tiara performed better than EukRep in analyzing the small dataset representing eukaryotic cell microbiome and large dataset from the pelagic zone of oceans. Tiara is also the only available tool correctly classifying organellar sequences, which was confirmed by the recovery of nearly complete plastid and mitochondrial genomes from the test data and real metagenomic data.Tiara is implemented in python 3.8, available at https://github.com/ibe-uw/tiara and tested on Unix-based systems. It is released under an open-source MIT license and documentation is available at https://ibe-uw.github.io/tiara. Version 1.0.1 of Tiara has been used for all benchmarks.Supplementary data are available at Bioinformatics online."																				
2021	"Kasinathan, Thenmozhi; Singaraju, Dakshayani; Uyyala, Srinivasulu Reddy"	Insect classification and detection in field crops using modern machine learning techniques	Images	CNN	Classification	Information Processing in Agriculture	8	3	446-457	10.1016/j.inpa.2020.09.006	https://www.sciencedirect.com/science/article/pii/S2214317320302067	"The agriculture sector has an immense potential to improve the requirement of food and supplies healthy and nutritious food. Crop insect detection is a challenging task for farmers as a significant portion of the crops are damaged, and the quality is degraded due to the pest attack. Traditional insect identification has the drawback of requiring well-trained taxonomists to identify insects based on morphological features accurately. Experiments were conducted for classification on nine and 24 insect classes of Wang and Xie dataset using the shape features and applying machine learning techniques such as artificial neural networks (ANN), support vector machine (SVM), k-nearest neighbors (KNN), naive bayes (NB) and convolutional neural network (CNN) model. This paper presents the insect pest detection algorithm that consists of foreground extraction and contour identification to detect the insects for Wang, Xie, Deng, and IP102 datasets in a highly complex background. The 9-fold cross-validation was applied to improve the performance of the classification models. The highest classification rate of 91.5% and 90% was achieved for nine and 24 class insects using the CNN model. The detection performance was accomplished with less computation time for Wang, Xie, Deng, and IP102 datasets using insect pest detection algorithm. The comparison results with the state-of-the-art classification algorithms exhibited considerable improvement in classification accuracy, computation time performance while apply more efficiently in field crops to recognize the insects. The results of classification accuracy are used to recognize the crop insects in the early stages and reduce the time to enhance the crop yield and crop quality in agriculture."																				
2021	"Kellenberger, Benjamin; Veen, Thor; Folmer, Eelke; Tuia, Devis"	21 000 birds in 4.5 h: efficient large-scale seabird detection with machine learning	Images	CNN	Regression	Remote Sensing in Ecology and Conservation	7	3	445-460	10.1002/rse2.200	https://onlinelibrary.wiley.com/doi/abs/10.1002/rse2.200	"We address the task of automatically detecting and counting seabirds in unmanned aerial vehicle (UAV) imagery using deep convolutional neural networks (CNNs). Our study area, the coast of West Africa, harbours significant breeding colonies of terns and gulls, which as top predators in the food web function as important bioindicators for the health of the marine ecosystem. Surveys to estimate breeding numbers have hitherto been carried out on foot, which is tedious, imprecise and causes disturbance. By using UAVs and CNNs that allow localizing tens of thousands of birds automatically, we show that all three limitations can be addressed elegantly. As we employ a lightweight CNN architecture and incorporate prior knowledge about the spatial distribution of birds within the colonies, we were able to reduce the number of bird annotations required for CNN training to just 200 examples per class. Our model obtains good accuracy for the most abundant species of royal terns (90% precision at 90% recall), but is less accurate for the rarer Caspian terns and gull species (60% precision at 68% recall, respectively 20% precision at 88% recall), which amounts to around 7% of all individuals present. In sum, our results show that we can detect and classify the majority of 21 000 birds in just 4.5 h, start to finish, as opposed to about 3 weeks of tediously identifying and labelling all birds by hand."																				
2021	"Khalighifar, Ali; Brown, Rafe M.; Goyes Vallejos, Johana; Peterson, A. Townsend"	Deep learning improves acoustic biodiversity monitoring and new candidate forest frog species identification (genus Platymantis) in the Philippines	Sound	CNN	Classification	Biodiversity and Conservation	30	3	643-657	10.1007/s10531-020-02107-1	https://doi.org/10.1007/s10531-020-02107-1	"One significant challenge to biodiversity assessment and conservation is persistent gaps in species diversity knowledge in Earth’s most biodiverse areas. Monitoring devices that utilize species-specific advertisement calls show promise in overcoming challenges associated with lagging frog species discovery rates. However, these devices generate data at paces faster than it can be analyzed. As such, automated platforms capable of efficient data processing and accurate species-level identification are at a premium. In addressing this gap, we used TensorFlow Inception v3 to design a robust, automated species identification system for 41 Philippine frog species (genus Platymantis), utilizing single-note audio spectrograms. With this model, we explored two concepts: (1) performance of our deep-learning model in discriminating closely-related frog species based on images representing advertisement call notes, and (2) the potential of this platform to accelerate new species discovery. TensorFlow identified species with a_~_94% overall correct identification rate. Incorporating distributional data increased the overall identification rate to_~_99%. In applying TensorFlow to a dataset that included undescribed species in addition to known species, our model was able to differentiate undescribed species through variation in “certainty” rate; the overall certainty rate for undescribed species was 65.5% versus 83.6% for described species. This indicates that, in addition to discriminating recognized frog species, our model has the potential to flag possible new species. As such, this work represents a proof-of-concept for automated, accelerated detection of novel species using acoustic mate-recognition signals, that can be applied to other groups characterized by vibrational cues, seismic signals, and vibrational mate-recognition."																				
2021	"Kittichai, Veerayuth; Pengsakul, Theerakamol; Chumchuen, Kemmapon; Samung, Yudthana; Sriwichai, Patchara; Phatthamolrat, Natthaphop; Tongloy, Teerawat; Jaksukam, Komgrit; Chuwongin, Santhad; Boonsang, Siridech"	Deep learning approaches for challenging species and gender identification of mosquito vectors	Images	CNN	"Classification, Regression"	Scientific Reports	11	1	4838	10.1038/s41598-021-84219-4	https://www.nature.com/articles/s41598-021-84219-4	"Microscopic observation of mosquito species, which is the basis of morphological identification, is a time-consuming and challenging process, particularly owing to the different skills and experience of public health personnel. We present deep learning models based on the well-known you-only-look-once (YOLO) algorithm. This model can be used to simultaneously classify and localize the images to identify the species of the gender of field-caught mosquitoes. The results indicated that the concatenated two YOLO v3 model exhibited the optimal performance in identifying the mosquitoes, as the mosquitoes were relatively small objects compared with the large proportional environment image. The robustness testing of the proposed model yielded a mean average precision and sensitivity of 99% and 92.4%, respectively. The model exhibited high performance in terms of the specificity and accuracy, with an extremely low rate of misclassification. The area under the receiver operating characteristic curve (AUC) was 0.958_±_0.011, which further demonstrated the model accuracy. Thirteen classes were detected with an accuracy of 100% based on a confusion matrix. Nevertheless, the relatively low detection rates for the two species were likely a result of the limited number of wild-caught biological samples available. The proposed model can help establish the population densities of mosquito vectors in remote areas to predict disease outbreaks in advance."																				
2021	"Kitzes, Justin; Blake, Rachael; Bombaci, Sara; Chapman, Melissa; Duran, Sandra M.; Huang, Tao; Joseph, Maxwell B.; Lapp, Samuel; Marconi, Sergio; Oestreich, William K.; Rhinehart, Tessa A.; Schweiger, Anna K.; Song, Yiluan; Surasinghe, Thilina; Yang, Di; Yule, Kelsey"	Expanding NEON biodiversity surveys with new instrumentation and machine learning approaches	NA	NA	Review	Ecosphere	12	11	e03795	10.1002/ecs2.3795	https://onlinelibrary.wiley.com/doi/abs/10.1002/ecs2.3795	"A core goal of the National Ecological Observatory Network (NEON) is to measure changes in biodiversity across the 30-yr horizon of the network. In contrast to NEON’s extensive use of automated instruments to collect environmental data, NEON’s biodiversity surveys are almost entirely conducted using traditional human-centric field methods. We believe that the combination of instrumentation for remote data collection and machine learning models to process such data represents an important opportunity for NEON to expand the scope, scale, and usability of its biodiversity data collection while potentially reducing long-term costs. In this manuscript, we first review the current status of instrument-based biodiversity surveys within the NEON project and previous research at the intersection of biodiversity, instrumentation, and machine learning at NEON sites. We then survey methods that have been developed at other locations but could potentially be employed at NEON sites in future. Finally, we expand on these ideas in five case studies that we believe suggest particularly fruitful future paths for automated biodiversity measurement at NEON sites: acoustic recorders for sound-producing taxa, camera traps for medium and large mammals, hydroacoustic and remote imagery for aquatic diversity, expanded remote and ground-based measurements for plant biodiversity, and laboratory-based imaging for physical specimens and samples in the NEON biorepository. Through its data science-literate staff and user community, NEON has a unique role to play in supporting the growth of such automated biodiversity survey methods, as well as demonstrating their ability to help answer key ecological questions that cannot be answered at the more limited spatiotemporal scales of human-driven surveys."																				
2021	"Knausgård, Kristian Muri; Wiklund, Arne; Sørdalen, Tonje Knutsen; Halvorsen, Kim Tallaksen; Kleiven, Alf Ring; Jiao, Lei; Goodwin, Morten"	Temperate fish detection and classification: a deep learning based approach	"Images, Video"	CNN	"Classification, Regression"	Applied Intelligence				10.1007/s10489-020-02154-9	https://link.springer.com/article/10.1007/s10489-020-02154-9	"A wide range of applications in marine ecology extensively uses underwater cameras. Still, to efficiently process the vast amount of data generated, we need to develop tools that can automatically detect and recognize species captured on film. Classifying fish species from videos and images in natural environments can be challenging because of noise and variation in illumination and the surrounding habitat. In this paper, we propose a two-step deep learning approach for the detection and classification of temperate fishes without pre-filtering. The first step is to detect each single fish in an image, independent of species and sex. For this purpose, we employ the You Only Look Once (YOLO) object detection technique. In the second step, we adopt a Convolutional Neural Network (CNN) with the Squeeze-and-Excitation (SE) architecture for classifying each fish in the image without pre-filtering. We apply transfer learning to overcome the limited training samples of temperate fishes and to improve the accuracy of the classification. This is done by training the object detection model with ImageNet and the fish classifier via a public dataset (Fish4Knowledge), whereupon both the object detection and classifier are updated with temperate fishes of interest. The weights obtained from pre-training are applied to post-training as a priori. Our solution achieves the state-of-the-art accuracy of 99.27% using the pre-training model. The accuracies using the post-training model are also high; 83.68% and 87.74% with and without image augmentation, respectively. This strongly indicates that the solution is viable with a more extensive dataset."																				
2021	"Kobayashi, Keigo; Masuda, Keisuke; Haga, Chihiro; Matsui, Takanori; Fukui, Dai; Machimura, Takashi"	Development of a species identification system of Japanese bats from echolocation calls using convolutional neural networks	Sound	CNN	Classification	Ecological Informatics	62		101253	10.1016/j.ecoinf.2021.101253	https://www.sciencedirect.com/science/article/pii/S1574954121000443	"Bats inhabit all continents except Antarctica, and they have enormous potential as bioindicators. Therefore, monitoring bats helps us to understand the surrounding environmental changes. However, bats are nocturnal, which makes it difficult to visually monitor their behavior. This paper proposes a bat species identifier method based on the analysis of ultrasound called echolocation calls, which is a promising method to monitor bats' activity levels effectively. We develop a robust method to identify the bat species with improved accuracy by analyzing their echolocation calls. First, 1400 sound files with four families, 13 genera, and 30 species were recorded in Japan and the Jincheon-gun in South Korea from 1999 to 2019. Bat echolocation calls were detected from the sound files and used to generate 54,525 spectrograms by applying short-time Fourier transform. We developed a deep learning–based bat species identifier using convolutional neural networks with MobileNetV1 used as the model's architecture. Furthermore, we applied nested cross-validation with the Bayesian optimization algorithm to search for the optimal combination of hyperparameters and evaluate the expected performance. We achieved 98.1% accuracy, which outperformed previous studies that treated more than 30 bat species. We visualized important regions of the spectrograms which correspond to prediction using the Guided Grad-CAM. Moreover, we discussed how to treat the noise class and minimize the model training time. Then, we proposed potential solutions to boost the identifier's performance, the generalization of the echolocation call recording protocols, and applicable techniques to improve the identification accuracy. Future perspectives are 1) to change the deep learning algorithm from image classification to object detection and 2) to apply the proposed identifier to unknown bat echolocation calls to evaluate the feasibility of estimating bat fauna and spatial activity distribution."																				
2021	"Kohls, Moritz; Kircher, Magdalena; Krepel, Jessica; Liebig, Pamela; Jung, Klaus"	Correcting the Estimation of Viral Taxa Distributions in Next-Generation Sequencing Data after Applying Artificial Neural Networks	Molecular	DNN	Classification	Genes	12	11	1755	10.3390/genes12111755	https://www.mdpi.com/2073-4425/12/11/1755	"Estimating the taxonomic composition of viral sequences in a biological samples processed by next-generation sequencing is an important step in comparative metagenomics. Mapping sequencing reads against a database of known viral reference genomes, however, fails to classify reads from novel viruses whose reference sequences are not yet available in public databases. Instead of a mapping approach, and in order to classify sequencing reads at least to a taxonomic level, the performance of artificial neural networks and other machine learning models was studied. Taxonomic and genomic data from the NCBI database were used to sample labelled sequencing reads as training data. The fitted neural network was applied to classify unlabelled reads of simulated and real-world test sets. Additional auxiliary test sets of labelled reads were used to estimate the conditional class probabilities, and to correct the prior estimation of the taxonomic distribution in the actual test set. Among the taxonomic levels, the biological order of viruses provided the most comprehensive data base to generate training data. The prediction accuracy of the artificial neural network to classify test reads to their viral order was considerably higher than that of a random classification. Posterior estimation of taxa frequencies could correct the primary classification results."																				
2021	"Korznikov, Kirill A.; Kislov, Dmitry E.; Altman, Jan; Dole_al, Ji_í; Vozmishcheva, Anna S.; Krestov, Pavel V."	"Using U-Net-Like Deep Convolutional Neural Networks for Precise Tree Recognition in Very High Resolution RGB (Red, Green, Blue) Satellite Images"	Images	CNN	Classification	Forests	12	1	66	10.3390/f12010066	https://www.mdpi.com/1999-4907/12/1/66	"Very high resolution satellite imageries provide an excellent foundation for precise mapping of plant communities and even single plants. We aim to perform individual tree recognition on the basis of very high resolution RGB (red, green, blue) satellite images using deep learning approaches for northern temperate mixed forests in the Primorsky Region of the Russian Far East. We used a pansharpened satellite RGB image by GeoEye-1 with a spatial resolution of 0.46 m\/pixel, obtained in late April 2019. We parametrized the standard U-Net convolutional neural network (CNN) and trained it in manually delineated satellite images to solve the satellite image segmentation problem. For comparison purposes, we also applied standard pixel-based classification algorithms, such as random forest, k-nearest neighbor classifier, naive Bayes classifier, and quadratic discrimination. Pattern-specific features based on grey level co-occurrence matrices (GLCM) were computed to improve the recognition ability of standard machine learning methods. The U-Net-like CNN allowed us to obtain precise recognition of Mongolian poplar (Populus suaveolens Fisch. ex Loudon s.l.) and evergreen coniferous trees (Abies holophylla Maxim., Pinus koraiensis Siebold &amp; Zucc.). We were able to distinguish species belonging to either poplar or coniferous groups but were unable to separate species within the same group (i.e. A. holophylla and P. koraiensis were not distinguishable). The accuracy of recognition was estimated by several metrics and exceeded values obtained for standard machine learning approaches. In contrast to pixel-based recognition algorithms, the U-Net-like CNN does not lead to an increase in false-positive decisions when facing green-colored objects that are similar to trees. By means of U-Net-like CNN, we obtained a mean accuracy score of up to 0.96 in our computational experiments. The U-Net-like CNN recognizes tree crowns not as a set of pixels with known RGB intensities but as spatial objects with a specific geometry and pattern. This CNN’s specific feature excludes misclassifications related to objects of similar colors as objects of interest. We highlight that utilization of satellite images obtained within the suitable phenological season is of high importance for successful tree recognition. The suitability of the phenological season is conceptualized as a group of conditions providing highlighting objects of interest over other components of vegetation cover. In our case, the use of satellite images captured in mid-spring allowed us to recognize evergreen fir and pine trees as the first class of objects (“conifers”) and poplars as the second class, which were in a leafless state among other deciduous tree species."																				
2021	"Kotwal, Shallu; Rani, Priya; Arif, Tasleem; Manhas, Jatinder; Sharma, Sparsh"	"Automated Bacterial Classifications Using Machine Learning Based Computational Techniques: Architectures, Challenges and Open Research Issues"	NA	NA	Review	Archives of Computational Methods in Engineering				10.1007/s11831-021-09660-0	https://link.springer.com/article/10.1007/s11831-021-09660-0	"Bacteria are important in a variety of practical domains, including industry, agriculture, medicine etc. A very few species of bacteria are favourable to humans. Whereas, majority of them are extremely dangerous and causes variety of life threatening illness to different living organisms. Traditionally, this class of microbes is detected and classified using different approaches like gram staining, biochemical testing, motility testing etc. However with the availability of large amount of data and technical advances in the field of medical and computer science, the machine learning methods have been widely used and have shown tremendous performance in automatic detection of bacteria. The inclusion of latest technology employing different Artificial Intelligence techniques are greatly assisting microbiologist in solving extremely complex problems in this domain. This paper presents a review of the literature on various machine learning approaches that have been used to classify bacteria, for the period 1998–2020. The resources include research papers and book chapters from different publishers of national and international repute such as Elsevier, Springer, IEEE, PLOS, etc. The study carried out a detailed and critical analysis of penetrating different Machine learning methodologies in the field of bacterial classification along with their limitations and future scope. In addition, different opportunities and challenges in implementing these techniques in the concerned field are also presented to provide a deep insight to the researchers working in this field."																				
2021	"Koudenoukpo, Zinsou Cosme; Odountan, Olaniran Hamed; Agboho, Prudenciène Ablawa; Dalu, Tatenda; Van Bocxlaer, Bert; Janssens de Bistoven, Luc; Chikou, Antoine; Backeljau, Thierry"	Using self–organizing maps and machine learning models to assess mollusc community structure in relation to physicochemical variables in a West Africa river–estuary system	Environmental	DNN	Modeling	Ecological Indicators	126		107706	10.1016/j.ecolind.2021.107706	https://www.sciencedirect.com/science/article/pii/S1470160X2100371X	"The poor understanding of changes in mollusc ecology along rivers, especially in West Africa, hampers the implementation of management measures. We used a self–organizing map, indicator species analysis, linear discriminant analysis and a random forest model to distinguish mollusc assemblages, to determine the ecological preferences of individual mollusc species and to associate major physicochemical variables with mollusc assemblages and occurrences in the Sô River Basin, Benin. We identified four mollusc assemblages along an upstream–downstream gradient. Dissolved oxygen (DO), biochemical oxygen demand (BOD), salinity, calcium (Ca), total nitrogen (TN), copper (Cu), lead (Pb), nickel (Ni), cadmium (Cd) and mercury (Hg) were the major physicochemical variables responsible for structuring these mollusc assemblages. However, the physicochemical factors responsible for shaping the distribution of individual species varied per species. Upstream sites (assemblage I) showed high DO and low BOD and mineral compounds (i.e., TN, salinity, and Ca), which are primarily responsible for structuring the occurrences of bivalves (Afropisidium pirothi, Etheria elliptica, Sphaerium hartmanni) and the gastropod Lanistes varicus. Sites along the middle reach (assemblage II) were characterised by a high degree of organic pollution but low heavy metal pollution; we detected no specific mollusc indicator species. Downstream sites (assemblage III) displayed high mineral and heavy metal concentrations and a fauna without specific indicator species. Finally, downstream sites associated with brackish water (assemblage IV) displayed important levels of organic and heavy metal pollution. These sites are dominated by diverse gastropods (i.e., Bulinus spp., Gabbiella africana, Indoplanorbis exustus, Pachymelania fusca, Radix natalensis, Stenophysa marmorata and Tympanotonos fuscatus). Our results highlight that mollusc communities in the Sô River Basin are structured by key physicochemical variables related to the river–estuary continuum. Habitats that are progressively more downstream are confronted with increasing anthropogenic stress. Conservation and management plans should focus on downstream habitats."																				
2021	"Kyathanahally, Sreenath P.; Hardeman, Thomas; Merz, Ewa; Bulas, Thea; Reyes, Marta; Isles, Peter; Pomati, Francesco; Baity-Jesi, Marco"	Deep Learning Classification of Lake Zooplankton	Images	"DNN, CNN"	Classification	Frontiers in Microbiology	12			10.3389/fmicb.2021.746297	https://www.frontiersin.org/article/10.3389/fmicb.2021.746297	"Plankton are effective indicators of environmental change and ecosystem health in freshwater habitats, but collection of plankton data using manual microscopic methods is extremely labor-intensive and expensive. Automated plankton imaging offers a promising way forward to monitor plankton communities with high frequency and accuracy in real-time. Yet, manual annotation of millions of images proposes a serious challenge to taxonomists. Deep learning classifiers have been successfully applied in various fields and provided encouraging results when used to categorize marine plankton images. Here, we present a set of deep learning models developed for the identification of lake plankton, and study several strategies to obtain optimal performances, which lead to operational prescriptions for users. To this aim, we annotated into 35 classes over 17900 images of zooplankton and large phytoplankton colonies, detected in Lake Greifensee (Switzerland) with the Dual Scripps Plankton Camera. Our best models were based on transfer learning and ensembling, which classified plankton images with 98% accuracy and 93% F1 score. When tested on freely available plankton datasets produced by other automated imaging tools (ZooScan, Imaging FlowCytobot, and ISIIS), our models performed better than previously used models. Our annotated data, code and classification models are freely available online."																				
2021	"Langlois, Juliette; Guilhaumon, François; Bockel, Thomas; Boissery, Pierre; De Almeida Braga, Cédric; Deter, Julie; Holon, Florian; Marre, Guilhem; Tribot, Anne-Sophie; Mouquet, Nicolas"	An integrated approach to estimate aesthetic and ecological values of coralligenous reefs	Images	CNN	Regression	Ecological Indicators	129		107935	10.1016/j.ecolind.2021.107935	https://www.sciencedirect.com/science/article/pii/S1470160X21006002	"Assessing non-material nature contributions to people has become one major challenge in biodiversity sciences. Among them, the aesthetic value of biodiversity is of strong importance as it contributes to human well-being and increases the collective willingness to engage in conservation efforts. Using the endangered coralligenous reefs along the French Mediterranean coastline as a case study, we propose a quantitative approach to estimate the aesthetic and ecological values of a marine ecosystem. We combined human image evaluation and deep learning algorithms to provide a quantitative estimation of the aesthetic value of 7692 photographic quadrats among 160 stations located between 20 and 90 m depth and gathered on 95 sites. To understand how aesthetic value is related to biodiversity metrics, environmental variables and anthropogenic pressures we used a structural equation modelling approach. We found that taxonomic diversity and species composition explained a significant part of the aesthetic value of the coralligenous reefs. Taxonomic diversity showed a net positive effect and species composition analysis highlighted both positive and negative effects of some species on the aesthetic value. Net negative effects of functional and phylogenetic diversities were found, which illustrates an aesthetic bias in human perception of ecological value. The aesthetic and ecological values were mapped along the French Mediterranean coastline in three dimensions (longitude, latitude, depth); this synthetic visualization could be of strong interest for conservation and communication purposes about this endangered benthic key-ecosystem of the Mediterranean Sea. Overall, our approach provides a geographically scalable estimate of the aesthetic value of biodiversity which is still an underestimated facet of nature contributions to people. It could be transposed to other marine ecosystems such as coral reefs but also to terrestrial landscapes for which an increasing number of images evaluated for human preference are becoming available."																				
2021	"Lebleux, Manon; Denimal, Emmanuel; De Oliveira, Déborah; Marin, Ambroise; Desroche, Nicolas; Alexandre, Hervé; Weidmann, Stéphanie; Rousseaux, Sandrine"	Prediction of Genetic Groups within Brettanomyces bruxellensis through Cell Morphology Using a Deep Learning Tool	Images	CNN	Classification	Journal of Fungi	7	8	581	10.3390/jof7080581	https://www.mdpi.com/2309-608X/7/8/581	"Brettanomyces bruxellensis is described as a wine spoilage yeast with many mainly strain-dependent genetic characteristics, bestowing tolerance against environmental stresses and persistence during the winemaking process. Thus, it is essential to discriminate B. bruxellensis isolates at the strain level in order to predict their stress resistance capacities. Few predictive tools are available to reveal intraspecific diversity within B. bruxellensis species; also, they require expertise and can be expensive. In this study, a Random Amplified Polymorphic DNA (RAPD) adapted PCR method was used with three different primers to discriminate 74 different B. bruxellensis isolates. High correlation between the results of this method using the primer OPA-09 and those of a previous microsatellite analysis was obtained, allowing us to cluster the isolates among four genetic groups more quickly and cheaply than microsatellite analysis. To make analysis even faster, we further investigated the correlation suggested in a previous study between genetic groups and cell polymorphism using the analysis of optical microscopy images via deep learning. A Convolutional Neural Network (CNN) was trained to predict the genetic group of B. bruxellensis isolates with 96.6% accuracy. These methods make intraspecific discrimination among B. bruxellensis species faster, simpler and less costly. These results open up very promising new perspectives in oenology for the study of microbial ecosystems."																				
2021	"Li, Daoliang; Du, Ling"	Recent advances of deep learning algorithms for aquacultural machine vision systems with emphasis on fish	NA	NA	Review	Artificial Intelligence Review				10.1007/s10462-021-10102-3	https://doi.org/10.1007/s10462-021-10102-3	"Monitoring the growth conditions and behavior of fish will enable scientific management, reduce the threat of losses caused by disease and stress. Traditional monitoring methods are time-consuming, laborious, and untimely monitoring readily leads to aquaculture accidents. As a non-invasive, objective, and repeatable tool, machine vision systems have been widely used in various aspects of aquaculture monitoring. Nevertheless, the complex underwater environment makes it difficult to obtain ideal data processing results only using traditional image processing methods. Due to their powerful feature extraction capabilities, deep learning (DL) algorithms have been widely used in underwater image processing. Hence, the combination of DL algorithms and machine vision for the automated monitoring of aquaculture is of great importance. As evidence for the multidisciplinary aspects of DL applications, attention is focused on the latest DL methods applied to five fields of research: classification, detection, counting, behavior recognition, and biomass estimation. Meanwhile, due to the low training efficiency of DL models caused by insufficient dataset, transfer learning and GAN have also put into spotlight of this filed to pursue high performance of DL models. We also present the challenges and benchmarks in terms of the advantages and disadvantages of the selected method in each field. In addition, we review the sources of image acquisition and pre-processing methods in aquaculture. Finally, the challenges and prospects of DL in aquaculture machine vision systems are discussed. The literature review shows that the deep neural networks such as AlexNet, LSTM, VGG, and GoogLeNet, have been used for aquaculture machine vision systems."																				
2021	"Li, Guoming; Xiong, Yijie; Du, Qian; Shi, Zhengxiang; Gates, Richard S."	Classifying Ingestive Behavior of Dairy Cows via Automatic Sound Recognition	Sound	RNN	Classification	Sensors	21	15	5231	10.3390/s21155231	https://www.mdpi.com/1424-8220/21/15/5231	"Determining ingestive behaviors of dairy cows is critical to evaluate their productivity and health status. The objectives of this research were to (1) develop the relationship between forage species/heights and sound characteristics of three different ingestive behaviors (bites, chews, and chew-bites); (2) comparatively evaluate three deep learning models and optimization strategies for classifying the three behaviors; and (3) examine the ability of deep learning modeling for classifying the three ingestive behaviors under various forage characteristics. The results show that the amplitude and duration of the bite, chew, and chew-bite sounds were mostly larger for tall forages (tall fescue and alfalfa) compared to their counterparts. The long short-term memory network using a filtered dataset with balanced duration and imbalanced audio files offered better performance than its counterparts. The best classification performance was over 0.93, and the best and poorest performance difference was 0.4–0.5 under different forage species and heights. In conclusion, the deep learning technique could classify the dairy cow ingestive behaviors but was unable to differentiate between them under some forage characteristics using acoustic signals. Thus, while the developed tool is useful to support precision dairy cow management, it requires further improvement."																				
2021	"Li, Joan Y. Q.; Duce, Stephanie; Joyce, Karen E.; Xiang, Wei"	SeeCucumbers: Using Deep Learning and Drone Imagery to Detect Sea Cucumbers on Coral Reef Flats	Images	CNN	"Classification, Regression"	Drones	5	2	28	10.3390/drones5020028	https://www.mdpi.com/2504-446X/5/2/28	"Sea cucumbers (Holothuroidea or holothurians) are a valuable fishery and are also crucial nutrient recyclers, bioturbation agents, and hosts for many biotic associates. Their ecological impacts could be substantial given their high abundance in some reef locations and thus monitoring their populations and spatial distribution is of research interest. Traditional in situ surveys are laborious and only cover small areas but drones offer an opportunity to scale observations more broadly, especially if the holothurians can be automatically detected in drone imagery using deep learning algorithms. We adapted the object detection algorithm YOLOv3 to detect holothurians from drone imagery at Hideaway Bay, Queensland, Australia. We successfully detected 11,462 of 12,956 individuals over 2.7ha with an average density of 0.5 individual/m2. We tested a range of hyperparameters to determine the optimal detector performance and achieved 0.855 mAP, 0.82 precision, 0.83 recall, and 0.82 F1 score. We found as few as ten labelled drone images was sufficient to train an acceptable detection model (0.799 mAP). Our results illustrate the potential of using small, affordable drones with direct implementation of open-source object detection models to survey holothurians and other shallow water sessile species."																				
2021	"Li, Junpeng; Zhu, Kaiyan; Wang, Fei; Jiang, Fengjiao"	Deep neural network-based real time fish detection method in the scene of marine fishing supervision	Video	CNN	"Classification, Regression"	Journal of Intelligent & Fuzzy Systems	41	3	4527-4532	10.3233/JIFS-189713	https://content.iospress.com/articles/journal-of-intelligent-and-fuzzy-systems/ifs189713	"Overfishing of marine fishery is a serious threat to fishery ecological security. Fishing supervision is one of the main ways to maintain marine fishery ecology. In order to improve the intelligence of fishing supervision system, a real time fish det"																				
2021	"Li, Wenyong; Wang, Dujin; Li, Ming; Gao, Yulin; Wu, Jianwei; Yang, Xinting"	Field detection of tiny pests from sticky trap images using deep learning in agricultural greenhouse	Images	CNN	"Classification, Regression"	Computers and Electronics in Agriculture	183		106048	10.1016/j.compag.2021.106048	https://www.sciencedirect.com/science/article/pii/S0168169921000661	"Agricultural pest catches on sticky traps can be used for the early detection and identification of hotspots, as well as for estimating relative abundances of adult pests, occurring in greenhouses. This study aimed to construct a detection model for whitefly and thrips from sticky trap images acquired in greenhouse conditions. An end-to-end model, based on the Faster regional-convolutional neural network (R-CNN), termed ‘TPest-RCNN’, was developed to improve the tiny pest detection accuracy. This architecture was trained using a transfer learning strategy on the Common Objects in Context dataset before training on the tiny pest training set to create the TPest-RCNN model. The new model achieved mean F1 score and average precision of 0.944 and 0.952, respectively, on a validation set. The TPest-RCNN model outperformed the Faster R-CNN architecture and other approaches using handcrafted features (color, shape and/or texture) in detecting multiple species from yellow sticky trap images. The test results also showed the model was robust to detect tiny pests on images of different pest densities and light reflections. Using a linear regression between the manual counts and an automatic detection results using the proposed method on images of 41 days, the determination coefficients reached 99.6% and 97.4% for whitefly and thrips, respectively. These results demonstrated that the proposed method could facilitate rapid gathering of information pertaining to numbers of the abundance of tiny pests in greenhouse agriculture and provide a technical reference for pest monitoring and population estimation."																				
2021	"Lin, Congtian; Huang, Xiongwei; Wang, Jiangning; Xi, Tianyu; Ji, Liqiang"	Learning niche features to improve image-based species identification	"Images, Environmental"	CNN	Classification	Ecological Informatics	61		101217	10.1016/j.ecoinf.2021.101217	https://www.sciencedirect.com/science/article/pii/S157495412100008X	"Species identification is a critical task of ecological research. Having accurate and intelligent methods of species identification would improve our ability to study and conserve biodiversity with saving much time and effort. But image-based deep learning methods have rarely taken account of domain knowledge, and perform poorly on imbalanced training dataset and similar species. Here, we propose NicheNet which combines ecological niche model and image-based deep learning model together expanding from the joint model framework invented by previous research. We incorporate an optimization process for NicheNet, and examine its performance on identifying Chinese Galliformes comparing with image-only model and Geo-prior-based model. For assessing the ability of both NicheNet and image-only models on distinguishing similar species, we initiate a new criterion named Near Error Rate in this study which decomposes identification error rate on each species along its classification. We show that the joint models gain significantly improvement on identifying our study species compared with image-only model. Against on an image-only baseline 82.5%, we observe 7.73% improvement in top-1 accuracy for NicheNet, and a 6.21% increase for Geo-prior-based model. NicheNet gains a 15.3% increment of average F1-Score and gets a _ 8.5% mean decrement in Near Species Error Rate while _4.4% in Near Genus Error Rate. Further cases analysis shows the background mechanism of NicheNet to improve image-only models. We demonstrate that NicheNet can learn the features from images and niche-prior, which is generated by niche model and finer than geo-prior by Geo-prior-based model, together to promote its ability on identifying species, especially on those with small training dataset and similar outlook. It is a flexible model framework, and we can introduce more biological features and domain models to strengthen its accuracy and robust in the future work. Our study shows that NicheNet can be widely adopted and will accurately accelerate automatic species identification task for biodiversity research and conservation."																				
2021	"Liu-Wei, Wang; Kafkas, _enay; Chen, Jun; Dimonaco, Nicholas J.; Tegnér, Jesper; Hoehndorf, Robert"	DeepViral: prediction of novel virus–host interactions from protein sequences and infectious disease phenotypes	"Molecular, Other"	"DNN, CNN"	Classification	Bioinformatics	37	17	2722-2729	10.1093/bioinformatics/btab147	https://doi.org/10.1093/bioinformatics/btab147	"Infectious diseases caused by novel viruses have become a major public health concern. Rapid identification of virus–host interactions can reveal mechanistic insights into infectious diseases and shed light on potential treatments. Current computational prediction methods for novel viruses are based mainly on protein sequences. However, it is not clear to what extent other important features, such as the symptoms caused by the viruses, could contribute to a predictor. Disease phenotypes (i.e. signs and symptoms) are readily accessible from clinical diagnosis and we hypothesize that they may act as a potential proxy and an additional source of information for the underlying molecular interactions between the pathogens and hosts.We developed DeepViral, a deep learning based method that predicts protein–protein interactions (PPI) between humans and viruses. Motivated by the potential utility of infectious disease phenotypes, we first embedded human proteins and viruses in a shared space using their associated phenotypes and functions, supported by formalized background knowledge from biomedical ontologies. By jointly learning from protein sequences and phenotype features, DeepViral significantly improves over existing sequence-based methods for intra- and inter-species PPI prediction.Code and datasets for reproduction and customization are available at https://github.com/bio-ontology-research-group/DeepViral. Prediction results for 14 virus families are available at https://doi.org/10.5281/zenodo.4429824.Supplementary data are available at Bioinformatics online."																				
2021	"Liu, Lingbo; Yu, Lejun; Wu, Dan; Ye, Junli; Feng, Hui; Liu, Qian; Yang, Wanneng"	PocketMaize: An Android-Smartphone Application for Maize Plant Phenotyping	Images	CNN	"Classification, Regression"	Frontiers in Plant Science	12			10.3389/fpls.2021.770217	https://www.frontiersin.org/article/10.3389/fpls.2021.770217	"A low-cost portable wild phenotyping system is useful for breeders to obtain detailed phenotypic characterization to identify promising wild species. However, compared with the larger, faster, and more advanced in-laboratory phenotyping systems developed in recent years, the progress for smaller phenotyping systems, which provide fast deployment and potential for wide usage in rural and wild areas, is quite limited. In this study, we developed a portable whole-plant on-device phenotyping smartphone application running on Android that can measure up to 45 traits, including 15 plant traits, 25 leaf traits and 5 stem traits, based on images. To avoid the influence of outdoor environments, we trained a DeepLabV3+ model for segmentation. In addition, an angle calibration algorithm was also designed to reduce the error introduced by the different imaging angles. The average execution time for the analysis of a 20-million-pixel image is within 2,500 ms. The application is a portable on-device fast phenotyping platform providing methods for real-time trait measurement, which will facilitate maize phenotyping in field and benefit crop breeding in future."																				
2021	"Liu, Maohua; Han, Ziwei; Chen, Yiming; Liu, Zhengjun; Han, Yanshun"	Tree species classification of LiDAR data based on 3D deep learning	Other	DNN	Classification	Measurement	177		109301	10.1016/j.measurement.2021.109301	https://www.sciencedirect.com/science/article/pii/S0263224121003043	"Accurate tree species identification is essential for ecological evaluation and other forest applications. In this paper, we proposed a point-based deep neural network called LayerNet. For light detection and ranging (LiDAR) data in forest regions, the network can divide multiple overlapping layers in Euclidean space to obtain the local three-dimensional (3D) structural features of the tree. The features of all layers are aggregated, and the global feature is obtained by convolution to classify the tree species. To validate the proposed framework, multiple experiments, including airborne and ground-based LiDAR datasets, are conducted and compared with several existing tree species classification algorithms. The test results show that LayerNet can directly use 3D data to accurately classify tree species, with the highest classification accuracy of 92.5%. Also, the results of comparative experiments demonstrate that the proposed framework has obvious advantages in classification accuracy and provides an effective solution for tree species classification tasks."																				
2021	"Liu, Shaobo; Shih, Frank Y.; Russell, Gareth; Russell, Kimberly; Phan, Hai"	Classification of Ecological Data by Deep Learning	Images	CNN	Classification	International Journal of Pattern Recognition and Artificial Intelligence	34	13	2052010	10.1142/S0218001420520102	https://www.worldscientific.com/doi/abs/10.1142/S0218001420520102	"Ecologists have been studying different computational models in the classification of ecological species. In this paper, we intend to take advantages of variant deep-learning models, including LeNet, AlexNet, VGG models, residual neural network, and inception models, to classify ecological datasets, such as bee wing and butterfly. Since the datasets contain relatively small data samples and unbalanced samples in each class, we apply data augmentation and transfer learning techniques. Furthermore, newly designed inception residual and inception modules are developed to enhance feature extraction and increase classification rates. As comparing against currently available deep-learning models, experimental results show that the proposed inception residual block can avoid the vanishing gradient problem and achieve a high accuracy rate of 92%."																				
2021	"Liu, XiaoLe; Yu, Si-yang; Flierman, Nico A.; Loyola, Sebastián; Kamermans, Maarten; Hoogland, Tycho M.; De Zeeuw, Chris I."	OptiFlex: Multi-Frame Animal Pose Estimation Combining Deep Learning With Optical Flow	"Video, Temporal"	CNN	Regression	Frontiers in Cellular Neuroscience	15			10.3389/fncel.2021.621252	https://www.frontiersin.org/article/10.3389/fncel.2021.621252	"Animal pose estimation tools based on deep learning have greatly improved animal behaviour quantification. These tools perform pose estimation on individual video frames, but do not account for variability of animal body shape in their prediction and evaluation. Here, we introduce a novel multi-frame animal pose estimation framework, referred to as OptiFlex. This framework integrates a flexible base model (i.e., FlexibleBaseline), which accounts for variability in animal body shape, with an OpticalFlow model that incorporates temporal context from nearby video frames. Pose estimation can be optimised using multi-view information to leverage all four dimensions (3D space and time). We evaluate FlexibleBaseline using datasets of four different lab animal species (mouse, fruit fly, zebrafish, and monkey) and introduce an intuitive evaluation metric—adjusted percentage of correct key points (aPCK). Our analyses show that OptiFlex provides prediction accuracy that outperforms current deep learning based tools, highlighting its potential for studying a wide range of behaviours across different animal species."																				
2021	"Liu, Yixue; Su, Jinya; Shen, Lei; Lu, Nan; Fang, Yulin; Liu, Fei; Song, Yuyang; Su, Baofeng"	Development of a mobile application for identification of grapevine (Vitis vinifera L.) cultivars via deep learning	Images	CNN	Classification	International Journal of Agricultural and Biological Engineering	14	5	172-179	10.25165/ijabe.v14i5.6593	https://www.ijabe.org/index.php/ijabe/article/view/6593	"Traditional vine variety identification methods usually rely on the sampling of vine leaves followed by physical, physiological, biochemical and molecular measurement, which are destructive, time-consuming, labor-intensive and require experienced grape phenotype analysts. To mitigate these problems, this study aimed to develop an application (App) running on Android client to identify the wine grape automatically and in real-time, which can help the growers to quickly obtain the variety information. Experimental results showed that all Convolutional Neural Network (CNN) classification algorithms could achieve an accuracy of over 94% for twenty-one categories on validation data, which proves the feasibility of using transfer deep learning to identify grape species in field environments. In particular, the classification model with the highest average accuracy was GoogLeNet (99.91%) with a learning rate of 0.001, mini-batch size of 32 and maximum number of epochs in 80. Testing results of the App on Android devices also confirmed these results. Keywords: deep learning, mobile phone, grapevine cultivar, vine leaf image, identification, Vitis vinifera L. DOI: 10.25165/j.ijabe.20211405.6593 Citation: Liu Y X, Shen L, Su J Y, Lu N, Fang Y L, Liu F, et al. Development of a mobile application for identification of grapevine (Vitis vinifera L.) cultivars via deep learning. Int J Agric & Biol Eng, 2021; 14(5): 172–179."																				
2021	"Lopes, Dercilio Junior Verly; Bobadilha, Gabrielly dos Santos; Burgreen, Greg W.; Entsminger, Edward D."	Identification of North American softwoods via machine-learning	Images	CNN	Classification	Canadian Journal of Forest Research	51	9	1245-1252	10.1139/cjfr-2020-0416	https://cdnsciencepub.com/doi/10.1139/cjfr-2020-0416	"This manuscript reports the feasibility of a sequential convolutional neural network (CNN) machine-learning model that correctly identifies 11 North American softwood species from 14_ magnified macroscopic end-grain images. The convolutional network contained a large kernel size, max pooling layers, and leaky rectified linear units to accelerate training. To reduce overfitting of training data, we employed L 2 regularization, custom initialization, and stratified 5-fold cross-validation techniques. The database consisted of 1789 wood end-grain images. The training data set consisted of 1431 images, whereas the validation set had approximately 358 images. In both sets, the input image size was 227 pixels _ 227 pixels. Data augmentation was performed on-the-fly by flipping, rotating, and zooming the images. We tested the performance of the CNN against precision, sensitivity, specificity, F1 score, and adjusted accuracy. The adjusted accuracy for the entire model was 94.0%. Confusion matrices indicated the lowest performance was in correctly classifying ponderosa pine (Pinus ponderosa Douglas ex P. Lawson &amp; C. Lawson) and eastern spruce (Picea spp. A. Dietr.) group with an average sensitivity of 89.0% for each. Even though high validation accuracy (&gt;94.0%) was achieved, we concluded that a much larger data set is needed for wood identification to obtain industrially accurate identification of softwoods, mainly due to their visual and macroscopic similarities."																				
2021	"Lopes, Dercilio Junior Verly; Monti, Gustavo Fardin; Burgreen, Greg W.; Moulin, Jordão Cabral; dos Santos Bobadilha, Gabrielly; Entsminger, Edward D.; Oliveira, Ramon Ferreira"	Creating High-Resolution Microscopic Cross-Section Images of Hardwood Species Using Generative Adversarial Networks	Images	GAN	Modeling	Frontiers in Plant Science	12			10.3389/fpls.2021.760139	https://www.frontiersin.org/article/10.3389/fpls.2021.760139	"Microscopic wood identification plays a critical role in many economically important areas in wood science. Historically, producing and curating relevant and representative microscopic cross-section images of wood species is limited to highly experienced and trained anatomists. This manuscript demonstrates the feasibility of generating synthetic microscopic cross-sections of hardwood species. We leveraged a publicly available dataset of 119 hardwood species to train a style-based generative adversarial network (GAN). The proposed GAN generated anatomically accurate cross-section images with remarkable fidelity to actual data. Quantitative metrics corroborated the capacity of the generative model in capturing complex wood structure by resulting in a Fréchet inception distance score of 17.38. Image diversity was calculated using the Structural Similarity Index Measure (SSIM). The SSIM results confirmed that the GAN approach can successfully synthesize diverse images. To confirm the usefulness and realism of the GAN generated images, eight professional wood anatomists in two experience levels participated in a visual Turing test and correctly identified fake and actual images at rates of 48.3 and 43.7%, respectively, with no statistical difference when compared to random guess. The generative model can synthesize realistic, diverse, and meaningful high-resolution microscope cross-section images that are virtually indistinguishable from real images. Furthermore, the framework presented may be suitable for improving current deep learning models, helping understand potential breeding between species, and may be used as an educational tool."																				
2021	"Lopez-Marcano, Sebastian; Brown, Christopher J.; Sievers, Michael; Connolly, Rod M."	The slow rise of technology: Computer vision techniques in fish population connectivity	NA	NA	Review	Aquatic Conservation: Marine and Freshwater Ecosystems	31	1	210-217	10.1002/aqc.3432	https://onlinelibrary.wiley.com/doi/abs/10.1002/aqc.3432	"Technological advancements in data collection and analysis are producing a new generation of ecological data. Among these, computer vision (CV) has received increased attention for its robust capabilities for rapidly processing large volumes of digital imagery. In marine ecosystems, the study of fish connectivity provides fundamental information for assessing fisheries stocks, designing and implementing protected areas and understanding the impact of habitat loss. While the field of fish connectivity has benefited from technological advancements, the extent to which novel techniques, such as CV, have been utilized has not been assessed. To inform future directions and developments, this study reviewed the current use of CV in fish connectivity research, quantified how the implementation of such technology in fish connectivity research compared with other areas of marine research and described how this field could benefit from CV. The review found that the use of remote camera systems in fish connectivity research is increasing, but the implementation of automated analysis of digital imagery has been slow. Successful implementation and expansion of CV frameworks in aquaculture and coral reef ecology suggest that CV techniques could greatly benefit fish connectivity research. A case study of potential use of CV in fish connectivity research, scaling up optimal foraging models to predict marine population connectivity, highlights how beneficial it could be. The capacity for CV techniques to be adopted alongside traditional approaches, the unparalleled speed, accuracy and reliability of these approaches and the benefits of being able to study ecosystems along multiple spatial–temporal scales, all make CV a valuable tool for assessing connectivity. Ultimately, these technologies can assist data-driven decisions that directly influence the health and productivity of marine ecosystems."																				
2021	"Lopez-Marcano, Sebastian; L. Jinks, Eric; Buelow, Christina A.; Brown, Christopher J.; Wang, Dadong; Kusy, Branislav; M. Ditria, Ellen; Connolly, Rod M."	Automatic detection of fish and tracking of movement for ecology	Video	CNN	Regression	Ecology and Evolution	11	12	8254-8263	10.1002/ece3.7656	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.7656	"Animal movement studies are conducted to monitor ecosystem health, understand ecological dynamics, and address management and conservation questions. In marine environments, traditional sampling and monitoring methods to measure animal movement are invasive, labor intensive, costly, and limited in the number of individuals that can be feasibly tracked. Automated detection and tracking of small-scale movements of many animals through cameras are possible but are largely untested in field conditions, hampering applications to ecological questions. Here, we aimed to test the ability of an automated object detection and object tracking pipeline to track small-scale movement of many individuals in videos. We applied the pipeline to track fish movement in the field and characterize movement behavior. We automated the detection of a common fisheries species (yellowfin bream, Acanthopagrus australis) along a known movement passageway from underwater videos. We then tracked fish movement with three types of tracking algorithms (MOSSE, Seq-NMS, and SiamMask) and evaluated their accuracy at characterizing movement. We successfully detected yellowfin bream in a multispecies assemblage (F1 score =91%). At least 120 of the 169 individual bream present in videos were correctly identified and tracked. The accuracies among the three tracking architectures varied, with MOSSE and SiamMask achieving an accuracy of 78% and Seq-NMS 84%. By employing this integrated object detection and tracking pipeline, we demonstrated a noninvasive and reliable approach to studying fish behavior by tracking their movement under field conditions. These cost-effective technologies provide a means for future studies to scale-up the analysis of movement across many visual monitoring systems."																				
2021	"Lozano, Roberto; Gazave, Elodie; dos Santos, Jhonathan P. R.; Stetter, Markus G.; Valluru, Ravi; Bandillo, Nonoy; Fernandes, Samuel B.; Brown, Patrick J.; Shakoor, Nadia; Mockler, Todd C.; Cooper, Elizabeth A.; Taylor Perkins, M.; Buckler, Edward S.; Ross-Ibarra, Jeffrey; Gore, Michael A."	Comparative evolutionary genetics of deleterious load in sorghum and maize	Molecular	CNN	Classification	Nature Plants	7	1	17-24	10.1038/s41477-020-00834-5	http://www.nature.com/articles/s41477-020-00834-5	"Sorghum and maize share a close evolutionary history that can be explored through comparative genomics1,2. To perform a large-scale comparison of the genomic variation between these two species, we analysed ~13 million variants identified from whole-genome resequencing of 499 sorghum lines together with 25 million variants previously identified in 1,218 maize lines. Deleterious mutations in both species were prevalent in pericentromeric regions, enriched in non-syntenic genes and present at low allele frequencies. A comparison of deleterious burden between sorghum and maize revealed that sorghum, in contrast to maize, departed from the domestication-cost hypothesis that predicts a higher deleterious burden among domesticates compared with wild lines. Additionally, sorghum and maize population genetic summary statistics were used to predict a gene deleterious index with an accuracy greater than 0.5. This research represents a key step towards understanding the evolutionary dynamics of deleterious variants in sorghum and provides a comparative genomics framework to start prioritizing these variants for removal through genome editing and breeding"																				
2021	"Lürig, Moritz D.; Donoughe, Seth; Svensson, Erik I.; Porto, Arthur; Tsuboi, Masahito"	"Computer vision, machine learning, and the promise of phenomics in ecology and evolutionary biology"	NA	NA	Review	Frontiers in Ecology and Evolution	9			10.3389/fevo.2021.642774	https://www.frontiersin.org/article/10.3389/fevo.2021.642774	"For centuries, ecologists and evolutionary biologists have used images such as drawings, paintings and photographs to record and quantify the shapes and patterns of life. With the advent of digital imaging, biologists continue to collect image data at an ever-increasing rate. This immense body of data provides insight into a wide range of biological phenomena, including phenotypic diversity, population dynamics, mechanisms of divergence and adaptation, and evolutionary change. However, the rate of image acquisition frequently outpaces our capacity to manually extract meaningful information from images. Moreover, manual image analysis is low-throughput, difficult to reproduce, and typically measures only a few traits at a time. This has proven to be an impediment to the growing field of phenomics – the study of many phenotypic dimensions together. Computer vision (CV), the automated extraction and processing of information from digital images, provides the opportunity to alleviate this longstanding analytical bottleneck. In this review, we illustrate the capabilities of CV as an efficient and comprehensive method to collect phenomic data in ecological and evolutionary research. First, we briefly review phenomics, arguing that ecologists and evolutionary biologists can effectively capture phenomic-level data by taking pictures and analyzing them using CV. Next we describe the primary types of image-based data, review CV approaches for extracting them (including techniques that entail machine learning and others that do not), and identify the most common hurdles and pitfalls. Finally, we highlight recent successful implementations and promising future applications of CV in the study of phenotypes. In anticipation that CV will become a basic component of the biologist’s toolkit, our review is intended as an entry point for ecologists and evolutionary biologists that are interested in extracting phenotypic information from digital images."																				
2021	"Mäder, Patrick; Boho, David; Rzanny, Michael; Seeland, Marco; Wittich, Hans Christian; Deggelmann, Alice; Wäldchen, Jana"	The Flora Incognita app – Interactive plant species identification	NA	NA	Other	Methods in Ecology and Evolution	12	7	1335-1342	10.1111/2041-210X.13611	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13611	"Being able to identify plant species is an important factor for understanding biodiversity and its change due to natural and anthropogenic drivers. We discuss the freely available Flora Incognita app for Android, iOS and Harmony OS devices that allows users to interactively identify plant species and capture their observations. Specifically developed deep learning algorithms, trained on an extensive repository of plant observations, classify plant images with yet unprecedented accuracy. By using this technology in a context-adaptive and interactive identification process, users are now able to reliably identify plants regardless of their botanical knowledge level. Users benefit from an intuitive interface and supplementary educational materials. The captured observations in combination with their metadata provide a rich resource for researching, monitoring and understanding plant diversity. Mobile applications such as Flora Incognita stimulate the successful interplay of citizen science, conservation and education."																				
2021	"Maekawa, Takuya; Higashide, Daiki; Hara, Takahiro; Matsumura, Kentarou; Ide, Kaoru; Miyatake, Takahisa; Kimura, Koutarou D.; Takahashi, Susumu"	Cross-species behavior analysis with attention-based domain-adversarial deep neural networks	Temporal	"CNN, Other"	Classification	Nature Communications	12	1	5519	10.1038/s41467-021-25636-x	https://www.nature.com/articles/s41467-021-25636-x	"Since the variables inherent to various diseases cannot be controlled directly in humans, behavioral dysfunctions have been examined in model organisms, leading to better understanding their underlying mechanisms. However, because the spatial and temporal scales of animal locomotion vary widely among species, conventional statistical analyses cannot be used to discover knowledge from the locomotion data. We propose a procedure to automatically discover locomotion features shared among animal species by means of domain-adversarial deep neural networks. Our neural network is equipped with a function which explains the meaning of segments of locomotion where the cross-species features are hidden by incorporating an attention mechanism into the neural network, regarded as a black box. It enables us to formulate a human-interpretable rule about the cross-species locomotion feature and validate it using statistical tests. We demonstrate the versatility of this procedure by identifying locomotion features shared across different species with dopamine deficiency, namely humans, mice, and worms, despite their evolutionary differences."																				
2021	"Mannocci, Laura; Villon, Sébastien; Chaumont, Marc; Guellati, Nacim; Mouquet, Nicolas; Iovan, Corina; Vigliola, Laurent; Mouillot, David"	Leveraging social media and deep learning to detect rare megafauna in video surveys	Video	CNN	Classification	Conservation Biology			cobi.13798	10.1111/cobi.13798	https://onlinelibrary.wiley.com/doi/10.1111/cobi.13798	"Deep learning has become a key tool for the automated monitoring of animal populations with video surveys. However, obtaining large numbers of images to train such models is a major challenge for rare and elusive species because ﬁeld video surveys provide few sightings. We designed a method that takes advantage of videos accumulated on social media for training deep-learning models to detect rare megafauna species in the ﬁeld. We trained convolutional neural networks (CNNs) with social media images and tested them on images collected from ﬁeld surveys. We applied our method to aerial video surveys of dugongs (Dugong dugon) in New Caledonia (southwestern Paciﬁc). CNNs trained with 1303 social media images yielded 25% false positives and 38% false negatives when tested on independent ﬁeld video surveys. Incorporating a small number of images from New Caledonia (equivalent to 12% of social media images) in the training data set resulted in a nearly 50% decrease in false negatives. Our results highlight how and the extent to which images collected on social media can offer a solid basis for training deep-learning models for rare megafauna detection and that the incorporation of a few images from the study site further boosts detection accuracy. Our method provides a new generation of deeplearning models that can be used to rapidly and accurately process ﬁeld video surveys for the monitoring of rare megafauna."																				
2021	"Marchal, Jean; Fabianek, François; Aubry, Yves"	Software performance for the automated identification of bird vocalisations: the case of two closely related species	Sound	CNN	Classification	Bioacoustics	0	0	17-Jan	10.1080/09524622.2021.1945952	https://www.tandfonline.com/doi/abs/10.1080/09524622.2021.1945952	"Autonomous recording units now facilitate the large collection of audio recordings. However, the analysis of large amounts of acoustic data remains a challenge. The time required for manually searching for bird vocalisations may be equivalent or greater to the duration of audio recordings. This major constraint can be significantly reduced through the use of software developed for automated identification of bird vocalisations in audio recordings. We have compared the performance of four software (CallSeeker, Kaleidoscope Pro, Raven Pro, and Song Scope) and a Convolutional Neural Network (CNN) using audio recordings containing calls of Bicknell’s Thrush and Gray-Cheeked Thrush, as well as the vocalisations of other bird species whose acoustic characteristics overlap with those of our target species. We evaluated all the software on the basis of two main criteria, their ability to detect calls and their ability to classify them correctly by species. Software performance ranged from 30 to 90% in terms of call detection (recall) and from 27 to 99% in terms of correct call classification (precision). CNNs offer a promising solution to the long-standing problem of detecting animal vocalisations in noisy soundscapes, while eliminating the tedious manual step of configuring the algorithms to maximise software performance."																				
2021	"Martin-Abadal, Miguel; Ruiz-Frau, Ana; Hinz, Hilmar; Gonzalez-Cid, Yolanda"	Jellytoring: Real-Time Jellyfish Monitoring Based on Deep Learning Object Detection	Video	CNN	"Classification, Regression"	Sensors	20	6	1708	10.3390/s20061708	https://www.mdpi.com/1424-8220/20/6/1708	"During the past decades, the composition and distribution of marine species have changed due to multiple anthropogenic pressures. Monitoring these changes in a cost-effective manner is of high relevance to assess the environmental status and evaluate the effectiveness of management measures. In particular, recent studies point to a rise of jellyfish populations on a global scale, negatively affecting diverse marine sectors like commercial fishing or the tourism industry. Past monitoring efforts using underwater video observations tended to be time-consuming and costly due to human-based data processing. In this paper, we present Jellytoring, a system to automatically detect and quantify different species of jellyfish based on a deep object detection neural network, allowing us to automatically record jellyfish presence during long periods of time. Jellytoring demonstrates outstanding performance on the jellyfish detection task, reaching an F1 score of 95.2%; and also on the jellyfish quantification task, as it correctly quantifies the number and class of jellyfish on a real-time processed video sequence up to a 93.8% of its duration. The results of this study are encouraging and provide the means towards a efficient way to monitor jellyfish, which can be used for the development of a jellyfish early-warning system, providing highly valuable information for marine biologists and contributing to the reduction of jellyfish impacts on humans."																				
2021	"Martin, Bradley T; Chafin, Tyler K; Douglas, Marlis R; Jr, John S Placyk; Birkhead, D; Phillips, Chris A; Douglas, Michael E"	The choices we make and the impacts they have: Machine learning and species delimitation in North American box turtles (Terrapene spp.)	Molecular	VAE	Classification	Molecular Ecology Resources			on-line ahead of print	10.1111/1755-0998.13350	https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13350	"Model-based approaches that attempt to delimit species are hampered by computational limitations as well as the unfortunate tendency by users to disregard algorithmic assumptions. Alternatives are clearly needed, and machine-learning (M-L) is attractive in this regard as it functions without the need to explicitly define a species concept. Unfortunately, its performance will vary according to which (of several) bioinformatic parameters are invoked. Herein, we gauge the effectiveness of M-L-based species-delimitation algorithms by parsing 64 variably-filtered versions of a ddRAD-derived SNP data set collected from North American box turtles (Terrapene spp.). Our filtering strategies included: (i) minor allele frequencies (MAF) of 5%, 3%, 1%, and 0% (= none), and (ii) maximum missing data per-individual/per-population at 25%, 50%, 75%, and 100% (= no filtering). We found that species-delimitation via unsupervised M-L impacted the signal-to-noise ratio in our data, as well as the discordance among resolved clades. The latter may also reflect biogeographic history, gene flow, incomplete lineage sorting, or combinations thereof (as corroborated from previously observed patterns of differential introgression). Our results substantiate M-L as a viable species-delimitation method, but also demonstrate how commonly observed patterns of phylogenetic discordance can seriously impact M-L-classification"																				
2021	"Matougui, Brahim; Boukelia, Abdelbasset; Belhadef, Hacene; Galiez, Clovis; Batouche, Mohamed"	NLP-MeTaxa: A Natural Language Processing Approach for Metagenomic Taxonomic Binning Based on Deep Learning	Molecular	DNN	Classification	Current Bioinformatics	16	7	992-1003	10.2174/1574893616666210621101150	https://www.eurekaselect.com/article/116264	"Background: Metagenomics is the study of genomic content in mass from an environment of interest such as the human gut or soil. Taxonomy is one of the most important fields of metagenomics, which is the science of defining and naming groups of microbial organisms that share the same characteristics. The problem of taxonomy classification is the identification and quantification of microbial species or higher-level taxa sampled by high throughput sequencing. Objective: Although many methods exist to deal with the taxonomic classification problem, assignment to low taxonomic ranks remains an important challenge for binning methods as is scalability to Gbsized datasets generated with deep sequencing techniques. Methods: In this paper, we introduce NLP-MeTaxa, a novel composition-based method for taxonomic binning, which relies on the use of words embeddings and deep learning architecture. The new proposed approach is word-based, where the metagenomic DNA fragments are processed as a set of overlapping words by using the word2vec model to vectorize them in order to feed the deep learning model. NLP-MeTaxa output is visualized as NCBI taxonomy tree, this representation helps to show the connection between the predicted taxonomic identifiers. NLP-MeTaxa was trained on large-scale data from the NCBI RefSeq, more than 14,000 complete microbial genomes. The NLP-MeTaxa code is available at the website: https://github.com/padriba/NLP_MeTaxa/. Results: We evaluated NLP-MeTaxa with a real and simulated metagenomic dataset and compared our results to other tools' results. The experimental results have shown that our method outperforms the other methods especially for the classification of low-ranking taxonomic class such as species and genus. Conclusion: In summary, our new method might provide novel insight for understanding the microbial community through the identification of the organisms it might contain."																				
2021	"Mattei, F.; Buonocore, E.; Franzese, P. P.; Scardi, M."	Global assessment of marine phytoplankton primary production: Integrating machine learning and environmental accounting models	Environmental	DNN	Modeling	Ecological Modelling	451		109578	10.1016/j.ecolmodel.2021.109578	https://www.sciencedirect.com/science/article/pii/S0304380021001435	"The emergy accounting method has been widely applied to terrestrial and marine ecosystems although there is a lack of emergy studies focusing on phytoplankton primary production. Phytoplankton production is a pivotal process since it is intimately coupled with oceanic food webs, energy fluxes, carbon cycle, and Earth's climate. In this study, we proposed a new methodology to perform a biophysical assessment of the global phytoplankton primary production combining Machine Learning (ML) techniques and an emergy-based accounting model. Firstly, we produced global phytoplankton production estimates using an Artificial Neural Network (ANN) model. Secondly, we assessed the main energy inputs supporting the global phytoplankton production. Finally, we converted these inputs into emergy units and analysed the results from an ecological perspective. Among the energy flows, tides showed the highest maximum emergy contribution to global phytoplankton production highlighting the importance of thise flow in the complex dynamics of marine ecosystems. In addition, an emergy/production ratio was calculated showing different global patterns in terms of emergy convergence into the primary production process. We believe that the proposed emergy-based assessment of phytoplankton production could be extremely valuable to improve our understanding of this key biological process at global scale adopting a systems perspective. This model can also provide a useful benchmark for future assessments of marine ecosystem services at global scale."																				
2021	"Miao, Zhongqi; Liu, Ziwei; Gaynor, Kaitlyn M.; Palmer, Meredith S.; Yu, Stella X.; Getz, Wayne M."	Iterative human and automated identification of wildlife images	Images	CNN	Classification	Nature Machine Intelligence	3	10	885-895	10.1038/s42256-021-00393-0	https://www.nature.com/articles/s42256-021-00393-0	"Camera trapping is increasingly being used to monitor wildlife, but this technology typically requires extensive data annotation. Recently, deep learning has substantially advanced automatic wildlife recognition. However, current methods are hampered by a dependence on large static datasets, whereas wildlife data are intrinsically dynamic and involve long-tailed distributions. These drawbacks can be overcome through a hybrid combination of machine learning and humans in the loop. Our proposed iterative human and automated identification approach is capable of learning from wildlife imagery data with a long-tailed distribution. Additionally, it includes self-updating learning, which facilitates capturing the community dynamics of rapidly changing natural systems. Extensive experiments show that our approach can achieve an ~90% accuracy employing only ~20% of the human annotations of existing approaches. Our synergistic collaboration of humans and machines transforms deep learning from a relatively inefficient post-annotation tool to a collaborative ongoing annotation tool that vastly reduces the burden of human annotation and enables efficient and constant model updates."																				
2021	"Miele, Vincent; Dussert, Gaspard; Spataro, Bruno; Chamaillé-Jammes, Simon; Allainé, Dominique; Bonenfant, Christophe"	Revisiting animal photo-identification using deep metric learning and network analysis	Images	CNN	Classification	Methods in Ecology and Evolution	12	5	863-873	10.1111/2041-210X.13577	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13577	"An increasing number of ecological monitoring programmes rely on photographic capture–recapture of individuals to study distribution, demography and abundance of species. Photo-identification of individuals can sometimes be done using idiosyncratic coat or skin patterns, instead of using tags or loggers. However, when performed manually, the task of going through photographs is tedious and rapidly becomes too time-consuming as the number of pictures grows. Computer vision techniques are an appealing and unavoidable help to tackle this apparently simple task in the big-data era. In this context, we propose to revisit animal re-identification using image similarity networks and metric learning with convolutional neural networks (CNNs), taking the giraffe as a working example. We first developed an end-to-end pipeline to retrieve a comprehensive set of re-identified giraffes from about 4,000 raw photographs. To do so, we combined CNN-based object detection, SIFT pattern matching and image similarity networks. We then quantified the performance of deep metric learning to retrieve the identity of known individuals, and to detect unknown individuals never seen in the previous years of monitoring. After a data augmentation procedure, the re-identification performance of the CNN reached a Top-1 accuracy of about 90%, despite the very small number of images per individual in the training dataset. While the complete pipeline succeeded in re-identifying known individuals, it slightly under-performed with unknown individuals. Fully based on open-source software packages, our work paves the way for further attempts to build automatic pipelines for re-identification of individual animals, not only in giraffes but also in other species."																				
2021	"Moreni, Mael; Theau, Jerome; Foucher, Samuel"	Train fast while reducing false positives: improving animal classification performance using convolutional neural networks	Images	CNN	Classification	Geomatics	1	1	34-49	10.3390/geomatics1010004	https://www.mdpi.com/2673-7418/1/1/4	"The combination of unmanned aerial vehicles (UAV) with deep learning models has the capacity to replace manned aircrafts for wildlife surveys. However, the scarcity of animals in the wild often leads to highly unbalanced, large datasets for which even a good detection method can return a large amount of false detections. Our objectives in this paper were to design a training method that would reduce training time, decrease the number of false positives and alleviate the fine-tuning effort of an image classifier in a context of animal surveys. We acquired two highly unbalanced datasets of deer images with a UAV and trained a Resnet-18 classifier using hard-negative mining and a series of recent techniques. Our method achieved sub-decimal false positive rates on two test sets (1 false positive per 19,162 and 213,312 negatives respectively), while training on small but relevant fractions of the data. The resulting training times were therefore significantly shorter than they would have been using the whole datasets. This high level of efficiency was achieved with little tuning effort and using simple techniques. We believe this parsimonious approach to dealing with highly unbalanced, large datasets could be particularly useful to projects with either limited resources or extremely large datasets."																				
2021	"Morera, Albert; Martínez de Aragón, Juan; Bonet, José Antonio; Liang, Jingjing; de-Miguel, Sergio"	Performance of statistical and machine learning-based methods for predicting biogeographical patterns of fungal productivity in forest ecosystems	Environmental	DNN	Regression	Forest Ecosystems	8	1	21	10.1186/s40663-021-00297-w	https://forestecosyst.springeropen.com/articles/10.1186/s40663-021-00297-w	"Background: The prediction of biogeographical patterns from a large number of driving factors with complex interactions, correlations and non-linear dependences require advanced analytical methods and modeling tools. This study compares different statistical and machine learning-based models for predicting fungal productivity biogeographical patterns as a case study for the thorough assessment of the performance of alternative modeling approaches to provide accurate and ecologically-consistent predictions. Methods: We evaluated and compared the performance of two statistical modeling techniques, namely, generalized linear mixed models and geographically weighted regression, and four techniques based on different machine learning algorithms, namely, random forest, extreme gradient boosting, support vector machine and artificial neural network to predict fungal productivity. Model evaluation was conducted using a systematic methodology combining random, spatial and environmental blocking together with the assessment of the ecological consistency of spatially-explicit model predictions according to scientific knowledge."																				
2021	"Morgan, M. M.; Braasch, J."	Long-term deep learning-facilitated environmental acoustic monitoring in the Capital Region of New York State	Sound	CNN	Classification	Ecological Informatics	61		101242	10.1016/j.ecoinf.2021.101242	https://www.sciencedirect.com/science/article/pii/S1574954121000339	"The effect of anthropogenic activity on animal communication is of increasing ecological concern. Passive acoustic recording offers a robust, minimally disruptive, long-term approach to monitoring species interactions, particularly because many indicator species of environmental health factors such as biodiversity, habitat quality, and pollution produce distinct vocalizations. Machine learning algorithms have been used in recent decades to automatically analyze the large quantities of audio data that result. In this study, a microphone array was used to collect continuous audio data at a site in the Capital Region of New York State for twelve months, resulting in over 8000 h of recordings. A 19-class database containing a variety of bio- and anthrophony was used to train a convolutional neural network in order to generate a reliable record of species-specific calling activity for the entire study period. These results were used to calculate an acoustics-based pseudo-species richness and abundance distribution. Additionally, heatmap plots were used to visualize (i) the time of day (x), sound category (y), and predicted number of sonic events for an average 30-day period and (ii) the day of the year (x), time of day (y), and predicted number of sonic events for each sound category. The correlations between these sonic events and various abiotic factors such as number of daylight hours, temperature, and weather activity were also examined."																				
2021	"Nazir, Sajid; Kaleem, Muhammad"	Advances in image acquisition and processing technologies transforming animal ecological studies	NA	NA	Review	Ecological Informatics	61		101212	10.1016/j.ecoinf.2021.101212	https://linkinghub.elsevier.com/retrieve/pii/S1574954121000030	"Images and videos have become pervasive in ecological research and the ease of acquiring image data and its subsequent processing can provide answers in research areas such as species recognition, animal behaviour, and population studies which are critical for animal conservation and biodiversity. Technological advances in imaging are enabling data collection from new areas such as from underwater, new modalities such as thermal and new ways of processing such as deep learning. These advances are accelerating due to ease of data collection, better storage and processing technologies with associated lowering costs. The advancements in state-of-the-art machine learning for image and video classification and analysis can directly be applied in ecology. Ecological applications are generally conducted in remote and harsh deployment environments, and therefore present formidable challenges that require appreciation of the limitations of such technologies. The ecological field is poised to make use of images acquired through drones, robotics, and satellites through machine learning for rapid advancements in critical research areas. Timely insights from such data help to understand and protect the species and environment. This paper provides a review of the advancements in image acquisition and processing technologies used in animal ecological studies. We also discuss concepts and technologies that would help foster future ecological research methodologies potentially opening new insights and quickening growth to an already rich and data-intensive field"																				
2021	"Ngô, M_nh C__ng; Selvan, Raghavendra; Tervo, Outi; Heide-Jørgensen, Mads Peter; Ditlevsen, Susanne"	Detection of foraging behavior from accelerometer data using U-Net type convolutional networks	Other	CNN	Classification	Ecological Informatics	62		101275	10.1016/j.ecoinf.2021.101275	https://www.sciencedirect.com/science/article/pii/S1574954121000662	"Narwhal (Monodon monoceros) is one of the most elusive marine mammals, due to its isolated habitat in the Arctic region. Tagging is a technology that has the potential to explore the activities of this species, where behavioral information can be collected from instrumented individuals. This includes accelerometer data, diving and acoustic data as well as GPS positioning. An essential element in understanding the ecological role of toothed whales is to characterize their feeding behavior and estimate the amount of food consumption. Buzzes are sounds emitted by toothed whales that are related directly to the foraging behaviors. It is therefore of interest to measure or estimate the rate of buzzing to estimate prey intake. The main goal of this paper is to find a way to detect prey capture attempts directly from accelerometer data, and thus be able to estimate food consumption without the need for the more demanding acoustic data. We develop three automated buzz detection methods based on accelerometer and depth data solely. We use a dataset from five narwhals instrumented in East Greenland in 2018 to train, validate and test a logistic regression model and the state-of-the art machine learning algorithms random forest and deep learning, using the buzzes detected from acoustic data as the ground truth. The deep learning algorithm performed best among the tested methods. We conclude that reliable buzz detectors can be derived from high-frequency-sampling, back-mounted accelerometer tags, thus providing an alternative tool for studies of foraging ecology of marine mammals in their natural environments. We also compare buzz detection with certain movement patterns, such as sudden changes in acceleration (jerks), found in other marine mammal species for estimating prey capture. We find that narwhals do not seem to make big jerks when foraging and conclude that their hunting patterns in that respect might differ from other marine mammals."																				
2021	"Nian, Rui; Yuan, Qiang; He, Hui; Geng, Xue; Su, Chi-Wei; He, Bo; Lendasse, Amaury"	"The Identification and Prediction in Abundance Variation of Atlantic Cod via Long Short-Term Memory With Periodicity, Time–Frequency Co-movement, and Lead-Lag Effect Across Sea Surface Temperature, Sea Surface Salinity, Catches, and Prey Biomass From 1919 to 2016"	Environmental	RNN	Regression	Frontiers in Marine Science	8			10.3389/fmars.2021.665716	https://www.frontiersin.org/article/10.3389/fmars.2021.665716	"The population of Atlantic cod significantly contributes to the prosperity of fishery production in the world. In this paper, we quantitatively investigate the global abundance variation in Atlantic cod from 1919 to 2016, in favor of spatiotemporal interactions over manifold impact factors at local observation sites, and propose to explore the predictive mechanism with the help of its periodicity, time–frequency co-movement, and lead-lag effects, via long short-term memory (LSTM). We first integrate evidences yielded from wavelet coefficients, to suggest that the abundance variation potentially follows a 36-year major cycle and 24-year secondary cycle at the time scales of 55 years and 37 years. We further evaluate the responses of Atlantic cod abundance to the external impact factors, including sea surface temperature (SST), catches, prey biomass, and sea surface salinity (SSS), in aid of the wavelet coherence and phase difference, which allows us to identify the dominantly correlative factors and capture the leading roles along the time domain and then divide the responses around the recent 60 years into three stages: before 1985, 1985–1995, and after 1995. At the first stage, the reason for the decline in abundance could be mainly attributed to the rapid rise of fish catches. At the second stage, the impact of SST and SSS also provides significant indices, besides overfishing; meanwhile, the mortality of primary producers and forced migration of fish species indirectly cause the decline. At the third stage, warming SST and growing SSS directly led to the decrease of abundance. Finally, we establish one ensemble of LSTM-SAE architecture to comprehensively reflect the predictive patterns at each stage. It has been demonstrated from experimental results that the models behaved better when intentionally feeding with the dominantly correlative multivariate inputs, instead of either all factors or only the abundance. The proposed scheme provides opportunities to symmetrically identify the underlying predictive attributes of Atlantic cod abundance and potentially perform as the quantitative references in reasonably making fishing decision. With the rapid development in deep learning capabilities, it is hopeful to expect better predictions of the responses to global changes, not only for Atlantic cod but also for other fish species and the ecosystem as a whole."																				
2021	"Norouzzadeh, Mohammad Sadegh; Morris, Dan; Beery, Sara; Joshi, Neel; Jojic, Nebojsa; Clune, Jeff"	A deep active learning system for species identification and counting in camera trap images	Images	CNN	Classification	Methods in Ecology and Evolution	12	1	150-161	10.1111/2041-210X.13504	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13504	"A typical camera trap survey may produce millions of images that require slow, expensive manual review. Consequently, critical conservation questions may be answered too slowly to support decision-making. Recent studies demonstrated the potential for computer vision to dramatically increase efficiency in image-based biodiversity surveys; however, the literature has focused on projects with a large set of labelled training images, and hence many projects with a smaller set of labelled images cannot benefit from existing machine learning techniques. Furthermore, even sizable projects have struggled to adopt computer vision methods because classification models overfit to specific image backgrounds (i.e. camera locations). In this paper, we combine the power of machine intelligence and human intelligence via a novel active learning system to minimize the manual work required to train a computer vision model. Furthermore, we utilize object detection models and transfer learning to prevent overfitting to camera locations. To our knowledge, this is the first work to apply an active learning approach to camera trap images. Our proposed scheme can match state-of-the-art accuracy on a 3.2 million image dataset with as few as 14,100 manual labels, which means decreasing manual labelling effort by over 99.5%. Our trained models are also less dependent on background pixels, since they operate only on cropped regions around animals. The proposed active deep learning scheme can significantly reduce the manual labour required to extract information from camera trap images. Automation of information extraction will not only benefit existing camera trap projects, but can also catalyse the deployment of larger camera trap arrays."																				
2021	"Nunes, Leon; Ampatzidis, Yiannis; Costa, Lucas; Wallau, Marcelo"	Horse foraging behavior detection using sound recognition techniques and artificial intelligence	"Sound, Video"	RNN	Classification	Computers and Electronics in Agriculture	183		106080	10.1016/j.compag.2021.106080	https://www.sciencedirect.com/science/article/pii/S0168169921000983	"Wearable sensing technologies can be used for precision livestock production and to study foraging strategies to better understand the relationships between herbivores, vegetation, and landscape. In this context, monitoring grazing behavior (i.e. chew and bite events) can provide critical information for livestock management. This study presents a computational tool that utilizes wearable sensing and deep learning to distinguish chew and bite events in horses. A micro camera equipped with a microphone (0–18 kHz) was used to obtain video/audio data from horses during grazing. The collected audio data were treated in a pre-processing filtering step, then used to train a recurrent neural network (RNN) with a long short-term memory (LSTM) layer to detect and distinguish chews, bites, and noise events. A post-processing sliding window technique was used to filter events with low confidence levels and lengths. Initial evaluation of this system showed an accuracy of 88.64% for bite identification and an accuracy of 94.13% for chew identification. The distinction between events and evaluation of responses to different pasture species and structure can provide useful information on the plant-animal interface. That is aligned to information such as bite rate, bite mass, and grazing time, and can help determine management strategies that optimize intake and provide data for modeling foraging behavior to predict pasture use and animal performance."																				
2021	"Olsson, Ola; Karlsson, Melanie; Persson, Anna S.; Smith, Henrik G.; Varadarajan, Vidula; Yourstone, Johanna; Stjernman, Martin"	"Efficient, automated and robust pollen analysis using deep learning"	Images	CNN	Classification	Methods in Ecology and Evolution	12	5	850-862	10.1111/2041-210X.13575	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13575	"Pollen analysis is an important tool in many fields, including pollination ecology, paleoclimatology, paleoecology, honey quality control, and even medicine and forensics. However, labour-intensive manual pollen analysis often constrains the number of samples processed or the number of pollen analysed per sample. Thus, there is a desire to develop reliable, high-throughput, automated systems. We present an automated method for pollen analysis, based on deep learning convolutional neural networks (CNN). We scanned microscope slides with fuchsine stained, fresh pollen and automatically extracted images of all individual pollen grains. CNN models were trained on reference samples (122,000 pollen grains, from 347 flowers of 83 species of 17 families). The models were used to classify images of different pollen grains in a series of experiments. We also propose an adjustment to reduce overestimation of sample diversity in cases where samples are likely to contain few species. Accuracy of a model for 83 species was 0.98 when all samples of each species were first pooled, and then split into a training and a validation set (splitting experiment). However, accuracy was much lower (0.41) when individual reference samples from different flowers were kept separate, and one such sample was used for validation of models trained on remaining samples of the species (leave-one-out experiment). We therefore combined species into 28 pollen types where a new leave-one-out experiment revealed an overall accuracy of 0.68, and recall rates >0.90 in most pollen types. When validating against 63,650 manually identified pollen grains from 370 bumblebee samples, we obtained an accuracy of 0.79, but our adjustment procedure increased this to 0.85. Validation through splitting experiments may overestimate robustness of CNN pollen analysis in new contexts (samples). Nevertheless, our method has the potential to allow large quantities of real pollen data to be analysed with reasonable accuracy. Although compiling pollen reference libraries is time-consuming, this is simplified by our method, and can lead to widely accessible and shareable resources for pollen analysis."																				
2021	"Onishi, Masanori; Ise, Takeshi"	Explainable identification and mapping of trees using UAV RGB image and deep learning	Images	CNN	Classification	Scientific Reports	11	1	903	10.1038/s41598-020-79653-9	https://www.nature.com/articles/s41598-020-79653-9	"The identification and mapping of trees via remotely sensed data for application in forest management is an active area of research. Previously proposed methods using airborne and hyperspectral sensors can identify tree species with high accuracy but are costly and are thus unsuitable for small-scale forest managers. In this work, we constructed a machine vision system for tree identification and mapping using Red–Green–Blue (RGB) image taken by an unmanned aerial vehicle (UAV) and a convolutional neural network (CNN). In this system, we first calculated the slope from the three-dimensional model obtained by the UAV, and segmented the UAV RGB photograph of the forest into several tree crown objects automatically using colour and three-dimensional information and the slope model, and lastly applied object-based CNN classification for each crown image. This system succeeded in classifying seven tree classes, including several tree species with more than 90% accuracy. The guided gradient-weighted class activation mapping (Guided Grad-CAM) showed that the CNN classified trees according to their shapes and leaf contrasts, which enhances the potential of the system for classifying individual trees with similar colours in a cost-effective manner—a useful feature for forest management."																				
2021	"Oswald, Julie N.; Walmsley, Sam F.; Casey, Caroline; Fregosi, Selene; Southall, Brandon; Janik, Vincent M."	Species information in whistle frequency modulation patterns of common dolphins	Sound	Other	Modeling	Philosophical Transactions of the Royal Society B: Biological Sciences	376	1836	20210046	10.1098/rstb.2021.0046	https://royalsocietypublishing.org/doi/10.1098/rstb.2021.0046	"The most flexible communication systems are those of open-ended vocal learners that can acquire new signals throughout their lifetimes. While acoustic signals carry information in general voice features that affect all of an individual's vocalizations, vocal learners can also introduce novel call types to their repertoires. Delphinids are known for using such learned call types in individual recognition, but their role in other contexts is less clear. We investigated the whistles of two closely related, sympatric common dolphin species, Delphinus delphis and Delphinus bairdii, to evaluate species differences in whistle contours. Acoustic recordings of single-species groups were obtained from the Southern California Bight. We used an unsupervised neural network to categorize whistles and compared the resulting whistle types between species. Of the whistle types recorded in more than one encounter, 169 were shared between species and 60 were species-specific (32 D. delphis types, 28 D. bairdii types). Delphinus delphis used 15 whistle types with an oscillatory frequency contour while only one such type was found in D. bairdii. Given the role of vocal learning in delphinid vocalizations, we argue that these differences in whistle production are probably culturally driven and could help facilitate species recognition between Delphinus species. This article is part of the theme issue ‘Vocal learning in animals and humans’."																				
2021	"Otálora, P.; Guzmán, J. L.; Acién, F. G.; Berenguel, M.; Reul, A."	Microalgae classification based on machine learning techniques	Images	CNN	"Classification, Regression"	Algal Research	55		102256	10.1016/j.algal.2021.102256	https://www.sciencedirect.com/science/article/pii/S2211926421000758	"In this paper, two models for classification of microalgae species based on artificial neural networks have been developed and validated. The models work in combination with FlowCAM, a device capable of capturing each of the particles detected in a sample and obtaining a set of descriptive features for each one. One of the models uses these feature variables as input, while the other makes use of the captured images, both being able to distinguish between two well-known species of microalgae, Scenedesmus almeriensis and Chlorella vulgaris, calculating the proportion of each of these in the analyzed mixture. The models were trained with pure samples of each specie and validated using mixed combinations of them. The results confirm the potential of image analysis and deep learning techniques for the identification of microalgae cultures, as well as the higher accuracy of the feature-based model, thus extending the range of classification approaches in this field."																				
2021	"Ouellette, Tom W.; Shaw, Jim; Awadalla, Philip"	Using image-based haplotype alignments to map global adaptation of SARS-CoV-2	Molecular	"CNN, RNN"	Classification	bioRxiv			e426571	10.1101/2021.01.13.426571	http://biorxiv.org/lookup/doi/10.1101/2021.01.13.426571	"Quantifying evolutionary change among viral genomes is an important clinical device to track critical adaptations geographically and temporally. We built image-based haplotype-guided evolutionary inference (ImHapE) to quantify adaptations in expanding populations of non-recombining SARS-CoV-2 genomes. By combining classic population genetic summaries with image-based deep learning methods, we show that different rates of positive selection are driving evolutionary fitness and dispersal of SARS-CoV-2 globally. A 1.35-fold increase in evolutionary fitness is observed within the UK, associated with expansion of both the B.1.177 and B.1.1.7 SARS-CoV-2 lineages."																				
2021	"Panigrahi, Swapnesh; Murat, Dorothée; Le Gall, Antoine; Martineau, Eugénie; Goldlust, Kelly; Fiche, Jean-Bernard; Rombouts, Sara; Nöllmann, Marcelo; Espinosa, Leon; Mignot, Tâm"	"Misic, a general deep learning-based method for the high-throughput cell segmentation of complex bacterial communities"	"Images, Other"	Other	"Classification, Regression"	eLife	10		e65151	10.7554/eLife.65151	https://doi.org/10.7554/eLife.65151	"Studies of bacterial communities, biofilms and microbiomes, are multiplying due to their impact on health and ecology. Live imaging of microbial communities requires new tools for the robust identification of bacterial cells in dense and often inter-species populations, sometimes over very large scales. Here, we developed MiSiC, a general deep-learning-based 2D segmentation method that automatically segments single bacteria in complex images of interacting bacterial communities with very little parameter adjustment, independent of the microscopy settings and imaging modality. Using a bacterial predator-prey interaction model, we demonstrate that MiSiC enables the analysis of interspecies interactions, resolving processes at subcellular scales and discriminating between species in millimeter size datasets. The simple implementation of MiSiC and the relatively low need in computing power make its use broadly accessible to fields interested in bacterial interactions and cell biology."																				
2021	"Pärtel, Jaak; Pärtel, Meelis; Wäldchen, Jana"	Plant image identification application demonstrates high accuracy in Northern Europe	NA	NA	Classification	AoB PLANTS	13	4	plab050	10.1093/aobpla/plab050	https://academic.oup.com/aobpla/article/doi/10.1093/aobpla/plab050/6329144	"Automated image-based plant identification has experienced rapid development and has been already used in research and nature management. However, there is a need for extensive studies on how accurately automatic plant identification works and which characteristics of observations and study species influence the results. We investigated the accuracy of the Flora Incognita application, a research-based tool for automated plant image identification. Our study was conducted in Estonia, Northern Europe. Photos originated from the Estonian national curated biodiversity observations database, originally without the intention to use them for automated identification (1496 photos, 542 species) were examined. Flora Incognita was also directly tested in field conditions in various habitats, taking images of plant organs as guided by the application (998 observations, 1703 photos, 280 species). Identification accuracy was compared among species characteristics: plant family, growth forms and life forms, habitat type and regional frequency. We also analysed image characteristics (plant organs, background, number of species in focus), and the number of training images that were available for particular species to develop the automated identification algorithm. From database images 79.6 % of species were correctly identified by Flora Incognita; in the field conditions species identification accuracy reached 85.3 %. Overall, the correct genus was found for 89 % and the correct plant family for 95 % of the species. Accuracy varied among different plant families, life forms and growth forms. Rare and common species and species from different habitats were identified with equal accuracy. Images with reproductive organs or with only the target species in focus were identified with greater success. The number of training images per species was positively correlated with the identification success. Even though a high accuracy has been already achieved for Flora Incognita, allowing its usage for research and practices, our results can guide further improvements of this application and automated plant identification in general."																				
2021	"Pataki, Balint Armin; Garriga, Joan; Eritja, Roger; Palmer, John R. B.; Bartumeus, Frederic; Csabai, Istvan"	Deep learning identification for citizen science surveillance of tiger mosquitoes	Images	CNN	Classification	Scientific Reports	11	1	4718	10.1038/s41598-021-83657-4	https://www.nature.com/articles/s41598-021-83657-4	"Global monitoring of disease vectors is undoubtedly becoming an urgent need as the human population rises and becomes increasingly mobile, international commercial exchanges increase, and climate change expands the habitats of many vector species. Traditional surveillance of mosquitoes, vectors of many diseases, relies on catches, which requires regular manual inspection and reporting, and dedicated personnel, making large-scale monitoring difficult and expensive. New approaches are solving the problem of scalability by relying on smartphones and the Internet to enable novel community-based and digital observatories, where people can upload pictures of mosquitoes whenever they encounter them. An example is the Mosquito Alert citizen science system, which includes a dedicated mobile phone app through which geotagged images are collected. This system provides a viable option for monitoring the spread of various mosquito species across the globe, although it is partly limited by the quality of the citizen scientists’ photos. To make the system useful for public health agencies, and to give feedback to the volunteering citizens, the submitted images are inspected and labeled by entomology experts. Although citizen-based data collection can greatly broaden disease-vector monitoring scales, manual inspection of each image is not an easily scalable option in the long run, and the system could be improved through automation. Based on Mosquito Alert’s curated database of expert-validated mosquito photos, we trained a deep learning model to find tiger mosquitoes (Aedes albopictus), a species that is responsible for spreading chikungunya, dengue, and Zika among other diseases. The highly accurate 0.96 area under the receiver operating characteristic curve score promises not only a helpful pre-selector for the expert validation process but also an automated classifier giving quick feedback to the app participants, which may help to keep them motivated. In the paper, we also explored the possibilities of using the model to improve future data collection quality as a feedback loop."																				
2021	"Pavoni, Gaia; Corsini, Massimiliano; Ponchio, Federico; Muntoni, Alessandro; Edwards, Clinton; Pedersen, Nicole; Sandin, Stuart; Cignoni, Paolo"	TagLab: AI-assisted annotation for the fast and accurate semantic segmentation of coral reef orthoimages	Images	CNN	Classification	Journal of Field Robotics	n/a	n/a		10.1002/rob.22049	https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.22049	"Semantic segmentation is a widespread image analysis task; in some applications, it requires such high accuracy that it still has to be done manually, taking a long time. Deep learning-based approaches can significantly reduce such times, but current automated solutions may produce results below expert standards. We propose agLab, an interactive tool for the rapid labelling and analysis of orthoimages that speeds up semantic segmentation. TagLab follows a human-centered artificial intelligence approach that, by integrating multiple degrees of automation, empowers human capabilities. We evaluated TagLab's efficiency in annotation time and accuracy through a user study based on a highly challenging task: the semantic segmentation of coral communities in marine ecology. In the assisted labelling of corals, TagLab increased the annotation speed by approximately 90% for nonexpert annotators while preserving the labelling accuracy. Furthermore, human–machine interaction has improved the accuracy of fully automatic predictions by about 7% on average and by 14% when the model generalizes poorly. Considering the experience done through the user study, TagLab has been improved, and preliminary investigations suggest a further significant reduction in annotation times."																				
2021	"Perez, Manolo F.; Bonatelli, Isabel A. S.; Romeiro-Brito, Monique; Franco, Fernando F.; Taylor, Nigel P.; Zappi, Daniela C.; Moraes, Evandro M."	Coalescent-based species delimitation meets deep learning: Insights from a highly fragmented cactus system	Molecular	CNN	Classification	Molecular Ecology Resources	22	3	1016-1028	10.1111/1755-0998.13534	https://onlinelibrary.wiley.com/doi/abs/10.1111/1755-0998.13534	"Delimiting species boundaries is a major goal in evolutionary biology. An increasing volume of literature has focused on the challenges of investigating cryptic diversity within complex evolutionary scenarios of speciation, including gene flow and demographic fluctuations. New methods based on model selection, such as approximate Bayesian computation, approximate likelihoods, and machine learning are promising tools arising in this field. Here, we introduce a framework for species delimitation using the multispecies coalescent model coupled with a deep learning algorithm based on convolutional neural networks (CNNs). We compared this strategy with a similar ABC approach. We applied both methods to test species boundary hypotheses based on current and previous taxonomic delimitations as well as genetic data (sequences from 41 loci) in Pilosocereus aurisetus, a cactus species complex with a sky-island distribution and taxonomic uncertainty. To validate our method, we also applied the same strategy on data from widely accepted species from the genus Drosophila. The results show that our CNN approach has a high capacity to distinguish among the simulated species delimitation scenarios, with higher accuracy than ABC. For the cactus data set, a splitter hypothesis without gene flow showed the highest probability in both CNN and ABC approaches, a result agreeing with previous taxonomic classifications and in line with the sky-island distribution and low dispersal of P. aurisetus. Our results highlight the cryptic diversity within the P. aurisetus complex and show that CNNs are a promising approach for distinguishing complex evolutionary histories, even outperforming the accuracy of other model-based approaches such as ABC."																				
2021	"Petso, Tinao; Jamisola, Rodrigo S.; Mpoeleng, Dimane; Bennitt, Emily; Mmereki, Wazha"	Automatic animal identification from drone camera based on point pattern analysis of herd behaviour	Images	CNN	"Classification, Regression"	Ecological Informatics	66		101485	10.1016/j.ecoinf.2021.101485	https://www.sciencedirect.com/science/article/pii/S1574954121002764	"This study investigated the accuracy of animal identification based on herd behaviour from drone camera footage. We evaluated object detection algorithms and point pattern analysis, using footage from drone altitudes ranging from 15 m to 130 m. We applied transfer learning to state-of-the-art lightweight object detection algorithms (Tensorflow and YOLO) based on feature extraction. In the point pattern analysis, we treated each animal as a point and identified them by the behavioural pattern of those points. The five animal species investigated were African elephant (Loxodonta africana), giraffe (Giraffa camelopardalis), white rhinoceros (Ceratotherium simum), wildebeest (Connochaetes taurinus) and zebra (Equus quaggas). As we increased the altitude of the drone camera, the detection algorithms using features significantly lost accuracy. Animal features are harder to detect at higher altitudes and in the presence of environmental camouflage, animal occlusion, and shadows. The performance of lightweight object detection algorithms (F1 score) decreased with increasing drone altitude to a minimum of 29%, while the point pattern algorithms produced an F1 score above 96% across all drone altitudes. Using point pattern analysis, the accuracy of animal identification is invariant to drone camera altitude and disturbances from environmental conditions. Animal social interactions within herds follow species-specific hidden patterns in their group structure that allow for reliable species identification."																				
2021	"Piazza, Giulia; Valsecchi, Cecile; Sottocornola, Gabriele"	Deep Learning Applied to SEM Images for Supporting Marine Coralline Algae Classification	Other	CNN	"Classification, Regression"	Diversity	13	12	640	10.3390/d13120640	https://www.mdpi.com/1424-2818/13/12/640	"The classification of coralline algae commonly relies on the morphology of cells and reproductive structures, along with thallus organization, observed through Scanning Electron Microscopy (SEM). Nevertheless, species identification based on morphology often leads to uncertainty, due to their general plasticity. Evolutionary and environmental studies featured coralline algae for their ecological significance in both recent and past Oceans and need to rely on robust taxonomy. Research efforts towards new putative diagnostic tools have recently been focused on cell wall ultrastructure. In this work, we explored a new classification tool for coralline algae, using fine-tuning pretrained Convolutional Neural Networks (CNNs) on SEM images paired to morphological categories, including cell wall ultrastructure. We considered four common Mediterranean species, classified at genus and at the species level (Lithothamnion corallioides, Mesophyllum philippii, Lithophyllum racemus, Lithophyllum pseudoracemus). Our model produced promising results in terms of image classification accuracy given the constraint of a limited dataset and was tested for the identification of two ambiguous samples referred to as L. cf. racemus. Overall, explanatory image analyses suggest a high diagnostic value of calcification patterns, which significantly contributed to class predictions. Thus, CNNs proved to be a valid support to the morphological approach to taxonomy in coralline algae."																				
2021	"Ponti, Moacir A.; dos Santos, Fernando P.; Ribeiro, Leo S. F.; Cavallari, Gabriel B."	Training deep networks from zero to hero: avoiding pitfalls and going beyond	NA	NA	Review	"2021 34th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)"			16-Sep	10.1109/SIBGRAPI54419.2021.00011	https://ieeexplore.ieee.org/document/9643120/	"Training deep neural networks may be challenging in real world data. Using models as black-boxes, even with transfer learning, can result in poor generalization or inconclusive results when it comes to small datasets or specific applications. This tutorial covers the basic steps as well as more recent options to improve models, in particular, but not restricted to, supervised learning. It can be particularly useful in datasets that are not as well-prepared as those in challenges, and also under scarce annotation and/or small data. We describe basic procedures as data preparation, optimization and transfer learning, but also recent architectural choices such as use of transformer modules, alternative convolutional layers, activation functions, wide/depth, as well as training procedures including curriculum, contrastive and self-supervised learning"																				
2021	"Puissant, Agathe; El Hourany, Roy; Charantonis, Anastase Alexandre; Bowler, Chris; Thiria, Sylvie"	Inversion of Phytoplankton Pigment Vertical Profiles from Satellite Data Using Machine Learning	Environmental	DNN	Modeling	Remote Sensing	13	8	1445	10.3390/rs13081445	https://www.mdpi.com/2072-4292/13/8/1445	"Observing the vertical dynamic of phytoplankton in the water column is essential to understand the evolution of the ocean primary productivity under climate change and the efficiency of the CO2 biological pump. This is usually made through in-situ measurements. In this paper, we propose a machine learning methodology to infer the vertical distribution of phytoplankton pigments from surface satellite observations, allowing their global estimation with a high spatial and temporal resolution. After imputing missing values through iterative completion Self-Organizing Maps, smoothing and reducing the vertical distributions through principal component analysis, we used a Self-Organizing Map to cluster the reduced profiles with satellite observations. These referent vector clusters were then used to invert the vertical profiles of phytoplankton pigments. The methodology was trained and validated on the MAREDAT dataset and tested on the Tara Oceans dataset. The different regression coefficients R2 between observed and estimated vertical profiles of pigment concentration are, on average, greater than 0.7. We could expect to monitor the vertical distribution of phytoplankton types in the global ocean."																				
2021	"Pushpanathan, Kalananthni; Hanafi, Marsyita; Mashohor, Syamsiah; Fazlil Ilahi, Wan Fazilah"	Machine learning in medicinal plants recognition: a review	NA	NA	Review	Artificial Intelligence Review	54	1	305-327	10.1007/s10462-020-09847-0	http://link.springer.com/10.1007/s10462-020-09847-0	"Medicinal plants are gaining attention in the pharmaceutical industry due to having less harmful effects reactions and cheaper than modern medicine. Based on these facts, many researchers have shown considerable interest in the research of automatic medicinal plants recognition. There are various opportunities for advancement in producing a robust classifier that has the ability to classify medicinal plants accurately in real-time. In this paper, various effective and reliable machine learning algorithms for plant classifications using leaf images that have been used in recent years are reviewed. The review includes the image processing methods used to detect leaf and extract important leaf features for some machine learning classifiers. These machine learning classifiers are categorised according to their performance when classifying leaf images based on typical plant features, namely shape, vein, texture and a combination of multiple features. The leaf databases that are publicly available for automatic plants recognition are reviewed as well and we conclude with a discussion of prominent ongoing research and opportunities for enhancement in this area"																				
2021	"Quinn, Thomas P.; Le, Vuong; Cardilini, Adam P. A."	Test set verification is an essential step in model building	NA	NA	Review	Methods in Ecology and Evolution	12	1	127-129	10.1111/2041-210X.13495	https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13495	"Recently, Christin et al. published an article that reviewed the field of deep learning and offered advice on how to train a deep learning model. We write here to emphasize the importance of model verification, which can help ensure that the model will generalize to new data. Specifically, we discuss the importance of using a test set for model verification, and of defining an explicit research hypothesis. We then present a revised workflow that will help ensure that the accuracy reported for your deep learning model is reliable"																				
2021	"Radig, Bernd; Bodesheim, Paul; Korsch, Dimitri; Denzler, Joachim; Haucke, Timm; Klasen, Morris; Steinhage, Volker"	Automated Visual Large Scale Monitoring of Faunal Biodiversity	NA	NA	Other	Pattern Recognition and Image Analysis	31	3	477-488	10.1134/S1054661821030214	https://doi.org/10.1134/S1054661821030214	"To observe biodiversity, the variety of plant and animal life in the world or in a particular habitat, human observers make the most common examinations, often assisted by technical equipment. Measuring objectively the number of different species of animals, plants, fungi, and microbes that make up the ecosystem can be difficult. In order to monitor changes in biodiversity, data have to be compared across space and time. Cameras are an essential sensor to determine the species range, abundance, and behavior of animals. The millions of recordings from camera traps set up in natural environments can no longer be analyzed by biologists. We started research on doing this analysis automatically without human interaction. The focus of our present sensor is on image capture of wildlife and moths. Special hardware elements for the detection of different species are designed, implemented, tested, and improved, as well as the algorithms for classification and counting of samples from images and image sequences, e.g., to calculate presence, absence, and abundance values or the duration of characteristic activities related to the spatial mobilities. For this purpose, we are developing stereo camera traps that allow spatial reconstruction of the observed animals. This allows three-dimensional coordinates to be recorded and the shape to be characterized. With this additional feature data, species identification and movement detection are facilitated. To classify and count moths, they are attracted to an illuminated screen, which is then photographed at intervals by a high-resolution color camera. To greatly reduce the volume of data, redundant elements and elements that are consistent from image to image are eliminated. All design decisions take into account that at remote sites and in fully autonomous operation, power supply on the one hand and possibilities for data exchange with central servers on the other hand are limited. Installation at hard-to-reach locations requires a sophisticated and demanding system design with an optimal balance between power requirements, bandwidth for data transmission, required service and operation in all environmental conditions for at least ten years."																				
2021	"Ravindran, Prabu; Owens, Frank C.; Wade, Adam C.; Vega, Patricia; Montenegro, Rolando; Shmulsky, Rubin; Wiedenhoeft, Alex C."	Field-Deployable Computer Vision Wood Identification of Peruvian Timbers	Images	CNN	Classification	Frontiers in Plant Science	12			10.3389/fpls.2021.647515	https://www.frontiersin.org/article/10.3389/fpls.2021.647515	"Illegal logging is a major threat to forests in Peru, in the Amazon more broadly, and in the tropics globally. In Peru alone, more than two thirds of logging concessions showed unauthorized tree harvesting in natural protected areas and indigenous territories, and in 2016 more than half of exported lumber was of illegal origin. To help combat illegal logging and support legal timber trade in Peru we trained a convolutional neural network using transfer learning on images obtained from specimens in six xylaria using the open source, field-deployable XyloTron platform, for the classification of 228 Peruvian species into 24 anatomically informed and contextually relevant classes. The trained models achieved accuracies of 97% for five-fold cross validation, and 86.5 and 92.4% for top-1 and top-2 classification, respectively, on unique independent specimens from a xylarium that did not contribute training data. These results are the first multi-site, multi-user, multi-system-instantiation study for a national scale, computer vision wood identification system evaluated on independent scientific wood specimens. We demonstrate system readiness for evaluation in real-world field screening scenarios using this accurate, affordable, and scalable technology for monitoring, incentivizing, and monetizing legal and sustainable wood value chains."																				
2021	"Resente, Giulia; Gillert, Alexander; Trouillier, Mario; Anadon-Rosell, Alba; Peters, Richard L.; von Arx, Georg; von Lukas, Uwe; Wilmking, Martin"	"Mask, train, repeat! Artificial intelligence for quantitative wood anatomy"	Images	CNN	Classification	Frontiers in Plant Science	12		767400	10.3389/fpls.2021.767400	https://www.frontiersin.org/articles/10.3389/fpls.2021.767400/full	"The recent developments in artificial intelligence have the potential to facilitate new research methods in ecology. Especially Deep Convolutional Neural Networks (DCNNs) have been shown to outperform other approaches in automatic image analyses. Here we apply a DCNN to facilitate quantitative wood anatomical (QWA) analyses, where the main challenges reside in the detection of a high number of cells, in the intrinsic variability of wood anatomical features, and in the sample quality. To properly classify and interpret features within the images, DCNNs need to undergo a training stage. We performed the training with images from transversal wood anatomical sections, together with manually created optimal outputs of the target cell areas. The target species included an example for the most common wood anatomical structures: four conifer species; a diffuse-porous species, black alder ( Alnus glutinosa L.); a diffuse to semi-diffuse-porous species, European beech ( Fagus sylvatica L.); and a ring-porous species, sessile oak ( Quercus petraea Liebl.). The DCNN was created in Python with Pytorch, and relies on a Mask-RCNN architecture. The developed algorithm detects and segments cells, and provides information on the measurement accuracy. To evaluate the performance of this tool we compared our Mask-RCNN outputs with U-Net, a model architecture employed in a similar study, and with ROXAS, a program based on traditional image analysis techniques. First, we evaluated how many target cells were correctly recognized. Next, we assessed the cell measurement accuracy by evaluating the number of pixels that were correctly assigned to each target cell. Overall, the “learning process” defining artificial intelligence plays a key role in overcoming the issues that are usually manually solved in QWA analyses. Mask-RCNN is the model that better detects which are the features characterizing a target cell when these issues occur. In general, U-Net did not attain the other algorithms’ performance, while ROXAS performed best for conifers, and Mask-RCNN showed the highest accuracy in detecting target cells and segmenting lumen areas of angiosperms. Our research demonstrates that future software tools for QWA analyses would greatly benefit from using DCNNs, saving time during the analysis phase, and providing a flexible approach that allows model retraining."																				
2021	"Rives, Alexander; Meier, Joshua; Sercu, Tom; Goyal, Siddharth; Lin, Zeming; Liu, Jason; Guo, Demi; Ott, Myle; Zitnick, C. Lawrence; Ma, Jerry; Fergus, Rob"	Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences	Molecular	Other	Modeling	Proceedings of the National Academy of Sciences	118	15	e2016239118	10.1073/pnas.2016239118	https://www.pnas.org/doi/10.1073/pnas.2016239118	"Significance  Learning biological properties from sequence data is a logical step toward generative and predictive artificial intelligence for biology. Here, we propose scaling a deep contextual language model with unsupervised learning to sequences spanning evolutionary diversity. We find that without prior knowledge, information emerges in the learned representations on fundamental properties of proteins such as secondary structure, contacts, and biological activity. We show the learned representations are useful across benchmarks for remote homology detection, prediction of secondary structure, long-range residue–residue contacts, and mutational effect. Unsupervised representation learning enables state-of-the-art supervised prediction of mutational effect and secondary structure and improves state-of-the-art features for long-range contact prediction."																				
2021	"Ruff, Zachary J.; Lesmeister, Damon B.; Appel, Cara L.; Sullivan, Christopher M."	Workflow and convolutional neural network for automated identification of animal sounds	Sound	CNN	Classification	Ecological Indicators	124		107419	10.1016/j.ecolind.2021.107419	https://www.sciencedirect.com/science/article/pii/S1470160X21000844	"The use of passive acoustic monitoring in wildlife ecology has increased dramatically in recent years as researchers take advantage of improvements in autonomous recording units and analytical methods. These technologies have allowed researchers to collect large quantities of acoustic data which must then be processed to extract meaningful information, e.g. target species detections. A persistent issue in acoustic monitoring is the challenge of efficiently automating the detection of species of interest, and deep learning has emerged as a powerful approach to accomplish this task. Here we report on the development and application of a deep convolutional neural network for the automated detection of 14 forest-adapted birds and mammals by classifying spectrogram images generated from short audio clips. The neural network performed well for most species, with precision exceeding 90% and recall exceeding 50% at high score thresholds, indicating high power to detect these species when they were present and vocally active, combined with a low proportion of false positives. We describe a multi-step workflow that integrates this neural network to efficiently process large volumes of audio data with a combination of automated detection and human review. This workflow reduces the necessary human effort by > 99% compared to full manual review of the data. As an optional component of this workflow, we developed a graphical interface for the neural network that can be run through RStudio using the Shiny package, creating a portable and user-friendly way for field biologists and managers to efficiently process audio data and detect these target species close to the point of collection and with minimal delays using consumer-grade computers."																				
2021	"Rum, Siti Nurulain Mohd; Nawawi, Fariz Az Zuhri"	FishDeTec: A Fish Identification Application using Image Recognition Approach	Images	CNN	Classification	International Journal of Advanced Computer Science and Applications (IJACSA)	12	3		10.14569/IJACSA.2021.0120312	https://thesai.org/Publications/ViewPaper?Volume=12&Issue=3&Code=IJACSA&SerialNo=12	"The underwater imagery processing is always in high demand, especially the fish species identification. This activity is as important not only for the biologist, scientist, and fisherman, but it is also important for the education purpose. It has been reported that there are more than 200 species of freshwater fish in Malaysia. Many attempts have been made to develop the fish recognition and classification via image processing approach, however, most of the existing work are developed for the saltwater fish species identification and used for a specific group of users. This research work focuses on the development of a prototype system named FishDeTec to the detect the freshwater fish species found in Malaysia through the image processing approach. In this study, the proposed predictive model of the FishDeTec is developed using the VGG16, is a deep Convolutional Neural Network (CNN) model for a large-scale image classification processing. The experimental study indicates that our proposed model is a promising result."																				
2021	"Rumelt, Reid B.; Basto, Arianna; Mere Roncal, Carla"	Automated audio recording as a means of surveying tinamous (Tinamidae) in the Peruvian Amazon	Sound	CNN	Classification	Ecology and Evolution	11	19	13518-13531	10.1002/ece3.8078	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.8078	"The use of machine learning technologies to process large quantities of remotely collected audio data is a powerful emerging research tool in ecology and conservation. We applied these methods to a field study of tinamou (Tinamidae) biology in Madre de Dios, Peru, a region expected to have high levels of interspecies competition and niche partitioning as a result of high tinamou alpha diversity. We used autonomous recording units to gather environmental audio over a period of several months at lowland rainforest sites in the Los Amigos Conservation Concession and developed a Convolutional Neural Network-based data processing pipeline to detect tinamou vocalizations in the dataset. The classified acoustic event data are comparable to similar metrics derived from an ongoing camera trapping survey at the same site, and it should be possible to combine the two datasets for future explorations of the target species' niche space parameters. Here, we provide an overview of the methodology used in the data collection and processing pipeline, offer general suggestions for processing large amounts of environmental audio data, and demonstrate how data collected in this manner can be used to answer questions about bird biology."																				
2021	"Ryazanov, Igor; Nylund, Amanda T.; Basu, Debabrota; Hassellöv, Ida-Maja; Schliep, Alexander"	Deep Learning for Deep Waters: An Expert-in-the-Loop Machine Learning Framework for Marine Sciences	Sound	CNN	Classification	Journal of Marine Science and Engineering	9	2	169	10.3390/jmse9020169	https://www.mdpi.com/2077-1312/9/2/169	"Driven by the unprecedented availability of data, machine learning has become a pervasive and transformative technology across industry and science. Its importance to marine science has been codified as one goal of the UN Ocean Decade. While increasing amounts of, for example, acoustic marine data are collected for research and monitoring purposes, and machine learning methods can achieve automatic processing and analysis of acoustic data, they require large training datasets annotated or labelled by experts. Consequently, addressing the relative scarcity of labelled data is, besides increasing data analysis and processing capacities, one of the main thrust areas. One approach to address label scarcity is the expert-in-the-loop approach which allows analysis of limited and unbalanced data efficiently. Its advantages are demonstrated with our novel deep learning-based expert-in-the-loop framework for automatic detection of turbulent wake signatures in echo sounder data. Using machine learning algorithms, such as the one presented in this study, greatly increases the capacity to analyse large amounts of acoustic data. It would be a first step in realising the full potential of the increasing amount of acoustic data in marine sciences."																				
2021	"Ryo, Masahiro; Angelov, Boyan; Mammola, Stefano; Kass, Jamie M.; Benito, Blas M.; Hartig, Florian"	Explainable artificial intelligence enhances the ecological interpretability of black_box species distribution models	NA	NA	Review	Ecography	44	2	199-205	10.1111/ecog.05360	https://onlinelibrary.wiley.com/doi/10.1111/ecog.05360	"Species distribution models (SDMs) are widely used in ecology, biogeography and conservation biology to estimate relationships between environmental variables and species occurrence data and make predictions of how their distributions vary in space and time. During the past two decades, the field has increasingly made use of machine learning approaches for constructing and validating SDMs. Model accuracy has steadily increased as a result, but the interpretability of the fitted models, for example the relative importance of predictor variables or their causal effects on focal species, has not always kept pace. Here we draw attention to an emerging subdiscipline of artificial intelligence, explainable AI (xAI), as a toolbox for better interpreting SDMs. xAI aims at deciphering the behavior of complex statistical or machine learning models (e.g. neural networks, random forests, boosted regression trees), and can produce more transparent and understandable SDM predictions. We describe the rationale behind xAI and provide a list of tools that can be used to help ecological modelers better understand complex model behavior at different scales. As an example, we perform a reproducible SDM analysis in R on the African elephant and showcase some xAI tools such as local interpretable model-agnostic explanation (LIME) to help interpret local-scale behavior of the model. We conclude with what we see as the benefits and caveats of these techniques and advocate for their use to improve the interpretability of machine learning SDMs"																				
2021	"Sanchez, Théophile; Madison Bray, Erik; Jobic, Pierre; Guez, Jérémy; Letournel, Anne-Catherine; Charpiat, Guillaume; Cury, Jean; Jay, Flora"	dnadna: Deep neural architectures for dna - a deep learning framework for population genetic inference	NA	NA	Other	HAL				NA	https://hal.archives-ouvertes.fr/hal-03352910	"We present dnadna, a flexible python-based software for deep learning inference in population genetics. It is task-agnostic and aims at facilitating the development, reproducibility, dissemination, and reusability of neural networks designed for genetic polymorphism data. dnadna defines multiple user-friendly workflows. First, users can implement new architectures and tasks, while benefiting from dnadna input/output and other utility functions, training procedure and test environment, which not only saves time but also decreases the probability of bugs. Second, implemented networks can be re-optimized based on user-specified training sets and/or tasks. Finally, users can apply pretrained networks in order to predict evolutionary history from alternative real or simulated genetic datasets, without the need of extensive knowledge in deep learning. Thanks to dnadna, newly implemented architectures and pretrained networks are easily shareable with the community for further benchmarking or applications. dnadna comes with a peer-reviewed exchangeable neural network allowing demographic inference from SNP data, that can be used directly or retrained to solve other tasks. Toy networks are also available to ease the exploration of the software, and we expect that the range of available architectures will keep expanding thanks to contributions from the community."																				
2021	"_anti_, Danijela; Piwosz, Kasia; Mati_, Frano; Vrdoljak Toma_, Ana; Arapov, Jasna; Dean, Jason Lawrence; _oli_, Mladen; Koblí_ek, Michal; Ku_pili_, Grozdan; _estanovi_, Stefanija"	Artificial neural network analysis of microbial diversity in the central and southern Adriatic Sea	Environmental	Other	Modeling	Scientific Reports	11	1	11186	10.1038/s41598-021-90863-7	https://www.nature.com/articles/s41598-021-90863-7	"Bacteria are an active and diverse component of pelagic communities. The identification of main factors governing microbial diversity and spatial distribution requires advanced mathematical analyses. Here, the bacterial community composition was analysed, along with a depth profile, in the open Adriatic Sea using amplicon sequencing of bacterial 16S rRNA and the Neural gas algorithm. The performed analysis classified the sample into four best matching units representing heterogenic patterns of the bacterial community composition. The observed parameters were more differentiated by depth than by area, with temperature and identified salinity as important environmental variables. The highest diversity was observed at the deep chlorophyll maximum, while bacterial abundance and production peaked in the upper layers. The most of the identified genera belonged to Proteobacteria, with uncultured AEGEAN-169 and SAR116 lineages being dominant Alphaproteobacteria, and OM60 (NOR5) and SAR86 being dominant Gammaproteobacteria. Marine Synechococcus and Cyanobium-related species were predominant in the shallow layer, while Prochlorococcus MIT 9313 formed a higher portion below 50 m depth. Bacteroidota were represented mostly by uncultured lineages (NS4, NS5 and NS9 marine lineages). In contrast, Actinobacteriota were dominated by a candidatus genus Ca. Actinomarina. A large contribution of Nitrospinae was evident at the deepest investigated layer. Our results document that neural network analysis of environmental data may provide a novel insight into factors affecting picoplankton in the open sea environment."																				
2021	"Schindler, Frank; Steinhage, Volker"	Identification of animals and recognition of their actions in wildlife videos using deep learning techniques	Video	CNN	Classification	Ecological Informatics	61		101215	10.1016/j.ecoinf.2021.101215	https://www.sciencedirect.com/science/article/pii/S1574954121000066	"Biodiversity crisis has continued to accelerate. Studying animal distribution, movement and behaviour is of critical importance to address environmental challenges such as spreading of diseases, invasive species, climate and land-use change. Camera traps are an appropriate technique for continuous animal monitoring in an automated 24/7/52 documentation. This study shows a proof-of-concept for an end-to-end pipeline to detect and classify animals and their behaviour in video clips. Video clips are captured with 8 frames per second by camera traps using infrared cameras and infrared flash-lights. The clips show deer, boars, foxes and hares - mostly at night time. Our approach shows an average precision of 63.8% for animal detection and identification. For action recognition the achieved accuracies range between 88.4% and 94.1%."																				
2021	"Scholl, Victoria M.; McGlinchy, Joseph; Price-Broncucia, Teo; Balch, Jennifer K.; Joseph, Maxwell B."	"Fusion neural networks for plant classification: learning to combine RGB, hyperspectral, and lidar data"	"Images, Other"	CNN	Classification	PeerJ	9		e11790	10.7717/peerj.11790	https://peerj.com/articles/11790	"Airborne remote sensing offers unprecedented opportunities to efficiently monitor vegetation, but methods to delineate and classify individual plant species using the collected data are still actively being developed and improved. The Integrating Data science with Trees and Remote Sensing (IDTReeS) plant identification competition openly invited scientists to create and compare individual tree mapping methods. Participants were tasked with training taxon identification algorithms based on two sites, to then transfer their methods to a third unseen site, using field-based plant observations in combination with airborne remote sensing image data products from the National Ecological Observatory Network (NEON). These data were captured by a high resolution digital camera sensitive to red, green, blue (RGB) light, hyperspectral imaging spectrometer spanning the visible to shortwave infrared wavelengths, and lidar systems to capture the spectral and structural properties of vegetation. As participants in the IDTReeS competition, we developed a two-stage deep learning approach to integrate NEON remote sensing data from all three sensors and classify individual plant species and genera. The first stage was a convolutional neural network that generates taxon probabilities from RGB images, and the second stage was a fusion neural network that “learns” how to combine these probabilities with hyperspectral and lidar data. Our two-stage approach leverages the ability of neural networks to flexibly and automatically extract descriptive features from complex image data with high dimensionality. Our method achieved an overall classification accuracy of 0.51 based on the training set, and 0.32 based on the test set which contained data from an unseen site with unknown taxa classes. Although transferability of classification algorithms to unseen sites with unknown species and genus classes proved to be a challenging task, developing methods with openly available NEON data that will be collected in a standardized format for 30 years allows for continual improvements and major gains for members of the computational ecology community. We outline promising directions related to data preparation and processing techniques for further investigation, and provide our code to contribute to open reproducible science efforts."																				
2021	"Schwartz, Shawn T.; Alfaro, Michael E."	Sashimi: A toolkit for facilitating high-throughput organismal image segmentation using deep learning	Images	CNN	Classification	Methods in Ecology and Evolution	12	12	2341-2354	10.1111/2041-210X.13712	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13712	"Digitized specimens are an indispensable resource for rapidly acquiring big datasets and typically must be pre-processed prior to conducting analyses. One crucial image pre-processing step in any image analysis workflow is image segmentation, or the ability to clearly contrast the foreground target from the background noise in an image. This procedure is typically done manually, creating a potential bottleneck for efforts to quantify biodiversity from image databases. Image segmentation meta-algorithms using deep learning provide an opportunity to relax this bottleneck. However, the most accessible pre-trained convolutional neural networks (CNNs) have been trained on a small fraction of biodiversity, thus limiting their utility. We trained a deep learning model to automatically segment target fish from images with both standardized and complex, noisy backgrounds. We then assessed the performance of our deep learning model using qualitative visual inspection and quantitative image segmentation metrics of pixel overlap between reference segmentation masks generated manually by experts and those automatically predicted by our model. Visual inspection revealed that our model segmented fishes with high precision and relatively few artifacts. These results suggest that the meta-algorithm (Mask R-CNN), in which our current fish segmentation model relies on, is well suited for generating high-fidelity segmented specimen images across a variety of background contexts at rapid pace. We present Sashimi, a user-friendly command line toolkit to facilitate rapid, automated high-throughput image segmentation of digitized organisms. Sashimi is accessible to non-programmers and does not require experience with deep learning to use. The flexibility of Mask R-CNN allows users to generate a segmentation model for use on diverse animal and plant images using transfer learning with training datasets as small as a few hundred images. To help grow the taxonomic scope of images that can be recognized, Sashimi also includes a central database for sharing and distributing custom-trained segmentation models of other unrepresented organisms. Lastly, Sashimi includes both auxiliary image pre-processing functions useful for some popular downstream color pattern analysis workflows, as well as a simple script to aid users in qualitatively and quantitatively assessing segmentation model performance for complementary sets of automatically and manually segmented images."																				
2021	"Shepley, Andrew; Falzon, Greg; Meek, Paul; Kwan, Paul"	Automated location invariant animal detection in camera trap images using publicly available data sources	Images	CNN	Classification	Ecology and Evolution	11	9	4494-4506	10.1002/ece3.7344	https://onlinelibrary.wiley.com/doi/10.1002/ece3.7344	"A time-consuming challenge faced by camera trap practitioners is the extraction of meaningful data from images to inform ecological management. An increasingly popular solution is automated image classification software. However, most solutions are not sufficiently robust to be deployed on a large scale due to lack of location invariance when transferring models between sites. This prevents optimal use of ecological data resulting in significant expenditure of time and resources to annotate and retrain deep learning models. We present a method ecologists can use to develop optimized location invariant camera trap object detectors by (a) evaluating publicly available image datasets characterized by high intradataset variability in training deep learning models for camera trap object detection and (b) using small subsets of camera trap images to optimize models for high accuracy domain-specific applications. We collected and annotated three datasets of images of striped hyena, rhinoceros, and pigs, from the image-sharing websites FlickR and iNaturalist (FiN), to train three object detection models. We compared the performance of these models to that of three models trained on the Wildlife Conservation Society and Camera CATalogue datasets, when tested on out-of-sample Snapshot Serengeti datasets. We then increased FiN model robustness by infusing small subsets of camera trap images into training. In all experiments, the mean Average Precision (mAP) of the FiN trained models was significantly higher (82.33%–88.59%) than that achieved by the models trained only on camera trap datasets (38.5%–66.74%). Infusion further improved mAP by 1.78%–32.08%. Ecologists can use FiN images for training deep learning object detection solutions for camera trap image processing to develop location invariant, robust, out-of-the-box software. Models can be further optimized by infusion of 5%–10% camera trap images into training data. This would allow AI technologies to be deployed on a large scale in ecological applications. Datasets and code related to this study are open source and available on this repository: https://doi-org.erl.lib.byu.edu/10.5061/dryad.1c59zw3tx"																				
2021	"Shi, Yun; Ma, Donghui; Lv, Jie; Li, Jie"	ACTL: Asymmetric Convolutional Transfer Learning for Tree Species Identification Based on Deep Neural Network	Other	CNN	Classification	IEEE Access	9		13643-13654	10.1109/ACCESS.2021.3051015	https://ieeexplore.ieee.org/document/9319859	"The identification of tree species is of great significance to the sustainable management and utilization of forest ecosystems. Hyperspectral data provide sufficient spectral and spatial information to classify tree species. Convolutional neural networks (CNN) have achieved great success in hyperspectral image (HSI) classification. The outstanding performance of CNN in HSI classification relies on sufficient training samples. However, it’s expensive and time consuming to acquire labeled training samples. In this article, a novel asymmetric convolutional transfer learning model for HSI classification is proposed. First, the tree species identification dataset is built from Goddard’s LiDAR, Hyperspectral & Thermal (G-LiHT) data. Then, the asymmetric convolutional transfer learning model and weights trained on ImageNet dataset are used to initialize the weights of the HSI classification model. Finally, a well fine-tuned neural network on tree species dataset is used to perform the HSI classification task. The experimental results reveal that the proposed model with asymmetric convolutional blocks effectively improves the accuracy of Howland forest tree species identification and provides a new idea for the classification of hyperspectral remote sensing images."																				
2021	"Shugar, Aaron N.; Drake, B. Lee; Kelley, Greg"	Rapid identification of wood species using XRF and neural network machine learning	Other	CNN	Classification	Scientific Reports	11	1	17533	10.1038/s41598-021-96850-2	https://www.nature.com/articles/s41598-021-96850-2	"An innovative approach for the rapid identification of wood species is presented. By combining X-ray fluorescence spectrometry with convolutional neural network machine learning, 48 different wood specimens were clearly differentiated and identified with a 99% accuracy. Wood species identification is imperative to assess illegally logged and transported lumber. Alternative options for identification can be time consuming and require some level of sampling. This non-invasive technique offers a viable, cost-effective alternative to rapidly and accurately identify timber in efforts to support environmental protection laws and regulations."																				
2021	"Sinka, Marianne E.; Zilli, Davide; Li, Yunpeng; Kiskin, Ivan; Kirkham, Daniel; Rafique, Waqas; Wang, Lawrence; Chan, Henry; Gutteridge, Benjamin; Herreros-Moya, Eva; Portwood, Henry; Roberts, Stephen; Willis, Kathy J."	HumBug – An Acoustic Mosquito Monitoring Tool for use on budget smartphones	Sound	Other	Classification	Methods in Ecology and Evolution	12	10	1848-1859	10.1111/2041-210X.13663	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13663	"Mosquito surveys are time-consuming, expensive and can provide a biased spatial sample of occurrence data—the data often representing the location of the surveys, not the occurrence of the mosquitoes. We present the HumBug project, an acoustic system that can turn any Android smartphone into a mosquito sensor. Our sensor has the potential to significantly increase the quantity of mosquito occurrence data as well as access locations that are more difficult to survey by traditional means. We describe our database of wild-captured mosquito fight tone audio data and outline our mosquito detection algorithms that these data train. We also present our MozzWear App, designed to work on budget smartphones, which, together with our HumBug Net (an adapted traditional bednet), facilitates data collection and allows the user to record and directly upload mosquito flight tones from any dwelling with a bednet in the field. Our HumBug system has the potential to vastly increase our understanding of the distribution of mosquito species in space and time and greatly improve surveys needed to assess the success or failure of ongoing vector control measures. At a time when the WHO reports a plateauing in the decade-long decline in malaria mortality rates, this new technological solution for surveying mosquito vectors will provide a timely new resource."																				
2021	"Smith, Brian Tilston; Gehara, Marcelo; Harvey, Michael G."	The demography of extinction in eastern North American birds	Molecular	DNN	Classification	Proceedings of the Royal Society B: Biological Sciences	288	1944	20201945	10.1098/rspb.2020.1945	https://royalsocietypublishing.org/doi/10.1098/rspb.2020.1945	"Species are being lost at an unprecedented rate during the Anthropocene. Progress has been made in clarifying how species traits influence their propensity to go extinct, but the role historical demography plays in species loss or persistence is unclear. In eastern North America, five charismatic landbirds went extinct last century, and the causes of their extinctions have been heavily debated. Although these extinctions are most often attributed to post-colonial human activity, other factors such as declining ancestral populations prior to European colonization could have made these species particularly susceptible. We used population genomic data from these extinct birds and compared them with those from four codistributed extant species. We found extinct species harboured lower genetic diversity and effective population sizes than extant species, but both extinct and non-extinct birds had similar demographic histories of population expansion. These demographic patterns are consistent with population size changes associated with glacial–interglacial cycles. The lack of support for overall population declines during the Pleistocene corroborates the view that, although species that went extinct may have been vulnerable due to low diversity or small population size, their disappearance was driven by human activities in the Anthropocene."																				
2021	"Spiesman, Brian J.; Gratton, Claudio; Hatfield, Richard G.; Hsu, William H.; Jepsen, Sarina; McCornack, Brian; Patel, Krushi; Wang, Guanghui"	Assessing the potential for deep learning and computer vision to identify bumble bee species from images	Images	CNN	Classification	Scientific Reports	11	1	7580	10.1038/s41598-021-87210-1	https://www.nature.com/articles/s41598-021-87210-1	"Pollinators are undergoing a global decline. Although vital to pollinator conservation and ecological research, species-level identification is expensive, time consuming, and requires specialized taxonomic training. However, deep learning and computer vision are providing ways to open this methodological bottleneck through automated identification from images. Focusing on bumble bees, we compare four convolutional neural network classification models to evaluate prediction speed, accuracy, and the potential of this technology for automated bee identification. We gathered over 89,000 images of bumble bees, representing 36 species in North America, to train the ResNet, Wide ResNet, InceptionV3, and MnasNet models. Among these models, InceptionV3 presented a good balance of accuracy (91.6%) and average speed (3.34 ms). Species-level error rates were generally smaller for species represented by more training images. However, error rates also depended on the level of morphological variability among individuals within a species and similarity to other species. Continued development of this technology for automatic species identification and monitoring has the potential to be transformative for the fields of ecology and conservation. To this end, we present BeeMachine, a web application that allows anyone to use our classification model to identify bumble bees in their own images."																				
2021	"Stock, Michiel; Nguyen, Bac; Courtens, Wouter; Verstraete, Hilbran; Stienen, Eric; De Baets, Bernard"	Otolith identification using a deep hierarchical classification model	Images	CNN	Classification	Computers and Electronics in Agriculture	180		105883	10.1016/j.compag.2020.105883	https://linkinghub.elsevier.com/retrieve/pii/S016816992033088X	"The diet of seabirds can yield important insights into the status of economically and ecologically important fish. By analyzing the otoliths found in the birds’ droppings, researchers can observe which fish the birds eat in which abundances. However, identifying the species based on an otolith image is quite labor-intensive and requires particular expertise. In this work, we show that a deep convolutional neural network can identify six fish species with high accuracy. We show that this deep learning approach outperforms more traditional methods and is also more accessible to set up in practice. By exploiting the hierarchy in the species labels, we impose a structure on the prediction probabilities, leading to a remarkable improvement compared to a conventional artificial neural network. Importantly, we can attain good results using only a modest dataset, demonstrating that such approaches are feasible for small-scale and specialized projects"																				
2021	"Strydom, Tanya; Catchen, Michael D.; Banville, Francis; Caron, Dominique; Dansereau, Gabriel; Desjardins-Proulx, Philippe; Forero-Muñoz, Norma R.; Higino, Gracielle; Mercier, Benjamin; Gonzalez, Andrew; Gravel, Dominique; Pollock, Laura; Poisot, Timothée"	A roadmap towards predicting species interaction networks (across space and time)	Environmental	DNN	Regression	Philosophical Transactions of the Royal Society B: Biological Sciences	376	1837	20210063	10.1098/rstb.2021.0063	https://royalsocietypublishing.org/doi/10.1098/rstb.2021.0063	"Networks of species interactions underpin numerous ecosystem processes, but comprehensively sampling these interactions is difficult. Interactions intrinsically vary across space and time, and given the number of species that compose ecological communities, it can be tough to distinguish between a true negative (where two species never interact) from a false negative (where two species have not been observed interacting even though they actually do). Assessing the likelihood of interactions between species is an imperative for several fields of ecology. This means that to predict interactions between species—and to describe the structure, variation, and change of the ecological networks they form—we need to rely on modelling tools. Here, we provide a proof-of-concept, where we show how a simple neural network model makes accurate predictions about species interactions given limited data. We then assess the challenges and opportunities associated with improving interaction predictions, and provide a conceptual roadmap forward towards predictive models of ecological networks that is explicitly spatial and temporal. We conclude with a brief primer on the relevant methods and tools needed to start building these models, which we hope will guide this research programme forward. This article is part of the theme issue ‘Infectious disease macroecology: parasite diversity and dynamics across the globe’."																				
2021	"Stupariu, Mihai-Sorin; Cushman, Samuel A.; Ple_oianu, Alin-Ionu_; P_tru-Stupariu, Ileana; Fürst, Christine"	Machine learning in landscape ecological analysis: a review of recent approaches	NA	NA	Review	Landscape Ecology				10.1007/s10980-021-01366-9	https://link.springer.com/10.1007/s10980-021-01366-9	"Objectives Our goal was to review the methods of AI, particularly ML, used in studies related to landscape ecology and the main topics addressed. We aimed to assess the trend in the number of ML papers and the methods used therein, and provide a synopsis and prospectus of current use and future applications of ML in landscape ecology. Methods We conducted a systematic literature search and selected 125 papers for review. These were examined and scored according to multiple criteria regarding methods and topic. We applied quantitative statistical methods, including cluster analysis based on titles, abstracts, and keywords and a non-metric multidimensional scaling based on attributes assigned during the review. We used Random Forests machine learning to describe the differences between identiﬁed clusters in terms of the topics and methods they included. Results The most frequent method found was Random Forests, but it is noteworthy to mention the increasing popularity of tools related to Deep Learning. The topics cover both ecologically oriented issues and the landscape-human interface. There has been a rapid increase in ML and AI methods in landscape ecology research, with Deep Learning and complex multi-step pipeline AI methods emerging in the last several years. Conclusions The rapid increase in the number of ML papers in landscape ecology research, and the range of"																				
2021	"Sudholz, Ashlee; Denman, Simon; Pople, Anthony; Brennan, Michael; Amos, Matt; Hamilton, Grant; Sudholz, Ashlee; Denman, Simon; Pople, Anthony; Brennan, Michael; Amos, Matt; Hamilton, Grant"	A comparison of manual and automated detection of rusa deer (Rusa timorensis) from RPAS-derived thermal imagery	Other	CNN	"Classification, Regression"	Wildlife Research	49	1	46-53	10.1071/WR20169	https://www.publish.csiro.au/wr/WR20169	"Context Monitoring is an essential part of managing invasive species; however, accurate, cost-effective detection techniques are necessary for it to be routinely undertaken. Current detection techniques for invasive deer are time consuming, expensive and have associated biases, which may be overcome by exploiting new technologies.Aims We assessed the accuracy and cost effectiveness of automated detection methods in comparison to manual detection of thermal footage of deer captured by remotely piloted aircraft systems.Methods Thermal footage captured by RPAS was assessed using an algorithm combining two object-detection techniques, namely, YOLO and Faster-RCNN. The number of deer found using manual review on each sampling day was compared with the number of deer found on each day using machine learning. Detection rates were compared across survey areas and sampling occasions.Key results Overall, there was no difference in the mean number of deer detected using manual and that detected by automated review (P = 0.057). The automated-detection algorithm identified between 66.7% and 100% of deer detected using manual review of thermal imagery on all but one of the sampling days. There was no difference in the mean proportion of deer detected using either manual or automated review at three repeated sampling events (P = 0.174). However, identifying deer using the automated review algorithm was 84% cheaper than the cost of manual review. Low cloud cover appeared to affect detectability using the automated review algorithm.Conclusions Automated methods provide a fast and effective way to detect deer. For maximum effectiveness, imagery that encompasses a range of environments should be used as part of the training dataset, as well as large groups for herding species. Adequate sensing conditions are essential to gain accurate counts of deer by automated detection.Implications Machine learning in combination with RPAS may decrease the cost and improve the detection and monitoring of invasive species."																				
2021	"Suh, Donghyuk; Lee, Jai Woo; Choi, Sun; Lee, Yoonji"	Recent Applications of Deep Learning Methods on Evolution- and Contact-Based Protein Structure Prediction	NA	NA	Review	International Journal of Molecular Sciences	22	11	6032	10.3390/ijms22116032	https://www.mdpi.com/1422-0067/22/11/6032	"The new advances in deep learning methods have influenced many aspects of scientific research, including the study of the protein system. The prediction of proteins’ 3D structural components is now heavily dependent on machine learning techniques that interpret how protein sequences and their homology govern the inter-residue contacts and structural organization. Especially, methods employing deep neural networks have had a significant impact on recent CASP13 and CASP14 competition. Here, we explore the recent applications of deep learning methods in the protein structure prediction area. We also look at the potential opportunities for deep learning methods to identify unknown protein structures and functions to be discovered and help guide drug–target interactions. Although significant problems still need to be addressed, we expect these techniques in the near future to play crucial roles in protein structural bioinformatics as well as in drug discovery."																				
2021	"Sun, Jianqiang; Futahashi, Ryo; Yamanaka, Takehiko"	Improving the Accuracy of Species Identification by Combining Deep Learning With Field Occurrence Records	"Images, Environmental"	CNN	Classification	Frontiers in Ecology and Evolution	9			10.3389/fevo.2021.762173	https://www.frontiersin.org/article/10.3389/fevo.2021.762173	"Citizen science is essential for nationwide ecological surveys of species distribution. While the accuracy of the information collected by beginner participants is not guaranteed, it is important to develop an automated system to assist species identification. Deep learning techniques for image recognition have been successfully applied in many fields and may contribute to species identification. However, deep learning techniques have not been utilized in ecological surveys of citizen science, because they require the collection of a large number of images, which is time-consuming and labor-intensive. To counter these issues, we propose a simple and effective strategy to construct species identification systems using fewer images. As an example, we collected 4,571 images of 204 species of Japanese dragonflies and damselflies from open-access websites (i.e., web scraping) and scanned 4,005 images from books and specimens for species identification. In addition, we obtained field occurrence records (i.e., range of distribution) of all species of dragonflies and damselflies from the National Biodiversity Center, Japan. Using the images and records, we developed a species identification system for Japanese dragonflies and damselflies. We validated that the accuracy of the species identification system was improved by combining web-scraped and scanned images; the top-1 accuracy of the system was 0.324 when trained using only web-scraped images, whereas it improved to 0.546 when trained using both web-scraped and scanned images. In addition, the combination of images and field occurrence records further improved the top-1 accuracy to 0.668. The values of top-3 accuracy under the three conditions were 0.565, 0.768, and 0.873, respectively. Thus, combining images with field occurrence records markedly improved the accuracy of the species identification system. The strategy of species identification proposed in this study can be applied to any group of organisms. Furthermore, it has the potential to strike a balance between continuously recruiting beginner participants and updating the data accuracy of citizen science."																				
2021	"Sun, Xiaohong; Gu, Jinan; Sun, Hongying"	Research progress of zero-shot learning	NA	NA	Review	Applied Intelligence	51	6	3600-3614	10.1007/s10489-020-02075-7	https://doi.org/10.1007/s10489-020-02075-7	"Although there have been encouraging breakthroughs in supervised learning since the renaissance of deep learning, the recognition of large-scale object classes remains a challenge, especially when some classes have no or few training samples. In this paper, the development of ZSL is reviewed comprehensively, including the evolution, key technologies, mainstream models, current research hotspots and future research directions. First, the evolution process is introduced from the perspectives of multi-shot, few-shot to zero-shot learning. Second, the key techniques of ZSL are analyzed in detail in terms of three aspects: visual feature extraction, semantic representation and visual-semantic mapping. Third, some typical models are interpreted in chronological order. Finally, closely related articles from the last three years are collected to analyze the current research hotspots and list future research directions."																				
2021	"Sun, Yongke; Lin, Qizhao; He, Xin; Zhao, Youjie; Dai, Fei; Qiu, Jian; Cao, Yong"	Wood Species Recognition with Small Data: A Deep Learning Approach	Images	CNN	Regression	International Journal of Computational Intelligence Systems			10	10.2991/ijcis.d.210423.001	https://www.atlantis-press.com/journals/ijcis/125956108	"Wood species recognition is an important work in the wood trade and wood commercial activities. Although many recognition methods were presented in recent years, the existing wood species recognition methods mainly use shallow recognition models with low accuracy and are still unsatisfying for many real-world applications. Besides, their generalization ability is not strong. In this paper, a novel deep-learning-based wood species recognition method was proposed, which improved the accuracy and generalization greatly. The method uses 20X amplifying glass to acquire wood images, extracts the image features with ResNet50 neural network, refines the features with linear discriminant analysis (LDA), and recognizes the wood species with a KNN classifier. Our data was small, but we adopted transfer learning to improve our method. About 3000 wood images were used in our wood species recognition experiments and our method was executed in 25 rare wood species and the results showed our method had better generalization performance and accuracy. Compared with traditional deep learning our results were obtained from a small amount of data, which just confirmed the effectiveness of our method."																				
2021	"Swarup, Pranjal; Chen, Peng; Hou, Rong; Que, Pinjia; Liu, Peng; Kong, Adams Wai Kin"	Giant panda behaviour recognition using images	Images	CNN	Classification	Global Ecology and Conservation	26		e01510	10.1016/j.gecco.2021.e01510	https://www.sciencedirect.com/science/article/pii/S2351989421000603	"Monitoring giant panda (Ailuropoda melanoleuca) behaviour is critical for their conservation and understanding their health conditions. Currently, captive giant panda behaviour is usually monitored by their caregivers. In previous studies, researchers observed panda behaviours for short time spans over a period. However, both caregivers and researchers cannot monitor them 24-h using traditional methods of observation. In other words, animal behaviour data are difficult to collect over long periods and are prone to errors when recorded manually. Some researchers have used wearable devices such as accelerometer ear tags and collar-mounted units with a global position system (GPS) receiver and contactless devices such as depth cameras and video cameras for understanding behaviour of other animals such as primates and American white pelicans. However, the giant panda, an icon of endangered species conservation, is almost completely neglected in these studies. To monitor giant panda behaviour effectively, a fully automated giant panda behaviour recognition method based on Faster R–CNN and two modified ResNet was created. The Faster R–CNN network was able to detect panda bodies and panda faces in images. One of the modified ResNet was trained to classify their behaviour into five classes, walking, sitting, resting, climbing, and eating and the other to recognise whether the panda’s eyes and mouth were opened or closed. Experiments were conducted on 10,804 images collected from over 218 pandas in various environments and illumination conditions. The experimental results were very encouraging and achieved an overall accuracy of 90% for the five panda behaviours and an overall accuracy of 84% for the subtle panda facial motions. The proposed method provides an effective way to monitor giant panda behaviour in captivity."																				
2021	"Takimoto, Hironori; Sato, Yasuhiro; Nagano, Atsushi J.; Shimizu, Kentaro K.; Kanagawa, Akihiro"	Using a two-stage convolutional neural network to rapidly identify tiny herbivorous beetles in the field	Video	CNN	"Classification, Regression"	Ecological Informatics	66		101466	10.1016/j.ecoinf.2021.101466	https://www.sciencedirect.com/science/article/pii/S1574954121002570	"Recently, deep convolutional neural networks (CNN) have been adopted to help non-experts identify insect species from field images. However, the application of these methods on the rapid identification of tiny congeneric species moving across heterogeneous background remains difficult. To improve rapid and automatic identification in the field, we customized an existing CNN-based method for a field video involving two Phyllotreta beetles. We first performed data augmentation using transformations, syntheses, and random erasing of the original images. We then proposed a two-stage method for the detection and identification of small insects based on CNN, where YOLOv4 and EfficientNet were used as a detector and a classifier, respectively. Evaluation of the model revealed that one-step object detection by YOLOv4 alone was not precise (Precision=0.55) when classifying two species of flea beetles and background objects. In contrast, the two-step CNNs improved the precision (Precision=0.89) with moderate accuracy (F-measure=0.55) and acceptable speed (ca. 5 frames per second for full HD images) of detection and identification of insect species in the field. Although real-time identification of tiny insects remains a challenge in the field, our method aids in improving small object detection on a heterogeneous background."																				
2021	"Tan, Hui Yuan; Goh, Zhi Yun; Loh, Kar-Hoe; Then, Amy Yee-Hui; Omar, Hasmahzaiti; Chang, Siow-Wee"	Cephalopod species identification using integrated analysis of machine learning and deep learning approaches	Images	CNN	Classification	PeerJ	9		e11825	10.7717/peerj.11825	https://peerj.com/articles/11825	"Background Despite the high commercial fisheries value and ecological importance as prey item for higher marine predators, very limited taxonomic work has been done on cephalopods in Malaysia. Due to the soft-bodied nature of cephalopods, the identification of cephalopod species based on the beak hard parts can be more reliable and useful than conventional body morphology. Since the traditional method for species classification was time-consuming, this study aimed to develop an automated identification model that can identify cephalopod species based on beak images. Methods A total of 174 samples of seven cephalopod species were collected from the west coast of Peninsular Malaysia. Both upper and lower beaks were extracted from the samples and the left lateral views of upper and lower beak images were acquired. Three types of traditional morphometric features were extracted namely grey histogram of oriented gradient (HOG), colour HOG, and morphological shape descriptor (MSD). In addition, deep features were extracted by using three pre-trained convolutional neural networks (CNN) models which are VGG19, InceptionV3, and Resnet50. Eight machine learning approaches were used in the classification step and compared for model performance. Results The results showed that the Artificial Neural Network (ANN) model achieved the best testing accuracy of 91.14%, using the deep features extracted from the VGG19 model from lower beak images. The results indicated that the deep features were more accurate than the traditional features in highlighting morphometric differences from the beak images of cephalopod species. In addition, the use of lower beaks of cephalopod species provided better results compared to the upper beaks, suggesting that the lower beaks possess more significant morphological differences between the studied cephalopod species. Future works should include more cephalopod species and sample size to enhance the identification accuracy and comprehensiveness of the developed model."																				
2021	"Theivaprakasham, Hari"	Identification of Indian butterflies using Deep Convolutional Neural Network	Images	CNN	Classification	Journal of Asia-Pacific Entomology	24	1	329-340	10.1016/j.aspen.2020.11.015	https://www.sciencedirect.com/science/article/pii/S1226861520307597	"The conventional butterfly identification method is based on their different morphological characters namely wing-venation, color, shape, patterns and through the dissection studies and molecular techniques which are tedious, expensive and highly time-consuming. To overcome the above aforesaid challenges, a new butterfly identification system using butterfly images has been designed to instantly identify the butterfly with high accuracy. In this study, we construct a new butterfly dataset with 34,024 butterfly images belonging to 315 species from India. We propose and prove the effectiveness of new data augmentation techniques on our dataset. To identify butterflies using photographic images, we built eleven new Deep Convolutional Neural Network (DCNN) butterfly classifier models using eleven pre-trained architectures namely ResNet-18, ResNet-34, ResNet-50, ResNet-121, ResNet-152, Alex-Net, DenseNet-121, DenseNet-161, VGG-16, VGG-19 and SqueezeNet-v1.1. The different model's classification results were compared and the proposed technique achieved a maximum top-1 accuracy(94.44%), top-3 accuracy(98.46%) and top-5 accuracy(99.09%) using ResNet-152 model, followed by DenseNet-161 model achieved the top-1 accuracy(94.31%), top-3 accuracy (98.07%) and top-5 accuracy (98.66%). The results suggest that models can be assertively used to identify butterflies in India."																				
2021	"Thevenoux, Romain; Le, Van Linh; Villessèche, Heloïse; Buisson, Alain; Beurton-Aimar, Marie; Grenier, Eric; Folcher, Laurent; Parisey, Nicolas"	Image based species identification of Globodera quarantine nematodes using computer vision and deep learning	Images	CNN	Classification	Computers and Electronics in Agriculture	186		106058	10.1016/j.compag.2021.106058	https://www.sciencedirect.com/science/article/pii/S0168169921000764	"Identification of plant parasitic nematode species is usually achieved following morphobiometric analysis, which requires a certain level of expertise and remains time consuming. Moreover, molecular and morphological discrimination of a number of emergent or cryptic species is sometimes difficult. Finding a way to achieve morphological characterisation quickly and accurately would greatly advance nematology science. Here, we developed a complete method in order to identify the two quarantine nematode species Globodera pallida and Globodera rostochiensis. First, we chose discriminative metrics on the stylet of nematodes that are able to be used by algorithms in order to build an automated process. Second, we used a custom computer vision algorithm (CCVA) and a convolutional neural network (CNN) to measure our metrics of interest. Third, we compared the CCVA and CNN predictions and their discriminative power to distinguish closely related species. Results show accurate identification of G. pallida and G. rostochiensis with the two methods, despite small-scale divergence (one to five µm depending on the metric used). However, the error rate is higher for Globodera mexicana, suggesting that the algorithms are too specific. Nonetheless, these methods represent a promising novel approach to automated morphological identification of nematodes and Globodera species in particular."																				
2021	"Toenies, Matthew; Rich, Lindsey"	Advancing bird survey efforts through novel recorder technology and automated species identification	Sound	CNN	Classification	California Fish and Wildlife Journal	107	2	56-70	10.51492/cfwj.107.5	https://nrm.dfg.ca.gov/FileHandler.ashx?DocumentID=193712&inline	"Recent advances in acoustic recorder technology and automated species identification hold great promise for avian monitoring efforts. Assessing how these innovations compare to existing recorder models and traditional species identification techniques is vital to understanding their utility to researchers and managers. We carried out field trials in Monterey County, California, to compare bird detection among four acoustic recorder models (AudioMoth, Swift Recorder, and Wildlife Acoustics SM3BAT and SM Mini) and concurrent point counts, and to assess the ability of the artificial neural network BirdNET to correctly identify bird species from AudioMoth recordings. We found that the lowest-cost unit (AudioMoth) performed comparably to higher-cost units and that on average, species detections were higher for three of the five recorder models (range 9.8 to 14.0) than for point counts (12.8). In our assessment of BirdNET, we developed a subsetting process that enabled us to achieve a high rate of correctly identified species (96%). Using longer recordings from a single recorder model, BirdNET identified a mean of 8.5 verified species per recording and a mean of 16.4 verified species per location over a 5-day period (more than point counts conducted in similar habitats). We demonstrate that a combination of long recordings from low-cost recorders and a conservative method for subsetting automated identifications from BirdNET presents a process for sampling avian community composition with low misidentification rates and limited need for human vetting. These low-cost and automated tools may greatly improve efforts to survey bird communities and their ecosystems, and consequently, efforts to conserve threatened indigenous biodiversity."																				
2021	"Triki, Abdelaziz; Bouaziz, Bassem; Gaikwad, Jitendra; Mahdi, Walid"	Deep leaf: Mask R-CNN based leaf detection and segmentation from digitized herbarium specimen images	Images	CNN	Classification	Pattern Recognition Letters	150		76-83	10.1016/j.patrec.2021.07.003	https://www.sciencedirect.com/science/article/pii/S0167865521002361	"The generation of morphological traits of plants such as the leaf length, width, perimeter, area, and petiole length are fundamental features of herbarium specimens, thus providing high-quality data to investigate plant responses to ongoing climatic change and plant history evolution. However, the existing measurement methods are primarily associated with manual analysis, which is labor-intensive and inefficient. This paper proposes a deep learning-based approach, called Deep Leaf, for detecting and pixel-wise segmentation of leaves based on the improved state-of-the-art instance segmentation approach, Mask Region Convolutional Neural Network (Mask R-CNN). Deep Leaf can accurately detect each leaf in the herbarium specimen and measure the associated morphological traits. The experimental results indicate that our automated approach can segment the leaves of different families. Compared to manual measurement done by ecologist and botanist experts, the average relative error of leaf length is 4.6%, while the average relative error of leaf width is 5.7%."																				
2021	"Triseleva, Tatiana; Petrosyan, Varos; Yatsuk, Aleksandra; Safonkin, Andrey"	"The role of plants in the formation of species-specific features in grass flies (Diptera, Chloropidae, Meromyza)"	Other	Other	Classification	Biodiversity Data Journal	9		e78017	10.3897/BDJ.9.e78017	https://bdj.pensoft.net/article/78017/	"In the current manuscript, we present the results of comparative analysis of seven species of Meromyza flies in the “variegata” cluster and of the evolutionary close species M. inornata, based the following criteria: 1) 14 external key features; 2) shape and area of the anterior processes of postgonites; 3) mtDNA CO1 region and 4) host plant diversity data. We could demonstrate the primary role of host plants in species formation inside genus Meromyza and calculated the timing of the divergence of M. inornata and the species of “variegata” cluster. Based on our estimates of evolution rate for mtDNA CO1 gene, we could conclude that that divergence of herbs happened before the speciation of grass flies Meromyza. Meromyza species, close to the ancestral species of the cluster, are adapted to the wide range of host plants. We revealed the most informative variables h1, S and Plant analysing data with the following statistical methods: linear discriminant analysis - LDA, regularised discriminant analysis - RDA, flexible discriminant analysis – FDA and probabilistic neural network - PNN. The highest classification accuracy was achieved using PNN (99%) and the lowest when using LDA (95.8%). When the Plant trait was excluded, the classification accuracy decreased by 14%. We revealed the significant trends in size change of the anterior process of the postgonite amongst studies species. This morphological structure is an element of male reproductive apparatus critical for the restriction of interspecies mating. We determined three branches of speciation in the “variegata” cluster and five trends in the evolution of this cluster, based on the external morphological features. We showed that M. variegata and especially M. mosquensis, the species closest to the ancestral haplotype, have the largest number of features typical of those of M. inornata. Based on the external features and the area of the anterior process of the postgonite, we reconstructed the phylogenetic position of M. elbergi in the cluster. In accordance with the obtained outcomes, we could conclude that the distribution, species diversity and the adaptation of the grass flies to narrow oligophagy were directly connected to host plant diversity. The adaptation to different host plants could be the main factor in divergence of grass flies and their evolution started later than the diversification in the Pooideae subfamily of grasses."																				
2021	"Tsai, Yiting; Baldwin, Susan A.; Gopaluni, Bhushan"	Identifying indicator species in ecological habitats using Deep Optimal Feature Learning	Environmental	DNN	Classification	PLOS ONE	16	9	e0256782	10.1371/journal.pone.0256782	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0256782	"Much of the current research on supervised modelling is focused on maximizing outcome prediction accuracy. However, in engineering disciplines, an arguably more important goal is that of feature extraction, the identification of relevant features associated with the various outcomes. For instance, in microbial communities, the identification of keystone species can often lead to improved prediction of future behavioral shifts. This paper proposes a novel feature extractor based on Deep Learning, which is largely agnostic to underlying assumptions regarding the training data. Starting from a collection of microbial species abundance counts, the Deep Learning model first trains itself to classify the selected distinct habitats. It then identifies indicator species associated with the habitats. The results are then compared and contrasted with those obtained by traditional statistical techniques. The indicator species are similar when compared at top taxonomic levels such as Domain and Phylum, despite visible differences in lower levels such as Class and Order. More importantly, when our estimated indicators are used to predict final habitat labels using simpler models (such as Support Vector Machines and traditional Artificial Neural Networks), the prediction accuracy is improved. Overall, this study serves as a preliminary step that bridges modern, black-box Machine Learning models with traditional, domain expertise-rich techniques."																				
2021	"Tuia, Devis; Kellenberger, Benjamin; Beery, Sara; Costelloe, Blair R.; Zuffi, Silvia; Risse, Benjamin; Mathis, Alexander; Mathis, Mackenzie W.; van Langevelde, Frank; Burghardt, Tilo; Kays, Roland; Klinck, Holger; Wikelski, Martin; Couzin, Iain D.; van Horn, Grant; Crofoot, Margaret C.; Stewart, Charles V.; Berger-Wolf, Tanya"	Perspectives in machine learning for wildlife conservation	NA	NA	Review	Nature Communications	13	792		10.1038/s41467-022-27980-y	https://www.nature.com/articles/s41467-022-27980-y	"Inexpensive and accessible sensors are accelerating data acquisition in animal ecology. These technologies hold great potential for large-scale ecological understanding, but are limited by current processing approaches which inefficiently distill data into relevant information. We argue that animal ecologists can capitalize on large datasets generated by modern sensors by combining machine learning approaches with domain knowledge. Incorporating machine learning into ecological workflows could improve inputs for ecological models and lead to integrated hybrid modeling tools. This approach will require close interdisciplinary collaboration to ensure the quality of novel approaches and train a new generation of data scientists in ecology and conservation."																				
2021	"Turkoglu, Muammer; Aslan, Muzaffer; Arı, Ali; Alçin, Zeynep Mine; Hanbay, Davut"	A multi-division convolutional neural network-based plant identification system	Images	CNN	Classification	PeerJ Computer Science	7		e572	10.7717/peerj-cs.572	https://peerj.com/articles/cs-572	"Background Plants have an important place in the life of all living things. Today, there is a risk of extinction for many plant species due to climate change and its environmental impact. Therefore, researchers have conducted various studies with the aim of protecting the diversity of the planet’s plant life. Generally, research in this area is aimed at determining plant species and diseases, with works predominantly based on plant images. Advances in deep learning techniques have provided very successful results in this field, and have become widely used in research studies to identify plant species. Methods In this paper, a Multi-Division Convolutional Neural Network (MD-CNN)-based plant recognition system was developed in order to address an agricultural problem related to the classification of plant species. In the proposed system, we divide plant images into equal nxn-sized pieces, and then deep features are extracted for each piece using a Convolutional Neural Network (CNN). For each part of the obtained deep features, effective features are selected using the Principal Component Analysis (PCA) algorithm. Finally, the obtained effective features are combined and classification conducted using the Support Vector Machine (SVM) method. Results In order to test the performance of the proposed deep-based system, eight different plant datasets were used: Flavia, Swedish, ICL, Foliage, Folio, Flower17, Flower102, and LeafSnap. According to the results of these experimental studies, 100% accuracy scores were achieved for the Flavia, Swedish, and Folio datasets, whilst the ICL, Foliage, Flower17, Flower102, and LeafSnap datasets achieved results of 99.77%, 99.93%, 97.87%, 98.03%, and 94.38%, respectively."																				
2021	"Ulhaq, Anwaar; Adams, Peter; Cox, Tarnya E.; Khan, Asim; Low, Tom; Paul, Manoranjan"	Automated Detection of Animals in Low-Resolution Airborne Thermal Imagery	Other	CNN	"Classification, Regression"	Remote Sensing	13	16	3276	10.3390/rs13163276	https://www.mdpi.com/2072-4292/13/16/3276	"Detecting animals to estimate abundance can be difficult, particularly when the habitat is dense or the target animals are fossorial. The recent surge in the use of thermal imagers in ecology and their use in animal detections can increase the accuracy of population estimates and improve the subsequent implementation of management programs. However, the use of thermal imagers results in many hours of captured flight videos which require manual review for confirmation of species detection and identification. Therefore, the perceived cost and efficiency trade-off often restricts the use of these systems. Additionally, for many off-the-shelf systems, the exported imagery can be quite low resolution (<9 Hz), increasing the difficulty of using automated detections algorithms to streamline the review process. This paper presents an animal species detection system that utilises the cost-effectiveness of these lower resolution thermal imagers while harnessing the power of transfer learning and an enhanced small object detection algorithm. We have proposed a distant object detection algorithm named Distant-YOLO (D-YOLO) that utilises YOLO (You Only Look Once) and improves its training and structure for the automated detection of target objects in thermal imagery. We trained our system on thermal imaging data of rabbits, their active warrens, feral pigs, and kangaroos collected by thermal imaging researchers in New South Wales and Western Australia. This work will enhance the visual analysis of animal species while performing well on low, medium and high-resolution thermal imagery."																				
2021	"van Essen, Rick; Mencarelli, Angelo; van Helmond, Aloysius; Nguyen, Linh; Batsleer, Jurgen; Poos, Jan-Jaap; Kootstra, Gert"	"Automatic discard registration in cluttered environments using deep learning and object tracking: class imbalance, occlusion, and a comparison to human review"	Images	CNN	"Classification, Regression"	ICES Journal of Marine Science	78	10	3834-3846	10.1093/icesjms/fsab233	https://academic.oup.com/icesjms/article/78/10/3834/6444891	"This paper presents and evaluates a method for detecting and counting demersal fish species in complex, cluttered, and occluded environments that can be installed on the conveyor belts of fishing vessels. Fishes on the conveyor belt were recorded using a colour camera and were detected using a deep neural network. To improve the detection, synthetic data were generated for rare fish species. The fishes were tracked over the consecutive images using a multi-object tracking algorithm, and based on multiple observations, the fish species was determined. The effect of the synthetic data, the amount of occlusion, and the observed dorsal or ventral fish side were investigated and a comparison with human electronic monitoring (EM) review was made. Using the presented method, a weighted counting error of 20% was achieved, compared to a counting error of 7% for human EM review on the same recordings."																				
2021	"Venegas, Pablo; Calderon, Francisco; Riofrío, Daniel; Benítez, Diego; Ramón, Giovani; Cisneros-Heredia, Diego; Coimbra, Miguel; Rojo-Álvarez, José Luis; Pérez, Noel"	Automatic ladybird beetle detection using deep-learning models	Images	CNN	Classification	PLOS ONE	16	6	e0253027	10.1371/journal.pone.0253027	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253027	"Fast and accurate taxonomic identification of invasive trans-located ladybird beetle species is essential to prevent significant impacts on biological communities, ecosystem functions, and agricultural business economics. Therefore, in this work we propose a two-step automatic detector for ladybird beetles in random environment images as the first stage towards an automated classification system. First, an image processing module composed of a saliency map representation, simple linear iterative clustering superpixels segmentation, and active contour methods allowed us to generate bounding boxes with possible ladybird beetles locations within an image. Subsequently, a deep convolutional neural network-based classifier selects only the bounding boxes with ladybird beetles as the final output. This method was validated on a 2, 300 ladybird beetle image data set from Ecuador and Colombia obtained from the iNaturalist project. The proposed approach achieved an accuracy score of 92% and an area under the receiver operating characteristic curve of 0.977 for the bounding box generation and classification tasks. These successful results enable the proposed detector as a valuable tool for helping specialists in the ladybird beetle detection problem."																				
2021	"Vidal, Maxime; Wolf, Nathan; Rosenberg, Beth; Harris, Bradley P; Mathis, Alexander"	Perspectives on individual animal identification from biology and computer vision	NA	NA	Review	Integrative and Comparative Biology	61	3	900-916	10.1093/icb/icab107	https://doi.org/10.1093/icb/icab107	"Synopsis  Identifying individual animals is crucial for many biological investigations. In response to some of the limitations of current identification methods, new automated computer vision approaches have emerged with strong performance. Here, we review current advances of computer vision identification techniques to provide both computer scientists and biologists with an overview of the available tools and discuss their applications. We conclude by offering recommendations for starting an animal identification project, illustrate current limitations, and propose how they might be addressed in the future."																				
2021	"Villon, Sébastien; Iovan, Corina; Mangeas, Morgan; Claverie, Thomas; Mouillot, David; Villéger, Sébastien; Vigliola, Laurent"	Automatic underwater fish species classification with limited data using few-shot learning	Images	"CNN, Other"	Classification	Ecological Informatics	63		101320	10.1016/j.ecoinf.2021.101320	https://www.sciencedirect.com/science/article/pii/S1574954121001114	"Underwater cameras are widely used to monitor marine biodiversity, and the trend is increasing due to the availability of cheap action cameras. The main bottleneck of video methods now resides in the manual processing of images, a time-consuming task requiring trained experts. Recently, several solutions based on Deep Learning (DL) have been proposed to automatically process underwater videos. The main limitation of such algorithms is that they require thousands of annotated images in order to learn to discriminate classes (here species). This limitation implies two issues: 1) the annotation of hundreds of common species requires a lot of efforts 2) many species are too rare to gather enough data to train a classic DL algorithm. Here, we propose to explore how few-shot learning (FSL), an emerging research field, could overcome DL limitations. Few-shot learning is based on the principle of training a Deep Learning algorithm on “how to learn a new classification problem with only few images”. In our case-study, we assess the robustness of FSL to discriminate 20 coral reef fish species with a range of training databases from 1 image per class to 30 images per class, and compare FSL to a classic DL approach with thousands of images per class. We found that FSL outperform classic DL approach in situations where annotated images are limited, yet still providing good classification accuracy."																				
2021	"Wagner, Fabien H."	The flowering of Atlantic Forest Pleroma trees	"Images, Other"	CNN	Classification	Scientific Reports	11	1	20437	10.1038/s41598-021-99304-x	https://www.nature.com/articles/s41598-021-99304-x	"Mapping the spatial distribution of a plant is a current challenge in ecology. Here, a convolutional neural network (CNN) and 33,798 Sentinel-2 satellite images were used to detect and map forest stands dominated by trees of the genus Pleroma by their magenta-to-deep-purple blossoms in the entire Brazilian Atlantic Forest domain, from June 2016 to July 2020. The Pleroma genus, known for its pioneer behaviour, was detected in an area representing 10.8% of the Atlantic Forest, associated negatively with temperature and positively with elevation, slope, tree cover and precipitation. The detection of another genus by the model, 18% of all the detections contained only pink blooming Handroanthus trees, highlighted that botanical identification from space must be taken with caution, particularly outside the known distribution range of the species. The Pleroma blossom seasonality occurred over a period of ~5–6 months centered on the March equinox and populations with distinct blossom timings were found. Our results indicate that in the Atlantic Forest, the remaining natural forest is less diverse than expected but is at least recovering from degradation. Our study suggests a method to produce ecological-domain scale maps of tree genera and species based on their blossoms that could be used for tree studies and biodiversity assessments."																				
2021	"Walter, Tristan; Couzin, Iain D"	"TRex, a fast multi-animal tracking system with markerless identification, and 2D estimation of posture and visual fields"	Video	CNN	Regression	eLife	10		e64000	10.7554/eLife.64000	https://doi.org/10.7554/eLife.64000	"Automated visual tracking of animals is rapidly becoming an indispensable tool for the study of behavior. It offers a quantitative methodology by which organisms’ sensing and decision-making can be studied in a wide range of ecological contexts. Despite this, existing solutions tend to be challenging to deploy in practice, especially when considering long and/or high-resolution video-streams. Here, we present TRex, a fast and easy-to-use solution for tracking a large number of individuals simultaneously using background-subtraction with real-time (60 Hz) tracking performance for up to approximately 256 individuals and estimates 2D visual-fields, outlines, and head/rear of bilateral animals, both in open and closed-loop contexts. Additionally, TRex offers highly accurate, deep-learning-based visual identification of up to approximately 100 unmarked individuals, where it is between 2.5 and 46.7 times faster, and requires 2–10 times less memory, than comparable software (with relative performance increasing for more organisms/longer videos) and provides interactive data-exploration within an intuitive, platform-independent graphical user-interface."																				
2021	"Wang, Bo; Jahanshahi, Hadi; Dutta, Hemen; Zambrano-Serrano, Ernesto; Grebenyuk, Vladimir; Bekiros, Stelios; Aly, Ayman A."	Incorporating fast and intelligent control technique into ecology: A Chebyshev neural network-based terminal sliding mode approach for fractional chaotic ecological systems	Environmental	Other	Regression	Ecological Complexity	47		100943	10.1016/j.ecocom.2021.100943	https://www.sciencedirect.com/science/article/pii/S1476945X21000362	"In the present study, a new neural network-based terminal sliding mode technique is proposed to stabilize and synchronize fractional-order chaotic ecological systems in finite-time. The Chebyshev neural network is implemented to estimate unknown functions of the system. Moreover, through the proposed Chebyshev neural network observer, the effects of external disturbances are fully taken into account. The weights of the Chebyshev neural network observer are adjusted based on adaptive laws. The finite-time convergence of the closed-loop system, which is a new concept for ecological systems, is proven. Then, the dependency of the system on the value of the fractional time derivatives is investigated. Lastly, the proposed control scheme is applied to the fractional-order ecological system. Through numerical simulations, the performance of the developed technique for synchronization and stabilization are assessed and compared with a conventional method. The numerical simulations strongly corroborate the effective performance of the proposed control technique in terms of accuracy, robustness, and convergence time for the unknown nonlinear system in the presence of external disturbances."																				
2021	"Wang, Dongfang; Wang, Jun; Li, Wenrui; Guan, Ping"	T-CNN: Trilinear convolutional neural networks model for visual detection of plant diseases	Images	CNN	Classification	Computers and Electronics in Agriculture	190		106468	10.1016/j.compag.2021.106468	https://www.sciencedirect.com/science/article/pii/S0168169921004853	"Plant diseases may threaten the safety of crops around the world, and timely detection of crop diseases and accurate determination of disease species are important to protect crop safety and control the spread of diseases. Recent studies have proposed the application of modern automatic recognition systems based on convolutional neural networks to the identification tasks of multiple crops and diseases. Although some research results have been achieved, studies have shown that these models are not optimal because they are susceptible to features unrelated to crop diseases, and have poor application ability in real-world environments. Therefore, this paper proposes a more concise method that separating the crop and disease identification and classify them independently, and demonstrates that it is more effective than the traditional crop-disease pairs approach. Meanwhile, we constructed a trilinear convolutional neural networks model using bilinear pooling and used images obtained in a real-world environment for the study of crop disease identification. The crop and disease identification accuracies achieved 99.99% and 99.7% on the test set in a controlled laboratory environment, and 84.11% and 75.58% on the test set in a real-world environment, respectively. The work in this paper improves the application value of crop disease identification research in the real-world."																				
2021	"Wang, Haining; Fu, Xiaoxue; Zhao, Chengqian; Luan, Zhendong; Li, Chaolun"	A Deep Learning Model to Recognize and Quantitatively Analyze Cold Seep Substrates and the Dominant Associated Species	Images	CNN	Regression	Frontiers in Marine Science	8			10.1002/rob.22049	https://www.frontiersin.org/article/10.3389/fmars.2021.775433	"Characterizing habitats and species distribution is important to understand the structure and function of cold seep ecosystems. This paper develops a deep learning model for the fast and accurate recognition and classification of substrates and the dominant associated species in cold seeps. Considering the dense distribution of the dominant associated species and small objects caused by overlap in cold seeps, the feature pyramid network (FPN) embed into the faster region-convolutional neural network (R-CNN) was used to detect large-scale changes and small missing objects without increasing the number of calculations. We applied three classifiers (Faster R-CNN + FPN for mussel beds, lobster clusters and biological mixing, CNN for shell debris and exposed authigenic carbonates, and VGG16 for reduced sediments and muddy bottom) to improve the recognition accuracy of substrates. The model’s results were manually verified using images obtained in the Formosa cold seep during a 2016 cruise. The recognition accuracy of the two dominant species, e.g., Gigantidas platifrons and Munidopsidae could be 70.85 and 56.16%, respectively. Seven subcategories of substrates were also classified with a mean accuracy of 74.87%. The developed model is a promising tool for the fast and accurate characterization of substrates and epifauna in cold seeps, which is crucial for large-scale quantitative analyses."																				
2021	"Wang, Jiangning; Chen, Yingying; Hou, Xinwen; Wang, Yong; Zhou, Libing; Chen, Xiaolin"	An intelligent identification system combining image and DNA sequence methods for fruit flies with economic importance (Diptera: Tephritidae)	Images	CNN	Classification	Pest Management Science	77	7	3382-3395	10.1002/ps.6383	https://onlinelibrary.wiley.com/doi/abs/10.1002/ps.6383	"BACKGROUND Images and DNA sequences are two important methods for identifying fruit fly species. In addition, the identification of insect species complexes is highly problematic when attempting to utilize automatic identification methods in an actual environment. We integrated the image and DNA sequence identification methods into a single system for the first time and explored an open interactive multi-image comparison function for solving the problem of species complexes. The Automated Fruit Fly Identification System 1.0 (AFIS1.0) was updated to AFIS2.0 by employing different models and developing the system under a novel framework. RESULTS AFIS2.0 was developed using 83 species belonging to eight genera in the Tephritidae, which includes most pests of this family. The system applies the Mask Region Convolutional Neural Network (Mask R-CNN) and discriminative deep metric learning (AlexNet based) methods for image identification, integrates Blast+ for DNA sequence comparison and specific weighting for the fusion result. At the species level, the best classification success rate for wing images (as the Top 1 species in the species list of outcomes) reached 90%, and the average classification success rate for wing, thorax, and abdomen images (as the Top 5 species in the species list of outcomes) was 94%. CONCLUSION AFIS2.0 is more accurate and convenient than AFIS1.0 and can be beneficial for users with or without specific expertise regarding Tephritidae. It also provides a more compact and fluent computer system for fruit fly identification, and can be easily applied in practice. © 2021 Society of Chemical Industry."																				
2021	"Wang, Kui; Wu, Pei; Xuan, Chuanzhong; Zhang, Yongan; Bu, Ku; Ma, YanHua"	Identification of grass growth conditions based on sheep grazing acoustic signals	Sound	"CNN, RNN"	Classification	Computers and Electronics in Agriculture	190		106463	10.1016/j.compag.2021.106463	https://www.sciencedirect.com/science/article/pii/S0168169921004804	"The acoustic signals of sheep grazing carry a wealth of information. To date, the information on grazing behavior and intake in acoustic signals has been thoroughly explored and utilized. However, information on grass growth conditions (grass conditions) has received little attention from scholars, although it is crucial for making rotational grazing decisions. This study tries to efficiently mine and process the grass condition information in acoustic signals to obtain a high-performing recognition model. First, the acoustic signals collected under three grass conditions were divided into many segment samples. Second, six types of formal samples were constructed from every segment sample. Last, the log-Mel features of the six formal samples were separately fed into a convolutional neural network (CNN) model or a recurrent neural network (RNN) model to identify the grass conditions. Before the log-Mel features were fed into the model, two methods of unifying the sample length and multiple specified lengths were used to pre-process the formal samples. The results showed that the combination of the fixed chewing and biting connection (FCB) sample and the CNN model performed the best, with an accuracy of 90.24%. The method of filling or truncating the sample’s waveform tended to be better than scaling the sample’s log-Mel feature when the specified length was longer than 8 s. The different specified lengths had an essential effect on the accuracy of the model with the filling method. The application of this study could provide a data reference for constructing a more rational rotational grazing strategy."																				
2021	"Wang, Yong; Zhang, Wei; Gao, Rui; Jin, Zheng; Wang, Xiaohuan"	Recent advances in the application of deep learning methods to forestry	NA	NA	Review	Wood Science and Technology	55	5	1171-1202	10.1007/s00226-021-01309-2	https://link.springer.com/article/10.1007/s00226-021-01309-2	"This paper provides an overview and analysis of the basic theory of deep learning (DL), and specifically, a number of important algorithms were compared and analyzed. The article reviewed and analyzed the main applications of DL methods in forestry including surface quality evaluation of sawn timber, forest resource survey, tree species identification, wood moisture content prediction, the specific application of forestry information text classification, etc. Through comprehensive analysis and review, it was found that: (1) DL method has been widely used in the surface quality evaluation of sawn timber, and the research field mainly uses convolutional neural network (CNN) DL algorithms to carry out research on surface evaluation of sawn timber, and the YOLOv4, YOLOv5m algorithm achieves near real-time target detection and recognition. (2) Establishing a suitable remote sensing image recognition method for forest resources based on DL is a method with great application value in the fields of the future forest resource investigation, statistics of forest vegetation coverage, and monitoring and analysis of plant growth status. (3) The tree species recognition method based on DL effectively avoids the disadvantages of other methods that require image preprocessing for tree images, which leads to cumbersome operation process, low efficiency, and large workload. (4) The DL method provides a quick and efficient prediction method for the prediction of wood moisture content. Moreover, the application of the DL method to the classification of forestry information text provides a new solution to the classification of forestry information text. At the end of the article, a summary of the whole paper is given, and the future development trends of applications of DL to forestry: the field of high-end forestry equipment research, microscopic research in forestry science, and smart forestry are predicted."																				
2021	"Wang, Zhanpeng; Wang, Jiaping; Kourakos, Michael; Hoang, Nhung; Lee, Hyong Hark; Mathieson, Iain; Mathieson, Sara"	Automatic inference of demographic parameters using generative adversarial networks	Molecular	GAN	"Regression, Modeling"	Molecular Ecology Resources	21	8	2689-2705	10.1111/1755-0998.13386	https://onlinelibrary.wiley.com/doi/abs/10.1111/1755-0998.13386	"Population genetics relies heavily on simulated data for validation, inference and intuition. In particular, since the evolutionary ‘ground truth’ for real data is always limited, simulated data are crucial for training supervised machine learning methods. Simulation software can accurately model evolutionary processes but requires many hand-selected input parameters. As a result, simulated data often fail to mirror the properties of real genetic data, which limits the scope of methods that rely on it. Here, we develop a novel approach to estimating parameters in population genetic models that automatically adapts to data from any population. Our method, pg-gan, is based on a generative adversarial network that gradually learns to generate realistic synthetic data. We demonstrate that our method is able to recover input parameters in a simulated isolation-with-migration model. We then apply our method to human data from the 1000 Genomes Project and show that we can accurately recapitulate the features of real data."																				
2021	"Whiteway, Matthew R.; Biderman, Dan; Friedman, Yoni; Dipoppa, Mario; Buchanan, E. Kelly; Wu, Anqi; Zhou, John; Bonacchi, Niccolò; Miska, Nathaniel J.; Noel, Jean-Paul; Rodriguez, Erica; Schartner, Michael; Socha, Karolina; Urai, Anne E.; Salzman, C. Daniel; The International Brain Laboratory; Cunningham, John P.; Paninski, Liam"	Partitioning variability in animal behavioral videos using semi-supervised variational autoencoders	Video	VAE	Classification	PLOS Computational Biology	17	9	e1009439	10.1371/journal.pcbi.1009439	https://dx.plos.org/10.1371/journal.pcbi.1009439	"Recent neuroscience studies demonstrate that a deeper understanding of brain function requires a deeper understanding of behavior. Detailed behavioral measurements are now often collected using video cameras, resulting in an increased need for computer vision algorithms that extract useful information from video data. Here we introduce a new video analysis tool that combines the output of supervised pose estimation algorithms (e.g. DeepLabCut) with unsupervised dimensionality reduction methods to produce interpretable, low-dimensional representations of behavioral videos that extract more information than pose estimates alone. We demonstrate this tool by extracting interpretable behavioral features from videos of three different head-fixed mouse preparations, as well as a freely moving mouse in an open field arena, and show how these interpretable features can facilitate downstream behavioral and neural analyses. We also show how the behavioral features produced by our model improve the precision and interpretation of these downstream analyses compared to using the outputs of either fully supervised or fully unsupervised methods alone."																				
2021	"Wu, Fanyou; Gazo, Rado; Benes, Bedrich; Haviarova, Eva"	Deep BarkID: a portable tree bark identification system by knowledge distillation	Images	CNN	Classification	European Journal of Forest Research	140	6	1391-1399	10.1007/s10342-021-01407-7	https://doi.org/10.1007/s10342-021-01407-7	"Species identification is one of the key steps in the management and conservation planning of many forest ecosystems. We introduce Deep BarkID, a portable tree identification system that detects tree species from bark images. Existing bark identification systems rely heavily on massive computing power access, which may be scarce in many locations. Our approach is deployed as a smartphone application that does not require any connection to a database. Its intended use is in a forest, where internet connection is often unavailable. The tree bark identification is expressed as a bark image classification task, and it is implemented as a convolutional neural network (CNN). This research focuses on developing light-weight CNN models through knowledge distillation. Overall, we achieved 96.12% accuracy for tree species classification tasks for ten common tree species in Indiana, USA. We also captured and prepared thousands of bark images—a dataset that we call Indiana Bark Dataset—and we make it available at https://github.com/wufanyou/DBID."																				
2021	"Wu, Fanyou; Gazo, Rado; Haviarova, Eva; Benes, Bedrich"	Wood identification based on longitudinal section images by using deep learning	Images	CNN	Classification	Wood Science and Technology	55	2	553-563	10.1007/s00226-021-01261-1	https://link.springer.com/article/10.1007/s00226-021-01261-1	"Automatic species identification has the potential to improve the efficacy and automation of wood processing systems significantly. Recent advances in deep learning allowed for the automation of many previously difficult tasks, and in this paper, we investigate the feasibility of using deep convolutional neural networks (CNNs) for hardwood lumber identification. In particular, two highly effective CNNs (ResNet-50 and DenseNet-121) as well as lightweight MobileNet-V2 were tested. Overall, 98.2% accuracy was achieved for 11 common hardwood species classification tasks."																				
2021	"Wührl, Lorenz; Pylatiuk, Christian; Giersch, Matthias; Lapp, Florian; von Rintelen, Thomas; Balke, Michael; Schmidt, Stefan; Cerretti, Pierfilippo; Meier, Rudolf"	DiversityScanner: Robotic handling of small invertebrates with machine learning methods	Images	CNN	Classification	Molecular Ecology Resources	n/a	n/a		10.1111/1755-0998.13567	https://onlinelibrary.wiley.com/doi/abs/10.1111/1755-0998.13567	"Invertebrate biodiversity remains poorly understood although it comprises much of the terrestrial animal biomass, most species and supplies many ecosystem services. The main obstacle is specimen-rich samples obtained with quantitative sampling techniques (e.g., Malaise trapping). Traditional sorting requires manual handling, while molecular techniques based on metabarcoding lose the association between individual specimens and sequences and thus struggle with obtaining precise abundance information. Here we present a sorting robot that prepares specimens from bulk samples for barcoding. It detects, images and measures individual specimens from a sample and then moves them into the wells of a 96-well microplate. We show that the images can be used to train convolutional neural networks (CNNs) that are capable of assigning the specimens to 14 insect taxa (usually families) that are particularly common in Malaise trap samples. The average assignment precision for all taxa is 91.4% (75%–100%). This ability of the robot to identify common taxa then allows for taxon-specific subsampling, because the robot can be instructed to only pick a prespecified number of specimens for abundant taxa. To obtain biomass information, the images are also used to measure specimen length and estimate body volume. We outline how the DiversityScanner can be a key component for tackling and monitoring invertebrate diversity by combining molecular and morphological tools: the images generated by the robot become training images for machine learning once they are labelled with taxonomic information from DNA barcodes. We suggest that a combination of automation, machine learning and DNA barcoding has the potential to tackle invertebrate diversity at an unprecedented scale."																				
2021	"Xie, Juanying; Lu, Yinyuan; Wu, Zhaozhong; Xu, Shengquan; Grant, Phil W."	Investigations of butterfly species identification from images in natural environments	Images	CNN	"Classification, Regression"	International Journal of Machine Learning and Cybernetics	12	8	2431-2442	10.1007/s13042-021-01322-8	https://doi.org/10.1007/s13042-021-01322-8	"It has been a challenging problem to identify species of butterflies, especially from images taken in natural environments. Therefore the First international butterfly species recognition competition was organized at the third Data Mining Competition in China in 2018, so as to find good solutions to this challenging problem. The baseline for the competition was based on the Faster R-CNN for it was the latest deep learning algorithm at that time. Nearly all the competition teams chose the Faster R-CNN, or its variations, to solve the problem. But the identification rates were not good enough, and Faster R-CNN is very time consuming. As a result we have been trying to find the most suitable algorithm to solve the butterfly species identification challenge. This paper will present some investigations we have undertaken in this field over the past two years, and show the results we have obtained. We propose a new partition and augmentation technique for the extremely unbalanced ecological butterfly database. We found that RetinaNet is, so far, the best deep learning algorithm to tackle butterfly species identification based on butterfly images taken in natural environments. The best result we obtained was 79.7% in terms of mAP (mean average precision). This is the best result compared to the state-of-the-art studies in this field on the same database so far."																				
2021	"Xiong, Jianbin; Yu, Dezheng; Liu, Shuangyin; Shu, Lei; Wang, Xiaochan; Liu, Zhaoke"	A Review of Plant Phenotypic Image Recognition Technology Based on Deep Learning	NA	NA	Review	Electronics	10	1	81	10.3390/electronics10010081	https://www.mdpi.com/2079-9292/10/1/81	"Plant phenotypic image recognition (PPIR) is an important branch of smart agriculture. In recent years, deep learning has achieved significant breakthroughs in image recognition. Consequently, PPIR technology that is based on deep learning is becoming increasingly popular. First, this paper introduces the development and application of PPIR technology, followed by its classification and analysis. Second, it presents the theory of four types of deep learning methods and their applications in PPIR. These methods include the convolutional neural network, deep belief network, recurrent neural network, and stacked autoencoder, and they are applied to identify plant species, diagnose plant diseases, etc. Finally, the difficulties and challenges of deep learning in PPIR are discussed."																				
2021	"Xu, Hao; Blonder, Benjamin; Jodra, Miguel; Malhi, Yadvinder; Fricker, Mark"	Automated and accurate segmentation of leaf venation networks via deep learning	Images	"CNN, Other"	Classification	New Phytologist	229	1	631-648	10.1111/nph.16923	https://onlinelibrary.wiley.com/doi/abs/10.1111/nph.16923	"Leaf vein network geometry can predict levels of resource transport, defence and mechanical support that operate at different spatial scales. However, it is challenging to quantify network architecture across scales due to the difficulties both in segmenting networks from images and in extracting multiscale statistics from subsequent network graph representations. Here we developed deep learning algorithms using convolutional neural networks (CNNs) to automatically segment leaf vein networks. Thirty-eight CNNs were trained on subsets of manually defined ground-truth regions from >700 leaves representing 50 southeast Asian plant families. Ensembles of six independently trained CNNs were used to segment networks from larger leaf regions (c. 100 mm2). Segmented networks were analysed using hierarchical loop decomposition to extract a range of statistics describing scale transitions in vein and areole geometry. The CNN approach gave a precision-recall harmonic mean of 94.5% ± 6%, outperforming other current network extraction methods, and accurately described the widths, angles and connectivity of veins. Multiscale statistics then enabled the identification of previously undescribed variation in network architecture across species. We provide a LeafVeinCNN software package to enable multiscale quantification of leaf vein networks, facilitating the comparison across species and the exploration of the functional significance of different leaf vein architectures."																				
2021	"Xu, Xiaoling; Li, Wensheng; Duan, Qingling"	Transfer learning and SE-ResNet152 networks-based for small-scale unbalanced fish species identification	Images	CNN	Classification	Computers and Electronics in Agriculture	180		105878	10.1016/j.compag.2020.105878	https://www.sciencedirect.com/science/article/pii/S0168169920330830	"Scientific studies on species identification in fish have considerable significance in aquatic ecosystems and quality evaluation. The morphological differences between different fish species are obvious. Machine learning methods use artificial prior knowledge to extract fish features, which is time-consuming, laborious, and subjective. Recently, deep learning-based identification of fish species has been widely used. However, fish species identification still faces many challenges due to the small scale of fish samples and the imbalance of the number of categories. For example, the model is prone to being overfitted, and the performance of the classifier is biased to the fish species of most samples. To solve the above problems, this paper proposes a fish species identification approach based on SE-ResNet152 and class-balanced focal loss. First, visualization analysis and image preprocessing of fish datasets are carried out. Second, the SE-ResNet152 model is constructed as a generalized feature extractor and is migrated to the target dataset. Finally, we apply the class-balanced focal loss function to train the SE-ResNet152 model, and realize fish species identification on three fish image views (body, head, and scale). The proposed method was tested on the Fish-Pak public dataset and achieved 98.80%, 96.67%, and 91.25% accuracy on the three fish image views, respectively. To ensure the superior performance of the proposed method, we performed an experimental comparison with other methods involving SENet154, DenseNet121, ResNet18, ResNet152, VGG16, cross-entropy, and focal loss. Comprehensive empirical analyses reveal that the proposed method achieves good performance on the three fish image views and outperforms common methods."																				
2021	"Xu, Zhiheng; Ding, Xiong; Yin, Kun; Li, Ziyue; Smyth, Joan A.; Sims, Maureen B.; McGinnis, Holly A.; Liu, Changchun"	TickPhone App: A Smartphone Application for Rapid Tick Identification Using Deep Learning	Images	CNN	Classification	Applied Sciences	11	16	7355	10.3390/app11167355	https://www.mdpi.com/2076-3417/11/16/7355	"Tick species are considered the second leading vector of human diseases. Different ticks can transmit a variety of pathogens that cause various tick-borne diseases (TBD), such as Lyme disease. Currently, it remains a challenge to diagnose Lyme disease because of its non-specific symptoms. Rapid and accurate identification of tick species plays an important role in predicting potential disease risk for tick-bitten patients, and ensuring timely and effective treatment. Here, we developed, optimized, and tested a smartphone-based deep learning algorithm (termed “TickPhone app”) for tick identification. The deep learning model was trained by more than 2000 tick images and optimized by different parameters, including normal sizes of images, deep learning architectures, image styles, and training–testing dataset distributions. The optimized deep learning model achieved a training accuracy of ~90% and a validation accuracy of ~85%. The TickPhone app was used to identify 31 independent tick species and achieved an accuracy of 95.69%. Such a simple and easy-to-use TickPhone app showed great potential to estimate epidemiology and risk of tick-borne disease, help health care providers better predict potential disease risk for tick-bitten patients, and ultimately enable timely and effective medical treatment for patients."																				
2021	"Xue, Alexander T; Schrider, Daniel R; Kern, Andrew D"	Discovery of Ongoing Selective Sweeps within Anopheles Mosquito Populations Using Deep Learning	Molecular	CNN	Classification	Molecular Biology and Evolution	38	3	1168-1183	10.1093/molbev/msaa259	https://academic.oup.com/mbe/article/38/3/1168/5918472	"Identification of partial sweeps, which include both hard and soft sweeps that have not currently reached fixation, provides crucial information about ongoing evolutionary responses. To this end, we introduce partialS\/HIC, a deep learning method to discover selective sweeps from population genomic data. partialS\/HIC uses a convolutional neural network for image processing, which is trained with a large suite of summary statistics derived from coalescent simulations incorporating population-specific history, to distinguish between completed versus partial sweeps, hard versus soft sweeps, and regions directly affected by selection versus those merely linked to nearby selective sweeps. We perform several simulation experiments under various demographic scenarios to demonstrate partialS\/HIC’s performance, which exhibits excellent resolution for detecting partial sweeps. We also apply our classifier to whole genomes from eight mosquito populations sampled across sub-Saharan Africa by the Anopheles gambiae 1000 Genomes Consortium, elucidating both continent-wide patterns as well as sweeps unique to specific geographic regions. These populations have experienced intense insecticide exposure over the past two decades, and we observe a strong overrepresentation of sweeps at insecticide resistance loci. Our analysis thus provides a list of candidate adaptive loci that may be relevant to mosquito control efforts. More broadly, our supervised machine learning approach introduces a method to distinguish between completed and partial sweeps, as well as between hard and soft sweeps, under a variety of demographic scenarios. As whole-genome data rapidly accumulate for a greater diversity of organisms, partialS\/HIC addresses an increasing demand for useful selection scan tools that can track in-progress evolutionary dynamics."																				
2021	"Yan, Ziyun; Liu, Honggao; Li, Jieqing; Wang, Yuanzhong"	Application of Identification and Evaluation Techniques for Edible Mushrooms: A Review	NA	NA	Review	Critical Reviews in Analytical Chemistry	0	0	21-Jan	10.1080/10408347.2021.1969886	https://www.tandfonline.com/doi/abs/10.1080/10408347.2021.1969886	"Edible mushrooms are healthy food with high nutritional value, which is popular with consumers. With the increase of the problem of mushrooms being confused with the real and pollution in the market, people pay more and more attention to food safety. More than 167 articles of edible mushroom published in the past 20 years were reviewed in this paper. The analysis tools and data analysis methods of identification and quality evaluation of edible mushroom species, origin, mineral elements were reviewed. Five techniques for identification and evaluation of edible mushrooms were introduced and summarized. The macroscopic, microscopic and molecular identification techniques can be used to identify species. Chromatography, spectroscopy technology combined with chemometrics can be used for qualitative and quantitative study of mushroom and evaluation of mushroom quality. In addition, multiple supervised pattern-recognition techniques have good classification ability. Deep learning is more and more widely used in edible mushroom, which shows its advantages in image recognition and prediction. These techniques and analytical methods can provide strong support and guarantee for the identification and evaluation of mushroom, which is of great significance to the development and utilization of edible mushroom."																				
2021	"Yang, Bing; Zhang, Zhenxin; Yang, Cai-Qing; Wang, Ying; Orr, Michael C; Wang, Hongbin; Zhang, Ai-Bing"	Identification of Species by Combining Molecular and Morphological Data Using Convolutional Neural Networks	"Images, Molecular"	CNN	Classification	Systematic Biology			syab076	10.1093/sysbio/syab076	https://academic.oup.com/sysbio/advance-article-abstract/doi/10.1093/sysbio/syab076/6370720	"Integrative taxonomy is central to modern taxonomy and systematic biology, including behavior, niche preference, distribution, morphological analysis, and DNA barcoding. However, decades of use demonstrate that these methods can face challenges when used in isolation, for instance, potential misidentifications due to phenotypic plasticity for morphological methods, and incorrect identifications because of introgression, incomplete lineage sorting, and horizontal gene transfer for DNA barcoding. Although researchers have advocated the use of integrative taxonomy, few detailed algorithms have been proposed. Here, we develop a convolutional neural network method (morphology-molecule network [MMNet]) that integrates morphological and molecular data for species identification. The newly proposed method (MMNet) worked better than four currently available alternative methods when tested with 10 independent data sets representing varying genetic diversity from different taxa. High accuracies were achieved for all groups, including beetles (98.1% of 123 species), butterflies (98.8% of 24 species), fishes (96.3% of 214 species), and moths (96.4% of 150 total species). Further, MMNet demonstrated a high degree of accuracy ($&gt;$98%) in four data sets including closely related species from the same genus. The average accuracy of two modest subgenomic (single nucleotide polymorphism) data sets, comprising eight putative subspecies respectively, is 90%. Additional tests show that the success rate of species identification under this method most strongly depends on the amount of training data, and is robust to sequence length and image size. Analyses on the contribution of different data types (image vs. gene) indicate that both morphological and genetic data are important to the model, and that genetic data contribute slightly more. The approaches developed here serve as a foundation for the future integration of multimodal information for integrative taxonomy, such as image, audio, video, 3D scanning, and biosensor data, to characterize organisms more comprehensively as a basis for improved investigation, monitoring, and conservation of biodiversity. [Convolutional neural network; deep learning; integrative taxonomy; single nucleotide polymorphism; species identification.]"																				
2021	"Yang, Zihan; Sinnott, Richard; Ke, Qiuhong; Bailey, James"	Individual feral cat identification through deep learning	Images	CNN	"Classification, Regression"	"2021 IEEE/ACM 8th International Conference on Big Data Computing, Applications and Technologies (BDCAT '21)"			101–110	10.1145/3492324.3494168	https://doi.org/10.1145/3492324.3494168	"Computer vision opportunities based on deep learning have seen an increasing trend in recent years through the proliferation of convolutional neural networks (CNN) and related deep learning models. However, limited training data often constrains the performance and accuracy of such models - this is a common situation for many detection and classification tasks especially in the ecological field. In this paper, we present a case study of how one such model: You Only Look Once (YOLO) version 5 can be applied to individual feral cat identification using a small unbalanced data set. We describe the procedures for preparing the training and validation data set, training the model using data augmentation and transfer learning techniques, and testing the model on both in-distribution and out-of-distribution samples. We explore the effectiveness of data augmentation methods including basic image manipulations and more advanced augmentation techniques that are now available"																				
2021	"Yelmen, Burak; Decelle, Aurélien; Ongaro, Linda; Marnetto, Davide; Tallec, Corentin; Montinaro, Francesco; Furtlehner, Cyril; Pagani, Luca; Jay, Flora"	Creating artificial human genomes Using generative neural networks	Molecular	CNN	Classification	PLoS Genetics	17	2	e1009303	10.1371/journal.pgen.1009303	https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1009303	"Generative models have shown breakthroughs in a wide spectrum of domains due to recent advancements in machine learning algorithms and increased computational power. Despite these impressive achievements, the ability of generative models to create realistic synthetic data is still under-exploited in genetics and absent from population genetics. Yet a known limitation in the field is the reduced access to many genetic databases due to concerns about violations of individual privacy, although they would provide a rich resource for data mining and integration towards advancing genetic studies. In this study, we demonstrated that deep generative adversarial networks (GANs) and restricted Boltzmann machines (RBMs) can be trained to learn the complex distributions of real genomic datasets and generate novel high-quality artificial genomes (AGs) with none to little privacy loss. We show that our generated AGs replicate characteristics of the source dataset such as allele frequencies, linkage disequilibrium, pairwise haplotype distances and population structure. Moreover, they can also inherit complex features such as signals of selection. To illustrate the promising outcomes of our method, we showed that imputation quality for low frequency alleles can be improved by data augmentation to reference panels with AGs and that the RBM latent space provides a relevant encoding of the data, hence allowing further exploration of the reference dataset and features for solving supervised tasks. Generative models and AGs have the potential to become valuable assets in genetic studies by providing a rich yet compact representation of existing genomes and high-quality, easy-access and anonymous alternatives for private databases."																				
2021	"Yu, Go-Eun; Shin, Younhee; Subramaniyam, Sathiyamoorthy; Kang, Sang-Ho; Lee, Si-Myung; Cho, Chuloh; Lee, Seung-Sik; Kim, Chang-Kug"	"Machine learning, transcriptome, and genotyping chip analyses provide insights into SNP markers identifying flower color in Platycodon grandiflorus"	Molecular	Other	Classification	Scientific Reports	11	1	8019	10.1038/s41598-021-87281-0	https://www.nature.com/articles/s41598-021-87281-0	"Bellflower is an edible ornamental gardening plant in Asia. For predicting the flower color in bellflower plants, a transcriptome-wide approach based on machine learning, transcriptome, and genotyping chip analyses was used to identify SNP markers. Six machine learning methods were deployed to explore the classification potential of the selected SNPs as features in two datasets, namely training (60 RNA-Seq samples) and validation (480 Fluidigm chip samples). SNP selection was performed in sequential order. Firstly, 96 SNPs were selected from the transcriptome-wide SNPs using the principal compound analysis (PCA). Then, 9 among 96 SNPs were later identified using the Random forest based feature selection method from the Fluidigm chip dataset. Among six machines, the random forest (RF) model produced higher classification performance than the other models. The 9 SNP marker candidates selected for classifying the flower color classification were verified using the genomic DNA PCR with Sanger sequencing. Our results suggest that this methodology could be used for future selection of breeding traits even though the plant accessions are highly heterogeneous."																				
2021	"Yu, Hui; Deng, Jian; Nathan, Ran; Kröschel, Max; Pekarsky, Sasha; Li, Guozheng; Klaassen, Marcel"	"An evaluation of machine learning classifiers for next-generation, continuous-ethogram smart trackers"	Other	DNN	Classification	Movement Ecology	9	1	15	10.1186/s40462-021-00245-x	https://doi.org/10.1186/s40462-021-00245-x	"Our understanding of movement patterns and behaviours of wildlife has advanced greatly through the use of improved tracking technologies, including application of accelerometry (ACC) across a wide range of taxa. However, most ACC studies either use intermittent sampling that hinders continuity or continuous data logging relying on tracker retrieval for data downloading which is not applicable for long term study. To allow long-term, fine-scale behavioural research, we evaluated a range of machine learning methods for their suitability for continuous on-board classification of ACC data into behaviour categories prior to data transmission."																				
2021	"Yu, Qiuyan; Ji, Wenjie; Prihodko, Lara; Ross, C. Wade; Anchang, Julius Y.; Hanan, Niall P."	Study becomes insight: Ecological learning from machine learning	NA	NA	Review	Methods in Ecology and Evolution	12	11	2117-2128	10.1111/2041-210X.13686	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13686	"The ecological and environmental science communities have embraced machine learning (ML) for empirical modelling and prediction. However, going beyond prediction to draw insights into underlying functional relationships between response variables and environmental ‘drivers’ is less straightforward. Deriving ecological insights from fitted ML models requires techniques to extract the ‘learning’ hidden in the ML models. We revisit the theoretical background and effectiveness of four approaches for deriving insights from ML: ranking independent variable importance (Gini importance, GI; permutation importance, PI; split importance, SI; and conditional permutation importance, CPI), and two approaches for inference of bivariate functional relationships (partial dependence plots, PDP; and accumulated local effect plots, ALE). We also explore the use of a surrogate model for visualization and interpretation of complex multi-variate relationships between response variables and environmental drivers. We examine the challenges and opportunities for extracting ecological insights with these interpretation approaches. Specifically, we aim to improve interpretation of ML models by investigating how effectiveness relates to (a) interpretation algorithm, (b) sample size and (c) the presence of spurious explanatory variables. We base the analysis on simulations with known underlying functional relationships between response and predictor variables, with added white noise and the presence of correlated but non-influential variables. The results indicate that deriving ecological insight is strongly affected by interpretation algorithm and spurious variables, and moderately impacted by sample size. Removing spurious variables improves interpretation of ML models. Meanwhile, increasing sample size has limited value in the presence of spurious variables, but increasing sample size does improves performance once spurious variables are omitted. Among the four ranking methods, SI is slightly more effective than the other methods in the presence of spurious variables, while GI and SI yield higher accuracy when spurious variables are removed. PDP is more effective in retrieving underlying functional relationships than ALE, but its reliability declines sharply in the presence of spurious variables. Visualization and interpretation of the interactive effects of predictors and the response variable can be enhanced using surrogate models, including three-dimensional visualizations and use of loess planes to represent independent variable effects and interactions. Machine learning analysts should be aware that including correlated independent variables in ML models with no clear causal relationship to response variables can interfere with ecological inference. When ecological inference is important, ML models should be constructed with independent variables that have clear causal effects on response variables. While interpreting ML models for ecological inference remains challenging, we show that careful choice of interpretation methods, exclusion of spurious variables and adequate sample size can provide more and better opportunities to ‘learn from machine learning’."																				
2021	"Yue, JiaQi; Huang, HengYu; Wang, YuanZhong"	A practical method superior to traditional spectral identification: Two-dimensional correlation spectroscopy combined with deep learning to identify Paris species	Other	CNN	Classification	Microchemical Journal	160		105731	10.1016/j.microc.2020.105731	https://www.sciencedirect.com/science/article/pii/S0026265X20332227	"Spectral analysis has the characteristics of fast and nondestructive. In order to conform to the development of the times, a practical method beyond the traditional spectral analysis was established. For the first time, the two-dimensional correlation spectroscopy (2DCOS) images of Fourier-transform mid-infrared spectroscopy combined with the Residual Neural Network (ResNet) was used for the identification and analysis of 12 Paris species, and the second derivative 2DCOS rarely involved in previous researchers was established. Besides, the fusion strategy of 2DCOS images based on feature bands was first proposed for modeling analysis. From the results, (1) 2DCOS combined with ResNet can successfully identify 12 Paris species. (2) 2DCOS is a powerful tool for identification, whether it is used for image visual analysis or modeling analysis. (3) Compared with asynchronous 2DCOS, synchronous 2DCOS is more suitable for the identification and analysis of complex mixed systems such as traditional Chinese medicine. (4) The modeling based on feature bands fusion strategy of 2DCOS has better model performance and is also suitable for the analysis of small samples. To sum up, what we proposed is an innovative and feasible method with wide applicability, which can not only solve the problem of identifying Paris, provide ideas and methods for the selection of spectral types and feature bands, but also provide practical reference for the research in analytical chemistry and other related fields."																				
2021	"Zang, Xiaoqin; Yin, Tianzhixi; Hou, Zhangshuan; Mueller, Robert P.; Deng, Zhiqun Daniel; Jacobson, Paul T."	Deep learning for automated detection and identification of migrating american eel Anguilla rostrata from imaging sonar data	Sound	CNN	Classification	Remote Sensing	13	14	2671	10.3390/rs13142671	https://www.mdpi.com/2072-4292/13/14/2671	"Adult American eels (Anguilla rostrata) are vulnerable to hydropower turbine mortality during outmigration from growth habitat in inland waters to the ocean where they spawn. Imaging sonar is a reliable and proven technology for monitoring of fish passage and migration; however, there is no efficient automated method for eel detection. We designed a deep learning model for automated detection of adult American eels from sonar data. The method employs convolution neural network (CNN) to distinguish between 14 images of eels and non-eel objects. Prior to image classification with CNN, background subtraction and wavelet denoising were applied to enhance sonar images. The CNN model was first trained and tested on data obtained from a laboratory experiment, which yielded overall accuracies of &gt;98% for image-based classification. Then, the model was trained and tested on field data that were obtained near the Iroquois Dam located on the St. Lawrence River; the accuracy achieved was commensurate with that of human experts."																				
2021	"Zhang, Haixi; He, Guiqing; Li, Feng; Xia, Zhaoqiang; Liu, Bin; Peng, Jinye"	Plant taxonomy-guided path-based tree classifier for large-scale plant species identification	Images	CNN	Classification	Journal of Electronic Imaging	30	2	23019	10.1117/1.JEI.30.2.023019	https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-30/issue-2/023019/Plant-taxonomy-guided-path-based-tree-classifier-for-large-scale/10.1117/1.JEI.30.2.023019.full	"A deep learning framework is proposed to recognize large-scale plant species by integrating attention-based deep feature extraction network and plant taxonomy-guided path-based tree classifier. First, a plant taxonomy is constructed for organizing large-scale fine-grained plant species hierarchically in a coarse-to-fine fashion. Second, a deep learning framework is proposed, where attention mechanism is used to remove useless feature components and a plant taxonomy-guided path-based two-layer tree classifier is used to replace the flat softmax classifier in traditional deep convolutional neural network structure. Furthermore, a specific path-based loss function and back-propagation method are proposed to optimize the weight parameters in both deep network and tree classifier. Experimental results on the Orchid2608 plant dataset can also prove that proposed deep attention network with path-based tree classifier can achieve improvements on large-scale plant species identification task."																				
2021	"Zhao, Zhenxi; Liu, Yang; Sun, Xudong; Liu, Jintao; Yang, Xinting; Zhou, Chao"	Composited FishNet: Fish Detection and Species Recognition From Low-Quality Underwater Videos	Images	CNN	"Classification, Regression"	IEEE Transactions on Image Processing	30		4719-4734	10.1109/TIP.2021.3074738	https://ieeexplore.ieee.org/document/9416821	"The automatic detection and identification of fish from underwater videos is of great significance for fishery resource assessment and ecological environment monitoring. However, due to the poor quality of underwater images and unconstrained fish movement, traditional hand-designed feature extraction methods or convolutional neural network (CNN)-based object detection algorithms cannot meet the detection requirements in real underwater scenes. Therefore, to realize fish recognition and localization in a complex underwater environment, this paper proposes a novel composite fish detection framework based on a composite backbone and an enhanced path aggregation network called Composited FishNet. By improving the residual network (ResNet), a new composite backbone network (CBresnet) is designed to learn the scene change information (source domain style), which is caused by the differences in the image brightness, fish orientation, seabed structure, aquatic plant movement, fish species shape and texture differences. Thus, the interference of underwater environmental information on the object characteristics is reduced, and the output of the main network to the object information is strengthened. In addition, to better integrate the high and low feature information output from CBresnet, the enhanced path aggregation network (EPANet) is also designed to solve the insufficient utilization of semantic information caused by linear upsampling. The experimental results show that the average precision (AP)0.5:0.95, AP50 and average recall (AR)max=10 of the proposed Composited FishNet are 75.2%, 92.8% and 81.1%, respectively. The composite backbone network enhances the characteristic information output of the detected object and improves the utilization of characteristic information. This method can be used for fish detection and identification in complex underwater environments such as oceans and aquaculture."																				
2021	"Zhao, Ziyu; Yang, Xiaoxia; Ge, Zhedong; Guo, Hui; Zhou, Yucheng"	Wood microscopic image identification method based on convolution neural network	Images	CNN	Classification	BioResources	16	3	4986-4999	10.15376/biores.16.3.4986-4999	https://bioresources.cnr.ncsu.edu/resources/wood-microscopic-image-identification-method-based-on-convolution-neural-network/	"To prevent the illegal trade of precious wood in circulation, a wood species identification method based on convolutional neural network (CNN), namely PWoodIDNet (Precise Wood Specifications Identification) model, is proposed. In this paper, the PWoodIDNet model for the identification of rare tree species is constructed to reduce network parameters by decomposing convolutional kernel, prevent overfitting, enrich the diversity of features, and improve the performance of the model. The results showed that the PWoodIDNet model can effectively improve the generalization ability, the characterization ability of detail features, and the recognition accuracy, and effectively improve the classification of wood identification. PWoodIDNet was used to analyze the identification accuracy of microscopic images of 16 kinds of wood, and the identification accuracy reached 99%, which was higher than the identification accuracy of several existing classical convolutional neural network models. In addition, the PWoodIDNet model was analyzed to verify the feasibility and effectiveness of the PWoodIDNet model as a wood identification method, which can provide a new direction and technical solution for the field of wood identification."																				
2021	"Zhong, Ming; Taylor, Ruth; Bates, Naomi; Christey, Damian; Basnet, Hari; Flippin, Jennifer; Palkovitz, Shane; Dodhia, Rahul; Lavista Ferres, Juan"	Acoustic detection of regionally rare bird species through deep convolutional neural networks	Sound	CNN	Classification	Ecological Informatics	64		101333	10.1016/j.ecoinf.2021.101333	https://www.sciencedirect.com/science/article/pii/S1574954121001242	"Bioacoustic monitoring with machine learning (ML) models can provide valuable insights for informed decision-making in conservation efforts. In this study, the team built deep convolutional neural networks to analyze field recordings and classify calls of Yellow-vented warbler (Phylloscopus cantator) and Rufous-throated wren-babbler (Spelaeornis caudatus), both of which are regionally rare in Nepal. Data augmentation techniques for calls of the two bird species were utilized to effectively increase the size of the training set and thus boost model performance. Nepali ornithologists were engaged in iterative data labeling from field recordings, leveraging ML technology in conjunction with expert manual labeling and verification. The model output provides insights of species activity and abundance throughout 2018–2019 in multiple ecosystems along an elevational transect in the Barun River Valley, Nepal. The results of this study may help conservationists better understand species distribution, behavior, diversity, and habitat preference. Additionally, the results provide baseline data to quantify future changes due to habitat disruption or climate change. This modeling methodology and its framework can be easily adopted by other acoustic classification problems."																				
2021	"Zhou, Meilun; Elmore, Jared A.; Samiappan, Sathishkumar; Evans, Kristine O.; Pfeiffer, Morgan B.; Blackwell, Bradley F.; Iglay, Raymond B."	Improving Animal Monitoring Using Small Unmanned Aircraft Systems (sUAS) and Deep Learning Networks	Images	CNN	Classification	Sensors	21	17	5697	10.3390/s21175697	https://www.mdpi.com/1424-8220/21/17/5697	"In recent years, small unmanned aircraft systems (sUAS) have been used widely to monitor animals because of their customizability, ease of operating, ability to access difficult to navigate places, and potential to minimize disturbance to animals. Automatic identification and classification of animals through images acquired using a sUAS may solve critical problems such as monitoring large areas with high vehicle traffic for animals to prevent collisions, such as animal-aircraft collisions on airports. In this research we demonstrate automated identification of four animal species using deep learning animal classification models trained on sUAS collected images. We used a sUAS mounted with visible spectrum cameras to capture 1288 images of four different animal species: cattle (Bos taurus), horses (Equus caballus), Canada Geese (Branta canadensis), and white-tailed deer (Odocoileus virginianus). We chose these animals because they were readily accessible and white-tailed deer and Canada Geese are considered aviation hazards, as well as being easily identifiable within aerial imagery. A four-class classification problem involving these species was developed from the acquired data using deep learning neural networks. We studied the performance of two deep neural network models, convolutional neural networks (CNN) and deep residual networks (ResNet). Results indicate that the ResNet model with 18 layers, ResNet 18, may be an effective algorithm at classifying between animals while using a relatively small number of training samples. The best ResNet architecture produced a 99.18% overall accuracy (OA) in animal identification and a Kappa statistic of 0.98. The highest OA and Kappa produced by CNN were 84.55% and 0.79 respectively. These findings suggest that ResNet is effective at distinguishing among the four species tested and shows promise for classifying larger datasets of more diverse animals."																				
2022	"Abade, André; Porto, Lucas Faria; Ferreira, Paulo Afonso; de Barros Vidal, Flávio"	NemaNet: A convolutional neural network model for identification of soybean nematodes	Images	CNN	Classification	Biosystems Engineering	213		39-62	10.1016/j.biosystemseng.2021.11.016	https://www.sciencedirect.com/science/article/pii/S153751102100283X	"Phytoparasitic nematodes (or phytonematodes) are causing severe damage to crops and generating large-scale economic losses worldwide. In soybean crops, annual losses are estimated at 10.6% of the world production. Besides, the identification of these species through microscopic analysis by an expert with taxonomic knowledge is often laborious, time-consuming, and susceptible to failure. From this perspective, robust and automatic approaches are necessary for identifying phytonematodes that are capable of providing correct diagnoses for the classification of species and subsidizing of all control and prevention measures. This work presents a new public data set called NemaDataset containing 3063 microscopic images from five nematode species with the most significant damage relevance for the soybean crop. Additionally, we propose a new Convolutional Neural Network (CNN) model defined as NemaNet and present a comparative assessment with thirteen popular models of CNNs, all of them representing state-of-the art classification and recognition. The general average was calculated for each model, on a from-scratch training; the NemaNet model reached 96.76% accuracy, while the best evaluation fold reached 98.04%. When training with transfer learning was performed, the average accuracy reached 98.82%. The best evaluation fold reached 99.35%, and overall accuracy improvements of over 6.83% and 4.1%, for from-scratch and transfer learning training, respectively, compared to other popular models were achieved."																				
2022	"Akbarian, Sina; Nelder, Mark P.; Russell, Curtis B.; Cawston, Tania; Moreno, Laurent; Patel, Samir N.; Allen, Vanessa G.; Dolatabadi, Elham"	A Computer Vision Approach to Identifying Ticks Related to Lyme Disease	Images	CNN	Classification	IEEE Journal of Translational Engineering in Health and Medicine	10		8-Jan	10.1109/JTEHM.2021.3137956	https://ieeexplore.ieee.org/document/9666042	"Background: Lyme disease (caused by Borrelia burgdorferi) is an infectious disease transmitted to humans by a bite from infected blacklegged ticks (Ixodes scapularis) in eastern North America. Lyme disease can be prevented if antibiotic prophylaxis is given to a patient within 72 hours of a blacklegged tick bite. Therefore, recognizing a blacklegged tick could facilitate the management of Lyme disease. Methods: In this work, we build an automated detection tool that can differentiate blacklegged ticks from other tick species using advanced computer vision approaches in real-time. Specially, we use convolution neural network models, trained end-to-end, to classify tick species. Also, advanced knowledge transfer techniques are adopted to improve the performance of convolution neural network models. Results: Our best convolution neural network model achieves 92% accuracy on unseen tick species. Conclusion: Our proposed vision-based approach simplifies tick identification and contributes to the emerging work on public health surveillance of ticks and tick-borne diseases. In addition, it can be integrated with the geography of exposure and potentially be leveraged to inform the risk of Lyme disease infection. This is the first report of using deep learning technologies to classify ticks, providing the basis for automation of tick surveillance, and advancing tick-borne disease ecology and risk management."																				
2022	"Aono, Alexandre H.; Nagai, James S.; Dickel, Gabriella da S. M.; Marinho, Rafaela C.; Oliveira, Paulo E. A. M. de; Papa, João P.; Faria, Fabio A."	A stomata classification and detection system in microscope images of maize cultivars	Images	CNN	Regression	PLOS ONE	16	10	e0258679	10.1371/journal.pone.0258679	https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0258679	"Plant stomata are essential structures (pores) that control the exchange of gases between plant leaves and the atmosphere, and also they influence plant adaptation to climate through photosynthesis and transpiration stream. Many works in literature aim for a better understanding of these structures and their role in the evolution process and the behavior of plants. Although stomata studies in dicots species have advanced considerably in the past years, even there is not much knowledge about the stomata of cereal grasses. Due to the high morphological variation of stomata traits intra- and inter-species, detecting and classifying stomata automatically becomes challenging. For this reason, in this work, we propose a new system for automatic stomata classification and detection in microscope images for maize cultivars based on transfer learning strategy of different deep convolution neural netwoks (DCNN). Our performed experiments show that our system achieves an approximated accuracy of 97.1% in identifying stomata regions using classifiers based on deep learning features, which figures out as a nearly perfect classification system. As the stomata are responsible for several plant functionalities, this work represents an important advance for maize research, providing an accurate system in replacing the current manual task of categorizing these pores on microscope images. Furthermore, this system can also be a reference for studies using images from different cereal grasses."																				
2022	"Boehnke, Rafa_; Wichorowski, Marcin; Trudnowska, Emilia; Balazy, Kaja; Jakubas, Dariusz; Wold, Anette; Wojczulanis-Jakubas, Katarzyna; Falk-Petersen, Stig; Kidawa, Dorota; Hop, Haakon; B_achowiak-Samo_yk, Katarzyna"	Application of artificial neural network to estimate the quality of little auks' potential foraging grounds on Spitsbergen	Environmental	DNN	Regression	Limnology and Oceanography: Methods	n/a	n/a		10.1002/lom3.10478	https://onlinelibrary.wiley.com/doi/abs/10.1002/lom3.10478	"The availability of food for the zooplanktivorous seabirds, such as an endemic High Arctic alcid, the little auk (Alle alle) is essential for its population status and in consequence for fertilizing nutrient-poor Svalbard tundra. Since the zooplankton composition and concentration vary over time and space on foraging grounds, it is challenging to monitor these changes and it could be facilitated by using original machine-learning methods. We propose to use supervised artificial neural network (ANN) with back-propagation algorithm, in which we rank each zooplankton taxonomical category (ZTC) based on its share in biomass of little auks' diet. The highest rank was assigned to the largest and most frequent prey, for example, fifth copepodid stage (CV) of Calanus glacialis (0.75), amphipod Apherusa glacialis (0.17) and females of Calanus hyperboreus (0.12). In order to qualify the potential foraging grounds for little auks, zooplankton samples were collected at sea, in the vicinity of five West Spitsbergen fjords characterized by different oceanographic conditions. Consequently, the southern and middle fjords of Spitsbergen were described as the best foraging grounds, while the lowest quality was designated to the northernmost locations. ANN was validated with independent long-term monitoring dataset from Hornsund and 78% of stations were classified correctly, which indicates that the presented method is reliable for quick estimation of little auks' foraging grounds qualities. This research proposes a new, automated approach for potential foraging grounds classification and delivers an open-access application that allows following and predicting changes in an emblematic Arctic predator–prey relationship (little auk-zooplankton)."																				
2022	"Chabot, Dominique; Stapleton, Seth; Francis, Charles M."	Using Web images to train a deep neural network to detect sparsely distributed wildlife in large volumes of remotely sensed imagery: A case study of polar bears on sea ice	Images	CNN	Classification	Ecological Informatics	68		101547	10.1016/j.ecoinf.2021.101547	https://linkinghub.elsevier.com/retrieve/pii/S1574954121003381	"Remote sensing can be a valuable alternative or complement to traditional techniques for monitoring wildlife populations, but often entails operational bottlenecks at the image analysis stage. For example, photographic aerial surveys have several advantages over surveys employing airborne observers or other more intrusive monitoring techniques, but produce onerous amounts of imagery for manual analysis when conducted across vast areas, such as the Arctic. Deep learning algorithms, chiefly convolutional neural networks (CNNs), have shown promise for automatically detecting wildlife in large and/or complex image sets. But for sparsely distributed species, such as polar bears (Ursus maritimus), there may not be sufficient known instances of the animals in an image set to train a CNN. We investigated the feasibility of instead providing ‘synthesized’ training data to a CNN to detect polar bears throughout large volumes of aerial imagery from a survey of the Baffin Bay subpopulation. We harvested 534 miscellaneous images of polar bears from the Web that we edited to more closely resemble 21 known images of bears from the aerial survey that were solely used for validation. We combined the Web images of polar bears with 6292 random background images from the aerial survey to train a CNN (ResNet-50), which subsequently correctly classified 20/21 (95%) bear images from the survey and 1172/1179 (99.4%) random background validation images. Given that even a small background misclassification rate could produce multitudinous false positives over many thousands of photos, we describe a potential workflow to efficiently screen out erroneous detections. We also discuss potential avenues to improve CNN accuracy, and the broader applicability of our approach to other image-based wildlife monitoring scenarios. Our results demonstrate the feasibility of using miscellaneously sourced images of animals to train deep neural networks for specific wildlife detection tasks."																				
2022	"Chen, Zhuo; Dou, Ming; Xia, Rui; Li, Guiqiu; Shen, Lisha"	"Spatiotemporal evolution of chlorophyll-a concentration from MODIS data inversion in the middle and lower reaches of the Hanjiang River, China"	Other	DNN	Regression	Environmental Science and Pollution Research				10.1007/s11356-021-18214-7	https://link.springer.com/article/10.1007/s11356-021-18214-7	"Owing to limitations in monitoring technologies, monitoring the algae content index of water has lagged behind the conventional water quality index. As a result, sample monitoring in many rivers has been too sparse, and the monitoring data have been inconsistent; thus the evolution of water eutrophication has not been fully reflected. This study focused on the middle and lower reaches of the Hanjiang River, China, and correlated moderate-resolution imaging spectroradiometer (MODIS) remote sensing data with measured chlorophyll-a concentrations. Algorithm settings for chlorophyll-a inversion in the middle and lower reaches of the Hanjiang River were established via the trial and error method. The algorithm model for the middle and lower reaches of the Hanjiang River chlorophyll-a concentration inversion, and the results of the inversion analysis for the spatiotemporal evolution characteristics were subsequently used to determine the influence of various environmental factors on changes in the chlorophyll-a concentration. The results indicate that (1) the band combinations B7/(B6_+_B5), B7/B5, B4-B2, and B4/(B3_+_B2) are well-correlated with the chlorophyll-a concentration; (2) the back propagation (BP) neural network model inversion achieved a better fit and more accurate inversion results than the band ratio model; (3) temporally, algal outbreaks were mostly concentrated occurring in February and March, with higher chlorophyll-a concentrations in the water column during 2000, 2006, 2007, and 2008; (4) spatially, high chlorophyll-a concentrations were observed in the Zhongxiang, the Shayang, and upper Xiantao sections; and (5) increases in the water temperature and decreases in the water level and flow rate could lead to higher chlorophyll-a concentrations; similarly, nutrient salts were identified to be a major factor contributing to changes in the chlorophyll-a concentrations."																				
2022	"de Silva, Elgiriyage M. K.; Kumarasinghe, Prabhash; Indrajith, Kottahachchi K. D. A. K.; Pushpakumara, Tennekoon V.; Vimukthi, Ranapura D. Y.; de Zoysa, Kasun; Gunawardana, Kasun; de Silva, Shermin"	Feasibility of using convolutional neural networks for individual-identification of wild Asian elephants	Images	CNN	Classification	Mammalian Biology				10.1007/s42991-021-00206-2	https://link.springer.com/article/10.1007/s42991-021-00206-2	"Individual identification is a basic requirement for research in behavior, ecology and conservation. Photographic records are commonly used in situations where individuals are visually distinct. However, keeping track of identities becomes challenging with increasing population sizes and corresponding datasets. There is growing interest in the potential of deep-learning methods for computer vision to assist with automating this task. Here we apply Convolutional Neural Networks, a popular architecture for Artificial Neural Networks used in image classification, to the problem of identifying individual Asian elephants through photographs. We evaluate the performance of five different types of CNN models used in facial recognition (VGG16, ResNet50, InceptionV3, Xception, and Alexnet), on datasets representing three different feature regions (the full body, face, and ears), trained with two techniques (transfer learning vs. training from scratch) for n_=_56 elephants. We tested accuracy in matching the top candidate as well as top five candidates. We found that VGG16 trained with the transfer-learning technique outperformed other models on the body and face datasets with accuracies of 21.34% and 42.35%, respectively, in matching the top candidate. Nevertheless, the best performance was achieved by an Xception model trained from the scratch on the ear dataset, with an accuracy of 89.02% for matching the top candidate and 99.27% for including the correct individual among the top five. However, this impressive level of accuracy was obtained with a dataset of 3816 labeled training images of 56 elephants. There are more than 1000 wild elephants in the population under observation, requiring extensive human effort and skill to initially annotate the images used as training data. Therefore, we consider this approach impractical for monitoring large wild populations. Nevertheless this it could be very useful in record keeping and fraud prevention for large captive elephant populations, as well as monitoring animals that have been rehabilitated and released or moved for management purposes."																				
2022	"Elhamod, Mohannad; Diamond, Kelly M.; Maga, A. Murat; Bakis, Yasin; Bart Jr., Henry L.; Mabee, Paula; Dahdul, Wasila; Leipzig, Jeremy; Greenberg, Jane; Avants, Brian; Karpatne, Anuj"	Hierarchy-guided neural network for species classification	Images	CNN	Classification	Methods in Ecology and Evolution	13	3	642-652	10.1111/2041-210X.13768	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13768	"Species classification is an important task which is the foundation of industrial, commercial, ecological and scientific applications involving the study of species distributions, dynamics and evolution. While conventional approaches for this task use off-the-shelf machine learning (ML) methods such as existing Convolutional Neural Network (ConvNet) architectures, there is an opportunity to inform the ConvNet architecture using our knowledge of biological hierarchies among taxonomic classes. In this work, we propose a new approach for species classification termed hierarchy-guided neural network (HGNN), which infuses hierarchical taxonomic information into the neural network's training to guide the structure and relationships among the extracted features. We perform extensive experiments on an illustrative use-case of classifying fish species to demonstrate that HGNN outperforms conventional ConvNet models in terms of classification accuracy, especially under scarce training data conditions. We also observe that HGNN shows better resilience to adversarial occlusions, when some of the most informative patch regions of the image are intentionally blocked and their effect on classification accuracy is studied."																				
2022	"Erkan, Ugur; Toktas, Abdurrahim; Ustun, Deniz"	Hyperparameter optimization of deep CNN classifier for plant species identification using artificial bee colony algorithm	Images	CNN	Classification	Journal of Ambient Intelligence and Humanized Computing				10.1007/s12652-021-03631-w	https://link.springer.com/article/10.1007/s12652-021-03631-w	"Tailoring a deep convolutional neural network (CNN) for an implementation is a tedious and time-consuming task especially in image identification. In this study, an optimization scheme based on artificial bee colony (ABC) algorithm so-called optimal deep CNN (ODC) classifier for hyperparameter optimization of deep CNN is proposed for plant species identification. It is implemented to a ready-made leaf dataset namely Folio containing #637 images with 32 different plant species. The images are undergone various image preprocessing such as scaling, segmentation and augmentation so as to improve the efficacy of the ODC classifier. Therefore, the dataset is augmented from #637 to #15,288 leaf images whose #12,103 images is allocated for training phase and the remainder for testing the ODC. Moreover, a validation process on 20% of the training dataset is performed along with the training phase in both optimization and classification stages. The accuracy and loss performance of the ODC are examined over the training and validation results. The achieved ODC is verified through the test phase as well as by a comparison with the results in the literature in terms of performance evaluation metrics such as accuracy, sensitivity, specificity and F1-score. In order to further corroborate the proposed scheme, it is even subjected to a benchmark with optimization-based studies such as genetic, particle swarm and firefly algorithms through MNIST digit-image dataset. The ODC identifies the leaf images and digit-images with the best accuracy of 98.99% and 99.21% surpassing the state of the arts. Therefore, the proposed ODC is effective and useful in achieving an optimal CNN thanks to ABC algorithm."																				
2022	"Greeff, Michael; Caspers, Max; Kalkman, Vincent; Willemse, Luc; Sunderland, Barry; Bánki, Olaf; Hogeweg, Laurens"	Sharing taxonomic expertise between natural history collections using image recognition	NA	NA	Review	Research Ideas and Outcomes	8		e79187	10.3897/rio.8.e79187	https://riojournal.com/article/79187/	"Natural history collections play a vital role in biodiversity research and conservation by providing a window to the past. The usefulness of the vast amount of historical data depends on their quality, with correct taxonomic identifications being the most critical. The identification of many of the objects of natural history collections, however, is wanting, doubtful or outdated. Providing correct identifications is difficult given the sheer number of objects and the scarcity of expertise. Here we outline the construction of an ecosystem for the collaborative development and exchange of image recognition algorithms designed to support the identification of objects. Such an ecosystem will facilitate sharing taxonomic expertise among institutions by offering image datasets that are correctly identified by their in-house taxonomic experts. Together with openly accessible machine learning algorithms and easy to use workbenches, this will allow other institutes to train image recognition algorithms and thereby compensate for the lacking expertise."																				
2022	"Hulse, Samuel V.; Renoult, Julien P.; Mendelson, Tamra C."	Using deep neural networks to model similarity between visual patterns: Application to fish sexual signals	Images	CNN	Regression	Ecological Informatics	67		101486	10.1016/j.ecoinf.2021.101486	https://www.sciencedirect.com/science/article/pii/S1574954121002776	"The evolution of visual patterns is a frontier in the theory of sexual selection as we seek to understand the function of complex visual patterning in courtship. Recently, the sensory drive and sensory bias models of sexual selection have been applied to higher-level visual processing. One prediction of this application is that animals' sexual signals will mimic the visual statistics of their habitats. An enduring difficulty of testing predictions of visual pattern evolution is in developing quantitative methods for comparing patterns. Advances in artificial neural networks address this challenge by allowing for the direct comparison of images using both simple and complex features. Here, we use VGG19, an industry_leading image classification network to test predictions of sensory drive, by comparing visual patterns in darter fish (Etheostoma spp.) to images of their habitats. We find that images of female darters are significantly more similar to images of their habitat than are images of males, supporting a role of camouflage in female patterning. We do not find direct evidence for sensory drive shaping the design of male patterns; however, this work demonstrates the utility of network methods for pattern analysis and suggests future directions for visual pattern research."																				
2022	"Kale, Amruta; Nguyen, Tin; Harris, Frederick C., Jr.; Li, Chenhao; Zhang, Jiyin; Ma, Xiaogang"	Provenance documentation to enable explainable and trustworthy AI: A literature review	NA	NA	Review	Data Intelligence			Jan-41	10.1162/dint_a_00119	https://direct.mit.edu/dint/article/doi/10.1162/dint_a_00119/109494/Provenance-documentation-to-enable-explainable-and	"Recently artificial intelligence (AI) and machine learning (ML) models have demonstrated remarkable progress with applications developed in various domains. It is also increasingly discussed that AI and ML models and applications should be transparent, explainable, and trustworthy. Accordingly, the field of Explainable AI (XAI) is expanding rapidly. XAI holds substantial promise for improving trust and transparency in AI-based systems by explaining how complex models such as the deep neural network (DNN) produces their outcomes. Moreover, many researchers and practitioners consider that using provenance to explain these complex models will help improve transparency in AI-based systems. In this paper, we conduct a systematic literature review of provenance, XAI, and trustworthy AI (TAI) to explain the fundamental concepts and illustrate the potential of using provenance as a medium to help accomplish explainability in AI-based systems. Moreover, we also discuss the patterns of recent developments in this area and offer a vision for research in the near future. We hope this literature review will serve as a starting point for scholars and practitioners interested in learning about essential components of provenance, XAI, and TAI."																				
2022	"Kandimalla, Vishnu; Richard, Matt; Smith, Frank; Quirion, Jean; Torgo, Luis; Whidden, Chris"	"Automated Detection, Classification and Counting of Fish in Fish Passages With Deep Learning"	"Images, Sound"	CNN	"Classification, Regression"	Frontiers in Marine Science	8			10.3389/fmars.2021.823173	https://www.frontiersin.org/article/10.3389/fmars.2021.823173	"The Ocean Aware project, led by Innovasea and funded through Canada's Ocean Supercluster, is developing a fish passage observation platform to monitor fish without the use of traditional tags. This will provide an alternative to standard tracking technology, such as acoustic telemetry fish tracking, which are often not appropriate for tracking at-risk fish species protected by legislation. Rather, the observation platform uses a combination of sensors including acoustic devices, visual and active sonar, and optical cameras. This will enable more in-depth scientific research and better support regulatory monitoring of at-risk fish species in fish passages or marine energy sites. Analysis of this data will require a robust and accurate method to automatically detect fish, count fish, and classify them by species in real-time using both sonar and optical cameras. To meet this need, we developed and tested an automated real-time deep learning framework combining state of the art convolutional neural networks and Kalman filters. First, we showed that an adaptation of the widely used YOLO machine learning model can accurately detect and classify eight species of fish from a public high resolution DIDSON imaging sonar dataset captured from the Ocqueoc River in Michigan, USA. Although there has been extensive research in the literature identifying particular fish such as eel vs. non-eel and seal vs. fish, to our knowledge this is the first successful application of deep learning for classifying multiple fish species with high resolution imaging sonar. Second, we integrated the Norfair object tracking framework to track and count fish using a public video dataset captured by optical cameras from the Wells Dam fish ladder on the Columbia River in Washington State, USA. Our results demonstrate that deep learning models can indeed be used to detect, classify species, and track fish using both high resolution imaging sonar and underwater video from a fish ladder. This work is a first step toward developing a fully implemented system which can accurately detect, classify and generate insights about fish in a wide variety of fish passage environments and conditions with data collected from multiple types of sensors."																				
2022	"Kim, Tae Kyung; Hong, Jeonghyun; Ryu, Daun; Kim, Sukyung; Byeon, Si Yeon; Huh, Woojin; Kim, Kunhyo; Baek, Gyu Heon; Kim, Hyun Seok"	Identifying and extracting bark key features of 42 tree species using convolutional neural networks and class activation mapping	Images	CNN	"Classification, Regression"	Scientific Reports	12	1	4772	10.1038/s41598-022-08571-9	https://www.nature.com/articles/s41598-022-08571-9	"The significance of automatic plant identification has already been recognized by academia and industry. There were several attempts to utilize leaves and flowers for identification; however, bark also could be beneficial, especially for trees, due to its consistency throughout the seasons and its easy accessibility, even in high crown conditions. Previous studies regarding bark identification have mostly contributed quantitatively to increasing classification accuracy. However, ever since computer vision algorithms surpassed the identification ability of humans, an open question arises as to how machines successfully interpret and unravel the complicated patterns of barks. Here, we trained two convolutional neural networks (CNNs) with distinct architectures using a large-scale bark image dataset and applied class activation mapping (CAM) aggregation to investigate diagnostic keys for identifying each species. CNNs could identify the barks of 42 species with_>_90% accuracy, and the overall accuracies showed a small difference between the two models. Diagnostic keys matched with salient shapes, which were also easily recognized by human eyes, and were typified as blisters, horizontal and vertical stripes, lenticels of various shapes, and vertical crevices and clefts. The two models exhibited disparate quality in the diagnostic features: the old and less complex model showed more general and well-matching patterns, while the better-performing model with much deeper layers indicated local patterns less relevant to barks. CNNs were also capable of predicting untrained species by 41.98% and 48.67% within the correct genus and family, respectively. Our methodologies and findings are potentially applicable to identify and visualize crucial traits of other plant organs."																				
2022	"Kittlein, Marcelo J.; Mora, Matías S.; Mapelli, Fernando J.; Austrich, Ailín; Gaggiotti, Oscar E."	Deep learning and satellite imagery predict genetic diversity and differentiation	Other	CNN	Regression	Methods in Ecology and Evolution	13	3	711-721	10.1111/2041-210X.13775	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13775	"During the last decade, convolutional neural networks (CNNs) have revolutionised the application of deep learning (DL) methods to classification tasks and object recognition. These procedures can capture key features of image data that are not easily visible to the human eye and use them to classify and predict outcomes with exceptional precision. Here, we show for the first time that CNNs provide highly accurate predictions for small-scale genetic differentiation and diversity in Ctenomys australis, a subterranean rodent from central Argentina. Using microsatellite genotypes and high-resolution satellite imagery, we trained a simple CNN to predict local FST and mean allele richness. To identify landscape features with high impact on predicted values, we applied species distribution models to obtain the distribution of suitable habitat. Subsequent use of a machine learning algorithm (random forest) allowed us to identify the attributes that contribute the most to predictions of population genetic metrics. Predictions obtained from the CNN accounted for more than 98% of the variation observed both in FST and mean allele richness values. Random forest regression on landscape metrics indicated that features involving connectivity and consistent prevalence of suitable habitat promoted genetic diversity and reduced genetic differentiation in C. australis. Validation with synthetic data via simulations of genetic differentiation based on the landscape structure of the study area and of a nearby area showed that DL models are able to capture complex relationships between actual data and synthetic data in the same landscape and between synthetic data generated under different landscapes. Our approach represents an objective and powerful approach to landscape genetics because it can extract information from patterns that are not easily identified by humans. Spatial predictions from the CNN may assist in the identification of areas of interest for biodiversity conservation and management of populations."																				
2022	"Klasen, Morris; Ahrens, Dirk; Eberle, Jonas; Steinhage, Volker"	Image-Based Automated Species Identification: Can Virtual Data Augmentation Overcome Problems of Insufficient Sampling?	Images	"CNN, GAN"	Classification	Systematic Biology	71	2	320-333	10.1093/sysbio/syab048	https://academic.oup.com/sysbio/article-abstract/71/2/320/6304883	"Automated species identification and delimitation is challenging, particularly in rare and thus often scarcely sampled species, which do not allow sufficient discrimination of infraspecific versus interspecific variation. Typical problems arising from either low or exaggerated interspecific morphological differentiation are best met by automated methods of machine learning that learn efficient and effective species identification from training samples. However, limited infraspecific sampling remains a key challenge also in machine learning. In this study, we assessed whether a data augmentation approach may help to overcome the problem of scarce training data in automated visual species identification. The stepwise augmentation of data comprised image rotation as well as visual and virtual augmentation. The visual data augmentation applies classic approaches of data augmentation and generation of artificial images using a generative adversarial networks approach. Descriptive feature vectors are derived from bottleneck features of a VGG-16 convolutional neural network that are then stepwise reduced in dimensionality using Global Average Pooling and principal component analysis to prevent overfitting. Finally, data augmentation employs synthetic additional sampling in feature space by an oversampling algorithm in vector space. Applied on four different image data sets, which include scarab beetle genitalia (Pleophylla, Schizonycha) as well as wing patterns of bees (Osmia) and cattleheart butterflies (Parides), our augmentation approach outperformed a deep learning baseline approach by means of resulting identification accuracy with nonaugmented data as well as a traditional 2D morphometric approach (Procrustes analysis of scarab beetle genitalia). [Deep learning; image-based species identification; generative adversarial networks; limited infraspecific sampling; synthetic oversampling.]"																				
2022	"Lee, Benjamin D.; Gitter, Anthony; Greene, Casey S.; Raschka, Sebastian; Maguire, Finlay; Titus, Alexander J.; Kessler, Michael D.; Lee, Alexandra J.; Chevrette, Marc G.; Stewart, Paul Allen; Britto-Borges, Thiago; Cofer, Evan M.; Yu, Kun-Hsing; Carmona, Juan Jose; Fertig, Elana J.; Kalinin, Alexandr A.; Signal, Brandon; Lengerich, Benjamin J.; Jr, Timothy J. Triche; Boca, Simina M."	Ten quick tips for deep learning in biology	NA	NA	Review	PLOS Computational Biology	3	18		10.1371/journal.pcbi.1009803	https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009803	NA																				
2022	"Lin, Mingli; Liu, Mingming; Lek, Sovan; Dong, Lijun; Zhang, Peijun; Gozlan, Rodolphe E.; Li, Songhai"	Modelling habitat suitability of the Indo-Pacific humpback dolphin using artificial neural network: The influence of shipping	Environmental	DNN	Classification	Ecological Informatics	62		101274	10.1016/j.ecoinf.2021.101274	https://www.sciencedirect.com/science/article/pii/S1574954121000650	"The distribution of cetaceans is generally studied on the basis of their visual locations. However, the absence of observations does not exclude the presence of dolphins and not allow to distinguish habitats favourable to the species but where it would be currently absent due to anthropic disturbances. The modelling of ecological niches represents a powerful alternative choice and intensive computer modelling has been increasingly used to reveal the complexity of the relationships between cetaceans and their habitat. Here, we predicted the presence/absence of the Indo-Pacific humpback dolphin (Sousa chinensis), an endangered species, using the artificial neural network model of back-propagation (BP-ANN) with eight environmental variables. The BP-ANN model had a higher success rate for correct prediction (74%) compared to linear discriminant analysis (67%), especially for the prediction of the presence of S. chinensis (63% to 31%), indicating its potential application in cetacean habitat research. In the model output map, three suitable habitats were predicted without S. chinensis sightings identified. However, only one was confirmed by subsequent field surveys, the other two being located in a strong shipping area. Therefore, we suggest that the traditional assessment of the baseline habitat based on visual sighting may miss the identification of some suitable habitats due to anthropogenic disturbance. We have also highlighted the importance of ecological modelling research for cetacean conservation. In addition, among the eight environmental variables studied, distance from shore, fish abundance and salinity proved to be the most important factors for the distribution of S. chinensis, indicating that coastal construction, sea recovery and overfishing would be key constraints for its conservation."																				
2022	"Mana, Suja Cherukullapurath; Sasipraba, T."	An Intelligent Deep Learning Enabled Marine Fish Species Detection and Classification Model	Images	"DNN, CNN"	"Classification, Regression"	International Journal on Artificial Intelligence Tools	31	1	2250017	10.1142/S0218213022500178	https://www.worldscientific.com/doi/abs/10.1142/S0218213022500178	"In recent times, marine fish species recognition becomes an important research area to protect the ocean environment. It is a tough and time-consuming operation to manually detect marine fish species on the ocean floor. Depending on the situation, extensive sample efforts may be required. These efforts might be harmful to the marine ecosystem. Automated classification methods are capable of properly classifying these fish on a consistent basis. An increasing number of people are becoming interested in utilizing electronic monitoring and reporting with artificial intelligence for the aim of fish identification and enhancing present techniques. It is becoming more usual to use video and pictures of fish (either underwater or on ships) in fishing operations. These techniques are operational, transportable, and non-invasive, and they provide high-quality pictures at a lower cost than traditional approaches. Automated image processing techniques such as Deep Learning (DL) and Machine Learning (ML) are now available, and they may be customized to perform efficient fish species identification and segmentation. In this aspect, this paper presents an Intelligent DL based Marine Fish Species Classification (IDL-MFSC) technique. The proposed IDL-MFSC technique involves three major processes such as pre-processing, fish detection and fish classification. Primarily, Weiner filtering-based noise removal process takes place as a pre-processing step. In addition, Mask R-CNN (Mask Region Based Convolutional Neural Networks) with Residual Network as a backbone network is used for fish detection. Moreover, Optimal Deep Kernel Extreme Learning Machine (ODKELM) based classification method is employed for determining the class labels of the marine fish species in which the parameter tuning of the DKELM model takes place using Water Wave Optimization (WWO) technique. The performance of the proposed method is tested using an openly accessible Fish4Knowledge dataset. The experimental result highlights the supremacy of the IDL-MFSC technique over the recent techniques with respect to various measures."																				
2022	"Minowa, Yasushi; Kubota, Yuhsuke"	Identification of broad-leaf trees using deep learning based on field photographs of multiple leaves	Images	CNN	Classification	Journal of Forest Research	0	0	9-Jan	10.1080/13416979.2021.2021640	https://www.tandfonline.com/doi/abs/10.1080/13416979.2021.2021640	"We used deep learning to identify broad-leaved tree species based on photographs taken outdoors that included multiple leaves. We took 300 photographs of each of 12 broad-leaved tree species, and used these to produce 43,200 256 _ 256 pixels images. We used Caffe as the deep learning framework, and AlexNet and GoogLeNet as the deep learning algorithms. We trained four learning models from a combination of test data ratios, with/without data augmentation, and assessed the classification accuracy based on the ratio of correct classifications to total classifications (“correct ratio”). We divided leaf images into 10 equal sets and conducted 10 iterations without duplication. The results indicated that the highest average correct ratio for the 10 sets was 97.0% in GoogLeNet after 200 epochs. GoogLeNet showed a higher average correct ratio than AlexNet for all of the learning models. A higher proportion of test data resulted in lower average correct ratios without data augmentation. However, the correct ratio tended to improve with data augmentation. Pairs of mutually misclassified species were not necessarily misidentified within categories based on morphological similarity."																				
2022	"Morita, Takashi; Toyoda, Aru; Aisu, Seitaro; Kaneko, Akihisa; Suda-Hashimoto, Naoko; Adachi, Ikuma; Matsuda, Ikki; Koda, Hiroki"	Effects of short-term isolation on social animals' behavior: An experimental case study of Japanese macaque	Other	CNN	Classification	Ecological Informatics	66		101435	10.1016/j.ecoinf.2021.101435	https://www.sciencedirect.com/science/article/pii/S1574954121002260	"One of the goals in animal socioecology is to understand the functions and dynamics of group living. While observations of free-ranging animals are a crucial source of information, an experimental investigation that manipulates the size or composition, or both, of animal groups in captivity can also bring complementary contributions to the research inquiry. When paired with an automatic data collection by biologging technology, experimental studies on captive animals also allow for big data analyses based on recent machine learning techniques. As an initial exploration of this research paradigm, the present study inquired to what extent isolation of captive Japanese macaques (Macaca fuscata) changed their movement patterns. Using three-dimensional location trajectories of the macaques that were systematically collected via Bluetooth Low Energy beacons and a deep neural network, we estimated the identifiability of whether a macaque was behaving in isolation or in group. We found that the neural network identified the isolation vs. in-group conditions with more than 90% accuracy from a five-minute location trajectory, suggesting that the isolation caused notable changes from the canonical group-living behaviors. In addition, the isolation made each individual more identifiable from one another based on their location trajectories."																				
2022	"Ott, Tankred; Lautenschlager, Ulrich"	GinJinn2: Object detection and segmentation for ecology and evolution	Images	CNN	"Classification, Regression"	Methods in Ecology and Evolution	13	3	603-610	10.1111/2041-210X.13787	https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13787	"Collection and preparation of empirical data still represent one of the most important, but also expensive steps in ecological and evolutionary/systematic research. Modern machine learning approaches, however, have the potential to automate a variety of tasks, which until recently could only be performed manually. Unfortunately, the application of such methods by researchers outside the field is hampered by technical difficulties. Here, we present GinJinn2, a user-friendly toolbox for deep learning-based object detection and instance segmentation on image data. Besides providing a convenient command-line interface to existing software libraries, it comprises several additional tools for data handling, pre- and postprocessing, and building advanced analysis pipelines. We demonstrate the application of GinJinn2 for biological purposes using four exemplary analyses, namely the evaluation of seed mixtures, detection of insects on glue traps, segmentation of stomata and extraction of leaf silhouettes from herbarium specimens. GinJinn2, by providing a coding-free environment, will enable users with a primary background in biology to apply deep learning-based methods for object detection and segmentation in order to automate feature extraction from image data."																				
2022	"Parmar, Jitendra; Chouhan, Satyendra Singh; Rathore, Santosh Singh"	"Open-world machine learning: applications, challenges, and opportunities"	NA	NA	Review	arXiv				10.48550/arXiv.2105.13448	http://arxiv.org/abs/2105.13448	"Traditional machine learning mainly supervised learning, follows the assumptions of closed-world learning, i.e., for each testing class, a training class is available. However, such machine learning models fail to identify the classes which were not available during training time. These classes can be referred to as unseen classes. Whereas open-world machine learning (OWML) deals with unseen classes. In this paper, first, we present an overview of OWML with importance to the real-world context. Next, different dimensions of open-world machine learning are explored and discussed. The area of OWML gained the attention of the research community in the last decade only. We have searched through different online digital libraries and scrutinized the work done in the last decade. This paper presents a systematic review of various techniques for OWML. It also presents the research gaps, challenges, and future directions in open-world machine learning. This paper will help researchers understand the comprehensive developments of OWML and the likelihood of extending the research in suitable areas. It will also help to select applicable methodologies and datasets to explore this further"																				
2022	"Picek, Luká_; _ulc, Milan; Matas, Ji_í; Heilmann-Clausen, Jacob; Jeppesen, Thomas S.; Lind, Emil"	Automatic Fungi Recognition: Deep Learning Meets Mycology	"Images, Environmental"	"CNN, Other"	Classification	Sensors	22	2	633	10.3390/s22020633	https://www.mdpi.com/1424-8220/22/2/633	"The article presents an AI-based fungi species recognition system for a citizen-science community. The system’s real-time identification too — FungiVision — with a mobile application front-end, led to increased public interest in fungi, quadrupling the number of citizens collecting data. FungiVision, deployed with a human-in-the-loop, reaches nearly 93% accuracy. Using the collected data, we developed a novel fine-grained classification dataset — Danish Fungi 2020 (DF20) — with several unique characteristics: species-level labels, a small number of errors, and rich observation metadata. The dataset enables the testing of the ability to improve classification using metadata, e.g., time, location, habitat and substrate, facilitates classifier calibration testing and finally allows the study of the impact of the device settings on the classification performance. The continual flow of labelled data supports improvements of the online recognition system. Finally, we present a novel method for the fungi recognition service, based on a Vision Transformer architecture. Trained on DF20 and exploiting available metadata, it achieves a recognition error that is 46.75% lower than the current system. By providing a stream of labeled data in one direction, and an accuracy increase in the other, the collaboration creates a virtuous cycle helping both communities."																				
2022	"Ramazi, Pouria; Kunegel-Lion, Mélodie; Greiner, Russell; Lewis, Mark A."	Predicting insect outbreaks using machine learning: A mountain pine beetle case study	Environmental	DNN	Regression	Ecology and Evolution	11	19	13014-13028	10.1002/ece3.7921	https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.7921	"Planning forest management relies on predicting insect outbreaks such as mountain pine beetle, particularly in the intermediate-term future, e.g., 5-year. Machine-learning algorithms are potential solutions to this challenging problem due to their many successes across a variety of prediction tasks. However, there are many subtle challenges in applying them: identifying the best learning models and the best subset of available covariates (including time lags) and properly evaluating the models to avoid misleading performance-measures. We systematically address these issues in predicting the chance of a mountain pine beetle outbreak in the Cypress Hills area and seek models with the best performance at predicting future 1-, 3-, 5- and 7-year infestations. We train nine machine-learning models, including two generalized boosted regression trees (GBM) that predict future 1- and 3-year infestations with 92% and 88% AUC, and two novel mixed models that predict future 5- and 7-year infestations with 86% and 84% AUC, respectively. We also consider forming the train and test datasets by splitting the original dataset randomly rather than using the appropriate year-based approach and show that this may obtain models that score high on the test dataset but low in practice, resulting in inaccurate performance evaluations. For example, a k-nearest neighbor model with the actual performance of 68% AUC, scores the misleadingly high 78% on a test dataset obtained from a random split, but the more accurate 66% on a year-based split. We then investigate how the prediction accuracy varies with respect to the provided history length of the covariates and find that neural network and naive Bayes, predict more accurately as history-length increases, particularly for future 1- and 3-year predictions, and roughly the same holds with GBM. Our approach is applicable to other invasive species. The resulting predictors can be used in planning forest and pest management and planning sampling locations in field studies."																				
2022	"Raschka, Sebastian; Liu, Yuxi (Hayden); Mirjalili, Vahid"	Machine Learning with PyTorch and Scikit-Learn	NA	NA	Review	Packt (publisher)				10.1016/S0304-3800(98)00149-5	https://www.packtpub.com/product/machine-learning-with-pytorch-and-scikit-learn/9781801819312	This book of the bestselling and widely acclaimed Python Machine Learning series is a comprehensive guide to machine and deep learning using PyTorch's simple to code framework																				
2022	"Reeb, Rachel A.; Aziz, Naeem; Lapp, Samuel M.; Kitzes, Justin; Heberling, J. Mason; Kuebbing, Sara E."	Using convolutional neural networks to efficiently extract immense phenological data from community science images	Images	CNN	Classification	Frontiers in Plant Science	12		787407	10.3389/fpls.2021.787407	https://www.frontiersin.org/articles/10.3389/fpls.2021.787407/full	"Community science image libraries offer a massive, but largely untapped, source of observational data for phenological research. The iNaturalist platform offers a particularly rich archive, containing more than 49 million verifiable, georeferenced, open access images, encompassing seven continents and over 278,000 species. A critical limitation preventing scientists from taking full advantage of this rich data source is labor. Each image must be manually inspected and categorized by phenophase, which is both time-intensive and costly. Consequently, researchers may only be able to use a subset of the total number of images available in the database. While iNaturalist has the potential to yield enough data for high-resolution and spatially extensive studies, it requires more efficient tools for phenological data extraction. A promising solution is automation of the image annotation process using deep learning. Recent innovations in deep learning have made these open-source tools accessible to a general research audience. However, it is unknown whether deep learning tools can accurately and efficiently annotate phenophases in community science images. Here, we train a convolutional neural network (CNN) to annotate images of Alliaria petiolata into distinct phenophases from iNaturalist and compare the performance of the model with non-expert human annotators. We demonstrate that researchers can successfully employ deep learning techniques to extract phenological information from community science images. A CNN classified two-stage phenology (flowering and non-flowering) with 95.9% accuracy and classified four-stage phenology (vegetative, budding, flowering, and fruiting) with 86.4% accuracy. The overall accuracy of the CNN did not differ from humans ( p = 0.383), although performance varied across phenophases. We found that a primary challenge of using deep learning for image annotation was not related to the model itself, but instead in the quality of the community science images. Up to 4% of A. petiolata images in iNaturalist were taken from an improper distance, were physically manipulated, or were digitally altered, which limited both human and machine annotators in accurately classifying phenology. Thus, we provide a list of photography guidelines that could be included in community science platforms to inform community scientists in the best practices for creating images that facilitate phenological analysis."																				
2022	"Rzanny, Michael; Wittich, Hans Christian; Mäder, Patrick; Deggelmann, Alice; Boho, David; Wäldchen, Jana"	Image-Based Automated Recognition of 31 Poaceae Species: The Most Relevant Perspectives	Images	CNN	Classification	Frontiers in Plant Science	12			10.3389/fpls.2021.804140	https://www.frontiersin.org/article/10.3389/fpls.2021.804140	"Poaceae represent one of the largest plant families in the world. Many species are of great economic importance as food and forage plants while others represent important weeds in agriculture. Although a large number of studies currently address the question of how plants can be best recognized on images, there is a lack of studies evaluating specific approaches for uniform species groups considered difficult to identify because they lack obvious visual characteristics. Poaceae represent an example of such a species group, especially when they are non-flowering. Here we present the results from an experiment to automatically identify Poaceae species based on images depicting six well-defined perspectives. One perspective shows the inflorescence while the others show vegetative parts of the plant such as the collar region with the ligule, adaxial and abaxial side of the leaf and culm nodes. For each species we collected 80 observations, each representing a series of six images taken with a smartphone camera. We extract feature representations from the images using five different convolutional neural networks (CNN) trained on objects from different domains and classify them using four state-of-the art classification algorithms. We combine these perspectives via score level fusion. In order to evaluate the potential of identifying non-flowering Poaceae we separately compared perspective combinations either comprising inflorescences or not. We find that for a fusion of all six perspectives, using the best combination of feature extraction CNN and classifier, an accuracy of 96.1% can be achieved. Without the inflorescence, the overall accuracy is still as high as 90.3%. In all but one case the perspective conveying the most information about the species (excluding inflorescence) is the ligule in frontal view. Our results show that even species considered very difficult to identify can achieve high accuracies in automatic identification as long as images depicting suitable perspectives are available. We suggest that our approach could be transferred to other difficult-to-distinguish species groups in order to identify the most relevant perspectives."																				
2022	"Sankara Narayanan, Prabha; Runthala, Ashish"	Accurate computational evolution of proteins and its dependence on deep learning and machine learning strategies	NA	NA	Review	Biocatalysis and Biotransformation	0	0	13-Jan	10.1080/10242422.2022.2030317	https://www.tandfonline.com/doi/abs/10.1080/10242422.2022.2030317	"Enzyme is the major workhorse to carry out the diverse cellular functions. It catalyses the biological reactions with a high specificity, with its topology playing a crucial role. For ecologically safe production of numerous bioproducts including drugs and chemicals, we have been striving to design the industrially useful enzyme molecules with highly improved catalytic capability. As the sequence space is enormous for an enzyme, its quick and effective exploration is quite improbable for the mutagenesis studies whose accuracy is greatly reliant on the prior information of the mutated sites and the extent of rigorous screening of the mutant libraries. Although directed evolution methods significantly aid the construction of a functionally improved molecule, their credibility depends on the successful excavation of the functionally similar sequence space in the available databases, encompassing billions of proteins. As deep learning methods aid us to extensively uncover the underlying network of all the key catalytic positions without any experimental data, their implementation has reliably increased the accuracy of directed evolution. The chapter comprehensively explains data mining and deep learning methods to further showcase their importance in enzyme engineering methods through several examples. The key biological and algorithmic limitations of these deep learning methodologies are lastly highlighted."																				
2022	"Sethi, Sarab S.; Ewers, Robert M.; Jones, Nick S.; Sleutel, Jani; Shabrani, Adi; Zulkifli, Nursyamin; Picinali, Lorenzo"	Soundscapes predict species occurrence in tropical forests	Sound	CNN	Classification	Oikos	2022	3	e08525	10.1111/oik.08525	https://onlinelibrary.wiley.com/doi/abs/10.1111/oik.08525	"Accurate occurrence data is necessary for the conservation of keystone or endangered species, but acquiring it is usually slow, laborious and costly. Automated acoustic monitoring offers a scalable alternative to manual surveys but identifying species vocalisations requires large manually annotated training datasets, and is not always possible (e.g. for lesser studied or silent species). A new approach is needed that rapidly predicts species occurrence using smaller and more coarsely labelled audio datasets. We investigated whether local soundscapes could be used to infer the presence of 32 avifaunal and seven herpetofaunal species in 20 min recordings across a tropical forest degradation gradient in Sabah, Malaysia. Using acoustic features derived from a convolutional neural network (CNN), we characterised species indicative soundscapes by training our models on a temporally coarse labelled point-count dataset. Soundscapes successfully predicted the occurrence of 34 out of the 39 species across the two taxonomic groups, with area under the curve (AUC) metrics from 0.53 up to 0.87. The highest accuracies were achieved for species with strong temporal occurrence patterns. Soundscapes were a better predictor of species occurrence than above-ground carbon density – a metric often used to quantify habitat quality across forest degradation gradients. Our results demonstrate that soundscapes can be used to efficiently predict the occurrence of a wide variety of species and provide a new direction for data driven large-scale assessments of habitat suitability."																				
2022	"Solis-Lemus, Claudia; Yang, Shengwen; Zepeda-Nunez, Leonardo"	Accurate phylogenetic inference with a symmetry-preserving neural network model	Molecular	"DNN, RNN"	Classification	arXiv				10.48550/arXiv.2201.04663	http://arxiv.org/abs/2201.04663	"Scientists world-wide are putting together massive efforts to understand how the biodiversity that we see on Earth evolved from single-cell organisms at the origin of life and this diversification process is represented through the Tree of Life. Low sampling rates and high heterogeneity in the rate of evolution across sites and lineages produce a phenomenon denoted ""long branch attraction"" (LBA) in which long non-sister lineages are estimated to be sisters regardless of their true evolutionary relationship. LBA has been a pervasive problem in phylogenetic inference affecting different types of methodologies from distance-based to likelihood-based. Here, we present a novel neural network model that outperforms standard phylogenetic methods and other neural network implementations under LBA settings. Furthermore, unlike existing neural network models, our model naturally accounts for the tree isomorphisms via permutation invariant functions which ultimately result in lower memory and allows the seamless extension to larger trees"																				
2022	"Suzuki-Ohno, Yukari; Westfechtel, Thomas; Yokoyama, Jun; Ohno, Kazunori; Nakashizuka, Tohru; Kawata, Masakado; Okatani, Takayuki"	Deep learning increases the availability of organism photographs taken by citizens in citizen science programs	Images	CNN	Classification	Scientific Reports	12	1	1210	10.1038/s41598-022-05163-5	https://www.nature.com/articles/s41598-022-05163-5	"Citizen science programs using organism photographs have become popular, but there are two problems related to photographs. One problem is the low quality of photographs. It is laborious to identify species in photographs taken outdoors because they are out of focus, partially invisible, or under different lighting conditions. The other is difficulty for non-experts to identify species. Organisms usually have interspecific similarity and intraspecific variation, which hinder species identification by non-experts. Deep learning solves these problems and increases the availability of organism photographs. We trained a deep convolutional neural network, Xception, to identify bee species using various quality of bee photographs that were taken by citizens. These bees belonged to two honey bee species and 10 bumble bee species with interspecific similarity and intraspecific variation. We investigated the accuracy of species identification by biologists and deep learning. The accuracy of species identification by Xception (83.4%) was much higher than that of biologists (53.7%). When we grouped bee photographs by different colors resulting from intraspecific variation in addition to species, the accuracy of species identification by Xception increased to 84.7%. The collaboration with deep learning and experts will increase the reliability of species identification and their use for scientific researches."																				
2022	"Thompson, Jaime W.; Zero, Victoria H.; Schwacke, Lori H.; Speakman, Todd R.; Quigley, Brian M.; Morey, Jeanine S.; McDonald, Trent L."	finFindR: Automated recognition and identification of marine mammal dorsal fins using residual convolutional neural networks	Images	CNN	"Classification, Regression"	Marine Mammal Science	38	1	139-150	10.1111/mms.12849	https://onlinelibrary.wiley.com/doi/abs/10.1111/mms.12849	"Photographic identification is an essential research and management tool for marine mammal scientists. However, manual identification of individuals is time-consuming. To shorten processing times, we developed finFindR, an open-source application that uses a series of neural networks to autonomously locate dorsal fins in unedited field images, quantify an individual's unique fin characteristics, and match them to an existing photograph catalog. During a blind test comparing manual searching to finFindR for common bottlenose dolphin (Tursiops Tursiops truncatus) photographs, experienced photo-identification technicians achieved similar match rates but examined an order of magnitude fewer photographs using finFindR (an average of 10 required with finFindR versus 124 with manual search). In those tests, the correct identity was ranked in the first position in 88% of cases and was within the top 50 ranked positions in 97% of cases. Our observations suggest that finFindR's matching capabilities are robust to moderate variation in image quality and fin distinctiveness. Importantly, finFindR allows users to build a catalog of known individuals through time and match an unlimited number of individuals instead of being restricted to a predefined set. finFindR's convolutional neural networks could be re-trained to identify members of many marine mammal species without altering finFindR's inherent structure."																				
2022	"Villon, Sébastien; Iovan, Corina; Mangeas, Morgan; Vigliola, Laurent"	Confronting deep-learning and biodiversity challenges for automatic video-monitoring of marine ecosystems	NA	NA	Review	Sensors	22	2	497	10.3390/s22020497	https://www.mdpi.com/1424-8220/22/2/497	"With the availability of low-cost and efficient digital cameras, ecologists can now survey the world’s biodiversity through image sensors, especially in the previously rather inaccessible marine realm. However, the data rapidly accumulates, and ecologists face a data processing bottleneck. While computer vision has long been used as a tool to speed up image processing, it is only since the breakthrough of deep learning (DL) algorithms that the revolution in the automatic assessment of biodiversity by video recording can be considered. However, current applications of DL models to biodiversity monitoring do not consider some universal rules of biodiversity, especially rules on the distribution of species abundance, species rarity and ecosystem openness. Yet, these rules imply three issues for deep learning applications: the imbalance of long-tail datasets biases the training of DL models; scarce data greatly lessens the performances of DL models for classes with few data. Finally, the open-world issue implies that objects that are absent from the training dataset are incorrectly classified in the application dataset. Promising solutions to these issues are discussed, including data augmentation, data generation, cross-entropy modification, few-shot learning and open set recognition. At a time when biodiversity faces the immense challenges of climate change and the Anthropocene defaunation, stronger collaboration between computer scientists and ecologists is urgently needed to unlock the automatic monitoring of biodiversity."																				
2022	"Woolcock, Alexander B.; Cotton, Sam; Cotton, Alison J."	Effectiveness of using drones and convolutional neural networks to monitor aquatic megafauna	Images	CNN	Regression	African Journal of Ecology	n/a	n/a		10.1111/aje.12950	https://onlinelibrary.wiley.com/doi/abs/10.1111/aje.12950	"Aquatic megafauna are difficult to observe and count due to the inaccessibility and issues of detectability. Traditional transect and helicopter counts are useful for obtaining population estimates, but they often have logistical and cost limitations. The recent proliferation of drone technology offers an innovative way of surveying animal populations. However, data collected from drones are hindered by an analysis bottleneck that increases the time needed to process them. Convolutional Neural Networks (CNNs) are an emerging category of deep learning that can automate this data analysis process. Here, we compare traditional methods with drone surveys, by detecting and counting Nile crocodiles (Crocodylus niloticus) and common hippopotami (Hippopotamus amphibious). We evaluate the utility of CNNs for object detection and quantification in complex environments. Drone counts were more accurate than traditional methods; identifying 21% more crocodiles. Where vegetation was open, hippo counts with a drone showed a similar pattern (identifying 43% more). When vegetation was dense the drone produced less-accurate population estimates than traditional methods. CNN accuracy was limited (85%) due to the reduced training dataset available for the CNN. However, with an expanded data set, object detection is likely to be more accurate, making it more applicable for expedited and automated data analysis."																				
2022	"Wu, Entao; Wang, Hongchang; Lu, Huaxiang; Zhu, Wenqi; Jia, Yifei; Wen, Li; Choi, Chi-Yeung; Guo, Huimin; Li, Bin; Sun, Lili; Lei, Guangchun; Lei, Jialin; Jian, Haifang"	Unlocking the potential of deep learning for migratory waterbirds monitoring using surveillance video	Video	Other	Regression	Remote Sensing	14	3	514	10.3390/rs14030514	https://www.mdpi.com/2072-4292/14/3/514	"Estimates of migratory waterbirds population provide the essential scientific basis to guide the conservation of coastal wetlands, which are heavily modified and threatened by economic development. New equipment and technology have been increasingly introduced in protected areas to expand the monitoring efforts, among which video surveillance and other unmanned devices are widely used in coastal wetlands. However, the massive amount of video records brings the dual challenge of storage and analysis. Manual analysis methods are time-consuming and error-prone, representing a significant bottleneck to rapid data processing and dissemination and application of results. Recently, video processing with deep learning has emerged as a solution, but its ability to accurately identify and count waterbirds across habitat types (e.g., mudflat, saltmarsh, and open water) is untested in coastal environments. In this study, we developed a two-step automatic waterbird monitoring framework. The first step involves automatic video segmentation, selection, processing, and mosaicking video footages into panorama images covering the entire monitoring area, which are subjected to the second step of counting and density estimation using a depth density estimation network (DDE). We tested the effectiveness and performance of the framework in Tiaozini, Jiangsu Province, China, which is a restored wetland, providing key high-tide roosting ground for migratory waterbirds in the East Asian–Australasian flyway. The results showed that our approach achieved an accuracy of 85.59%, outperforming many other popular deep learning algorithms. Furthermore, the standard error of our model was very small (se = 0.0004), suggesting the high stability of the method. The framework is computing effective—it takes about one minute to process a theme covering the entire site using a high-performance desktop computer. These results demonstrate that our framework can extract ecologically meaningful data and information from video surveillance footages accurately to assist biodiversity monitoring, fulfilling the gap in the efficient use of existing monitoring equipment deployed in protected areas."																				
2022	"Xi, Tianyu; Wang, Jiangning; Han, Yan; Lin, Congtian; Ji, Liqiang"	Multiple butterfly recognition based on deep residual learning and image analysis	Images	CNN	Classification	Entomological Research	52	1	44-53	10.1111/1748-5967.12564	https://onlinelibrary.wiley.com/doi/abs/10.1111/1748-5967.12564	"Insect recognition is crucial for taxonomy. It helps researchers to process tremendous and various ecology data. Most studies focus on fine-tuning the deep learning network or altering the algorithm to enhance the identification accuracy, and some useful tools have been generated with these methods. This study focuses on the influence of image data on the recognition model. The single data set source of the existing automated identification tools is relatively simple, and the competition-based data set released only focuses on evaluating the model at present. For the first time, this article integrates butterfly image data sets from multiple sources, covered illustrated books, and popular butterfly science websites. The image types include standard specimen images, illustrated book scan images and camera shots. In addition, these images included not only fixed poses, but also various other images of butterflies in natural poses. The size of these images is also various. The testing data set is new data that does not belong to the training set, which also verifies the generalizability of the model, indicating that in practical applications this model can identify new images. This testing method is a breakthrough compared to the previous work. We designed different data sets using the ResNet18 network to train a classifier, which achieves a validation accuracy of 86% in the end of the analysis. By adjusting the data sets, the accuracy changes as well. This study provides a method to recognize hundreds of butterfly species and analyzes the testing progress from the point of view of data. It is the first to combine butterflies from multiple countries in a single data set, with a recognition accuracy that outperforms previous experiments, to the best of our knowledge. We further analyze the testing results of butterfly recognition at the family and genus level. We perform two more experiments to demonstrate the model in the case of similar species or genus."																				
2022	"Xu, Chunpeng; Wang, Bo; Fan, Li; Jarzembowski, Edmund A.; Fang, Yan; Wang, He; Li, Ting; Zhuo, De; Ding, Ming; Engel, Michael S."	Widespread mimicry and camouflage among mid-Cretaceous insects	Images	CNN	Regression	Gondwana Research	101		94-102	10.1016/j.gr.2021.07.025	https://www.sciencedirect.com/science/article/pii/S1342937X21002355	"The avoidance of detection by predators and parasites is critical to survival. Two complex mechanisms for such avoidance are mimicry and camouflage, with fossils providing valuable insight into the evolution of these strategies. Such fossil evidence is, however, rare, and the frequent partial and lopsided occurrence. Here, we report a diverse insect assemblage exhibiting these adaptations from mid-Cretaceous Kachin amber (99 million years ago), including plant mimesis in Tridactylidae (pygmy mole crickets) and debris-carrying camouflage in Gelastocoridae (toad bugs) and Psocodea (bark lice). Critically, Mesozoic plant mimesis in Tridactylidae is supported by our Siamese Network analysis, a Deep Learning model and potentially powerful tool for investigating ancient mimicry. Together with previously known records, our fossils demonstrate that most extant debris-carrying insects (eight groups with direct camouflage) had evolved exogenous camouflage by the mid-Cretaceous. Our results suggest that a complex biological response was already widespread among insects in mid-Cretaceous ecosystems during the rise of angiosperms, probably in response to similar selective pressures as experienced by their extant counterparts."																				
2022	"Zaharias, Paul; Grosshauser, Martin; Warnow, Tandy"	Re-evaluating deep neural networks for phylogeny estimation: the issue of taxon sampling	Molecular	CNN	Classification	Journal of Computational Biology	29	1	74-89	10.1089/cmb.2021.0383	https://www.liebertpub.com/doi/10.1089/cmb.2021.0383	"Deep neural networks (DNNs) have been recently proposed for quartet tree phylogeny estimation. Here, we present a study evaluating recently trained DNNs in comparison to a collection of standard phylogeny estimation methods on a heterogeneous collection of datasets simulated under the same models that were used to train the DNNs, and also under similar conditions but with higher rates of evolution. Our study shows that using DNNs with quartet amalgamation is less accurate than several standard phylogeny estimation methods we explore (e.g., maximum likelihood and maximum parsimony). We further find that simple standard phylogeny estimation methods match or improve on DNNs for quartet accuracy, especially, but not exclusively, when used in a global manner (i.e., the tree on the full dataset is computed and then the induced quartet trees are extracted from the full tree). Thus, our study provides evidence that a major challenge impacting the utility of current DNNs for phylogeny estimation is their restriction to estimating quartet trees that must subsequently be combined into a tree on the full dataset. In contrast, global methods (i.e., those that estimate trees from the full set of sequences) are able to benefit from taxon sampling, and hence have higher accuracy on large datasets"																				
2022	"Zhang, Beini; Zhou, Zhentao; Cao, Wenbin; Qi, Xirui; Xu, Chen; Wen, Weijia"	A new few-shot learning method of bacterial colony counting based on the edge computing device	Images	CNN	"Classification, Regression"	Biology	11	2	156	10.3390/biology11020156	https://www.mdpi.com/2079-7737/11/2/156	"Bacterial colony counting is a time consuming but important task for many fields, such as food quality testing and pathogen detection, which own the high demand for accurate on-site testing. However, bacterial colonies are often overlapped, adherent with each other, and difficult to precisely process by traditional algorithms. The development of deep learning has brought new possibilities for bacterial colony counting, but deep learning networks usually require a large amount of training data and highly configured test equipment. The culture and annotation time of bacteria are costly, and professional deep learning workstations are too expensive and large to meet portable requirements. To solve these problems, we propose a lightweight improved YOLOv3 network based on the few-shot learning strategy, which is able to accomplish high detection accuracy with only five raw images and be deployed on a low-cost edge device. Compared with the traditional methods, our method improved the average accuracy from 64.3% to 97.4% and decreased the False Negative Rate from 32.1% to 1.5%. Our method could greatly improve the detection accuracy, realize the portability for on-site testing, and significantly save the cost of data collection and annotation over 80%, which brings more potential for bacterial colony counting."																				
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																
																																